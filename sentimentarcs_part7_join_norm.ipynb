{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "name": "sentimentarcs_part7_join_norm.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0y_ryJo3kuFU",
        "fLpdPoYZswu7",
        "HFJtnCYhi_N4",
        "0h_KDF-a29ir"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "311.997px",
        "left": "719px",
        "top": "111px",
        "width": "416.267px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jon-chun/sentimentarcs/blob/main/sentimentarcs_part7_join_norm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j637s-I4vbg_"
      },
      "source": [
        "# **SentimentArcs Part 7: Join Norm**\n",
        "\n",
        "Jon Chun\n",
        "15 Sep 2021\n",
        "\n",
        "* https://colab.research.google.com/github/chengjun/mybook/blob/main/11-4-sentiment-classifier.ipynb#scrollTo=c749tKCSZpbw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y_ryJo3kuFU"
      },
      "source": [
        "# **Sandbox Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eezrxk__kxYr"
      },
      "source": [
        "!pip install alpha_vantage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMF4EZ7dktvv"
      },
      "source": [
        "# https://algotrading101.com/learn/python-correlation-guide/\n",
        "\n",
        "import pandas as pd\n",
        "from alpha_vantage.timeseries import TimeSeries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cojcf0jMktrq"
      },
      "source": [
        "#grab tickers from csv file\n",
        "\n",
        "# watchlist_df = pd.read_csv('watchlist.csv', header=None)\n",
        "# watchlist = watchlist_df.iloc[0].tolist()\n",
        "\n",
        "watchlist = ['AAPL', 'MSFT', 'GLD', 'XOM', 'NFLX']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TUnL3MMlmbd"
      },
      "source": [
        "%env ALPHAVANTAGE_API_KEY='8BK5HZ2RTSMFHG9U'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjVSshXLlA6d"
      },
      "source": [
        "#instantiate TimeSeries class from alpha_vantage library\n",
        "app = TimeSeries(output_format='pandas')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKMVHGZzlA27"
      },
      "source": [
        "#itter through watchlist and retrieve daily price data\n",
        "stocks_df = pd.DataFrame()\n",
        "for ticker in watchlist:\n",
        "    alphav_df = app.get_daily_adjusted(ticker)\n",
        "    # print(f'alphav header:\\n    {type(alphav_df)}')\n",
        "    alphav_df = alphav_df[0]\n",
        "    alphav_df.columns = [i.split(' ')[1] for i in alphav_df.columns]\n",
        "\n",
        "    stocks_df[ticker] = alphav_df['adjusted'].pct_change()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KvovZSEmgvQ"
      },
      "source": [
        "stocks_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EZ4CiHnmdN3"
      },
      "source": [
        "stocks_df.iloc[0]['AAPL'] # .isna().all()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKwa79Mem080"
      },
      "source": [
        "stocks_df[stocks_df.isna().any(axis=1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhLfywyEk5UG"
      },
      "source": [
        "stocks_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy6faxT-k5OL"
      },
      "source": [
        "print(stocks_df.AAPL.corr(stocks_df.MSFT))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzR9VKH1nXC2"
      },
      "source": [
        "print(stocks_df.AAPL.corr(stocks_df.NFLX))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9StqzT4nW-s"
      },
      "source": [
        "print(stocks_df.AAPL.corr(stocks_df.NFLX, method='spearman'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-Fzz0UJktmJ"
      },
      "source": [
        "print(stocks_df.AAPL.corr(stocks_df.NFLX, method='kendall'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua4B3QuMnnT7"
      },
      "source": [
        "stocks_df.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHWb8WoGnnPh"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ax = sns.heatmap(stocks_df.corr())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgfJ2PDxoxOZ"
      },
      "source": [
        "ax = sns.heatmap(stocks_df.corr(), cmap='RdYlGn', linewidths=.1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph0O4GA-oxKV"
      },
      "source": [
        "nflx_corr_df = stocks_df.corr().NFLX\n",
        "print(nflx_corr_df.idxmax())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oexAShTGphDM"
      },
      "source": [
        "nflx_corr_df[ nflx_corr_df < 1 ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg61S3_DpVn8"
      },
      "source": [
        "  print(nflx_corr_df[ nflx_corr_df < 1 ].idxmax())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zje2Bix-pVja"
      },
      "source": [
        "print(nflx_corr_df.idxmin())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAyaMDYmoxEv"
      },
      "source": [
        "stocks_df.cov()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPBjy8n_qwlw"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIsyBnBKq2lH"
      },
      "source": [
        "print(stocks_df.AAPL.corr(stocks_df.NFLX, method='spearman'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH0TzXakpxLS"
      },
      "source": [
        "print(np.square(stocks_df.AAPL.corr(stocks_df.NFLX, method='spearman')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMEGqRLapxG4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGMdLc4ipxCr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSQ-I05UnnKz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilw75IeETnUU"
      },
      "source": [
        "# **Install and Load Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8ds1sz9kjep"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGfcL2r2kowI"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import io\n",
        "import glob\n",
        "import pickle\n",
        "\n",
        "import re\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McslKTBZZpbU"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8F9Djjr9NA_"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exL5Iu1E3ayR"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve, plot_precision_recall_curve\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer, HashingVectorizer\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR1wMm3mudlN"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler   # To normalize time series\n",
        "from sklearn.preprocessing import StandardScaler # To Standardize time series: center(sub mean) and rescale within 1 SD (only for well-behaved guassian distributions)\n",
        "from sklearn.preprocessing import RobustScaler   # To Standardize time series: center(sub median) and rescale within 25%-75% (1st-3rd) IQR (better for noisy, outliers distributions)\n",
        "\n",
        "minmax_scaler = MinMaxScaler()\n",
        "mean_std_scaler = StandardScaler()\n",
        "median_iqr_scaler = RobustScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKPSE6ZU1bNp"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "porter=PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLpdPoYZswu7"
      },
      "source": [
        "# **Configure Jupyter**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CkX9gONAsmp"
      },
      "source": [
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK8zKENjsyig"
      },
      "source": [
        "# Configure Jupyter\n",
        "\n",
        "# Enable multiple outputs from one code cell\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "from IPython.display import display\n",
        "from ipywidgets import widgets, interactive\n",
        "\n",
        "# Configure Google Colab\n",
        "\n",
        "# %load_ext google.colab.data_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH1Ad3OxsyqC"
      },
      "source": [
        "# Text wrap\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho0zbRFZTFNe"
      },
      "source": [
        "# Enlarge matplotlib plot size\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (20, 40)\n",
        "\n",
        "# temporarily\n",
        "# from matplotlib.pyplot import figure\n",
        "# figure(figsize=(8, 6), dpi=80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d43OmkheT_Vt"
      },
      "source": [
        "# **Connect to gDrive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G64etjAUOOSm"
      },
      "source": [
        "# Connect to Google gDrive\n",
        "\n",
        "# Flag to indicate first run through code \n",
        "flag_first_run = True\n",
        "\n",
        "from google.colab import drive, files\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfpfvAvRUMpW"
      },
      "source": [
        "%cd ./research/2021/sa_book_code/books_sa/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFJtnCYhi_N4"
      },
      "source": [
        "# **Globals**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knAxs8VYU8u5"
      },
      "source": [
        "# List of Corpora\n",
        "\n",
        "corpora_ls = ['cdickens_achristmascarol',\n",
        "              'cdickens_greatexpectations',\n",
        "              'ddefoe_robinsoncrusoe',\n",
        "              'emforster_howardsend',\n",
        "              'fbaum_thewonderfulwizardofoz',\n",
        "              'fdouglass_narrativelifeofaslave',\n",
        "              'fscottfitzgerald_thegreatgatsby',\n",
        "              'geliot_middlemarch',\n",
        "              'hjames_portraitofalady',\n",
        "              'homer-ewilson_odyssey',\n",
        "              'imcewan_machineslikeme',\n",
        "              'jausten_prideandprejudice', # missing RoBERTaXML8lang\n",
        "              'jconrad_heartofdarkness',\n",
        "              'jjoyce_portraitoftheartist',\n",
        "              'jkrowling_1sorcerersstone',  \n",
        "              'mproust-mtreharne_3guermantesway', # missing all Transformers\n",
        "              'mshelley_frankenstein',\n",
        "              'mtwain_huckleberryfinn',\n",
        "              'staugustine_confessions9end',\n",
        "              'tmorrison_beloved',\n",
        "              'vnabokov_palefire',\n",
        "              'vwoolf_mrsdalloway',\n",
        "              'vwoolf_orlando',\n",
        "              'vwoolf_thewaves',\n",
        "              'vwoolf_tothelighthouse']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G-sL4VjU8nA"
      },
      "source": [
        "# Taxonomy of Models \n",
        "\n",
        "groups_ls = ['models_baseline_ls',\n",
        "                'models_sentimentr_ls',\n",
        "                'models_syuzhetr_ls',\n",
        "                'models_transformer_ls']\n",
        "\n",
        "# Could add suffix '_sst2' if classifiers trained on SST2 (currently requires 30m on Colab Pro/GPU+RAM)\n",
        "models_supervised_ls = ['linreg_imdb50k',\n",
        "                   'svc_imdb50k',\n",
        "                   'logreg_imdb50k',\n",
        "                   'dforest_imdb50k',\n",
        "                   'multinb_imdb50k']\n",
        "\n",
        "models_baseline_ls = ['sentimentr',\n",
        "                      'syuzhet',\n",
        "                      'bing',\n",
        "                      'sentiword',\n",
        "                      'senticnet',\n",
        "                      'nrc',\n",
        "                      'afinn',\n",
        "                      'vader',\n",
        "                      'textblob',\n",
        "                      'flair',\n",
        "                      'pattern',\n",
        "                      'stanza']\n",
        "\n",
        "models_sentimentr_ls = ['jockers_rinker',\n",
        "                        'jockers',\n",
        "                        'huliu',\n",
        "                        'senticnet',\n",
        "                        'sentiword',\n",
        "                        'nrc',\n",
        "                        'lmcd']\n",
        "\n",
        "models_syuzhetr_ls = ['syuzhet',\n",
        "                      'bing',\n",
        "                      'afinn',\n",
        "                      'nrc']\n",
        "\n",
        "models_transformer_ls = ['roberta15lg', \n",
        "                         'nlptown', \n",
        "                         'yelp', \n",
        "                         'hinglish',\n",
        "                         'imdb2way', \n",
        "                         'huggingface', \n",
        "                         't5imdb50k', \n",
        "                         'robertaxml8lang']\n",
        "\n",
        "models_ml_ls = ['multinb',\n",
        "             'logreg',\n",
        "             'logreg_cv',\n",
        "             'rf',\n",
        "             'xgb',\n",
        "             'flaml',\n",
        "             'autogluon']\n",
        "             \n",
        "models_dnn_ls = ['fcn',\n",
        "              'lstm',\n",
        "              'cnn']\n",
        "\n",
        "# Temporarily redefine from English to French Transformer Models\n",
        "# models_transformer_ls = ['flaubert', 'nlptown', 'robertaxml8lang']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8NF_KUmUb-b"
      },
      "source": [
        "corpora_full_dt = {\n",
        "    'cdickens_achristmascarol':'A Christmas Carol by Charles Dickens',\n",
        "    'cdickens_greatexpectations':'Great Expectations by Charles Dickens',\n",
        "    'ddefoe_robinsoncrusoe':'Robinson Crusoe by Daniel Defoe',\n",
        "    'emforster_howardsend':'Howards End by E.M.Forster',\n",
        "    'fbaum_thewonderfulwizardofoz':'The Wonderful Wizard of Oz by Frank Baum',\n",
        "    'fdouglass_narrativelifeofaslave':'Narrative of the Life of Frederick Douglass, An American Slave',\n",
        "    'fscottfitzgerald_thegreatgatsby':'The Great Gatsby by F.Scott Fitzgerald',\n",
        "    'geliot_middlemarch':'Middlemarch by George Eliot',\n",
        "    'hjames_portraitofalady':'Portrait of a Lady by Henry James',\n",
        "    'homer-ewilson_odyssey':'The Odyssey by Homer (trans. Emily Wilson)',\n",
        "    'imcewan_machineslikeme':'Machines Like Me by Ian McEwan',\n",
        "    'jausten_prideandprejudice':'Pride and Prejudice by Jane Austen',\n",
        "    'jconrad_heartofdarkness':'Heart of Darkness by Joseph Conrad',\n",
        "    'jjoyce_portraitoftheartist':'A Portrait of the Artist as a Young Man by James Joyce',\n",
        "    'jkrowling_1sorcerersstone':'Harry Potter and the Sorcerers Stone by J.K.Rowling',\n",
        "    'mproust-mtreharne_3guermantesway':'The Guermantes Way by Marcel Proust',\n",
        "    'mshelley_frankenstein':'Frankenstein by Mary Shelley',\n",
        "    'mtwain_huckleberryfinn':'Huckleberry Finn by Mark Twain',\n",
        "    'staugustine_confessions9end':'Confessions (thru Book 9) by St. Augustine',\n",
        "    'tmorrison_beloved':'Beloved by Toni Morrison',\n",
        "    'vnabokov_palefire':'Palefire by Vladimir Nabokov',\n",
        "    'vwoolf_mrsdalloway':'Mrs. Dalloway by Virginia Woolf',\n",
        "    'vwoolf_orlando':'Orlando by Virginia Woolf',\n",
        "    'vwoolf_thewaves':'The Waves by Virginia Woolf',\n",
        "    'vwoolf_tothelighthouse':'To The Lighthouse by Virginia Woolf'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SSwoDSmjAyd"
      },
      "source": [
        "# Master Dictionary of DataFrames (one per Corpus), each column with raw sentiment polarities from a given model \n",
        "#   declare early to minimize accidental clobbering/deletion\n",
        "\n",
        "corpora_all_dt = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h_KDF-a29ir"
      },
      "source": [
        "# **Custom Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qoLaZ-U2_hz"
      },
      "source": [
        "# https://www.kaggle.com/aditya6040/7-models-on-imdb-dataset-best-score-88-2/notebook\n",
        "\n",
        "def get_metrics(model,x,y):\n",
        "    y_pred = model.predict(x)\n",
        "    acc = accuracy_score(y, y_pred)\n",
        "    f1=f1_score(y, y_pred)\n",
        "    cm=confusion_matrix(y, y_pred)\n",
        "    report=classification_report(y,y_pred)\n",
        "    plt.figure(figsize=(4,4))\n",
        "    sns.heatmap(cm,annot=True,cmap='Blues',xticklabels=[0,1],fmt='d',annot_kws={\"fontsize\":19})\n",
        "    plt.xlabel(\"Predicted\",fontsize=16)\n",
        "    plt.ylabel(\"Actual\",fontsize=16)\n",
        "    plt.show()\n",
        "    print(\"\\nAccuracy: \",round(acc,2))\n",
        "    print(\"\\nF1 Score: \",round(f1,2))\n",
        "#     print(\"\\nConfusion Matrix: \\n\",cm)\n",
        "    print(\"\\nReport:\",report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT3eoNO5To5X"
      },
      "source": [
        "# **Read Every Model Sentiment Data**\n",
        "\n",
        "* https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EidAawQwn861"
      },
      "source": [
        "# Get list of files in data subdir\n",
        "\n",
        "data_dir = './data_corpora_sa'\n",
        "\n",
        "filenames_ls = os.listdir(data_dir)\n",
        "filenames_ls\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrBaJODOFsi2"
      },
      "source": [
        "## **Read Individual Models [corpora_sa_df]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTseQdxTILEE"
      },
      "source": [
        "%%time\n",
        "\n",
        "# NOTE: 1m10s\n",
        "\n",
        "# Read in all models sentiment values in *.csv files located in data_dir\n",
        "#   into Global Dict (corpora_sa_dt) \n",
        "#   with keys=corpora and values=models sentiment values\n",
        "\n",
        "corpora_sa_dt = {}\n",
        "model_group_set = set()\n",
        "\n",
        "def read_csvfiles(folder_path):\n",
        "\n",
        "  for i,afile in enumerate(filenames_ls):\n",
        "    print(f'Reading in afile #{i}: {afile}')\n",
        "    full_path = f'{folder_path}/{afile}'\n",
        "    print(f'  full_path: {full_path}')\n",
        "    model_name = '_'.join(afile.split('_')[1:])\n",
        "    model_name = model_name.split('.')[0]\n",
        "    print(f'  model_name: {model_name}')\n",
        "    corpora_sa_dt[model_name] = pd.read_csv(full_path) # .to_dict()\n",
        "    model_group = model_name.split('_')[0]\n",
        "    print(f'  model_group: {model_group}')\n",
        "    model_group_set.add(model_group)\n",
        "\n",
        "read_csvfiles(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QLHuLhddpI-"
      },
      "source": [
        "# Show model groups based upon datafile prefix (e.g. 'baseline_' or 'dnn_')\n",
        "\n",
        "print(f'model_group_set:\\n  {model_group_set}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOGOpDEzKw5B"
      },
      "source": [
        "# Verify the number and names of Corpora read\n",
        "\n",
        "[i for i in corpora_sa_dt.keys()]\n",
        "\n",
        "print(f'\\n\\n    Read {len(corpora_sa_dt.keys())} Corpora')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUSWMSxRckWP"
      },
      "source": [
        "corpora_sa_dt['ml_vwoolf_thewaves'].columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfNCyat2IK_u"
      },
      "source": [
        "corpora_sa_dt['baseline_cdickens_achristmascarol'].head(1)\n",
        "corpora_sa_dt['baseline_cdickens_achristmascarol'].info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7SJHQ4tFyxb"
      },
      "source": [
        "## **Merge all Models together for each Corpus [corpora_all_df]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbNrTHDrH3KT"
      },
      "source": [
        "# Get common corpus roots \n",
        "\n",
        "corpus_root_set = set()\n",
        "\n",
        "# print(f'\\nStarting with {len(filenames_ls)} total corpus x model combinations\\n')\n",
        "for acorpus_model in filenames_ls:\n",
        "  corpus_model_root = '_'.join(acorpus_model.split('_')[2:])\n",
        "  corpus_model_root = corpus_model_root.split('.')[0]\n",
        "  print(f'corpus_model_root: {corpus_model_root}')\n",
        "  corpus_root_set.add(corpus_model_root)\n",
        "\n",
        "corpus_root_ls = list(corpus_root_set)\n",
        "print(f'\\nThese {len(filenames_ls)} original (corpus)x(model) combination files\\n  were reduced to {len(corpus_root_ls)} unique corpus roots')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C28Kt6rfCs9"
      },
      "source": [
        "corpora_sa_dt.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRLHxCvqe3ry"
      },
      "source": [
        "# Verify sample Model features\n",
        "\n",
        "corpora_sa_dt['ml_fdouglass_narrativelifeofaslave'].info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl0cIoHpgfx0"
      },
      "source": [
        "corpora_all_dt = {}\n",
        "\n",
        "models_dnn_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnskdy8CppY9"
      },
      "source": [
        "# Create corpus_all_df that merges all Models for a given Corpus\n",
        "\n",
        "model_dfs_ls = []\n",
        "\n",
        "for i,acorpus in enumerate(corpus_root_ls):\n",
        "  model_dfs_ls = []\n",
        "\n",
        "  # Get all the 'corpus_model' keys for each 'corpus'\n",
        "  for j, agroup in enumerate(model_group_set):\n",
        "    corpus_model = f'{agroup}_{acorpus}'\n",
        "    print(f'\\n\\n{agroup.upper()} Models #{i*len(model_group_set) + j}: {corpus_model}.csv')\n",
        "    model_cols_ls = corpora_sa_dt[corpus_model].columns\n",
        "    print(f'  Cols: {model_cols_ls}')\n",
        "    corpus_model_path = f'{data_dir}/models_{corpus_model}.csv'\n",
        "    # adf = pd.DataFrame()\n",
        "    adf = pd.read_csv(corpus_model_path, index_col=None)\n",
        "    model_dfs_ls.append(adf)\n",
        "  \n",
        "  # Merge the 3 DataFrames (baseline_, ml_, dnn_)\n",
        "  corpus_all_df = model_dfs_ls[0].merge(model_dfs_ls[1], on='sent_no').merge(model_dfs_ls[2], on='sent_no') # pd.concat(model_dfs_ls, axis=0, ignore_index=True)\n",
        "  corpus_all_df = corpus_all_df.loc[:, ~corpus_all_df.columns.str.contains('Unnamed')]\n",
        "  corpus_all_df = corpus_all_df.loc[:, ~corpus_all_df.columns.str.contains('stdscaler')]\n",
        "  corpus_all_df = corpus_all_df.loc[:, ~corpus_all_df.columns.str.contains('scores')]\n",
        "  corpus_all_df = corpus_all_df.loc[:, ~corpus_all_df.columns.str.contains('_len')]\n",
        "  corpus_all_df = corpus_all_df.loc[:, ~corpus_all_df.columns.str.contains('_x')]\n",
        "  corpus_all_df = corpus_all_df.loc[:, ~corpus_all_df.columns.str.contains('_y')]\n",
        "  print('\\n')\n",
        "  corpora_all_dt[acorpus] = corpus_all_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWJMWIVsqegZ"
      },
      "source": [
        "# Check copora and model counts\n",
        "\n",
        "col_nonmodel_ct = 5 # non model columns (e.g. sent_no, parag_no, sect_no, sent_raw, sent_clean)\n",
        "\n",
        "print('SUMMARY ----------')\n",
        "print(f'{len(corpora_all_dt)} Corpora in dataset')\n",
        "print(f\"{len(corpora_all_dt['hjames_portraitofalady'].columns) - col_nonmodel_ct} Models for each Corpus\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GumwGGXkj3C"
      },
      "source": [
        "corpora_sa_dt['ml_hjames_portraitofalady'].head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIlIrHb3j_aI"
      },
      "source": [
        "corpora_all_dt['hjames_portraitofalady'].head(2)\n",
        "# corpora_all_dt['hjames_portraitofalady'].info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2uLLLyMGMPZ"
      },
      "source": [
        "corpora_all_dt['cdickens_achristmascarol'].info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zJu46WerCrj"
      },
      "source": [
        "corpora_all_dt['tmorrison_beloved']['pattern'].rolling(400, center=True).mean().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS-M-Ovxrb0k"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54-DVAq4rd6f"
      },
      "source": [
        "temp_df = pd.read_csv('./tmorrison_beloved/beloved_pattern.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VTdyJJernNa"
      },
      "source": [
        "temp_df['pattern'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPvDpZPltVdD"
      },
      "source": [
        "# **Standardize and Smooth**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw-8Pr1SEZ1H"
      },
      "source": [
        "## **Option (a): Read in zScore/SMA 10% DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uSPn44UtX6l"
      },
      "source": [
        "# ERROR: must get median_z\n",
        "\n",
        "# Read all models with orignal and zscore values\n",
        "\n",
        "subdir_all = 'data_corpora_all'\n",
        "\n",
        "corpora_all_dt = {}\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "\n",
        "  filepath = f'./{subdir_all}/models_all_{acorpus}.csv'\n",
        "\n",
        "  print(f'Reading {acorpus} from:\\n    {filepath}\\n')\n",
        "\n",
        "  corpora_all_dt[acorpus] = pd.read_csv(filepath, index_col=[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTf-S3I3Ghem"
      },
      "source": [
        "# Verify a Model columns for both regular and z-Score values\n",
        "\n",
        "corpora_all_dt['cdickens_achristmascarol'].columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxNO6r4tZV5S"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (40,20)\n",
        "\n",
        "win10per = int(0.1*corpora_all_dt['cdickens_achristmascarol'].shape[0])\n",
        "               \n",
        "corpora_all_dt['cdickens_achristmascarol']['median_z'].rolling(win10per, center=True, min_periods=1).mean().plot()\n",
        "\n",
        "corpora_all_dt['vwoolf_tothelighthouse']['median_z'].rolling(win10per, center=True, min_periods=1).mean().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA_OJZUvZwkT"
      },
      "source": [
        "## **Execute for both Option (a) and Option (b)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NosICvotX3B"
      },
      "source": [
        "models_ls = corpora_all_dt.keys()\n",
        "print(models_ls)\n",
        "print(f'\\nThere are {len(models_ls)} Corpora')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tRkCLrjtXzd"
      },
      "source": [
        "model_all_cols_ls = corpora_all_dt['cdickens_achristmascarol'].columns\n",
        "print(model_all_cols_ls)\n",
        "\n",
        "print(f'\\nEach Corpus has {len(model_all_cols_ls)} Columns')\n",
        "\n",
        "model_noncols_ls = ['sent_no', 'parag_no', 'sect_no', 'sent_raw', 'sent_clean']\n",
        "print(f'\\n  {len(model_noncols_ls)} Columns are meta-information (not Models)\\n  {model_noncols_ls}')\n",
        "\n",
        "\n",
        "model_cols_ls = list(set(model_all_cols_ls) - set(model_noncols_ls))\n",
        "print(f'\\n  {len(model_cols_ls)} Columns are these Models:\\n  {[i for i in model_cols_ls]}')\n",
        "\n",
        "# Get list of zScore Model Columns in Corpus DataFrame\n",
        "model_z_cols_ls = [i for i in model_cols_ls if i.endswith('_z')]\n",
        "print(f'\\n  {len(model_z_cols_ls)} zScore Columns are these Models:\\n  {[i for i in model_z_cols_ls]}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkGeLuCwEfty"
      },
      "source": [
        "## **Option (b): Generate zScore/SMA 10% DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMUbr-euFOoN"
      },
      "source": [
        "# Specific types for Corpus columns\n",
        "\n",
        "print('Before specifying Corpus column types:')\n",
        "corpora_all_dt['cdickens_achristmascarol'].info()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(f'Processing Corpus: {acorpus}')\n",
        "  for j, amodel in enumerate(model_cols_ls):\n",
        "    corpora_all_dt[acorpus][amodel] = corpora_all_dt[acorpus][amodel].astype('float')\n",
        "  corpora_all_dt[acorpus]['sent_raw'] = corpora_all_dt[acorpus]['sent_raw'].astype('string')\n",
        "  corpora_all_dt[acorpus]['sent_clean'] = corpora_all_dt[acorpus]['sent_clean'].astype('string')\n",
        "\n",
        "\n",
        "print('After specifying Corpus column types:')\n",
        "corpora_all_dt['cdickens_achristmascarol'].info()\n",
        "# corpora_all_dt[acorpus][amodel].astype(np.float64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uigsoBWaKa-q"
      },
      "source": [
        "# Setup\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "stdscaler = StandardScaler()\n",
        "\n",
        "# fit and transform the data\n",
        "# scaled_data = scaler.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKtMMpBINLc6"
      },
      "source": [
        "type(stdscaler.fit_transform(np.asarray(corpora_all_dt['cdickens_achristmascarol']['xgb']).reshape(1,-1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhKDeen6Pb1n"
      },
      "source": [
        "# corpora_all_dt['cdickens_achristmascarol']['xgb_stdscaler'] = stdscaler.fit_transform(np.asarray(corpora_all_dt['cdickens_achristmascarol']['xgb']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuc-HFHPJTnG"
      },
      "source": [
        "# Setup\n",
        "\n",
        "from scipy.stats import zscore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JlbXeI5R0zc"
      },
      "source": [
        "# Test scipy zscore with plot\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (40,20)\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "# stats.zscore(a)\n",
        "temp_np = np.asarray(corpora_all_dt['cdickens_achristmascarol']['vader'])\n",
        "temp_z_np = zscore(temp_np)\n",
        "\n",
        "# temp_std_ser = stdscaler.fit_transform(np.asarray(temp_ser).reshape(1,-1)).ravel()\n",
        "# pd.Series(temp_std_ser)\n",
        "temp_df['test'] = pd.Series(temp_z_np)\n",
        "win10per = int(0.1*temp_df.shape[0])\n",
        "temp_df['test'].rolling(win10per, center=True, min_periods=1).mean().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WikuAp_UV7D0"
      },
      "source": [
        "# Compute z-scores for all Model Time Series and add to corpora_all_dt[acorpus] DataFrame\n",
        "\n",
        "# corpora_allz_dt = {}\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "pattern_z = re.compile(r'_z$')\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(f'Processing Corpus: {acorpus}')\n",
        "  for j, amodel in enumerate(model_cols_ls):\n",
        "    # print(f'Corpus #{i} {acorpus} with Model #{j} {amodel}: has {len(corpora_all_dt[acorpus].columns)} columns but only {len(model_cols_ls)} model columns')\n",
        "\n",
        "    # Skip existing z-Scores\n",
        "    if not pattern_z.search(amodel): \n",
        "      print(f'  processing model: {amodel}')\n",
        "      temp_np = np.asarray(corpora_all_dt[acorpus][amodel])\n",
        "      temp_z_np = zscore(temp_np)\n",
        "\n",
        "      amodel_z = f'{amodel}_z'\n",
        "      corpora_all_dt[acorpus][amodel_z] = pd.Series(temp_z_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7vEHmbtKw7k"
      },
      "source": [
        "# Verify zScores for all Models are computed\n",
        "\n",
        "corpora_all_dt[acorpus].loc[:, corpora_all_dt[acorpus].columns.str.contains('_z')].columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYde92c4Wgi9"
      },
      "source": [
        "# Compute the median_z for all individual zScore Models in each Corpus\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(f'Processing Corpus: {acorpus}')\n",
        "\n",
        "  if 'median_z' in corpora_all_dt[acorpus].columns:\n",
        "    print(f'  Skip, median_z already exists')\n",
        "  else:\n",
        "    print(f'  Added median_z')\n",
        "    corpora_all_dt[acorpus]['median_z'] = corpora_all_dt[acorpus].loc[:, corpora_all_dt[acorpus].columns.str.contains('_z')].median(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cgC2LXzL-9e"
      },
      "source": [
        "corpora_all_dt['cdickens_achristmascarol']['median_z']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4kPKtgsLzci"
      },
      "source": [
        "# Test median calculation with plot\n",
        "\n",
        "win10per = int(0.1*temp_df.shape[0])\n",
        "corpora_all_dt['cdickens_achristmascarol']['median_z'].plot()\n",
        "win10per = int(0.1*corpora_all_dt['cdickens_achristmascarol'].shape[0]) \n",
        "corpora_all_dt['cdickens_achristmascarol']['median_z'].rolling(win10per, center=True, min_periods=1).mean().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkFdxJ4EKge3"
      },
      "source": [
        "# Test scipy zscore with plot\n",
        "\"\"\"\n",
        "plt.rcParams[\"figure.figsize\"] = (40,20)\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "# stats.zscore(a)\n",
        "temp_np = np.asarray(corpora_all_dt['cdickens_achristmascarol']['median_z'])\n",
        "temp_z_np = zscore(temp_np)\n",
        "\n",
        "# temp_std_ser = stdscaler.fit_transform(np.asarray(temp_ser).reshape(1,-1)).ravel()\n",
        "# pd.Series(temp_std_ser)\n",
        "temp_df['test'] = pd.Series(temp_z_np)\n",
        "win10per = int(0.1*temp_df.shape[0])\n",
        "temp_df['test'].rolling(win10per, center=True).mean().plot()\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07bZS85silLE"
      },
      "source": [
        "corpora_all_dt['cdickens_achristmascarol'].head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGy49ijicsLY"
      },
      "source": [
        "corpora_all_dt['vwoolf_tothelighthouse'].head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rk3OZXJUYHD"
      },
      "source": [
        "## **Plot zScore/SMA 10%**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0_BhjBeZ6MD"
      },
      "source": [
        "corpora_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAkyN2_naCJV"
      },
      "source": [
        "model_cols_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ysIcCxRaFhn"
      },
      "source": [
        "%whos list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ostEXF5gPJP_"
      },
      "source": [
        "# Plot zScore + SMA 10% for all Models in each Corpus (including bold median_z)\n",
        "\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (40,20)\n",
        "\n",
        "save_plot = False\n",
        "\n",
        "subdir_name = 'data_corpora_plots'\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls[:2]): # [:2]):\n",
        "  print(f'Processing Corpus: {acorpus}...')\n",
        "  win10per = int(0.1*corpora_all_dt[acorpus]['median_z'].shape[0])\n",
        "\n",
        "  for j, amodel_z in enumerate(model_z_cols_ls): # model_cols_ls):\n",
        "\n",
        "    print(f'Corpus #{i} {acorpus} with Model #{j} {amodel_z}: has {len(corpora_all_dt[acorpus].columns)} columns but only {len(model_cols_ls)} model columns')\n",
        "\n",
        "    # amodel_z = f'{amodel}_z'\n",
        "    corpora_all_dt[acorpus][amodel_z].rolling(win10per, center=True, min_periods=1).mean().plot(label=f'z-Score {amodel_z}', alpha=0.3) # , style=['r*-'], linewidth=2.0)\n",
        "\n",
        "  corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True, min_periods=1).mean().plot(label='z-Score Median', style=['r'], linewidth=5.0)\n",
        "\n",
        "  plt.title(f'{corpora_full_dt[acorpus]}\\n zScore and SMA 10%')    \n",
        "  plt.legend(loc='best')\n",
        "  # corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True, min_periods=1).mean().plot(label='z-Score Median', style=['r'], linewidth=3.0)\n",
        "\n",
        "  if save_plot:\n",
        "    filename_plt = f'./{subdir_name}/plt_sma10_{amodel_z}.png'\n",
        "    plt.savefig(filename_plt)\n",
        "\n",
        "  plt.show();\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TIrSDJDWNyH"
      },
      "source": [
        "## **SKIP to [Save zScore] below**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYubpcv6FmlX"
      },
      "source": [
        "# Create list of all <model>_z DataFrames\n",
        "\n",
        "pattern_z = re.compile(r'_z$')\n",
        "pattern_zz = re.compile(r'_z_z$')\n",
        "models_z_dt = {}\n",
        "models_z_ls = []\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls): # [:2]):\n",
        "  print(f'Processing Corpus: {acorpus}')\n",
        "\n",
        "  acorpus_model_ls = corpora_allz_dt[acorpus].columns\n",
        "  for j, amodel in enumerate(acorpus_model_ls):\n",
        "\n",
        "    # win10per = int(0.10*corpora_all_dt[acorpus].shape[0])\n",
        "\n",
        "    if pattern_z.search(amodel) and not pattern_zz.search(amodel):\n",
        "      models_z_ls.append(amodel)\n",
        "\n",
        "  models_z_dt[acorpus] = copy.deepcopy(models_z_ls) # .copy(deep=True)\n",
        "  models_z_ls = []\n",
        "\n",
        "  print(f'models_z_dt[acorpus]: {models_z_dt[acorpus]}\\n\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OpyH9A5Ifv0"
      },
      "source": [
        "models_z_dt['cdickens_achristmascarol']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XJmibPasHYo_"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (40,20)\n",
        "\n",
        "subdir_name = 'data_corpora_plots'\n",
        "pattern_z = re.compile(r'_z$')\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls): # [:2]):\n",
        "  print(acorpus)\n",
        "\n",
        "  models_z_ls = models_z_dt[acorpus]\n",
        "  win10per = int(0.1*corpora_allz_dt[acorpus]['median_z'].shape[0])\n",
        "\n",
        "  corpora_allz_dt[acorpus][models_z_ls].rolling(win10per, center=True).mean().plot(label=amodel_z, alpha=0.3)\n",
        "\n",
        "  # if i == (len(corpora_ls)):\n",
        "  #   corpora_all_dt[amodel]['median_z'].rolling(win10per, center=True).mean().plot(alpha=0.6, color='black', width=2)\n",
        "  #   plt.title(f'{acorpus} Simple Moving Average')\n",
        "  #  plt.legend(loc='best')\n",
        "  \n",
        "  # atitle = f'{acorpus}\\n z-Score SMA 10%'\n",
        "  # ax.title(atitle)\n",
        "  plt.title(f'{acorpus}\\n z-Score SMA 10%')    \n",
        "  plt.legend(loc='best')\n",
        "  \n",
        "  # corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True).mean().plot(label='z-Score Median', style=['r*-'], linewidth=2.0)\n",
        "\n",
        "  filename_plt = f'./{subdir_name}/plt_zsma10_{amodel}.png'\n",
        "  plt.savefig(filename_plt)\n",
        "\n",
        "  fig.show()\n",
        "  # plt.show();  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAW9c88odV9K"
      },
      "source": [
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (40,20)\n",
        "\n",
        "subdir_name = 'data_corpora_plots'\n",
        "pattern_z = re.compile(r'_z$')\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls): # [:2]):\n",
        "  print(acorpus)\n",
        "  # fig,ax = plt.subplots()\n",
        "\n",
        "  for j, amodel in enumerate(model_cols_ls):\n",
        "\n",
        "    # win10per = int(0.1*corpora_all_dt[acorpus]['median_z'].shape[0])\n",
        "\n",
        "    # if j == 0:\n",
        "    #   corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True).mean().plot(label='z-Score Median', style=['r*-'], linewidth=2.0)\n",
        "\n",
        "    # print(f'Corpus #{i} {acorpus} with Model #{j} {amodel}: has {len(corpora_all_dt[acorpus].columns)} columns but only {len(model_cols_ls)} model columns')\n",
        "    win10per = int(0.10*corpora_all_dt[acorpus].shape[0])\n",
        "\n",
        "    # Skip existing z-Scores\n",
        "    if pattern_z.search(amodel):    \n",
        "\n",
        "      # amodel_z = f'{amodel}_z'\n",
        "\n",
        "      # corpora_all_dt[acorpus][amodel_z].rolling(win10per, center=True).mean().plot(label=amodel_z, alpha=0.3)\n",
        "\n",
        "      # corpora_all_dt[acorpus][amodel].astype(np.float64)\n",
        "      # temp_df[amodel] = corpora_all_dt[acorpus][amodel].value.rolling(win10per, min_periods=1,center=True).apply(zscore)\n",
        "      \n",
        "      # temp_df[amodel] = pd.Series(type(stdscaler.fit_transform(np.asarray(corpora_all_dt[acorpus][amodel]).reshape(-1,1)))) # .reshape(-1,1))\n",
        "      # print(f'temp_df[amodel]: {temp_df[amodel]}')\n",
        "      # print(f'len(temp_df[amodel]: {len(temp_df[amodel])}')\n",
        "\n",
        "      # corpora_all_dt[acorpus][amodel_z].rolling(win10per, min_periods=1,center=True).mean().plot() # .mean().plot(label=amodel)\n",
        "\n",
        "      # ax.plot(corpora_all_dt[acorpus][amodel_z].index, corpora_all_dt[acorpus][amodel_z].rolling(win10per, min_periods=1,center=True).mean(), label=amodel_z)\n",
        "      # ax.set_xlabel('Sentence No.')\n",
        "      # ax.set_ylabel('Sentiment (z-Score')\n",
        "      # ax.legend(loc='best')\n",
        "\n",
        "      # plt.title(f'{acorpus}\\n z-Score SMA 10%')\n",
        "      # plt.legend(loc='best') \n",
        "      pass\n",
        "\n",
        "    corpora_all_dt[acorpus][amodel_z].rolling(win10per, center=True).mean().plot(label=amodel_z, alpha=0.3)\n",
        "\n",
        "  # if i == (len(corpora_ls)):\n",
        "  #   corpora_all_dt[amodel]['median_z'].rolling(win10per, center=True).mean().plot(alpha=0.6, color='black', width=2)\n",
        "  #   plt.title(f'{acorpus} Simple Moving Average')\n",
        "  #  plt.legend(loc='best')\n",
        "  \n",
        "  atitle = f'{acorpus}\\n z-Score SMA 10%'\n",
        "  ax.title(atitle)\n",
        "  # plt.title(f'{acorpus}\\n z-Score SMA 10%')    \n",
        "  # plt.legend(loc='best')\n",
        "  \n",
        "  # corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True).mean().plot(label='z-Score Median', style=['r*-'], linewidth=2.0)\n",
        "\n",
        "  filename_plt = f'./{subdir_name}/plt_sma10_{amodel}.png'\n",
        "  plt.savefig(filename_plt)\n",
        "\n",
        "  fig.show()\n",
        "  # plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ8M0zj6FCRC"
      },
      "source": [
        "## **Temp Patch Dataset Errors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I11EaPcYtFuK"
      },
      "source": [
        "corpora_all_dt['tmorrison_beloved'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZd9y_bnvBxR"
      },
      "source": [
        "%whos dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI7O_mOcvIjD"
      },
      "source": [
        "corpora_sa_dt.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RDoSHcCu76i"
      },
      "source": [
        "# TODO: Fix error (all 0) for tmorrison_beloved/pattern model (leads to NaN in zScore/SMA/LTTB)\n",
        "\n",
        "corpora_sa_dt['baseline_tmorrison_beloved']['pattern'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGxJfDo4tJds"
      },
      "source": [
        "corpora_all_dt['tmorrison_beloved']['pattern'].value_counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itjLd_i5uCXe"
      },
      "source": [
        "corpora_all_dt['tmorrison_beloved']['pattern'].rolling(400, center=True, min_periods=1).mean().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yw7hbYCtPkd"
      },
      "source": [
        "corpora_all_dt['tmorrison_beloved']['pattern_z'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecpWwI8fuKQz"
      },
      "source": [
        "corpora_all_dt['tmorrison_beloved']['pattern_z'].rolling(400, center=True, min_periods=1).mean().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph5YmLX6zUw2"
      },
      "source": [
        "## **Save zScore/SMA 10% DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY9g47jj7i8O"
      },
      "source": [
        "# Save all models with orignal and zscore values\n",
        "\n",
        "subdir_out = 'data_corpora_all'\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(acorpus)\n",
        "  # acorpus_sent_len = corpora_all_dt[acorpus]['xgb'].shape[0]\n",
        "\n",
        "  filename_out = f'models_all_{acorpus}.csv'\n",
        "  fullpath_out = f'./{subdir_out}/{filename_out}'\n",
        "\n",
        "  print(f'\\nSaving Corpus: {acorpus}...')\n",
        "  corpora_all_dt[acorpus].to_csv(fullpath_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF8PT9ILFkyo"
      },
      "source": [
        "# **Total Model Coherence per Corpus**\n",
        "\n",
        "For each Corpus, compute a Coherence Metric for all Models by:\n",
        "* Computing the Euclidian Distance of each zScore/SMA Model from the zScore/SMA Median\n",
        "* Sum all Euclidian Distances \n",
        "* Identify and record furtherest outliers per Corpus/Model\n",
        "* Sum all Euclidian Distances after removing 2-3 of ~35 outliers (5-10% discard)\n",
        "* Normalize 2 Sums of Euclidian Distances over the entire set of Corpora\n",
        "* Rank order the Corpora in terms of Coherence\n",
        "* Rank Order Models in terms of Outlier frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86gBdkVDKZhw"
      },
      "source": [
        "%whos list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLqUMQ_CKTXE"
      },
      "source": [
        "corpora_all_dt['cdickens_achristmascarol'].info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMSuxca_zyju"
      },
      "source": [
        "model_z_cols_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZlfwGiv7T59"
      },
      "source": [
        "np.sum(np.abs(corpora_all_dt['cdickens_achristmascarol']['vader_z'] - corpora_all_dt['cdickens_achristmascarol']['median_z']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXRJgCtWArla"
      },
      "source": [
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5e9iUQkFkk_"
      },
      "source": [
        "# Save all models with orignal and zscore values\n",
        "\n",
        "subdir_out = 'data_corpora_all'\n",
        "\n",
        "median_model_area_ls = []\n",
        "corpora_median_area_dt = {}\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(f'Processing Corpus #{i}: {acorpus}')\n",
        "\n",
        "  median_model_area_ls = []\n",
        "\n",
        "  for j, amodel_z in enumerate(model_z_cols_ls):\n",
        "    print(f'  with Model #{j}: {amodel_z}')\n",
        "\n",
        "    median_model_area = np.sum(np.abs(corpora_all_dt[acorpus][amodel_z] - corpora_all_dt[acorpus]['median_z']))\n",
        "    print(f'    Area between Median: {median_model_area}')\n",
        "\n",
        "    median_model_area_ls.append((amodel_z, median_model_area))\n",
        "    print(f'      Growing list: {median_model_area_ls}')\n",
        "\n",
        "  median_model_area_sorted_ls = copy.deepcopy(median_model_area_ls) # .sort(key=lambda x:x[1]) #  # .sort(key=lambda x: float(x[1])) # .sort(key=lambda y: y[1]) # .sort(key=lambda y: y[1])\n",
        "  # median_model_area_sorted_ls.sort(key=lambda x:x[1], reverse=True)\n",
        "  print(f'        Copying sorted list: {median_model_area_sorted_ls}')\n",
        "\n",
        "  corpora_median_area_dt[acorpus] = copy.deepcopy(median_model_area_sorted_ls)\n",
        "\n",
        "  # corpora_all_dt[acorpus][model_z_cols_ls].head(2)\n",
        "\n",
        "  # TODO: Check for NaN and Impute\n",
        "\n",
        "  # corpora_all_dt[acorpus]['all_z_std'] = corpora_all_dt[acorpus][model_z_cols_ls].std(axis=1)\n",
        "\n",
        "  # acorpus_sent_len = corpora_all_dt[acorpus]['xgb'].shape[0]\n",
        "\n",
        "  # filename_out = f'models_all_{acorpus}.csv'\n",
        "  # fullpath_out = f'./{subdir_out}/{filename_out}'\n",
        "\n",
        "  # print(f'\\nSaving Corpus: {acorpus}...')\n",
        "  # corpora_all_dt[acorpus].to_csv(fullpath_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-AledYmeXb7"
      },
      "source": [
        "corpora_median_area_dt['cdickens_achristmascarol']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e80W_c7Sf5yC"
      },
      "source": [
        "# Gather the Error/Area between Model zScore and Median zScore for all Corpora in one DataFrame\n",
        "\n",
        "corpora_median_area_df = pd.DataFrame()\n",
        "\n",
        "first_loop_fl = True\n",
        "\n",
        "for acorpus, area_tup_ls in corpora_median_area_dt.items():\n",
        "  \n",
        "  print(f'\\nCorpus: {acorpus}\\n') #   {area_tup_ls}')\n",
        "\n",
        "  areas_ls = [i[1] for i in area_tup_ls]\n",
        "  models_ls = [i[0] for i in area_tup_ls]\n",
        "\n",
        "  # print(f'  areas_ls: {areas_ls}')\n",
        "\n",
        "  temp_df = pd.DataFrame({'model_z' : models_ls,'area_z' : areas_ls})\n",
        "  temp_len = temp_df.shape[0]\n",
        "  temp_df['area_z_norm'] = temp_df['area_z']/corpora_all_dt[acorpus].shape[0]\n",
        "  model_col = [acorpus] * temp_len\n",
        "  first_ser = pd.Series(model_col)\n",
        "  temp_df = pd.concat([first_ser, temp_df], axis=1)\n",
        "  temp_df.rename(columns={0:'corpus'}, inplace=True)\n",
        "  \n",
        "  temp_df.head()\n",
        "\n",
        "  if first_loop_fl:\n",
        "    print(f'  Adding {acorpus} as first DataFrame')\n",
        "    corpora_model_area_df = temp_df.copy(deep=True)\n",
        "    first_loop_fl = False\n",
        "  else:\n",
        "    # temp_copy_df = temp_df.copy(deep=True)\n",
        "    print(f'  Adding {acorpus} as successive DataFrame')\n",
        "    corpora_model_area_df = pd.concat([corpora_model_area_df, temp_df], axis=0)\n",
        "\n",
        "  # pd.DataFrame(model_col, columns=['corpus'])], axis=1, join='inner')\n",
        "\n",
        "  # lst = pd.Series([0.25,1.24865,2.541,3.1,4.4582]) # <-converted to series\n",
        "  # pd.concat([pd.Series(lst), df], axis=1)\n",
        "\n",
        "  temp_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx6_pU7EvJS8"
      },
      "source": [
        "corpora_median_area_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ptiPx0dwsKq"
      },
      "source": [
        "corpora_model_area_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-xnVhvbwLQ6"
      },
      "source": [
        "corpora_model_area_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4aTa_1AJdrc"
      },
      "source": [
        "corpora_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqfWZQwETwfb"
      },
      "source": [
        "model_z_cols_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhnimzsJwkw7"
      },
      "source": [
        "## **Plot Model Rank by Corpus**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhuKX1oervGw"
      },
      "source": [
        "# Plot Rank of Model Area from Median per Corpus\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
        "\n",
        "save_plot = False\n",
        "\n",
        "subdir_name = 'data_corpora_plots'\n",
        "\n",
        "models_all_order_dt = {}\n",
        "for acorpus in corpora_ls:\n",
        "  if acorpus != 'median_z':\n",
        "    models_all_order_dt[acorpus] = []\n",
        "  # for amodel_z in model_z_cols_ls:\n",
        "  #   models_all_order_dt[acorpus][amodel_z] = []\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(f'Plotting Model-Median Area for Corpus #{i}: {acorpus}')\n",
        "  temp_df = corpora_model_area_df[corpora_model_area_df.corpus == acorpus]\n",
        "\n",
        "  # Drop the 'median_z' row\n",
        "  temp_df = temp_df[temp_df.model_z != 'median_z']\n",
        "\n",
        "  # Sort in place \n",
        "  temp_df.sort_values(by=['area_z_norm'], inplace=True, ascending=False)\n",
        "  # temp_df.head(2) # area_z.plot(kind='bar')\n",
        "  # temp_df.area_z.plot(kind='bar' x=model_z, y=area_z)\n",
        "\n",
        "  # Store order for each Model\n",
        "  models_order_ls = temp_df.model_z.to_list()\n",
        "  # for j, amodel_ord in enumerate(models_order_ls):\n",
        "  #   models_all_order_dt[acorpus][amodel_ord].append(str(j)) \n",
        "  models_order_ls.reverse()  # Reverses in-place\n",
        "  models_all_order_dt[acorpus] = models_order_ls\n",
        "\n",
        "  #ax = temp_df.plot.bar(x='model_z', y='area_z', rot=90)\n",
        "\n",
        "  plt.barh('model_z', 'area_z_norm', data=temp_df)\n",
        "  # plt.xticks(fontsize=20) # , rotation=0)\n",
        "  # plt.yticks(fontsize=20) # , rotation=0)\n",
        "  plt.rcParams.update({'font.size': 20})\n",
        "  plt.title(f'{corpora_full_dt[acorpus]}\\n Error Area between zScore Models and Median', pad=20, fontdict={'fontsize':24})\n",
        "\n",
        "  if save_plot:\n",
        "    filename_plt = f'./{subdir_name}/plt_models_rank_{acorpus}.png'\n",
        "    plt.savefig(filename_plt)\n",
        "\n",
        "  plt.show()\n",
        "  plt.close();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct6MDByLUmO4"
      },
      "source": [
        "print(models_all_order_dt['cdickens_achristmascarol'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U4ywQ9Iwroc"
      },
      "source": [
        "## **Plot Rank and Spread by Model over the Corpora**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWFSxYrrXbgE"
      },
      "source": [
        "# Create a Dict (Models) of Lists (Ranks)\n",
        "\n",
        "models_all_rank_dt = {}\n",
        "\n",
        "models_z_rank_ls = models_all_order_dt['cdickens_achristmascarol']\n",
        "for amodel_z in models_z_rank_ls:\n",
        "  models_all_rank_dt[amodel_z] = []\n",
        "\n",
        "for key, values in models_all_order_dt.items():\n",
        "  print(f'Corpus: {key}')\n",
        "  for i, amodel in enumerate(values):\n",
        "    print(f' Model #{i}: {amodel}')\n",
        "    models_all_rank_dt[amodel].append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTGW9o9SYmBN"
      },
      "source": [
        "# models_all_rank_dt.keys()\n",
        "\n",
        "models_z_rank_ls = models_all_order_dt['cdickens_achristmascarol']\n",
        "models_mean_ls = []\n",
        "models_std_ls = []\n",
        "models_max_ls = []\n",
        "models_min_ls = []\n",
        "models_ranks_ls_ls = []\n",
        "\n",
        "for i, amodel_z in enumerate(models_z_rank_ls):\n",
        "  print(f'For Model: {amodel_z}:')\n",
        "  model_mean = np.mean(models_all_rank_dt[amodel_z])\n",
        "  print(f'  Mean: {model_mean}')\n",
        "  models_mean_ls.append(model_mean)\n",
        "\n",
        "  model_std = np.std(models_all_rank_dt[amodel_z])\n",
        "  print(f'  STD: {model_std}')\n",
        "  models_std_ls.append(model_std)\n",
        "\n",
        "  model_min = np.min(models_all_rank_dt[amodel_z])\n",
        "  print(f'  Min: {model_min}')\n",
        "  models_min_ls.append(model_min)\n",
        "\n",
        "  model_max = np.max(models_all_rank_dt[amodel_z])\n",
        "  print(f'  Max: {model_max}')\n",
        "  models_max_ls.append(model_max)\n",
        "\n",
        "  model_ranks_ls = models_all_rank_dt[amodel_z]\n",
        "  print(f' Ranks: {model_ranks_ls}')\n",
        "  models_ranks_ls_ls.append(model_ranks_ls)\n",
        "\n",
        "\n",
        "models_rank_dt = {'model_z': models_z_rank_ls,\n",
        "                  'mean':models_mean_ls,\n",
        "                  'std':models_std_ls,\n",
        "                  'min':models_min_ls,\n",
        "                  'max':models_max_ls,\n",
        "                  'ranks':models_ranks_ls_ls}\n",
        "\n",
        "models_rank_df = pd.DataFrame.from_dict(models_rank_dt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgxCt6Jud1lv"
      },
      "source": [
        "models_rank_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjISpq2GlD7c"
      },
      "source": [
        "models_labels_ls = ['-'.join(i.split('_')[:-1]) for i in models_rank_df.model_z.to_list()]\n",
        "models_labels_ls\n",
        "len(models_labels_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVZ_nDWumFxv"
      },
      "source": [
        "len(models_labels_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVezKhsPiEym"
      },
      "source": [
        "# models_labels_ls = models_rank_df.model_z.to_list()\n",
        "# models_labels_ls = ['-'.join(i.split('_')[:-1]) for i in models_labels_ls]\n",
        "# models_labels_ls = [w.replace('_', '-') for w in models_labels_ls]\n",
        "# models_labels_ls = [i.split('_')[:-1] for i in models_rank_df.model_z.to_list()]\n",
        "\n",
        "# models_box_ready_df = pd.DataFrame(np.array(models_rank_df.ranks.to_list()).T, columns=models_labels_ls)\n",
        "models_box_ready_df = pd.DataFrame(np.array(models_rank_df.ranks.to_list()).T, columns=models_labels_ls)\n",
        "models_box_ready_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irsjV5afiEq7"
      },
      "source": [
        "# Plot Rank and Spread of Models across all 25 Corpora\n",
        "\n",
        "save_plot = True\n",
        "subdir_name = 'data_corpora_plots'\n",
        "\n",
        "models_box_ready_df.plot(kind='box')\n",
        "# ax.invert_yaxis()\n",
        "\n",
        "plt.xticks(fontsize=20, rotation=90)\n",
        "# plt.yticks(fontsize=20) # , rotation=0)\n",
        "# plt.rcParams.update({'font.size': 20})\n",
        "# plt.title(f'{corpora_full_dt[acorpus]}\\n Error Area between zScore Models and Median', pad=20, fontdict={'fontsize':24})\n",
        "plt.grid(alpha=0.3)\n",
        "plt.title('Rank and Spread of Models across all 25 Corpora')\n",
        "\n",
        "\n",
        "if save_plot:\n",
        "  filename_plt = f'./{subdir_name}/plt_models_all_rank_spread.png'\n",
        "  plt.savefig(filename_plt)\n",
        "\n",
        "plt.show()\n",
        "plt.close();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLUHKoFNTj7o"
      },
      "source": [
        "## **SKIP to [Downsample with LTTB]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYvRjFOnd1hJ"
      },
      "source": [
        "models_rank_df[['model_z', 'ranks']].T.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGuAxQANd1c_"
      },
      "source": [
        "(models_all_order_dt['cdickens_achristmascarol'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVWavYihaJSJ"
      },
      "source": [
        "\n",
        "models_z_rank_ls = models_all_order_dt['cdickens_achristmascarol']\n",
        "\n",
        "for amodel_z in models_z_rank_ls:\n",
        "  models_all_rank_dt[amodel_z] = []\n",
        "\n",
        "for key, values in models_all_order_dt.items():\n",
        "  print(f'Corpus: {key}')\n",
        "  for i, amodel in enumerate(values):\n",
        "    print(f' Model #{i}: {amodel}')\n",
        "    # models_all_rank_dt[amodel].append(i)\n",
        "\n",
        "  models_all_rank_dt['logreg_cv_z']\n",
        "  print('\\n')\n",
        "\n",
        "  model_median = np.median(models_all_rank_dt['logreg_cv_z'])\n",
        "  print(f'  Model Median: {model_median}')\n",
        "\n",
        "  model_std = np.std(models_all_rank_dt['logreg_cv_z'])\n",
        "  print(f'  Model STD: {model_std}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS9ExZhsEKTI"
      },
      "source": [
        "# Create DataFrame from Dictionaries\n",
        "\n",
        "corpora_median_area_dt = {}\n",
        "temp_df = pd.DataFrame()\n",
        "first_loop_fl = True\n",
        "\n",
        "for acorpus, area_tup_ls in corpora_median_area_dt.items():\n",
        "  \n",
        "  print(f'\\nCorpus: {acorpus}\\n   {area_tup_ls}')\n",
        "\n",
        "  areas_ls = [i[1] for i in area_tup_ls]\n",
        "  model_ls = [i[0] for i in area_tup_ls]\n",
        "  temp_df = pd.DataFrame(areas_ls, columns=['area_z'] )\n",
        "  print(f'temp_df.head():\\n{temp_df.head()}')\n",
        "  if first_loop_fl:\n",
        "    corpora_median_area_dt[acorpus] = temp_df.copy(deep=True)\n",
        "    first_loop_fl = False\n",
        "  else:\n",
        "    corpora_median_area_dt = pd.merge(corpora_median_area_dt, temp_df, how='inner', on = 'model_z')\n",
        "\n",
        "# corpora_median_area_df = pd.DataFrame(corpora_median_area_dt, columns=['model_z', 'area_z'])\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "for acorpus, area_tup_ls in corpora_median_area_dt.items():\n",
        "  \n",
        "  print(f'Corpus: {acorpus}\\n   {area_tup_ls}')\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(f'Processing Corpus #{i}: {acorpus}')\n",
        "\n",
        "  median_model_area_ls = []\n",
        "\n",
        "  for j, amodel_z in enumerate(model_z_cols_ls):\n",
        "    print(f'  with Model #{j}: {amodel_z}')\n",
        "\n",
        "    median_model_area = np.sum(np.abs(corpora_all_dt[acorpus][amodel_z] - corpora_all_dt[acorpus]['median_z']))\n",
        "    print(f'    Area between Median: {median_model_area}')\n",
        "\n",
        "    median_model_area_ls.append((amodel_z, median_model_area))\n",
        "\n",
        "\n",
        "corpora_median_area_dt['cdickens_achristmascarol'].plot(kind=bar)\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5XsT-ogeIr9"
      },
      "source": [
        "corpora_median_area_dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pVZYLfaJy06"
      },
      "source": [
        "corpora_median_area_dt.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_uAmi1kJs33"
      },
      "source": [
        "corpora_median_area_dt['cdickens_achristmascarol']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN_ajoJ4G1pW"
      },
      "source": [
        "corpora_median_area_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p6Oa6rvAPRw"
      },
      "source": [
        "print(corpora_median_area_dt['cdickens_achristmascarol'][0][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZrRbAanC09h"
      },
      "source": [
        "print(corpora_median_area_dt['cdickens_achristmascarol'].sort(key=lambda x:x[0][1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZaUNdEZ-TZb"
      },
      "source": [
        "print(corpora_median_area_dt['cdickens_achristmascarol']) #.sort(key=lambda y: y[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yb3qxjN8vra"
      },
      "source": [
        "mx = max(corpora_median_area_dt['cdickens_achristmascarol'], key=lambda e: int(e[1]))\n",
        "print(mx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shMPbC_L8vjC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2uyFWyLbt7_"
      },
      "source": [
        "# **Downsample with LTTB**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "059Ty0n6btrn"
      },
      "source": [
        "!pip install lttb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwL2wKM9cnre"
      },
      "source": [
        "import lttb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0iyVTICEwTi"
      },
      "source": [
        "## **Option (a): Read in SMA 10%/LTTB DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiSG9vASE3Ip"
      },
      "source": [
        "# Save all Corpora with both old and new LTTB reduced Models\n",
        "\n",
        "corpora_all25_dt = {}\n",
        "\n",
        "subdir_all = 'data_corpora_all'\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "\n",
        "\n",
        "  # acorpus_sent_len = corpora_all_dt[acorpus]['xgb'].shape[0]\n",
        "\n",
        "  filename_out = f'models_all25_{acorpus}.csv'\n",
        "  fullpath_out = f'./{subdir_all}/{filename_out}'\n",
        "  print(f'Reading Corpus: {acorpus} from file: {fullpath_out}')\n",
        "\n",
        "  corpora_all25_dt[acorpus] = pd.read_csv(fullpath_out, index_col=[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4y5DW1WYENZ"
      },
      "source": [
        "%whos list "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0t96JyDYEHZ"
      },
      "source": [
        "# Test Plot of first corpus\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (40,20)\n",
        "\n",
        "lttb_pts = 25\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls[:1]):\n",
        "\n",
        "  corpora_all25_dt[acorpus].plot()\n",
        "  plt.title(f'{corpora_full_dt[acorpus]}\\n zScore/SMA 10% Downsampled to {lttb_pts} Points with LTTB', fontdict = {'fontsize' : 16})\n",
        "  plt.legend(loc='best') \n",
        "  plt.show()\n",
        "  plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ysO-EHFE4A3"
      },
      "source": [
        "## **Option (b): Generate SMA 10%/LTTB DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEjycZNecj_4"
      },
      "source": [
        "acorpus = 'cdickens_achristmascarol'\n",
        "\n",
        "print(f'Corpus: {acorpus} has {corpora_all_dt[acorpus].shape[0]} time values')\n",
        "\n",
        "win10per = int(0.1*corpora_all_dt[acorpus].shape[0])\n",
        "corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True, min_periods=1).mean().plot(label='z-Score Median', style=['r*-'], linewidth=2.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67HtX5mefOeC"
      },
      "source": [
        "acorpus = 'cdickens_achristmascarol'\n",
        "model_z = 'nrc_z'\n",
        "\n",
        "type(corpora_all_dt[acorpus][model_z].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APkuuQpre5e4"
      },
      "source": [
        "# Downsample to n_pts points:\n",
        "\n",
        "n_pts = 50\n",
        "\n",
        "x_np = corpora_all_dt[acorpus]['median_z'].shape[0]\n",
        "\n",
        "# Generate an example data set of 100 random points:\n",
        "#  - column 0 represents time values (strictly increasing)\n",
        "#  - column 1 represents the metric of interest: CPU usage, stock price, etc.\n",
        "\n",
        "y_np = corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True, min_periods=1).mean().values\n",
        "data = np.array([range(x_np), y_np]).T # np.random.random(100)]).T\n",
        "\n",
        "# Downsample it to 20 points:\n",
        "small_data = lttb.downsample(data, n_out=n_pts)\n",
        "assert small_data.shape == (n_pts, 2)\n",
        "\n",
        "# temp_np = corpora_all_dt[acorpus]['median_z'].values.reshape(1,-1) # ).ravel()\n",
        "# print(f'Shape temp_np: {temp_np.shape}')\n",
        "# small_data = lttb.downsample(temp_np, n_out=20)\n",
        "# assert small_data.shape == (20, 2)\n",
        "\n",
        "plt.plot(small_data.T[0],small_data.T[1])\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IHlfu-Th0nB"
      },
      "source": [
        "n_pts = 25\n",
        "\n",
        "x_np = corpora_all_dt[acorpus]['median_z'].shape[0]\n",
        "\n",
        "# Generate an example data set of 100 random points:\n",
        "#  - column 0 represents time values (strictly increasing)\n",
        "#  - column 1 represents the metric of interest: CPU usage, stock price, etc.\n",
        "\n",
        "y_np = corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True, min_periods=1).mean().values\n",
        "data = np.array([range(x_np), y_np]).T # np.random.random(100)]).\n",
        "# Downsample it to 20 points:\n",
        "small_data = lttb.downsample(data, n_out=n_pts)\n",
        "assert small_data.shape == (n_pts, 2)\n",
        "print(f'type small_data: {type(small_data)}')\n",
        "print(f'small_data.shape: {small_data.shape}')\n",
        "\n",
        "# temp_np = corpora_all_dt[acorpus]['median_z'].values.reshape(1,-1) # ).ravel()\n",
        "# print(f'Shape temp_np: {temp_np.shape}')\n",
        "# small_data = lttb.downsample(temp_np, n_out=20)\n",
        "# assert small_data.shape == (20, 2)\n",
        "\n",
        "plt.plot(small_data.T[0],small_data.T[1])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKOgg7VAZyL2"
      },
      "source": [
        "## **Plot zScore/SMA 10% with Downsampling via LTTB**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlKqdcoogg-E"
      },
      "source": [
        "# Anomaly: tmorrison_beloved/pattern is all 0s\n",
        "\n",
        "corpora_all_dt['tmorrison_beloved'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqH86gAtwho7"
      },
      "source": [
        "# For Corpora 'tmorrison_beloved' both 'pattern' and thus 'pattern_z' are 0 and NaN respectively\n",
        "#   for now, just fillna both with '0' as place holders for this one model (pattern) to view all other Models\n",
        "\n",
        "corpora_all_dt['tmorrison_beloved']['pattern_z'] = corpora_all_dt['tmorrison_beloved']['pattern_z'].fillna(0)\n",
        "\n",
        "# corpora_all_dt['tmorrison_beloved']['pattern_z'] = corpora_all_dt['tmorrison_beloved']['syuzhet_z']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKlgKxNywhad"
      },
      "source": [
        "# Verify corpora_all_dt['tomorrison-beloved']['pattern_z'] are all (NaN -> 0)\n",
        "\n",
        "corpora_all_dt['tmorrison_beloved'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOc5Os1IgP8H"
      },
      "source": [
        "# Check if any NaN in tmorrison_beloved\n",
        "# corpora_all_dt[corpora_all_dt['tmorrison_beloved'].isnull().any(axis=1)]\n",
        "\n",
        "corpora_all_dt['tmorrison_beloved'].isnull().any(axis=1).any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9W6GLNJamm3"
      },
      "source": [
        "model_all_cols_ls = corpora_all_dt['cdickens_achristmascarol'].columns\n",
        "print(model_all_cols_ls)\n",
        "\n",
        "print(f'\\nEach Corpus has {len(model_all_cols_ls)} Columns')\n",
        "\n",
        "# Get list of non-Model Columns in Corpus DataFrame\n",
        "model_noncols_ls = ['sent_no', 'parag_no', 'sect_no', 'sent_raw', 'sent_clean']\n",
        "print(f'\\n  {len(model_noncols_ls)} Columns are meta-information (not Models) [model_noncols_ls]:  \\n  {model_noncols_ls}')\n",
        "\n",
        "# Get list of Model Columns in Corpus DataFrame\n",
        "model_cols_ls = list(set(model_all_cols_ls) - set(model_noncols_ls))\n",
        "print(f'\\n  {len(model_cols_ls)} Columns are these Models [model_cols_ls]:\\n  {[i for i in model_cols_ls]}')\n",
        "\n",
        "# Get list of zScore Model Columns in Corpus DataFrame\n",
        "model_z_cols_ls = [i for i in model_cols_ls if i.endswith('_z')]\n",
        "print(f'\\n  {len(model_z_cols_ls)} Columns are zScore Models [model_z_cols_ls]:\\n  {model_z_cols_ls}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK4ok9hKhB3I"
      },
      "source": [
        "corpora_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbiiZeSwhLCs"
      },
      "source": [
        "# Workaround to deal with break at NaN in tmorrison_beloved/pattern_z \n",
        "#   change NaN->0 and continue execution for the rest of these Corpora\n",
        "\n",
        "corpora_temp_ls = [\n",
        "                    'tmorrison_beloved',\n",
        "                    'vnabokov_palefire',\n",
        "                    'vwoolf_mrsdalloway',\n",
        "                    'vwoolf_orlando',\n",
        "                    'vwoolf_thewaves',\n",
        "                    'vwoolf_tothelighthouse'\n",
        "                    ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIuFBoyy5CcS"
      },
      "source": [
        "model_z_cols_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lER4ROcV3Cl0"
      },
      "source": [
        "## **TEMP STOP 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKK_508HYvIJ"
      },
      "source": [
        "# %%capture\n",
        "\n",
        "# Downsample all z-Score Model Series to n_pts with LTTB Algo\n",
        "\n",
        "# Plot config for all Models in same Corpus Graph\n",
        "plt.rcParams[\"figure.figsize\"] = (40,20)\n",
        "plt.rcParams.update({'font.size': 14})\n",
        "\n",
        "# Plot config for on Model per Graph\n",
        "# plt.rcParams[\"figure.figsize\"] = (20,3)\n",
        "# plt.rcParams.update({'font.size': 10})\n",
        "\n",
        "lttb_pts = 25\n",
        "\n",
        "save_plot = False\n",
        "\n",
        "subdir_name = 'data_corpora_plots'\n",
        "\n",
        "corpora_all25_dt = {}\n",
        "\n",
        "for acorpus in corpora_ls:\n",
        "  corpora_all25_dt[acorpus] = pd.DataFrame()\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls): # corpora_ls): # corpora_temp_ls): # [:2]):\n",
        "  print(acorpus)\n",
        "  # acorpus_sent_len = corpora_all_dt[acorpus]['xgb'].shape[0]\n",
        "\n",
        "  for j, amodel_z in enumerate(model_z_cols_ls):\n",
        "    # if j == 0:\n",
        "    #   corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True).mean().plot(label='z-Score Median', style=['r*-'], linewidth=2.0)\n",
        "\n",
        "    print(f'Corpus #{i} {acorpus} with Model #{j} {amodel_z}: has {len(corpora_all_dt[acorpus].columns)} columns but only {len(model_cols_ls)} model columns')\n",
        "\n",
        "    amodel_z_nlttb = f'{amodel_z}_{lttb_pts}lttb'\n",
        "\n",
        "    x_np = corpora_all_dt[acorpus][amodel_z].index # shape[0]\n",
        "    y_np = corpora_all_dt[acorpus][amodel_z].rolling(win10per, center=True, min_periods=1).mean().values\n",
        "    # data = np.array([range(x_np), y_np]).T\n",
        "    data = np.array([x_np, y_np]).T\n",
        "\n",
        "    # Downsample it to lttb_pts points:\n",
        "    small_data = lttb.downsample(data, n_out=lttb_pts)\n",
        "    assert small_data.shape == (lttb_pts, 2)\n",
        "\n",
        "    temp_ser = pd.Series()\n",
        "    temp_ser = pd.Series(small_data.T[1].tolist()) # small_data.T[0], small_data.T[1])\n",
        "    corpora_all25_dt[acorpus][amodel_z_nlttb] = temp_ser.copy(deep=True) # = pd.Series(small_data.T[1].tolist()) # small_data.T[0], small_data.T[1])\n",
        "\n",
        "    # temp_np = corpora_all_dt[acorpus]['vader_z'].values.reshape(1,-1) # ).ravel()\n",
        "    # print(f'Shape temp_np: {temp_np.shape}')\n",
        "    # small_data = lttb.downsample(temp_np, n_out=20)\n",
        "    # assert small_data.shape == (20, 2)\n",
        "\n",
        "    \n",
        "    plt.plot(small_data.T[0],small_data.T[1], label=amodel_z)\n",
        "    \n",
        "\n",
        "    # Plot each Model separately \n",
        "\n",
        "\n",
        "  # Plot all Models on same Corpus Graph\n",
        "  plt.title(f'{corpora_full_dt[acorpus]}\\n zScore/SMA 10% Downsampled to {lttb_pts} Points with LTTB', fontsize=20)\n",
        "\n",
        "  plt.legend(loc='best') \n",
        "\n",
        "  if save_plot:\n",
        "    filename_plt = f'./{subdir_name}/plt_lttb{lttb_pts}_{amodel_z}.png'\n",
        "    plt.savefig(filename_plt)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "\"\"\"\n",
        "    # Plot each Model separately \n",
        "\n",
        "    plt.title(f'{corpora_full_dt[acorpus]} with Model: {amodel_z}\\n zScore/SMA 10% Downsampled to {lttb_pts} Points with LTTB')\n",
        "\n",
        "    plt.legend(loc='best') \n",
        "    \n",
        "    if save_plot:\n",
        "      filename_plt = f'./{subdir_name}/plt_lttb{lttb_pts}_{amodel_z}.png'\n",
        "      plt.savefig(filename_plt)\n",
        "    plt.show()\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0mYaYw41IJb"
      },
      "source": [
        "# import copy\n",
        "\n",
        "# corpora_all25_dt = copy.deepcopy(corpora_all50_dt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FsUDlMcy8A6"
      },
      "source": [
        "corpora_all25_dt.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-X1By-StQJG"
      },
      "source": [
        "# Verify the LTTB Dim-Red corpora dimensions\n",
        "\n",
        "corpora_all25_dt['cdickens_achristmascarol'].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1pVcBv_2AWQ"
      },
      "source": [
        "corpora_all25_dt['cdickens_achristmascarol'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2-JGSzpy-TG"
      },
      "source": [
        "# Verify the LTTB Dim-Red corpora dimensions\n",
        "\n",
        "corpora_all25_dt['vnabokov_palefire'].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQmeMFqmtS2Q"
      },
      "source": [
        "corpora_all25_dt['vnabokov_palefire'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q26cE0480t4R"
      },
      "source": [
        "## **SKIP to [Save zScore/SMA/LTTB DataFrames]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfgIUex00myY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywL3vL3uf-9e"
      },
      "source": [
        "# If only a few missing, could've interpolated missing values from surrounding non-NaN values\n",
        "\n",
        "# corpora_all_dt[corpora_all_dt['tmorrison_beloved'].interpolate(method='linear', limit_direction='both')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEUgYI5cbU4k"
      },
      "source": [
        "corpora_all_dt['cdickens_achristmascarol'].columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOY3ek-PCF-k"
      },
      "source": [
        "# Downsample all z-Score Model Series to n_pts with LTTB Algo\n",
        "\n",
        "lttb_pts = 50\n",
        "\n",
        "subdir_name = 'data_corpora_plots'\n",
        "\n",
        "corpora_all50_dt = {}\n",
        "\n",
        "for acorpus in corpora_ls:\n",
        "  corpora_all50_dt[acorpus] = pd.DataFrame()\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls): # [:2]):\n",
        "  print(acorpus)\n",
        "  # acorpus_sent_len = corpora_all_dt[acorpus]['xgb'].shape[0]\n",
        "\n",
        "  for j, amodel in enumerate(model_cols_ls):\n",
        "    if j == 0:\n",
        "      corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True).mean().plot(label='z-Score Median', style=['r*-'], linewidth=2.0)\n",
        "\n",
        "    print(f'Corpus #{i} {acorpus} with Model #{j} {amodel}: has {len(corpora_all_dt[acorpus].columns)} columns but only {len(model_cols_ls)} model columns')\n",
        "\n",
        "    amodel_z = f'{amodel}_z'\n",
        "\n",
        "    x_np = corpora_all_dt[acorpus][amodel_z].shape[0]\n",
        "    y_np = corpora_all_dt[acorpus][amodel_z].rolling(win10per, center=True, min_periods=1).mean().values\n",
        "    data = np.array([range(x_np), y_np]).T\n",
        "\n",
        "    # Downsample it to lttb_pts points:\n",
        "    small_data = lttb.downsample(data, n_out=lttb_pts)\n",
        "    assert small_data.shape == (lttb_pts, 2)\n",
        "\n",
        "    corpora_all50_dt[acorpus][amodel] = pd.Series(small_data.tolist()) # small_data.T[0], small_data.T[1])\n",
        "\n",
        "    # temp_np = corpora_all_dt[acorpus]['vader_z'].values.reshape(1,-1) # ).ravel()\n",
        "    # print(f'Shape temp_np: {temp_np.shape}')\n",
        "    # small_data = lttb.downsample(temp_np, n_out=20)\n",
        "    # assert small_data.shape == (20, 2)\n",
        "\n",
        "    plt.plot(small_data.T[0],small_data.T[1], label=amodel)\n",
        "\n",
        "  plt.title(f'{acorpus}\\n SMA 10% Followed by LTTB Downsampled to {lttb_pts} Points')\n",
        "  plt.legend(loc='best') \n",
        "  filename_plt = f'./{subdir_name}/plt_lttb{lttb_pts}_{amodel}.png'\n",
        "  plt.savefig(filename_plt)\n",
        "  plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5Dtwn9QD0KP"
      },
      "source": [
        "corpora_all50_dt['cdickens_achristmascarol']['vader'][:5]\n",
        "type(corpora_all50_dt['cdickens_achristmascarol']['vader'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO8-1qjN_zs-"
      },
      "source": [
        "# Save all models with orignal and zscore values\n",
        "\n",
        "subdir_out = 'data_corpora_all'\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(acorpus)\n",
        "  # acorpus_sent_len = corpora_all_dt[acorpus]['xgb'].shape[0]\n",
        "\n",
        "  filename_out = f'models_all50_{acorpus}.csv'\n",
        "  fullpath_out = f'./{subdir_out}/{filename_out}'\n",
        "\n",
        "  print(f'\\nSaving Corpus: {acorpus}...')\n",
        "  corpora_all50_dt[acorpus].to_csv(fullpath_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUnEPAU_FJ8l"
      },
      "source": [
        "## **Save zScore/SMA/LTTB DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9g1eqwzFJrX"
      },
      "source": [
        "# Save all Corpora with both old and new LTTB reduced Models\n",
        "\n",
        "subdir_out = 'data_corpora_all'\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(acorpus)\n",
        "  # acorpus_sent_len = corpora_all_dt[acorpus]['xgb'].shape[0]\n",
        "\n",
        "  filename_out = f'models_all25_{acorpus}.csv'\n",
        "  fullpath_out = f'./{subdir_out}/{filename_out}'\n",
        "\n",
        "  print(f'\\nSaving Corpus: {acorpus}...')\n",
        "  corpora_all25_dt[acorpus].to_csv(fullpath_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z02wV6y6_w0C"
      },
      "source": [
        "# **[DEFUNCT] LOWESS Smoothing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGuuDFcb3LNz"
      },
      "source": [
        "# from statsmodels.nonparametric.smoothers_lowess import lowess\n",
        "\n",
        "import statsmodels.api as sm\n",
        "lowess = sm.nonparametric.lowess"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAMP4J6bEc26"
      },
      "source": [
        "# Downsample all z-Score Model Series to n_pts with LTTB Algo\n",
        "\n",
        "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
        "\n",
        "afrac = 0.1 \n",
        "\n",
        "def make_lowess(series, frac=0.1):\n",
        "    endog = series.values\n",
        "    exog = series.index.values\n",
        "\n",
        "    smooth = lowess(endog, exog, frac)\n",
        "    index, data = np.transpose(smooth)\n",
        "\n",
        "    return pd.Series(data, index=pd.to_datetime(index)) \n",
        "\n",
        "for acorpus in corpora_ls:\n",
        "  corpora_all50_dt[acorpus] = pd.DataFrame()\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls[:2]):\n",
        "  print(acorpus)\n",
        "  # acorpus_sent_len = corpora_all_dt[acorpus]['xgb'].shape[0]\n",
        "\n",
        "  for j, amodel in enumerate(model_cols_ls):\n",
        "    if j == 0:\n",
        "      corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True).mean().plot(label='z-Score Median', style=['r*-'], linewidth=2.0)\n",
        "\n",
        "    print(f'Corpus #{i} {acorpus} with Model #{j} {amodel}: has {len(corpora_all_dt[acorpus].columns)} columns but only {len(model_cols_ls)} model columns')\n",
        "\n",
        "    amodel_lowess = f\"{amodel}_lowess{''.join(str(afrac).split('.'))}\"\n",
        "    print(f'amodel_lowess: {amodel_lowess}')\n",
        "\n",
        "    temp_np = make_lowess(corpora_all_dt[acorpus][amodel], frac=afrac)\n",
        "    # plt.plot(temp_np[0], temp_np[1], label=amodel)\n",
        "\n",
        "    corpora_all_dt[acorpus][amodel_lowess] = pd.Series(temp_np.tolist()) # small_data.T[0], small_data.T[1])\n",
        "\n",
        "\n",
        "\n",
        "    # temp_np = corpora_all_dt[acorpus]['vader_z'].values.reshape(1,-1) # ).ravel()\n",
        "    # print(f'Shape temp_np: {temp_np.shape}')\n",
        "    # small_data = lttb.downsample(temp_np, n_out=20)\n",
        "    # assert small_data.shape == (20, 2)\n",
        "\n",
        "    # plt.plot(small_data.T[0],small_data.T[1], label=amodel)\n",
        "\n",
        "  plt.title(f'{acorpus} LTTB Downsampled SMA 10%')\n",
        "  plt.legend(loc='best') \n",
        "  plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OceHxv73Zbi"
      },
      "source": [
        "x = np.random.uniform(low = -2*np.pi, high = 2*np.pi, size=500)\n",
        "y = np.sin(x) + np.random.normal(size=len(x))\n",
        "\n",
        "z = lowess(y, x)\n",
        "w = lowess(y, x, frac=1./3)\n",
        "\n",
        "# plt.plot(w)\n",
        "\n",
        "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
        "\n",
        "def make_lowess(series, frac=0.1):\n",
        "    endog = series.values\n",
        "    exog = series.index.values\n",
        "\n",
        "    smooth = lowess(endog, exog, frac)\n",
        "    index, data = np.transpose(smooth)\n",
        "\n",
        "    return pd.Series(data, index=pd.to_datetime(index)) \n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "temp_df['test'] = make_lowess(corpora_all_dt['cdickens_achristmascarol']['vader_z'], frac=0.1)\n",
        "\n",
        "temp_df['test'].plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnR-Hmjk7Okb"
      },
      "source": [
        "temp_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pk8LZyRPdmTh"
      },
      "source": [
        "# Downsample all z-Score Model Series to n_pts with LTTB Algo\n",
        "\n",
        "n_pts = 100\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls[:2]):\n",
        "  print(acorpus)\n",
        "  # acorpus_sent_len = corpora_all_dt[acorpus]['xgb'].shape[0]\n",
        "\n",
        "  for j, amodel in enumerate(model_cols_ls):\n",
        "    if j == 0:\n",
        "      corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True).mean().plot(label='z-Score Median', style=['r*-'], linewidth=2.0)\n",
        "\n",
        "    print(f'Corpus #{i} {acorpus} with Model #{j} {amodel}: has {len(corpora_all_dt[acorpus].columns)} columns but only {len(model_cols_ls)} model columns')\n",
        "\n",
        "    amodel_z = f'{amodel}_z'\n",
        "    \n",
        "    x_np = corpora_all_dt[acorpus][amodel_z].shape[0]\n",
        "    y_np = corpora_all_dt[acorpus][amodel_z].rolling(win10per, center=True, min_periods=1).mean().values\n",
        "    data = np.array([range(x_np), y_np]).T\n",
        "\n",
        "    # Downsample it to n_pts points:\n",
        "    small_data = lttb.downsample(data, n_out=n_pts)\n",
        "    assert small_data.shape == (n_pts, 2)\n",
        "\n",
        "    # temp_np = corpora_all_dt[acorpus]['vader_z'].values.reshape(1,-1) # ).ravel()\n",
        "    # print(f'Shape temp_np: {temp_np.shape}')\n",
        "    # small_data = lttb.downsample(temp_np, n_out=20)\n",
        "    # assert small_data.shape == (20, 2)\n",
        "\n",
        "    plt.plot(small_data.T[0],small_data.T[1], label=amodel)\n",
        "\n",
        "  plt.title(f'{acorpus} LTTB Downsampled SMA 10%')\n",
        "  plt.legend(loc='best') \n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    win10per = int(0.10*corpora_all_dt[acorpus].shape[0])\n",
        "\n",
        "    temp_np = np.asarray(corpora_all_dt[acorpus][amodel])\n",
        "    temp_z_np = zscore(temp_np)\n",
        "\n",
        "    # temp_std_ser = stdscaler.fit_transform(np.asarray(temp_ser).reshape(1,-1)).ravel()\n",
        "    # pd.Series(temp_std_ser)\n",
        "    amodel_z = f'{amodel}_z'\n",
        "    corpora_all_dt[acorpus][amodel_z] = pd.Series(temp_z_np)\n",
        "    corpora_all_dt[acorpus][amodel_z].rolling(win10per, center=True).mean().plot(label=amodel_z, alpha=0.3)\n",
        "\n",
        "    # corpora_all_dt[acorpus][amodel].astype(np.float64)\n",
        "    # temp_df[amodel] = corpora_all_dt[acorpus][amodel].value.rolling(win10per, min_periods=1,center=True).apply(zscore)\n",
        "    \n",
        "    # temp_df[amodel] = pd.Series(type(stdscaler.fit_transform(np.asarray(corpora_all_dt[acorpus][amodel]).reshape(-1,1)))) # .reshape(-1,1))\n",
        "    # print(f'temp_df[amodel]: {temp_df[amodel]}')\n",
        "    # print(f'len(temp_df[amodel]: {len(temp_df[amodel])}')\n",
        "    # temp_df[amodel].rolling(win10per, min_periods=1,center=True).mean().plot() # .mean().plot(label=amodel)\n",
        "\n",
        "    # plt.title(f'{acorpus} Simple Moving Average')\n",
        "    # plt.legend(loc='best') \n",
        "\n",
        "  # if i == (len(corpora_ls)):\n",
        "  #   corpora_all_dt[amodel]['median_z'].rolling(win10per, center=True).mean().plot(alpha=0.6, color='black', width=2)\n",
        "  #   plt.title(f'{acorpus} Simple Moving Average')\n",
        "  #  plt.legend(loc='best')\n",
        "  plt.title(f'{acorpus} Simple Moving Average')    \n",
        "  plt.legend(loc='best')\n",
        "  corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True).mean().plot(label='z-Score Median', style=['r*-'], linewidth=2.0)\n",
        "  plt.show();\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx_98LiHdmPe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGAyLsV2btn2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYRtM17Pb11c"
      },
      "source": [
        "# **DTW Hierarchical Clustering**\n",
        "\n",
        "* https://github.com/wannesm/dtaidistance\n",
        "\n",
        "* https://dtaidistance.readthedocs.io/en/latest/usage/clustering.html\n",
        "\n",
        "* DTW w/Hierachical Clustering https://github.com/wannesm/dtaidistance\n",
        "\n",
        "* HITL/Interactive Clustering (DTAIDistance+COBRAS) https://github.com/ML-KULeuven/cobras \n",
        "\n",
        "* https://github.com/markdregan/K-Nearest-Neighbors-with-Dynamic-Time-Warping\n",
        "\n",
        "* https://github.com/timeseriesAI/tsai\n",
        "\n",
        "* https://github.com/tslearn-team/tslearn\n",
        "\n",
        "* https://stats.stackexchange.com/questions/131281/dynamic-time-warping-clustering\n",
        "\n",
        "* https://stats.stackexchange.com/questions/109343/dynamic-time-warping-for-irregular-time-series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc25Hc2E8K5L"
      },
      "source": [
        "!pip install dtaidistance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOgda-tJLv4b"
      },
      "source": [
        "from dtaidistance import dtw\n",
        "from dtaidistance import clustering\n",
        "from dtaidistance import dtw_visualisation as dtwvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shTeMM6abtjy"
      },
      "source": [
        "corpora_all25_dt.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXPAVORq7wpW"
      },
      "source": [
        "corpora_all25_dt['cdickens_achristmascarol'].columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF0YbYyuKgG5"
      },
      "source": [
        "models_all25_ls = corpora_all25_dt['cdickens_achristmascarol'].columns.tolist()\n",
        "type(models_all25_ls)\n",
        "models_all25_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJpLhuD8OSO5"
      },
      "source": [
        "list(corpora_all25_dt.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuADTll_3MgV"
      },
      "source": [
        "## **TEMP STOP 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25m5ZJY0bgvg"
      },
      "source": [
        "corpora_all25_dt['cdickens_achristmascarol'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q9DOnZMKT8w"
      },
      "source": [
        "# DTW Hierarchical Clustering for every Model per each Corpus\n",
        "\n",
        "# Flag to indicate save plot to file\n",
        "save_plots = False\n",
        "\n",
        "# Dict[Corpus] of all Distance Matricies \n",
        "corpora_all_dist_dt = {}\n",
        "\n",
        "# Create list of 1D vectorized distance matricies (one for each Corpus with Model distances)\n",
        "corpora_all25vec_dt = {}\n",
        "\n",
        "# Get lists of LTTB Dimensionality-Reduced Corpora/Models\n",
        "corpora_all25_ls = list(corpora_all25_dt.keys())\n",
        "\n",
        "for i, acorpus in enumerate(corpora_all25_ls): # [:2]):\n",
        "  # print(f'Processing Corpus: {acorpus}')\n",
        "\n",
        "  models_all25_ls = corpora_all25_dt[acorpus].columns.tolist()\n",
        "\n",
        "  models_all25_ls = [i if i != 'logreg_cv_z_25lttb' else 'logreg-cv_z_25lttb' for i in models_all25_ls]\n",
        "  models_all25_ls = [i if i != 'jockers_rinker_z_25lttb' else 'jockers-rinker_z_25lttb' for i in models_all25_ls]\n",
        "\n",
        "  models_all25_ls = [i.split('_')[0] for i in models_all25_ls]\n",
        "\n",
        "  print(f'Corpus #{i} {acorpus} has {len(corpora_all25_dt[acorpus].columns)} model columns')\n",
        "\n",
        "  aseries = corpora_all25_dt[acorpus].to_numpy().T\n",
        "  print(f'aseries.shape: {aseries.shape}')\n",
        "  \n",
        "  ds = dtw.distance_matrix_fast(aseries) #  block=((1, 4), (3, 5)))\n",
        "  corpora_all_dist_dt[acorpus] = ds\n",
        "\n",
        "  # Convert upper triangular part of this Distance Matrix (not incl diag) into 1D vector\n",
        "  ds_1d = ds[np.triu_indices(ds.shape[0], k = 1)] # offset\n",
        "  corpora_all25vec_dt[acorpus] = ds_1d\n",
        "\n",
        "  # Custom Hierarchical clustering\n",
        "  model1 = clustering.Hierarchical(dtw.distance_matrix, {})\n",
        "  cluster_idx = model1.fit(aseries)\n",
        "  # Augment Hierarchical object to keep track of the full tree\n",
        "  model2 = clustering.HierarchicalTree(model1, tr_left_margin=0) # , tr_label_margin=-10)\n",
        "  cluster_idx = model2.fit(aseries)\n",
        "\n",
        "  # SciPy linkage clustering\n",
        "  model3 = clustering.LinkageTree(dtw.distance_matrix, {})\n",
        "  cluster_idx = model3.fit(aseries)\n",
        "\n",
        "  # Plot Agglomerative Hierarchical Tree and Save as file\n",
        "  fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(40,40))\n",
        "  # show_ts_label = lambda idx: \"ts-\" + str(idx)\n",
        "  show_ts_label = lambda idx: models_all25_ls[idx]\n",
        "  fig.tight_layout()\n",
        "  fig.subplots_adjust(top=0.95)\n",
        "  corpus_title = f'{acorpus}'\n",
        "  fig.suptitle(corpus_title)\n",
        "  acorpus = f'{acorpus}'\n",
        "  filename_path = f'./data_corpora_plots/plot_dtw25_{acorpus}.png'\n",
        "  if save_plots:\n",
        "    # Save Plot to File\n",
        "    model2.plot(filename_path, axes=ax, show_ts_label=show_ts_label, # True, # lttb_cols_ls,\n",
        "              show_tr_label=True, ts_label_margin=0,\n",
        "              ts_left_margin=0, tr_label_margin=0.1) #  ts_sample_length=1)\n",
        "    # Display Plot File\n",
        "    Image(filename_path)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "  else:\n",
        "    # Just Display Plots (no save to file)\n",
        "    model2.plot(axes=ax, show_ts_label=show_ts_label, # True, # lttb_cols_ls,\n",
        "              show_tr_label=True, ts_label_margin=0,\n",
        "              ts_left_margin=0, tr_label_margin=0.1) #  ts_sample_length=1)\n",
        "    plt.show()    \n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7TCMX1ZM0c3"
      },
      "source": [
        "print(corpora_all_dist_dt['cdickens_achristmascarol'].shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yQLH4FlMlY5"
      },
      "source": [
        "type(corpora_all25vec_dt['cdickens_achristmascarol'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSbgT2X5krhB"
      },
      "source": [
        "temp_df = pd.DataFrame(corpora_all_dist_dt['cdickens_achristmascarol'])\n",
        "temp_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y93ylqfMvUQh"
      },
      "source": [
        "models_all25_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXbeAb2fwHL5"
      },
      "source": [
        "## **Visualize Distance Matrix as Network**\n",
        "\n",
        "* https://stackoverflow.com/questions/46712208/networkx-draw-network-from-distance-matrix-in-pandas-dataframe-from/51126772\n",
        "* https://networkx.org/documentation/latest/reference/generated/networkx.relabel.relabel_nodes.html\n",
        "* https://orangedatamining.com/widget-catalog/networks/networkexplorer/\n",
        "* (related) https://github.com/ResidentMario/missingno"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT2cyqmxNRHQ"
      },
      "source": [
        "with np.printoptions(threshold=np.inf):\n",
        "  print(corpora_all_dist_dt['cdickens_achristmascarol'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS2a8rTbuquI"
      },
      "source": [
        "import networkx as nx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bU5I0LDuocG"
      },
      "source": [
        "%%time\n",
        "\n",
        "# NOTE:\n",
        "\n",
        "G = nx.from_numpy_matrix(temp_df.values)\n",
        "\n",
        "# labels = temp_df.columns.values\n",
        "labels = models_all25_ls\n",
        "\n",
        "G = nx.relabel_nodes(G, dict(zip(range(len(labels)), labels)))\n",
        "\n",
        "nx.draw(G, with_labels=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IvRVnSMwyHt"
      },
      "source": [
        "%%time\n",
        "\n",
        "# NOTE:\n",
        "\n",
        "# https://stackoverflow.com/questions/60859554/runtimeerror-filtering-the-edges-with-weight-below-the-threshold-networkx\n",
        "\n",
        "F = G.copy()\n",
        "threshold = 0.8 # 0.4\n",
        "F.remove_edges_from([(n1, n2) for n1, n2, w in F.edges(data=\"weight\") if w < threshold])\n",
        "nx.draw(F, with_labels=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c3OeRqzysd-"
      },
      "source": [
        "## **Voronoi Diagram**\n",
        "\n",
        "* https://stackoverflow.com/questions/3081066/what-techniques-exists-in-r-to-visualize-a-distance-matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DveNCMoysNe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZxmdklCxpE2"
      },
      "source": [
        "## **Distance Between 2 Networks**\n",
        "\n",
        "* https://netrd.readthedocs.io/en/latest/distance.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE85DmL0UbLP"
      },
      "source": [
        "## **Save Distance Matrices and Vectorizations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx3jugEgUaXR"
      },
      "source": [
        "# Save all Corpora with both old and new LTTB reduced Models\n",
        "\n",
        "# SAVE: corpora_all25vec_dt\n",
        "\n",
        "subdir_out = 'data_corpora_all'\n",
        "\n",
        "filename_out = f'models_all25vec'\n",
        "fullpath_out = f'./{subdir_out}/{filename_out}'\n",
        "\n",
        "try:\n",
        "  fp = open(fullpath_out, 'wb')\n",
        "  pickle.dump(corpora_all25vec_dt, fp)\n",
        "  fp.close()\n",
        "  print(f'Saved {fullpath} to pickle file')\n",
        "  \n",
        "except:\n",
        "    print(f'ERROR: Could not save {fullpath_out} to pickle file')\n",
        "\n",
        "\n",
        "# SAVE: corpora_all_dist_dt\n",
        "\n",
        "filename_out = f'models_allvec_dist'\n",
        "fullpath_out = f'./{subdir_out}/{filename_out}'\n",
        "\n",
        "try:\n",
        "  fp = open(fullpath_out, 'wb')\n",
        "  pickle.dump(corpora_all_dist_dt, fp)\n",
        "  fp.close()\n",
        "  print(f'Saved {fullpath_out} to pickle file')\n",
        "\n",
        "except:\n",
        "    print(f'ERROR: Could not save {fullpath} to pickle file')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l12l46VCXTFg"
      },
      "source": [
        "import pickle\n",
        "  \n",
        "\n",
        "corpora_all25vec_dt\n",
        "\n",
        "corpora_all_dist_dt\n",
        "\n",
        "  \n",
        "try:\n",
        "    geeky_file = open('geekyfile', 'wb')\n",
        "    pickle.dump(dictionary, geeky_file)\n",
        "    geeky_file.close()\n",
        "  \n",
        "except:\n",
        "    print(\"Something went wrong\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMBcHf3RHZSP"
      },
      "source": [
        "# **Model Stability in Hierarchical Tree**\n",
        "\n",
        "Per Corpus and across all Corpora, compute a Stability Metric per Model and Model Type:\n",
        "\n",
        "* Model Type Stability: Lexicon, AutoML, DNN, BERT by Weighted Clustering Formula\n",
        "* Individual Model Stability: by %variability of every other model by degree of closeness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvq5NHL-HZIB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mtBpLm2HZEp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj8hm5EhHZAN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfkH4TrwUA-w"
      },
      "source": [
        "# **Cluster Distance Matrices**\n",
        "\n",
        "* https://machinelearningmastery.com/clustering-algorithms-with-python/\n",
        "\n",
        "* https://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html \n",
        "\n",
        "* https://www.geeksforgeeks.org/implementing-dbscan-algorithm-using-sklearn/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXppIVltJDYm"
      },
      "source": [
        "## **Option (a) Read Universal Matrix of Distance Matricies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2ycANx6JC19"
      },
      "source": [
        "# DOES NOT WORK\n",
        "\n",
        "# Read Universal Matrix of all Vectorized Distance Matricies (one per Corpus)\n",
        "\n",
        "subdir_name = 'data_corpora_all'\n",
        "\n",
        "filename_data = f'models_all_dist_matrix.csv'\n",
        "fullpath_name = f'./{subdir_name}/{filename_data}'\n",
        "\n",
        "dist_vecs_df = pd.read_csv(fullpath_name)\n",
        "\n",
        "print(f'\\n\\n  Read Universal Matrix with shape: {dist_vecs_df.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eggKYVADJNBd"
      },
      "source": [
        "## **Option (b): Generate Universal Matrix of Distance Matricies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elpzhIpnUG29"
      },
      "source": [
        "# Vectorized 1D Distance Matrices saved in corpora_all25v_dt\n",
        "\n",
        "corpora_all25v_dt.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TYMFf8yaSf2"
      },
      "source": [
        "corpora_all25v_dt['cdickens_achristmascarol']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILNoJI9UaxgJ"
      },
      "source": [
        "# Convert Dictionary of Vectors into Numpy Array\n",
        "\n",
        "dist_vecs_obj = corpora_all25v_dt.values()\n",
        "models_obj = corpora_all25v_dt.items()\n",
        "\n",
        "# Convert object to a list\n",
        "data_ls = list(dist_vecs_obj)\n",
        "model_ls = list(models_obj)\n",
        "\n",
        "# Convert list to an array\n",
        "dist_np = np.array(data_ls)\n",
        "  \n",
        "# print the numpy array\n",
        "print(dist_np)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYngloXab3oa"
      },
      "source": [
        "dist_vecs_df = pd.DataFrame(corpora_all25v_dt)\n",
        "dist_vecs_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3g1FWtPJZBk"
      },
      "source": [
        "## **Save Universal Matrix of all Vectorized Distance Matricies (one per Corpus)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ3y_WTUURzs"
      },
      "source": [
        "# # Save Vectorized Distance Matricies\n",
        "\n",
        "subdir_out = 'data_corpora_all'\n",
        "\n",
        "filename_out = f'models_all_dist_matrix.csv'\n",
        "fullpath_out = f'./{subdir_out}/{filename_out}'\n",
        "\n",
        "print(f'\\nSaving Single Matrix containing a row of 1D Vectorized Distance Matricies for each of the {dist_vecs_df.shape[1]} Corpus (distance between Models)')\n",
        "dist_vecs_df.to_csv(fullpath_out)\n",
        "\n",
        "print(f'\\n\\n  Matrix shape: {dist_vecs_df.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fFvPobVJgfc"
      },
      "source": [
        "## **Heatmap of Universal Matrix of Vectorized Distance Matricies (one per Corpus)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B39LCVPtbNHo"
      },
      "source": [
        "import seaborn as sns; sns.set(color_codes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKPTg8LkjwiD"
      },
      "source": [
        "dist_vecs_T_df = pd.DataFrame()\n",
        "dist_vecs_T_df = dist_vecs_df.T # pivot(columns=[i for i in range(35)])\n",
        "dist_vecs_T_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QjM-UB-b_jy"
      },
      "source": [
        "dist_vecs_T_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spO_uA5QbRXb"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Hint:\n",
        "\n",
        "# Cluster \n",
        "# https://colab.research.google.com/github/saskeli/data-analysis-with-python-summer-2019/blob/master/clustering.ipynb#scrollTo=8u0WPsxaYUkZ\n",
        "\n",
        "\n",
        "# iris = sns.load_dataset(\"iris\")\n",
        "# species = iris.pop(\"species\")   # Remove the species column\n",
        "# print(species.unique())         # The samples seems to be from these three species\n",
        "\n",
        "# plt.rcParams[\"figure.figsize\"] = (40,40)\n",
        "# sns.set(rc={'figure.figsize':(20, 20)})\n",
        "# plt.figure(figsize=(40,40))\n",
        "# fig, ax = plt.subplots()\n",
        "# fig.set_size_inches(20, 20)\n",
        "\n",
        "sns.set(font_scale=1.8)\n",
        "# g = sns.clustermap(dist_vecs_T_df, method=\"ward\", col_cluster=False, cbar_kws={'label': 'distance'}, figsize=(30,30)); # Cluster only the rows\n",
        "# g = sns.clustermap(dist_vecs_T_df, method=\"ward\", col_cluster=False, cbar_kws={'label': 'distance'}, z_score=0, cmap=\"vlag\", figsize=(30,30)); # Cluster only the rows\n",
        "g = sns.clustermap(dist_vecs_T_df, method=\"ward\", col_cluster=False, cbar_kws={'label': 'distance'}, standard_scale=1, cmap=\"vlag\", figsize=(30,30)); # Cluster only the rows\n",
        "g.fig.suptitle('Distance Between Corpora based upon Sentiment Model Distances') \n",
        "#plt.colorbar().ax.set_title('This is a title')\n",
        "#plt.gca().images[-1].colorbar.ax.set_title(\"title\")\n",
        "\n",
        "subdir_out = 'data_corpora_plots'\n",
        "\n",
        "filename_out = f'models_all_dist_matrix.png'\n",
        "fullpath_out = f'./{subdir_out}/{filename_out}'\n",
        "\n",
        "plt.savefig(fullpath_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GujUuHAO1RK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb8MIfWTO1M0"
      },
      "source": [
        "# https://towardsdatascience.com/heatmap-basics-with-pythons-seaborn-fb92ea280a6c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgylMAYFOix5"
      },
      "source": [
        "# read dataset\n",
        "df = pd.read_csv('data/cereal.csv')\n",
        "# get correlations\n",
        "df_corr = df.corr()\n",
        "# irrelevant fields\n",
        "fields = ['rating', 'shelf', 'cups', 'weight']\n",
        "# drop rows\n",
        "df_corr.drop(fields, inplace=True)\n",
        "# drop cols\n",
        "df_corr.drop(fields, axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NytpBybmOitC"
      },
      "source": [
        "mask = np.triu(np.ones_like(df_corr, dtype=np.bool))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZBYVD-lOinh"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "# mask\n",
        "mask = np.triu(np.ones_like(df_corr, dtype=np.bool))\n",
        "# adjust mask and df\n",
        "mask = mask[1:, :-1]\n",
        "corr = df_corr.iloc[1:,:-1].copy()\n",
        "# plot heatmap\n",
        "sb.heatmap(corr, mask=mask, annot=True, fmt=\".2f\", cmap='Blues',\n",
        "           vmin=-1, vmax=1, cbar_kws={\"shrink\": .8})\n",
        "# yticks\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66aZ3bJtOzQg"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "# mask\n",
        "mask = np.triu(np.ones_like(df_corr, dtype=np.bool))\n",
        "# adjust mask and df\n",
        "mask = mask[1:, :-1]\n",
        "corr = df_corr.iloc[1:,:-1].copy()\n",
        "# color map\n",
        "cmap = sb.diverging_palette(0, 230, 90, 60, as_cmap=True)\n",
        "# plot heatmap\n",
        "sb.heatmap(corr, mask=mask, annot=True, fmt=\".2f\", \n",
        "           linewidths=5, cmap=cmap, vmin=-1, vmax=1, \n",
        "           cbar_kws={\"shrink\": .8}, square=True)\n",
        "# ticks\n",
        "yticks = [i.upper() for i in corr.index]\n",
        "xticks = [i.upper() for i in corr.columns]\n",
        "plt.yticks(plt.yticks()[0], labels=yticks, rotation=0)\n",
        "plt.xticks(plt.xticks()[0], labels=xticks)\n",
        "# title\n",
        "title = 'CORRELATION MATRIX\\nSAMPLED CEREALS COMPOSITION\\n'\n",
        "plt.title(title, loc='left', fontsize=18)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rElLLMt-OzMX"
      },
      "source": [
        "# Scatter and kde Density Plot\n",
        "\n",
        "fig, ax = plt.subplots(1, figsize=(12,8))\n",
        "sb.kdeplot(df.potass, df.fiber, cmap='Blues',\n",
        "           shade=True, shade_lowest=False, clip=(-1,300))\n",
        "plt.scatter(df.potass, df.fiber, color='orangered')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwG9SCMcOzHc"
      },
      "source": [
        "# https://towardsdatascience.com/reordering-pandas-dataframe-columns-thumbs-down-on-standard-solutions-1ff0bc2941d5\n",
        "\n",
        "def movecol(df, cols_to_move=[], ref_col='', place='After'):\n",
        "    \n",
        "    cols = df.columns.tolist()\n",
        "    if place == 'After':\n",
        "        seg1 = cols[:list(cols).index(ref_col) + 1]\n",
        "        seg2 = cols_to_move\n",
        "    if place == 'Before':\n",
        "        seg1 = cols[:list(cols).index(ref_col)]\n",
        "        seg2 = cols_to_move + [ref_col]\n",
        "    \n",
        "    seg1 = [i for i in seg1 if i not in seg2]\n",
        "    seg3 = [i for i in cols if i not in seg1 + seg2]\n",
        "    \n",
        "    return(df[seg1 + seg2 + seg3])\n",
        "  \n",
        "# Test\n",
        "\n",
        "df = movecol(df, \n",
        "             cols_to_move=['Score','Grade'], \n",
        "             ref_col='Room',\n",
        "             place='After')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy5KAzFtOigI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvjVjrrJejsU"
      },
      "source": [
        "# DBSCAN Clustering\n",
        "\n",
        "# https://www.geeksforgeeks.org/implementing-dbscan-algorithm-using-sklearn/\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "  \n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiWIWlpsejo8"
      },
      "source": [
        "# Scaling the data to bring all the attributes to a comparable level\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(dist_vecs_df)\n",
        "  \n",
        "# Normalizing the data so that \n",
        "# the data approximately follows a Gaussian distribution\n",
        "X_normalized = normalize(X_scaled)\n",
        "  \n",
        "# Converting the numpy array into a pandas DataFrame\n",
        "X_normalized = pd.DataFrame(X_normalized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVPjdrgWejjs"
      },
      "source": [
        "#  Reducing the dimensionality of the data to make it visualizable\n",
        "\n",
        "pca = PCA(n_components = 2)\n",
        "X_principal = pca.fit_transform(X_normalized)\n",
        "X_principal = pd.DataFrame(X_principal)\n",
        "X_principal.columns = ['P1', 'P2']\n",
        "print(X_principal.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F04IoCFUejfT"
      },
      "source": [
        "# Numpy array of all the cluster labels assigned to each data point\n",
        "\n",
        "db_default = DBSCAN(eps = 0.0375, min_samples = 2).fit(X_principal)\n",
        "labels = db_default.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpfG-taUfbqk"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpUtSo4pgkIk"
      },
      "source": [
        "np.min(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVNKyEH6gtYC"
      },
      "source": [
        "np.max(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlX1jwhggtND"
      },
      "source": [
        "np.unique(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aykrwmzehANB"
      },
      "source": [
        "4%3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCXlJni8ejaw"
      },
      "source": [
        "# Building the label to colour mapping\n",
        "\n",
        "# https://www.geeksforgeeks.org/implementing-dbscan-algorithm-using-sklearn/ \n",
        "\n",
        "colours = {}\n",
        "\n",
        "label_max = np.max(labels)\n",
        "for i in range(label_max+1):\n",
        "  i_scaled = (i/label_max)\n",
        "  colours[i] = (i_scaled, i_scaled, i_scaled)\n",
        "\n",
        "\n",
        "# colours[0] = 'r'\n",
        "# colours[1] = 'g'\n",
        "# colours[2] = 'b'\n",
        "colours[-1] = 'k'\n",
        "# colours[3] = 'k'\n",
        "\n",
        "# Building the colour vector for each data point\n",
        "cvec = [colours[label%4] for label in labels]\n",
        "  \n",
        "# For the construction of the legend of the plot\n",
        "r = plt.scatter(X_principal['P1'], X_principal['P2'], color ='r');\n",
        "g = plt.scatter(X_principal['P1'], X_principal['P2'], color ='g');\n",
        "b = plt.scatter(X_principal['P1'], X_principal['P2'], color ='b');\n",
        "k = plt.scatter(X_principal['P1'], X_principal['P2'], color ='k');\n",
        "  \n",
        "# Plotting P1 on the X-Axis and P2 on the Y-Axis \n",
        "# according to the colour vector defined\n",
        "plt.figure(figsize =(9, 9))\n",
        "plt.scatter(X_principal['P1'], X_principal['P2'], c = cvec)\n",
        "  \n",
        "# Building the legend\n",
        "plt.legend((r, g, b, k), ('Label 0', 'Label 1', 'Label 2', 'Label -1'))\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww2Nn1OZejW_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WUmUHbPf2CV"
      },
      "source": [
        "# https://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html \n",
        "\n",
        "print(__doc__)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# #############################################################################\n",
        "# Generate sample data\n",
        "centers = [[1, 1], [-1, -1], [1, -1]]\n",
        "X, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,\n",
        "                            random_state=0)\n",
        "\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "# #############################################################################\n",
        "# Compute DBSCAN\n",
        "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
        "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
        "core_samples_mask[db.core_sample_indices_] = True\n",
        "labels = db.labels_\n",
        "\n",
        "# Number of clusters in labels, ignoring noise if present.\n",
        "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "n_noise_ = list(labels).count(-1)\n",
        "\n",
        "print('Estimated number of clusters: %d' % n_clusters_)\n",
        "print('Estimated number of noise points: %d' % n_noise_)\n",
        "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
        "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
        "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
        "print(\"Adjusted Rand Index: %0.3f\"\n",
        "      % metrics.adjusted_rand_score(labels_true, labels))\n",
        "print(\"Adjusted Mutual Information: %0.3f\"\n",
        "      % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
        "print(\"Silhouette Coefficient: %0.3f\"\n",
        "      % metrics.silhouette_score(X, labels))\n",
        "\n",
        "# #############################################################################\n",
        "# Plot result\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Black removed and is used for noise instead.\n",
        "unique_labels = set(labels)\n",
        "colors = [plt.cm.Spectral(each)\n",
        "          for each in np.linspace(0, 1, len(unique_labels))]\n",
        "for k, col in zip(unique_labels, colors):\n",
        "    if k == -1:\n",
        "        # Black used for noise.\n",
        "        col = [0, 0, 0, 1]\n",
        "\n",
        "    class_member_mask = (labels == k)\n",
        "\n",
        "    xy = X[class_member_mask & core_samples_mask]\n",
        "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
        "             markeredgecolor='k', markersize=14)\n",
        "\n",
        "    xy = X[class_member_mask & ~core_samples_mask]\n",
        "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
        "             markeredgecolor='k', markersize=6)\n",
        "\n",
        "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SElJId3if19Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEl-kUECf14F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhgdDasqbWNa"
      },
      "source": [
        "iris.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o99xq6oCc_zG"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (40,40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOm_kie4UGu1"
      },
      "source": [
        "# Cluster \n",
        "# https://colab.research.google.com/github/saskeli/data-analysis-with-python-summer-2019/blob/master/clustering.ipynb#scrollTo=8u0WPsxaYUkZ\n",
        "\n",
        "\n",
        "iris = sns.load_dataset(\"iris\")\n",
        "species = iris.pop(\"species\")   # Remove the species column\n",
        "print(species.unique())         # The samples seems to be from these three species\n",
        "sns.clustermap(iris, method=\"ward\", col_cluster=False, cbar_kws={'label': 'centimeters'}); # Cluster only the rows\n",
        "#plt.colorbar().ax.set_title('This is a title')\n",
        "#plt.gca().images[-1].colorbar.ax.set_title(\"title\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlP_IZpTUVka"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ySYwtCXUGqs"
      },
      "source": [
        "# Dimensionality Reduction and Visualization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78o89FHOUVYI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqk9FgF6QhY3"
      },
      "source": [
        "# **END OF NOTEBOOK**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bul5lZQJL0os"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP22YKd2L0hX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoalZBHO8BM-"
      },
      "source": [
        "s1 = np.array([0., 0, 1, 2, 1, 0, 1, 0, 0, 2, 1, 0, 0, 0, 1, 1])\n",
        "s2 = np.array([0., 1, 2, 3, 1, 0, 0, 0, 2, 1, 0, 0, 0])\n",
        "path = dtw.warping_path(s1, s2)\n",
        "\n",
        "dtwvis.plot_warping(s1, s2, path, filename=\"warp.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE9sL1ciuH6f"
      },
      "source": [
        "from IPython.display import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yK38I0A8BJC"
      },
      "source": [
        "Image('warp.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAyFuoqfD8mK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x2G4B-luwLS"
      },
      "source": [
        "corpora_all25_dt.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZWr1THiuwLT"
      },
      "source": [
        "lttb_cols_ls = corpora_all25_dt['cdickens_achristmascarol'].columns.to_list()\n",
        "# lttb_cols_ls.sort()\n",
        "\n",
        "\n",
        "lttb_cols_ls = [i if i != 'logreg_cv_z_25lttb' else 'logreg-cv_z_25lttb' for i in lttb_cols_ls]\n",
        "lttb_cols_ls = [i if i != 'jockers_rinker_z_25lttb' else 'jockers-rinker_z_25lttb' for i in lttb_cols_ls]\n",
        "\n",
        "lttb_cols_ls = [i.split('_')[0] for i in lttb_cols_ls]\n",
        "print(lttb_cols_ls)\n",
        "len(lttb_cols_ls)\n",
        "\n",
        "# [unicode(x.strip()) if x is not None else '' for x in row]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qeoj9B6juzBu"
      },
      "source": [
        "corpora_all25_dt['cdickens_achristmascarol'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywjxux9XvJLq"
      },
      "source": [
        "series = corpora_all25_dt['cdickens_achristmascarol'].to_numpy().T\n",
        "series"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ7vdyxVUdV-"
      },
      "source": [
        "series.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8aHuwMLulgZ"
      },
      "source": [
        "%%time\n",
        "\n",
        "# NOTE:\n",
        "\n",
        "ds = dtw.distance_matrix_fast(series) #  block=((1, 4), (3, 5)))\n",
        "\n",
        "# OR\n",
        "\n",
        "# ds = dtw.distance_matrix(series) # , block=((1, 4), (3, 5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVCtbPmp6udC"
      },
      "source": [
        "ds = dtw.distance_matrix(series) # , compact=True) # , block=((1, 4), (3, 5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhAhhr4S7AcD"
      },
      "source": [
        "ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJWuOxgfUivw"
      },
      "source": [
        "ds.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgF0VQvUVabf"
      },
      "source": [
        "35*35"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLnw8UiUUpiI"
      },
      "source": [
        "X = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
        "#array([[1, 2, 3],\n",
        "#       [4, 5, 6],\n",
        "#       [7, 8, 9]])\n",
        "\n",
        "#get the upper triangular part of this matrix\n",
        "v = X[np.triu_indices(X.shape[0], k = 1)] # offset\n",
        "print(v)\n",
        "# [2 3 6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0atbQhFVOO9"
      },
      "source": [
        "ds_1d = ds[np.triu_indices(ds.shape[0], k=1)]\n",
        "len(ds_1d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjavk1KCVOKn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geKdAmiAVOG_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrmChaciH7xc"
      },
      "source": [
        "import seaborn as sns; sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K_BtZXtH4ld"
      },
      "source": [
        "ax = sns.heatmap(ds, annot=True, fmt=\"d\")\n",
        "\n",
        "plt.title(\"How to visualize (plot) \\n a numpy array in python using seaborn ?\",fontsize=12)\n",
        "\n",
        "plt.savefig(\"visualize_numpy_array_01.png\", bbox_inches='tight', dpi=100)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHxBS773wCZL"
      },
      "source": [
        "%%time\n",
        "\n",
        "# NOTE:\n",
        "\n",
        "# Custom Hierarchical clustering\n",
        "model1 = clustering.Hierarchical(dtw.distance_matrix, {})\n",
        "cluster_idx = model1.fit(series)\n",
        "\n",
        "# Augment Hierarchical object to keep track of the full tree\n",
        "model2 = clustering.HierarchicalTree(model1, tr_left_margin=0) # , tr_label_margin=-10)\n",
        "cluster_idx = model2.fit(series)\n",
        "\n",
        "# SciPy linkage clustering\n",
        "model3 = clustering.LinkageTree(dtw.distance_matrix, {})\n",
        "cluster_idx = model3.fit(series)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAOHLFQ34_1L"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmKbTzIi5Jct"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (40, 40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTMxmAb24OHN"
      },
      "source": [
        "%%time\n",
        "\n",
        "# NOTE:\n",
        "\n",
        "# model2.plot(ts_label_margin=0, show_ts_label=lttb_cols_ls, show_tr_label=True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1B1_qiUCLSo"
      },
      "source": [
        "plt.rcParams.update({'font.size': 20})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z5_8fgc_KJa"
      },
      "source": [
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(40,40))\n",
        "# show_ts_label = lambda idx: \"ts-\" + str(idx)\n",
        "show_ts_label = lambda idx: lttb_cols_ls[idx]\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(top=0.95)\n",
        "corpus_title = 'A Christmas Carol by Charles Dickens'\n",
        "fig.suptitle(corpus_title)\n",
        "acorpus = f'cdickens_achristmascarol'\n",
        "filename_path = f'./data_corpora_plots/plot_dtw25_{acorpus}.png'\n",
        "model2.plot(filename_path, axes=ax, show_ts_label=show_ts_label, # True, # lttb_cols_ls,\n",
        "           show_tr_label=True, ts_label_margin=0,\n",
        "           ts_left_margin=0, tr_label_margin=0.1) #  ts_sample_length=1)\n",
        "\n",
        "Image(filename_plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZOlPRGgFSAn"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUhaLAr0wCZN"
      },
      "source": [
        "model2.plot(\"myplot.png\", show_ts_label=True, show_tr_label=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7j2LdO30z2N"
      },
      "source": [
        "Image('myplot.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJJqLI4nulXY"
      },
      "source": [
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(40,40))\n",
        "# show_ts_label = lambda idx: \"ts-\" + str(idx)\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(top=0.95)\n",
        "fig.suptitle('A Christmas Carol by Charles Dickens')\n",
        "# fig.title('A Christmas Carol by Charles Dickens')\n",
        "model3.plot(axes=ax, show_ts_label=lttb_cols_ls,\n",
        "           show_tr_label=True, ts_label_margin=0,\n",
        "           ts_left_margin=0, tr_label_margin=0.1) #  ts_sample_length=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8nL-axuulUD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpqAfeq4ulQQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZNgdGyeulMm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0bX-TL677-H"
      },
      "source": [
        "# **END OF NOTEBOOK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYQ3UterjMJF"
      },
      "source": [
        "# **Get Corpora**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6BTm4_mk-M7"
      },
      "source": [
        "corpora_ls[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1uV3CSqk8TB"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Fts10_lF6C"
      },
      "source": [
        "corpus_name = corpora_ls[0]\n",
        "\n",
        "!ls -altr $corpus_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s42B_qHLlYwd"
      },
      "source": [
        "temp_df = pd.read_csv(f'./{corpus_name}/corpus_text_sents_clean_{corpus_name}.csv')\n",
        "temp_df.rename(columns={'Unnamed: 0':'sent_no'}, inplace=True)\n",
        "temp_df['sent_clean'] = temp_df['sent_clean'].astype('string')\n",
        "temp_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtplBhyWk6z0"
      },
      "source": [
        "temp_df = f'./{corpora_ls[0]}/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0l-WY269us0"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ApuWfaAkSTv"
      },
      "source": [
        "# Get a Dictionary of clean text for every item in the corpora (listed in corpora_ls)\n",
        "\n",
        "corpora_dt = {}\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(f'\\nREADING #{i}: {acorpus}\\n========================================\\n')\n",
        "  # os.listdir(adir)\n",
        "  corpus_csv = f'./{acorpus}/corpus_text_sents_clean_{acorpus}.csv'\n",
        "  print(f'{os.getcwd()}\\n     {corpus_csv}')\n",
        "  temp_df = pd.DataFrame()\n",
        "  temp_df = pd.read_csv(corpus_csv, encoding='ISO-88591')\n",
        "  temp_df.rename(columns={'Unnamed: 0':'sent_no'}, inplace=True)\n",
        "  temp_df['sent_clean'] = temp_df['sent_clean'].astype('string')\n",
        "  corpora_dt[acorpus] = temp_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3BgRRT5NBiu"
      },
      "source": [
        "corpora_dt['cdickens_achristmascarol'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd2F-Onkm5n8"
      },
      "source": [
        "len(corpora_dt.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCtS7awhkR4S"
      },
      "source": [
        "[f'{corpus_name}' for corpus_name in corpora_dt.keys()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auUsC0WWod8N"
      },
      "source": [
        "corpora_dt['cdickens_achristmascarol'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLtU2fu9sYvs"
      },
      "source": [
        "corpora_dt['cdickens_achristmascarol'].info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESGThFMlojv0"
      },
      "source": [
        "corpora_dt['cdickens_achristmascarol'].shape"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}