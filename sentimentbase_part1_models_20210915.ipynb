{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentimentbase_part1_models_20210915.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lR2Yy930dpe6",
        "ot6VpHC7KkIJ",
        "u932nJxdh0Ac",
        "yHhgMMFIG-WC",
        "lTeszVJnmTXj",
        "Aozb5eJlGa7t",
        "KBBV8mIPvQc8",
        "M4kOFpSaoE2R",
        "HLnBb5AdHO0a",
        "XvcCyYAUHREu",
        "GWC94af-HfwO",
        "KiVDI0rj8bU4",
        "aMLbyx6gIPqj",
        "2CEiOZzv5lw9",
        "XUvKJEybUIeP",
        "yXwKR4gA8Ouk",
        "3YJJcvDVnUuT",
        "qjb60CVnz5SF",
        "PVCkjat0vffd",
        "YFC8GTnw6HrG",
        "j2tIua7tTSRz",
        "XbvcZo4oiCa7",
        "QZjqwTvU76AR",
        "NA3dWsnF78mi",
        "SkNZVk128jV9",
        "dUcANLM_8mtT",
        "Cn4KQYpH3glK",
        "jRTjCPLb8cbB",
        "gAEiglIPDfFI",
        "iCN4c-G48e7-",
        "G2blGfVlKb_s",
        "wsaziON_Z263",
        "AIGQgWvyOtg6"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jon-chun/sentimentarcs/blob/main/sentimentbase_part1_models_20210915.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibHFmIWoU3Vx"
      },
      "source": [
        "# **An Analytic Methodology to Extract Narratives from Text: Using Sentiment Analysis to find the Arcs and Crux Points in Novels, Social Media and Chat Transcripts**\n",
        "\n",
        "By: Jon Chun\n",
        "12 Jun 2021\n",
        "\n",
        "References:\n",
        "\n",
        "* Coming...\n",
        "\n",
        "TODO:\n",
        "* Demo datafiles\n",
        "* Error detection around Crux points context (out of bounds)\n",
        "* lex_discrete2continous (research binary->gaussian transformation fn)\n",
        "* Text Preprocessing hints/tips/flowchart\n",
        "* Clearly document workflow and partition across notebooks/libraries\n",
        "* Code review and extraction to libraries\n",
        "* Corpus ingestion for any format\n",
        "* XAI (mlm false peak 1717SyuzhetR/1732SentimentR/1797robertalg15 adam watches war argument at dinner) \n",
        "* Centralize and Standardize Model name lists\n",
        "* Normalize model SA Series lengths\n",
        "* Standardize all SA Series with the same method\n",
        "* Seamless report generation/file saving\n",
        "* Get raw text from SentimentR\n",
        "* Filter out non-printable characters\n",
        "* Roll-over Crux-Points (SentNo+Sent/Parag) (plotly)\n",
        "* Label/Roll-over Chapter/Sect No at Boundries\n",
        "* Generate Report PDF/csv\n",
        "* Option to select raw or discrete2continous transformation (Bing)\n",
        "* Annotation functionality + Share/Collaboration of findings/reseearch\n",
        "* clusters, centroids = kmeans1d.cluster(np.array(corpus_sentimentr_df['jockers_rinker']), k)\n",
        "* plotly prefered library to save dynamic images: kaleido\n",
        "* Correlation heatmaps: Justify choice of Spearman, Pearson, or other algo\n",
        "\n",
        "Facts:\n",
        "* SyuzhetR vs SentimentTime Clean/Preprocess\n",
        "* V.Woolf - To The Lighthouse\n",
        "* SyuzhetR Clean: 3511 (SyuzhetR Preprocessed) Sentences (SentimentTime Preprocessed) 3403\n",
        "* SentimentTime Clean: (Raw) 3402  (Clean) 3402\n",
        "\n",
        "\n",
        "Preprocessing of Corpus Textfile\n",
        "* Put headers in ALL CAPS\n",
        "* Put \\n\\n between each CHAPTER/BOOK or SECTION header or Paragraphs\n",
        "* Keep your format/spacing consistent\n",
        "* Try to use utf-8 (not cp1252 (e.g. \\n <- \\n\\r)\n",
        "* No leading blank lines, one trailing blank line at end of textfile\n",
        "* Check for illegal, non-printable or other problematic code (e.g. curly single/double quotes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmk-6u1fYP9b"
      },
      "source": [
        "# **Reference Code**\n",
        "\n",
        "Surveys:\n",
        "* https://github.com/prrao87/fine-grained-sentiment (20210409) Fine-grained SA (7 Models)\n",
        "\n",
        "\n",
        "Other:\n",
        "* https://github.com/annabiancajones/GA_capstone_project/blob/master/part3_mine_refine.ipynb\n",
        "* https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6 CV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43oGeYK19Pyq"
      },
      "source": [
        "# **Installs Requiring [Restart Runtime]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00aSE0js9V9z"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5nckvibLOtL"
      },
      "source": [
        "import transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X05awke6vYdu"
      },
      "source": [
        "# Test\n",
        "\n",
        "# !pip install kmeans1d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBWhXS9bxrtd"
      },
      "source": [
        "\"\"\"\n",
        "import kmeans1d\n",
        "\n",
        "k = corpus_sentimentr_df.shape[0]//500  \n",
        "\n",
        "clusters, centroids = kmeans1d.cluster(np.array(corpus_sentimentr_df['jockers_rinker']), k)\n",
        "type(clusters)\n",
        "\n",
        "[[x,clusters.count(x)] for x in set(clusters)]\n",
        "centroids\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZY1ox2AIRA9"
      },
      "source": [
        "# **Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR2Yy930dpe6"
      },
      "source": [
        "## **Install Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlgpe_IOdrL5"
      },
      "source": [
        "!pip install contractions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZvHzXX-ZP31"
      },
      "source": [
        "# Install more sophisticated Sentence Boundry Detection\n",
        "\n",
        "!pip install pysbd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOzjFtsGeg7w"
      },
      "source": [
        "# Read R datafiles directly into Python\n",
        "\n",
        "!pip install pyreadr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot6VpHC7KkIJ"
      },
      "source": [
        "## **Load Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV9Fnrd9Ih1L"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylS6GL07jFbH"
      },
      "source": [
        "from unicodedata import normalize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Juy3eMBtfE8t"
      },
      "source": [
        "# Read R datafiles directly into Python\n",
        "\n",
        "import pyreadr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7X3Rm9IeBle"
      },
      "source": [
        "import re\n",
        "import csv\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn53ISMMdtBw"
      },
      "source": [
        "import string\n",
        "PUNCT_TO_REMOVE = string.punctuation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFEWWoTHKsnj"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7hMxX7_LPBI"
      },
      "source": [
        "# Configure matplotlib and seaborn\n",
        "\n",
        "# Plotting pretty figures and avoid blurry images\n",
        "# %config InlineBackend.figure_format = 'retina'\n",
        "# Larger scale for plots in notebooks\n",
        "# sns.set_context('talk')\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = [20, 10]\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.rc('figure', facecolor='white')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdu2km4bL4Ay"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import plotly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v7lCM0qeHii"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkzJlUORYpQG"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svsKVVjNlDeh"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTURHmC8lVFi"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "nltk.download('porter')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi-FGH54lxjj"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'ner'])\n",
        "nlp.add_pipe(nlp.create_pipe('sentencizer'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx_dc1pNwhTD"
      },
      "source": [
        "def lemmatize_pipe(doc):\n",
        "    lemma_list = [str(tok.lemma_).lower() for tok in doc] #  if tok.is_alpha and tok.text.lower() not in stopwords] \n",
        "    return lemma_list\n",
        "\n",
        "def preprocess_pipe(texts):\n",
        "    preproc_pipe = []\n",
        "    for doc in nlp.pipe(texts, batch_size=20):\n",
        "        preproc_pipe.append(lemmatize_pipe(doc))\n",
        "    return preproc_pipe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6xiN3Atduvg"
      },
      "source": [
        "import contractions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtPBqwoYjlnj"
      },
      "source": [
        "contraction_map = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzXn11cn-VCG"
      },
      "source": [
        "# Scikit Utilities, Metrics, Pipelines and Models\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve, plot_precision_recall_curve\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ-7MDUYeWov"
      },
      "source": [
        "## **Pandas Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht0A5ZmzeVa9"
      },
      "source": [
        "pd.set_option('max_colwidth', 100) # -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFo9DWy8LMjV"
      },
      "source": [
        "## **Jupyter Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70jmB-YZLPBH"
      },
      "source": [
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KBDF4d2LPBF"
      },
      "source": [
        "from IPython.display import HTML # , display\n",
        "\n",
        "# Text wrap\n",
        "\n",
        "def my_css():\n",
        "   display(HTML(\"\"\"<style>table.dataframe td{white-space: nowrap;}</style>\"\"\"))\n",
        "\n",
        "get_ipython().events.register('pre_run_cell', my_css)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Srel7vuiLPBK"
      },
      "source": [
        "# Configure Jupyter\n",
        "\n",
        "# Enable multiple outputs from one code cell\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "from IPython.display import display\n",
        "from ipywidgets import widgets, interactive\n",
        "\n",
        "# Configure Google Colab\n",
        "\n",
        "# %load_ext google.colab.data_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaeftgXTLPBK"
      },
      "source": [
        "# Text wrap\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY4ouM5bdzgF"
      },
      "source": [
        "from IPython.core.display import display, HTML\n",
        "\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d31JU4L8HtwL"
      },
      "source": [
        "# **Configuration**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u932nJxdh0Ac"
      },
      "source": [
        "## **Step #1: (Auto)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_a9eQyBiiTG"
      },
      "source": [
        "**Global Configuration Constants**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi9g8I7z_b32"
      },
      "source": [
        "# NEW\n",
        "\n",
        "CORPUS_LANGUAGE = 'english'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT2MyyjpihFj"
      },
      "source": [
        "# Hardcoded Sentiment Analysis Models\n",
        "\n",
        "CORPUS_ENCODING = 'utf-8' # Default character/text encoding scheme (others: 'utf-8', but often 'iso-8859-1', 'windows-1252', 'cp1252', or 'ascii')\n",
        "\n",
        "MODELS_LS = ['vader','textblob','stanza','afinn','bing','sentimentr','syuzhet','pattern','sentiword','senticnet','nrc']\n",
        "            \n",
        "# Minimum lengths for Sentences and Paragraphs\n",
        "#   (Shorter Sents/Parags will be deleted)\n",
        "\n",
        "MIN_CHAP_LEN = 50\n",
        "MIN_SECT_LEN = 25  # Minimum char length to be included in section DataFrame\n",
        "MIN_PARAG_LEN = 2\n",
        "MIN_SENT_LEN = 2\n",
        "\n",
        "# Simple Moving Average/Rolling Mean \n",
        "roll_str = \"roll10\" # Default 10% Rolling Mean Window \n",
        "\n",
        "# Min/Max statistics on each lexicon's sentiment values applied to corpus\n",
        "corpus_lexicons_stats_dt = {}\n",
        "corpus_cruxes_dt = {}\n",
        "\n",
        "# Crux Points Dict key:model, value:list of crux point tuples (x,y)\n",
        "corpus_cruxes_all_dt = {}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w22Gihpa8zdw"
      },
      "source": [
        "# NEW\n",
        "# Training Datasets\n",
        "\n",
        "data_training = ['imdb',\n",
        "                 'yelp',\n",
        "                 'amazon',\n",
        "                 'sentiment140',\n",
        "                 'news',\n",
        "                 'cmu',\n",
        "                 'sst2']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOuNdwd68qqF"
      },
      "source": [
        "# NEW\n",
        "# Model Families\n",
        "\n",
        "# 8 lexicons\n",
        "model_leixcon = ['jockers_rinker',\n",
        "                 'jockers',\n",
        "                 'afinn',\n",
        "                 'huliu',   # 'bing'\n",
        "                 'senticnet',\n",
        "                 'sentiword',\n",
        "                 'liwc',\n",
        "                 'mpqa',\n",
        "                 'nrc',\n",
        "                 'lmcd']\n",
        "\n",
        "model_lexrules = ['vader', 'sentimentr']\n",
        "\n",
        "model_embeddings = ['textblob',\n",
        "                    'flair']\n",
        "\n",
        "model_supervised = ['multinb',\n",
        "                    'svc',\n",
        "                    'linreg',\n",
        "                    'logreg',\n",
        "                    'rforest',\n",
        "                    'xgboost',\n",
        "                    'catboost',\n",
        "                    'adaboost',\n",
        "                    'automl']\n",
        "\n",
        "model_linguistic = ['stanza',\n",
        "                    'pattern']\n",
        "\n",
        "model_dnn = ['fcn',\n",
        "             'rnn',\n",
        "             'lstn',\n",
        "             'cnn']\n",
        "             # 'automl' # https://github.com/IntelLabs/nlp-architec\n",
        "\n",
        "models_transformer_ls = ['roberta15lg', \n",
        "                         'nlptown', \n",
        "                         'yelp', \n",
        "                         'hinglish',\n",
        "                         'imdb2way', \n",
        "                         'huggingface', \n",
        "                         't5imdb50k', \n",
        "                         'robertaxml8lang']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEaKBbWAHZLN"
      },
      "source": [
        "## **Step #2: (Manual)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDCaUjgQHY4D"
      },
      "source": [
        "# Upload Kaggle credentials file (default: kaggle.json) to authenticate and download databases\n",
        "\n",
        "# Directions: https://www.kaggle.com/docs/api\n",
        "\n",
        "files.upload()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6vFMZ_cCDVz"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8wAOlNmB95Y"
      },
      "source": [
        "# !rm -rf ./root/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMl8txx8J4v8"
      },
      "source": [
        "# Create expected subdirectory for kaggle.json\n",
        "# NOTE: may already exist (if so, continue to next step)\n",
        "\n",
        "!mkdir /root/.kaggle\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG1ZvWZkJ4wB"
      },
      "source": [
        "# Move auth file kaggle.json to expected subdirectory\n",
        "\n",
        "!mv kaggle.json /root/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40Llw1brHojK"
      },
      "source": [
        "## **Step #3: (Auto)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNfHzGr-BCZP"
      },
      "source": [
        "# **Library Function**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHhgMMFIG-WC"
      },
      "source": [
        "## **File Utilities**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qteiz7iVObZT"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "# This function converts to lower-case, removes square bracket, removes numbers/punctuation, end of line hyphens\n",
        "\n",
        "# https://towardsdatascience.com/nlp-building-text-cleanup-and-preprocessing-pipeline-eba4095245a0\n",
        "# https://machinelearningmastery.com/prepare-french-english-dataset-machine-translation/ \n",
        "\n",
        "def clean_text(text):\n",
        "\n",
        "  # normalize unicode characters\n",
        "  #   library [normalize] imported in Setup above\n",
        "\n",
        "  if CORPUS_LANGUAGE == 'english':\n",
        "    text = normalize('NFD', text).encode('ascii', 'ignore')\n",
        "    text = text.decode('UTF-8')\n",
        "\n",
        "    # remove non-printable chars form each token\n",
        "    # regex pattern [re_print] defined in Setup above\n",
        "    text = re_print.sub('', text)\n",
        "\n",
        "    # to lower\n",
        "    text = text.lower()\n",
        "\n",
        "    # Spelling correction\n",
        "    # from autocorrect import Speller #correcting the spellings\n",
        "    \n",
        "    # Adjust apostrophes and contractions\n",
        "    # from contractions import contractions_dict # to solve contractions\n",
        "    text = contractions.fix(text)  # Expand contrations\n",
        "    # TODO: Problem with The Great Gatsby [I'm] -> [I' ]\n",
        "    text = re.sub(\"\\\\'s\", \" own\", text)  # After expanding normal apostrophes, expand possessive apostrophes \"Mary's car\" -> \"Mary own car\"\n",
        "\n",
        "    # Join end of line words split by continuation hyphens \n",
        "    text = re.sub(\"-\\n\", \" \", text)       \n",
        "    text = re.sub(\"-\\n\\r\", \" \", text)\n",
        "    text = re.sub(\"-\\r\", \" \", text)\n",
        "    text = re.sub(\"\\[.*?\\]\", \" \", text)\n",
        "\n",
        "    text = re.sub(\"-\", \" \", text)  # Special care for hypenated words well-known: choose option (a)\n",
        "                                    # (a) 'well known', (b) 'wellknown' (c) 'well known' and 'wellknown' cf: https://datascience.stackexchange.com/questions/81072/how-to-process-the-hyphenated-english-words-for-any-nlp-problem\n",
        "\n",
        "    text = re.sub(\"/\", \" \", text)  # sociability/conversation/interesting -> sociability conversation interesting                             \n",
        "\n",
        "    # Split string into tokens\n",
        "    line = text.split()\n",
        "\n",
        "    # remove punctuation from each token\n",
        "    line = [word.translate(table) for word in line]\n",
        "    # OLD string way: text = re.sub(\"[%s]\" % re.escape(string.punctuation), \" \", text)\n",
        "\n",
        "    # remove tokens with numbers in them\n",
        "    line = [word for word in line if word.isalpha()]    \n",
        "    # OLD stirng way: text = re.sub(\"\\w*\\d\\w*\", \" \", text)\n",
        "\n",
        "    # collapse/replace any whitespace(s) with a single hard space\n",
        "    # OLD string way: text = re.sub(\"[\\n]\", \" \", text)  # Replace newline with space\n",
        "    # reassemble tokens into single string to return\n",
        "    text_cleaned = ' '.join(line)\n",
        "\n",
        "  elif CORPUS_LANGUAGE == 'french':\n",
        "    # FRENCH: Minimal processing to preserve accents for Transformers\n",
        "    # text = normalize('NFD', text).encode('ascii', 'ignore')\n",
        "    # text = text.decode('UTF-8')\n",
        "\n",
        "    # remove non-printable chars form each token\n",
        "    # regex pattern [re_print] defined in Setup above\n",
        "    # text = re_print.sub('', text)\n",
        "\n",
        "    # to lower\n",
        "    text = text.lower()\n",
        "\n",
        "    # Spelling correction\n",
        "    # from autocorrect import Speller #correcting the spellings\n",
        "    \n",
        "    # Adjust apostrophes and contractions\n",
        "    # from contractions import contractions_dict # to solve contractions\n",
        "    # text = contractions.fix(text)  # Expand contrations\n",
        "    # TODO: Problem with The Great Gatsby [I'm] -> [I' ]\n",
        "    # text = re.sub(\"\\\\'s\", \" own\", text)  # After expanding normal apostrophes, expand possessive apostrophes \"Mary's car\" -> \"Mary own car\"\n",
        "\n",
        "    # Join end of line words split by continuation hyphens \n",
        "    text = re.sub(\"-\\n\", \" \", text)       \n",
        "    text = re.sub(\"-\\n\\r\", \" \", text)\n",
        "    text = re.sub(\"-\\r\", \" \", text)\n",
        "    text = re.sub(\"\\[.*?\\]\", \" \", text)\n",
        "\n",
        "    text = re.sub(\"-\", \" \", text)  # Special care for hypenated words well-known: choose option (a)\n",
        "                                    # (a) 'well known', (b) 'wellknown' (c) 'well known' and 'wellknown' cf: https://datascience.stackexchange.com/questions/81072/how-to-process-the-hyphenated-english-words-for-any-nlp-problem\n",
        "\n",
        "    text = re.sub(\"/\", \" \", text)  # sociability/conversation/interesting -> sociability conversation interesting                             \n",
        "\n",
        "    # Split string into tokens\n",
        "    line = text.split()\n",
        "\n",
        "    # remove punctuation from each token\n",
        "    # line = [word.translate(table) for word in line]\n",
        "    # OLD string way: text = re.sub(\"[%s]\" % re.escape(string.punctuation), \" \", text)\n",
        "\n",
        "    # remove tokens with numbers in them\n",
        "    line = [word for word in line if word.isalpha()]    \n",
        "    # OLD stirng way: text = re.sub(\"\\w*\\d\\w*\", \" \", text)\n",
        "\n",
        "    # collapse/replace any whitespace(s) with a single hard space\n",
        "    # OLD string way: text = re.sub(\"[\\n]\", \" \", text)  # Replace newline with space\n",
        "    # reassemble tokens into single string to return\n",
        "    text_cleaned = ' '.join(line)\n",
        "\n",
        "  else:\n",
        "    print(f'ERROR: CORPUS_LANG must be [english|french] but was set to: {CORPUS_LANG}')\n",
        "\n",
        "  return text_cleaned\n",
        "\n",
        "\n",
        "\"\"\";\n",
        "\n",
        "\"\"\"\n",
        "# Test\n",
        "\n",
        "print(clean_text(\"Le pépiement matinal des oiseaux semblait insipide à Françoise. I'm going to eat at Sloppy Joes's Place tonight.\"))\n",
        "\n",
        "\n",
        "# clean a list of lines\n",
        "def clean_lines(lines):\n",
        "\tcleaned = list()\n",
        "\t# prepare regex for char filtering\n",
        "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "\t# prepare translation table for removing punctuation\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\tfor line in lines:\n",
        "\t\t# normalize unicode characters\n",
        "\t\tline = normalize('NFD', line).encode('ascii', 'ignore')\n",
        "\t\tline = line.decode('UTF-8')\n",
        "\t\t# tokenize on white space\n",
        "\t\tline = line.split()\n",
        "\t\t# convert to lower case\n",
        "\t\tline = [word.lower() for word in line]\n",
        "\t\t# remove punctuation from each token\n",
        "\t\tline = [word.translate(table) for word in line]\n",
        "\t\t# remove non-printable chars form each token\n",
        "\t\tline = [re_print.sub('', w) for w in line]\n",
        "\t\t# remove tokens with numbers in them\n",
        "\t\tline = [word for word in line if word.isalpha()]\n",
        "\t\t# store as string\n",
        "\t\tcleaned.append(' '.join(line))\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTeszVJnmTXj"
      },
      "source": [
        "## **Text Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNJCU_bBmcT1"
      },
      "source": [
        "def clean_dataframe(df_clean):\n",
        "  '''\n",
        "  Given a Pandas DataFrame\n",
        "  Return same DataFrame after dropping duplicate rows and rows with empty values\n",
        "  '''\n",
        "\n",
        "  # Check for null values \n",
        "  null_values = df_clean.isnull().sum()\n",
        "\n",
        "  print('Check for null values in DataFrame:')\n",
        "  print(f'  [{null_values.index[0]}] has {null_values[0]} missing values')\n",
        "  print(f'  [{null_values.index[1]}] has {null_values[1]} missing values')\n",
        "\n",
        "  df_clean.dropna(axis=0, inplace=True)\n",
        "  print('\\n')\n",
        "\n",
        "  # Check for duplicate rows\n",
        "  print('Check for duplicate rows in DataFrame:')\n",
        "  num_duplicates = df_clean.duplicated().sum() \n",
        "\n",
        "  print(f'  {num_duplicates} duplicate rows\\n')\n",
        "\n",
        "  if num_duplicates > 0:\n",
        "    # View duplicate reviews\n",
        "    reviews = df_clean['text_raw']\n",
        "    dup_reviews = df_clean[reviews.isin(reviews[reviews.duplicated()])].sort_values(\"text_raw\")\n",
        "\n",
        "    print(f'  First duplicated rows to be dropped:')\n",
        "    dup_reviews.head()\n",
        "\n",
        "    #drop duplicate reviews\n",
        "    print(f'  Original DataFrame: #{df_clean.shape[0]} reviews')\n",
        "    df_clean.drop_duplicates(inplace = True)\n",
        "    print(f'                      #{df_clean.shape[0]} reviews after dropping duplicates\\n')\n",
        "\n",
        "  return df_clean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oua0ZUXabhLx"
      },
      "source": [
        " textmoji2text_dt = {\n",
        "        \":‑)\":\"smiley\",\n",
        "        \":-]\":\"smiley\",\n",
        "        \":-3\":\"smiley\",\n",
        "        \":->\":\"smiley\",\n",
        "        \"8-)\":\"smiley\",\n",
        "        \":-}\":\"smiley\",\n",
        "        \":)\":\"smiley\",\n",
        "        \":]\":\"smiley\",\n",
        "        \":3\":\"smiley\",\n",
        "        \":>\":\"smiley\",\n",
        "        \"8)\":\"smiley\",\n",
        "        \":}\":\"smiley\",\n",
        "        \":o)\":\"smiley\",\n",
        "        \":c)\":\"smiley\",\n",
        "        \":^)\":\"smiley\",\n",
        "        \"=]\":\"smiley\",\n",
        "        \"=)\":\"smiley\",\n",
        "        \":-))\":\"smiley\",\n",
        "        \":‑D\":\"smiley\",\n",
        "        \"8‑D\":\"smiley\",\n",
        "        \"x‑D\":\"smiley\",\n",
        "        \"X‑D\":\"smiley\",\n",
        "        \":D\":\"smiley\",\n",
        "        \"8D\":\"smiley\",\n",
        "        \"xD\":\"smiley\",\n",
        "        \"XD\":\"smiley\",\n",
        "        \":‑(\":\"sad\",\n",
        "        \":‑c\":\"sad\",\n",
        "        \":‑<\":\"sad\",\n",
        "        \":‑[\":\"sad\",\n",
        "        \":(\":\"sad\",\n",
        "        \":c\":\"sad\",\n",
        "        \":<\":\"sad\",\n",
        "        \":[\":\"sad\",\n",
        "        \":-||\":\"sad\",\n",
        "        \">:[\":\"sad\",\n",
        "        \":{\":\"sad\",\n",
        "        \":@\":\"sad\",\n",
        "        \">:(\":\"sad\",\n",
        "        \":'‑(\":\"sad\",\n",
        "        \":'(\":\"sad\",\n",
        "        \":‑P\":\"playful\",\n",
        "        \"X‑P\":\"playful\",\n",
        "        \"x‑p\":\"playful\",\n",
        "        \":‑p\":\"playful\",\n",
        "        \":‑Þ\":\"playful\",\n",
        "        \":‑þ\":\"playful\",\n",
        "        \":‑b\":\"playful\",\n",
        "        \":P\":\"playful\",\n",
        "        \"XP\":\"playful\",\n",
        "        \"xp\":\"playful\",\n",
        "        \":p\":\"playful\",\n",
        "        \":Þ\":\"playful\",\n",
        "        \":þ\":\"playful\",\n",
        "        \":b\":\"playful\",\n",
        "        \"<3\":\"love\"\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPGximftb9Ju"
      },
      "source": [
        "contractions_dt = {\n",
        "        \"ain't\":\"is not\",\n",
        "        \"amn't\":\"am not\",\n",
        "        \"aren't\":\"are not\",\n",
        "        \"can't\":\"cannot\",\n",
        "        \"'cause\":\"because\",\n",
        "        \"couldn't\":\"could not\",\n",
        "        \"couldn't've\":\"could not have\",\n",
        "        \"could've\":\"could have\",\n",
        "        \"daren't\":\"dare not\",\n",
        "        \"daresn't\":\"dare not\",\n",
        "        \"dasn't\":\"dare not\",\n",
        "        \"didn't\":\"did not\",\n",
        "        \"doesn't\":\"does not\",\n",
        "        \"don't\":\"do not\",\n",
        "        \"e'er\":\"ever\",\n",
        "        \"em\":\"them\",\n",
        "        \"everyone's\":\"everyone is\",\n",
        "        \"finna\":\"fixing to\",\n",
        "        \"gimme\":\"give me\",\n",
        "        \"gonna\":\"going to\",\n",
        "        \"gon't\":\"go not\",\n",
        "        \"gotta\":\"got to\",\n",
        "        \"hadn't\":\"had not\",\n",
        "        \"hasn't\":\"has not\",\n",
        "        \"haven't\":\"have not\",\n",
        "        \"he'd\":\"he would\",\n",
        "        \"he'll\":\"he will\",\n",
        "        \"he's\":\"he is\",\n",
        "        \"he've\":\"he have\",\n",
        "        \"how'd\":\"how would\",\n",
        "        \"how'll\":\"how will\",\n",
        "        \"how're\":\"how are\",\n",
        "        \"how's\":\"how is\",\n",
        "        \"I'd\":\"I would\",\n",
        "        \"I'll\":\"I will\",\n",
        "        \"I'm\":\"I am\",\n",
        "        \"I'm'a\":\"I am about to\",\n",
        "        \"I'm'o\":\"I am going to\",\n",
        "        \"isn't\":\"is not\",\n",
        "        \"it'd\":\"it would\",\n",
        "        \"it'll\":\"it will\",\n",
        "        \"it's\":\"it is\",\n",
        "        \"I've\":\"I have\",\n",
        "        \"kinda\":\"kind of\",\n",
        "        \"let's\":\"let us\",\n",
        "        \"mayn't\":\"may not\",\n",
        "        \"may've\":\"may have\",\n",
        "        \"mightn't\":\"might not\",\n",
        "        \"might've\":\"might have\",\n",
        "        \"mustn't\":\"must not\",\n",
        "        \"mustn't've\":\"must not have\",\n",
        "        \"must've\":\"must have\",\n",
        "        \"needn't\":\"need not\",\n",
        "        \"ne'er\":\"never\",\n",
        "        \"o'\":\"of\",\n",
        "        \"o'er\":\"over\",\n",
        "        \"ol'\":\"old\",\n",
        "        \"oughtn't\":\"ought not\",\n",
        "        \"shalln't\":\"shall not\",\n",
        "        \"shan't\":\"shall not\",\n",
        "        \"she'd\":\"she would\",\n",
        "        \"she'll\":\"she will\",\n",
        "        \"she's\":\"she is\",\n",
        "        \"shouldn't\":\"should not\",\n",
        "        \"shouldn't've\":\"should not have\",\n",
        "        \"should've\":\"should have\",\n",
        "        \"somebody's\":\"somebody is\",\n",
        "        \"someone's\":\"someone is\",\n",
        "        \"something's\":\"something is\",\n",
        "        \"that'd\":\"that would\",\n",
        "        \"that'll\":\"that will\",\n",
        "        \"that're\":\"that are\",\n",
        "        \"that's\":\"that is\",\n",
        "        \"there'd\":\"there would\",\n",
        "        \"there'll\":\"there will\",\n",
        "        \"there're\":\"there are\",\n",
        "        \"there's\":\"there is\",\n",
        "        \"these're\":\"these are\",\n",
        "        \"they'd\":\"they would\",\n",
        "        \"they'll\":\"they will\",\n",
        "        \"they're\":\"they are\",\n",
        "        \"they've\":\"they have\",\n",
        "        \"this's\":\"this is\",\n",
        "        \"those're\":\"those are\",\n",
        "        \"'tis\":\"it is\",\n",
        "        \"'twas\":\"it was\",\n",
        "        \"wanna\":\"want to\",\n",
        "        \"wasn't\":\"was not\",\n",
        "        \"we'd\":\"we would\",\n",
        "        \"we'd've\":\"we would have\",\n",
        "        \"we'll\":\"we will\",\n",
        "        \"we're\":\"we are\",\n",
        "        \"weren't\":\"were not\",\n",
        "        \"we've\":\"we have\",\n",
        "        \"what'd\":\"what did\",\n",
        "        \"what'll\":\"what will\",\n",
        "        \"what're\":\"what are\",\n",
        "        \"what's\":\"what is\",\n",
        "        \"what've\":\"what have\",\n",
        "        \"when's\":\"when is\",\n",
        "        \"where'd\":\"where did\",\n",
        "        \"where're\":\"where are\",\n",
        "        \"where's\":\"where is\",\n",
        "        \"where've\":\"where have\",\n",
        "        \"which's\":\"which is\",\n",
        "        \"who'd\":\"who would\",\n",
        "        \"who'd've\":\"who would have\",\n",
        "        \"who'll\":\"who will\",\n",
        "        \"who're\":\"who are\",\n",
        "        \"who's\":\"who is\",\n",
        "        \"who've\":\"who have\",\n",
        "        \"why'd\":\"why did\",\n",
        "        \"why're\":\"why are\",\n",
        "        \"why's\":\"why is\",\n",
        "        \"won't\":\"will not\",\n",
        "        \"wouldn't\":\"would not\",\n",
        "        \"would've\":\"would have\",\n",
        "        \"y'all\":\"you all\",\n",
        "        \"you'd\":\"you would\",\n",
        "        \"you'll\":\"you will\",\n",
        "        \"you're\":\"you are\",\n",
        "        \"you've\":\"you have\",\n",
        "        \"Whatcha\":\"What are you\",\n",
        "        \"luv\":\"love\",\n",
        "        \"sux\":\"sucks\"\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q80H-DFl8yP"
      },
      "source": [
        "from joblib import Parallel, delayed\n",
        "\n",
        "def chunker(iterable, total_length, chunksize):\n",
        "    return (iterable[pos: pos + chunksize] for pos in range(0, total_length, chunksize))\n",
        "\n",
        "def flatten(list_of_lists):\n",
        "    \"Flatten a list of lists to a combined list\"\n",
        "    return [item for sublist in list_of_lists for item in sublist]\n",
        "\n",
        "def process_chunk(texts):\n",
        "    preproc_pipe = []\n",
        "    for doc in nlp.pipe(texts, batch_size=20):\n",
        "        preproc_pipe.append(lemmatize_pipe(doc))\n",
        "    return preproc_pipe\n",
        "\n",
        "def preprocess_parallel(texts, chunksize=100):\n",
        "    executor = Parallel(n_jobs=7, backend='multiprocessing', prefer=\"processes\")\n",
        "    do = delayed(process_chunk)\n",
        "    tasks = (do(chunk) for chunk in chunker(texts, len(df_preproc), chunksize=chunksize))\n",
        "    result = executor(tasks)\n",
        "    return flatten(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjvvWTpkQsQq"
      },
      "source": [
        "def lemma_pipe(texts):\n",
        "  '''\n",
        "  Given a text string\n",
        "  Return a text string with all tokens lemmatized using SpaCy pipe for speed\n",
        "  Called by clean_text() with SpaCy Lemmatizer\n",
        "  '''\n",
        "  # https://prrao87.github.io/blog/spacy/nlp/performance/2020/05/02/spacy-multiprocess.html\n",
        "\n",
        "  lemma_tokens = []\n",
        "  for doc in nlp.pipe(texts, batch_size=200):\n",
        "      lemma_tokens.append([str(tok.lemma_).lower() for tok in doc])\n",
        "      \n",
        "  return lemma_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DWVba6FmXJj"
      },
      "source": [
        "def clean_text(text_str, text_type='basic', corpus_size='normal'):\n",
        "  '''\n",
        "  Given a string and a type = (basic,advanced,tweet)\n",
        "  Return a cleaned version of the string according to cleaing rules of type\n",
        "  '''\n",
        "\n",
        "  # Cleaningn Rules\n",
        "\n",
        "  # Remove URLs\n",
        "  text_str = re.sub(r'http\\S+', '', text_str) #remove urls\n",
        "\n",
        "  # Remove HTML Tags\n",
        "  html_re = re.compile('<.*?>')\n",
        "  text_str = re.sub(html_re, '', text_str)\n",
        "  # tweet = BeautifulSoup(tweet).get_text()\n",
        "\n",
        "  # Emojis to words\n",
        "  emoji_clean= re.compile(\"[\"\n",
        "                          u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                          u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                          u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                          u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                          u\"\\U00002702-\\U000027B0\"\n",
        "                          u\"\\U000024C2-\\U0001F251\"\n",
        "                          \"]+\", flags=re.UNICODE)\n",
        "\n",
        "  # Emojis to Words\n",
        "  # https://github.com/carpedm20/emoji/\n",
        "  # tweet = emoji.demojize(tweet)\n",
        "\n",
        "  # Textmoji to Words\n",
        "  # https://en.wikipedia.org/wiki/List_of_emoticons\n",
        "  # textmoji2text_dt\n",
        "\n",
        "  # Slang translation\n",
        "\n",
        "  # Filter smart quotes\n",
        "  # https://opensource.com/article/17/3/python-scribus-smart-quotes\n",
        "\n",
        "  # Filter angled quotes/ticks quotes\n",
        "  angled_quotes = [\"’\", \"‘\", \"´\", \"`\"]\n",
        "  for s in angled_quotes:\n",
        "    text_str = text_str.replace(s, \"'\")\n",
        "\n",
        "  # Filter Non-Printing Unicode\n",
        "  re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "  text_str = re_print.sub('', text_str)\n",
        "\n",
        "  # Convert to ASCII\n",
        "  if CORPUS_LANGUAGE == 'english':\n",
        "    text_str = normalize('NFD', text_str).encode('ascii', 'ignore')\n",
        "    text_str = text_str.decode('UTF-8')\n",
        "  else:\n",
        "    print(f'ERROR: In clean_test() with invalid CORPUS_LANGUGE: {CORPUS_LANGUAGE}')\n",
        "\n",
        "  # Join end of line words split by continuation hyphens \n",
        "  text_str = re.sub(\"-\\n\", \" \", text_str)       \n",
        "  text_str = re.sub(\"-\\n\\r\", \" \", text_str)\n",
        "  text_str = re.sub(\"-\\r\", \" \", text_str)\n",
        "  text_str = re.sub(\"\\[.*?\\]\", \" \", text_str)\n",
        "  text_str = re.sub(\"-\", \" \", text_str)  # Special care for hypenated words well-known: choose option (a)\n",
        "                                  # (a) 'well known', (b) 'wellknown' (c) 'well known' and 'wellknown' cf: https://datascience.stackexchange.com/questions/81072/how-to-process-the-hyphenated-english-words-for-any-nlp-problem\n",
        "\n",
        "  # Slashes\n",
        "  # text = re.sub(\"/\", \" \", text)  # sociability/conversation/interesting -> sociability conversation interesting       \n",
        "\n",
        "  # Expand contractions: Manual Rules (Advantages: speed, exact control)\n",
        "  text_str = ' '.join([contraction_map[t] if t in contraction_map else t for t in text_str.split(\" \")])\n",
        "\n",
        "  # Expand contractions: Automatic\n",
        "  # Add custom contractions: \n",
        "  # contractions.add('mychange', 'my change')\n",
        "  # text_str = contractions.fix(text_str)\n",
        "\n",
        "  # Remove stopwords (+custom) (OPTIONA: Can indicate sentiment, very happy vs not very happy)\n",
        "  # stopwords_custom_st = {'bazinga', 'hoohaw', 'pating'}\n",
        "  # STOPWORDS.union(stopwords_custom_st)\n",
        "  # text_str = \" \".join([word for word in str(text_str).split() if word not in STOPWORDS])\n",
        "\n",
        "  # Correct Spelling\n",
        "  # https://stackoverflow.com/questions/62809934/how-to-efficiently-use-spell-correction-for-a-large-text-corpus-in-python\n",
        "  # TextBlob, symSpell, JamSpell, \n",
        "  # https://github.com/barrust/pyspellchecker (20210327 358s)\n",
        "  # https://github.com/filyp/autocorrect (20210421 148s)\n",
        "  # need to tokenize, correct\n",
        "\n",
        "  # Filter punctuation (OPTIONAL: Can indicate sentiment, stop vs STOP!!!!)\n",
        "  # tweet = ' '.join(re.sub(\"[\\.\\,\\!\\?\\:\\;\\-\\=]\", \" \", tweet).split())\n",
        "  # text_str = text_str.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
        "  punct_remove_st = set([x for x in PUNCT_TO_REMOVE])\n",
        "  punct_remove_st = punct_remove_st.difference({'!','?','.'})\n",
        "  # text_str = \" \".join([x for x in text_str.split() if x not in punct_remove_st])\n",
        "  # text_str = re.sub(r\"[#$%&\\'()*+,-/:;<=>@[\\\\]^_`{|}~]*\", '', text_str)\n",
        "  text_str = text_str.translate(str.maketrans('', '', '#$%&\\()*+,-/:;<=>@[\\\\]^_`{|}~]*'))\n",
        "\n",
        "  # Filter Numbers\n",
        "  # text_str = \" \".join([word for word in text_str if word.isalpha()])\n",
        "  alpha_re = re.compile(r\"[0-9\\.-]+\")\n",
        "  text_str = alpha_re.sub('', text_str)\n",
        "\n",
        "  # Lowercase (OPTIONAL: Can indicate sentiment, STOP vs stop)\n",
        "  # text_str = text_str.lower()\n",
        "\n",
        "  # Stem: NLTK Porter\n",
        "  # text_str = \" \".join([stemmer.stem(word) for word in text_str.split()])\n",
        "\n",
        "  # Lemmatize: NTLK WordNet\n",
        "  # text_str = \" \".join([lemmatizer.lemmatize(word) for word in text_str.split()])\n",
        "\n",
        "  # Lemmatize: SpaCy (avoid automatic -PRON- substitutions)\n",
        "  # Options:     https://www.geeksforgeeks.org/python-lemmatization-approaches-with-examples/ (NLTK WordNet/POS, TextBlob/POS, TreeTagger, Pattern, CoreNLP)\n",
        "  #              https://stackoverflow.com/questions/67865226/problem-with-importing-lemmatization-from-gensim (Stanza, UDPipe, -gensim/Pattern)\n",
        "  # Speed:       https://prrao87.github.io/blog/spacy/nlp/performance/2020/05/02/spacy-multiprocess.html \n",
        "  #              https://towardsdatascience.com/turbo-charge-your-spacy-nlp-pipeline-551435b664ad\n",
        "  # memoization  https://stackoverflow.com/questions/51372724/how-to-speed-up-spacy-lemmatization \n",
        "  #              https://gist.github.com/dhruvpathak/a7b96f469fd404a2351de69a5ff41144\n",
        "  # min pipeline: https://gist.github.com/dhruvpathak/a7b96f469fd404a2351de69a5ff41144\n",
        "  # \n",
        "\n",
        "  if corpus_size == 'normal':\n",
        "    doc = nlp(text_str)\n",
        "    text_str = \" \".join([token.lemma_.lower() if token.lemma_ != '-PRON-' else token.lower_ for token in doc])\n",
        "  else:\n",
        "    # For very large corpora use SpaCy nlp.pipeline \n",
        "    #    skip and use batched pipeline in calling routine, not one individual row calls here\n",
        "    pass\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  # Create list of tokens from given string\n",
        "  tokens = []\n",
        "  for token in doc:\n",
        "    tokens.append(token)\n",
        "  text_str = \" \".join([token.lemma_ for token in doc])\n",
        "  \"\"\";\n",
        "\n",
        "  # Fix end of sentence punctuation\n",
        "  text_str = re.sub(r\" ([!?.])\", r\"\\1\", text_str)\n",
        "\n",
        "  # Condense multiple whitespaces\n",
        "  text_str = \" \".join(text_str.split())\n",
        "\n",
        "  # Strip whitespaces\n",
        "  text_str = text_str.strip()\n",
        "\n",
        "  if text_type == 'basic':\n",
        "    pass\n",
        "  elif text_type == 'advanced':\n",
        "    pass\n",
        "  elif text_type == 'tweet':\n",
        "    pass\n",
        "  else:\n",
        "    print(f'ERROR: In clean_text() with invalid atype arguement: {text_type}')\n",
        "\n",
        "  return text_str\n",
        "\n",
        "# Test\n",
        "# print(clean_text(\"<b>HELLO</b>, but I don't believe he's thinking:  the 32 cats are sitting on - her 16 mats!\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XbR1Ex0BMi1"
      },
      "source": [
        "## **Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubKkbRe2BCKm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aozb5eJlGa7t"
      },
      "source": [
        "## **Model Utilities**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MRV23rqjTvR"
      },
      "source": [
        "def lexicon_sentiment(lexicon_dt, text_str):\n",
        "  '''\n",
        "  Given a lexicon dict[word]=sentiment and a string\n",
        "  Return a sentiment ('pos'|'neg') and a polarity (-1.0 to 1.0)\n",
        "  '''\n",
        "\n",
        "  word_ls = text_str.split()\n",
        "  text_polarity = 0\n",
        "\n",
        "  for aword in word_ls:\n",
        "    word_sentiment = lexicon_dt.get(aword)\n",
        "    if word_sentiment != None: #lexicon_dt.get(aword) != None:\n",
        "      # print(f'Word: {aword} Polarity: {word_sentiment}')\n",
        "      text_polarity += word_sentiment # lexicon_dt[aword]\n",
        "\n",
        "  if text_polarity > 0.0:\n",
        "    text_sentiment = 'pos'\n",
        "  else:\n",
        "    text_sentiment = 'neg'\n",
        "  \n",
        "  # Return tuple of polarity ('positive'|'negative') and sentiment float value (-1.0 to 1.0)\n",
        "  return text_sentiment, round(text_polarity, 4)\n",
        "\n",
        "# Test\n",
        "\"\"\"\n",
        "test_str = \"I love enjoying the great outdoors!\"\n",
        "test_tp = lexicon_sentiment(lexicon_jockersrinker_dt, test_str)\n",
        "print(f'The Sentence: {test_str}\\n\\n  Sentiment: {test_tp[0]}\\n\\n  Polarity:  {test_tp[1]}')\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSLqFGzPBCHB"
      },
      "source": [
        "# https://www.kaggle.com/aditya6040/7-models-on-imdb-dataset-best-score-88-2/notebook\n",
        "\n",
        "def metrics(model,x,y):\n",
        "    y_pred = model.predict(x)\n",
        "    acc = accuracy_score(y, y_pred)\n",
        "    f1=f1_score(y, y_pred)\n",
        "    cm=confusion_matrix(y, y_pred)\n",
        "    report=classification_report(y,y_pred)\n",
        "    plt.figure(figsize=(4,4))\n",
        "    sns.heatmap(cm,annot=True,cmap='Blues',xticklabels=[0,1],fmt='d',annot_kws={\"fontsize\":19})\n",
        "    plt.xlabel(\"Predicted\",fontsize=16)\n",
        "    plt.ylabel(\"Actual\",fontsize=16)\n",
        "    plt.show()\n",
        "    print(\"\\nAccuracy: \",round(acc,2))\n",
        "    print(\"\\nF1 Score: \",round(f1,2))\n",
        "#     print(\"\\nConfusion Matrix: \\n\",cm)\n",
        "    print(\"\\nReport:\",report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATqWwSe0wYpA"
      },
      "source": [
        "def lexicon_metrics(y, y_pred):\n",
        "    acc = accuracy_score(y, y_pred)\n",
        "    f1=f1_score(y, y_pred)\n",
        "    cm=confusion_matrix(y, y_pred)\n",
        "    report=classification_report(y, y_pred)\n",
        "    plt.figure(figsize=(4,4))\n",
        "    sns.heatmap(cm,annot=True,cmap='Blues',xticklabels=[0,1],fmt='d',annot_kws={\"fontsize\":19})\n",
        "    plt.xlabel(\"Predicted\",fontsize=16)\n",
        "    plt.ylabel(\"Actual\",fontsize=16)\n",
        "    plt.show()\n",
        "    print(\"\\nAccuracy: \",round(acc,2))\n",
        "    print(\"\\nF1 Score: \",round(f1,2))\n",
        "#     print(\"\\nConfusion Matrix: \\n\",cm)\n",
        "    print(\"\\nReport:\",report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFKXsbTt5up5"
      },
      "source": [
        "# **EDA**\n",
        "\n",
        "* https://www.kaggle.com/derrelldsouza/imdb-sentiment-analysis-eda-ml-lstm-bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U1NMjbE51SM"
      },
      "source": [
        "## **WordCloud**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3zyJN0Q50TQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggmcKAqG6Ate"
      },
      "source": [
        "## **Frequencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9Jb24c86AbW"
      },
      "source": [
        "# https://www.kaggle.com/aryantiwari123/tweets-sentiment-analysis\n",
        "\n",
        "sns.set_palette(\"Paired\")\n",
        "sns.pairplot(data,hue='Sentiment',height=5.5,palette='colorblind')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEeHIeDe7yyL"
      },
      "source": [
        "# https://www.kaggle.com/aryantiwari123/tweets-sentiment-analysis\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('SentimentText')\n",
        "sns.kdeplot(data['Sentiment'],shade=True,color='blue')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxhg5ibW55g9"
      },
      "source": [
        "## **Histograms/Distributions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk1e6X3K50LE"
      },
      "source": [
        "# https://www.kaggle.com/khotijahs1/using-autonlp-for-sentiment-analysis\n",
        "\n",
        "\n",
        "\n",
        "train_x, test_x, final, predicted= Auto_NLP(input_feature, train, test,target,\n",
        "                                            score_type=\"balanced_accuracy\",\n",
        "                                            top_num_features=500,\n",
        "                                            modeltype=\"Classification\",\n",
        "                                            verbose=2,\n",
        "                                            build_model=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mebSNjpwXgA1"
      },
      "source": [
        "## **Baseline Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik478Fb_d7J7"
      },
      "source": [
        "%who DataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxXffkPJ5w90"
      },
      "source": [
        "print(training_df['sentiment'].value_counts(normalize=True))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN55u2yc5xYt"
      },
      "source": [
        "# **Models**\n",
        "\n",
        "**Lexicon Models (10)**\n",
        "* Jockers-Rinker (extracted from SyuzhetR)\n",
        "* Jockers (extracted from SyzuhetR)\n",
        "* NRC\n",
        "* Hu-Liu (aka Bing)\n",
        "* AFINN\n",
        "* SentiWord\n",
        "* SenticNet\n",
        "* Loughlan-McDonald \n",
        "* LIWC\n",
        "* MPQA\n",
        "\n",
        "**Lexicon + Heuristic Rules (10)**\n",
        "* VADER\n",
        "* SentimentR\n",
        "\n",
        "**Embeddings (2)**\n",
        "* TextBlob\n",
        "* Flair\n",
        "\n",
        "**Supervised Models (10)**\n",
        "* Multinomial Naive Bayes\n",
        "* SVC\n",
        "* Linear Regression\n",
        "* Logistic Regression\n",
        "* Random Forest\n",
        "* XGBoost\n",
        "* CATBoost\n",
        "* AdaBoost\n",
        "* AutoML: A\n",
        "* AutoML: B\n",
        "\n",
        "**Linguistic Models (2)**\n",
        "* Stanza\n",
        "* Pattern \n",
        "\n",
        "**Deep Neural Networks (4)**\n",
        "* Fully Connected Networks\n",
        "* RNN\n",
        "* LSTN\n",
        "* CNN\n",
        "* AutoML:  https://github.com/IntelLabs/nlp-architec\n",
        "\n",
        "**Transformer Models (8)**\n",
        "* roberta15lg', \n",
        "* Multilingual BERT: NLPTown\n",
        "* BERT tuned on Yelp\n",
        "* BERT Dual Coded English/Hindu\n",
        "* BERT tuned on IMDB\n",
        "* Distilled BERT (Huggingface default)\n",
        "* T5 tuned on IMDB\n",
        "* Multilingual RoBERTa XML 8 Languages\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-2xz10b6Y6q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov1cUBUm6HJ4"
      },
      "source": [
        "## **Lexicons**\n",
        "\n",
        "* https://github.com/trinker/lexicon/tree/master/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZe-VOc16dYh"
      },
      "source": [
        "### **Jockers-Rinker**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMQ89K356f_U"
      },
      "source": [
        "lexicon = 'jockersrinker'\n",
        "\n",
        "# !wget https://github.com/trinker/lexicon/blob/master/data/hash_sentiment_jockers_rinker.rda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ww2IOTXetbV"
      },
      "source": [
        "# Get Lexicon from SentimentR github repo\n",
        "\n",
        "url = \"https://github.com/trinker/lexicon/blob/master/data/hash_sentiment_jockers_rinker.rda?raw=true\"\n",
        "dst_path = \"jockersrinker.rda\"\n",
        "dst_path_again = pyreadr.download_file(url, dst_path)\n",
        "res = pyreadr.read_r(dst_path)\n",
        "print(f'type(res): {type(res)}\\n')\n",
        "res\n",
        "\n",
        "# Convert to DataFrame\n",
        "lexicon_jockersrinker_df = res['hash_sentiment_jockers_rinker']\n",
        "lexicon_jockersrinker_df.head()\n",
        "lexicon_jockersrinker_df.info()\n",
        "\n",
        "# Reshape into Dictionary[word] = sentiment\n",
        "lexicon_jockersrinker_df.set_index('x', inplace=True)\n",
        "lexicon_jockersrinker_dt = lexicon_jockersrinker_df.to_dict()['y']\n",
        "\n",
        "# Set to working lexicon\n",
        "lexicon_dt = lexicon_jockersrinker_dt\n",
        "\n",
        "aword = 'berserk'\n",
        "print('\\n')\n",
        "print(f'The word: [{aword}] has a [{lexicon}] sentiment value of [{lexicon_jockersrinker_dt[aword]}]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9bCl3yjz5Oy"
      },
      "source": [
        "# import rpy2.robjects as robjects\n",
        "# !mkdir lexicons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EJtK5YjsaUo"
      },
      "source": [
        "training_df = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1_YHnO2yu0L"
      },
      "source": [
        "training_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP25pd8Hp5Aj"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Note: 3.3s\n",
        "\n",
        "training_df['jockersrinker'] = training_df['text_clean'].apply(lambda x: lexicon_sentiment(lexicon_dt, x))\n",
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbh6q-8lp458"
      },
      "source": [
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeUIeEsNBXf5"
      },
      "source": [
        "# Extract Polarity float values as pd.Series\n",
        "\n",
        "sentiment_tup, polarity_tup = zip(*training_df.jockersrinker)\n",
        "polarity_ser = pd.Series(polarity_tup)\n",
        "polarity_ser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga1bgYMBxFU_"
      },
      "source": [
        "# Get Lexicon predictions\n",
        "\n",
        "y_pred = np.where(polarity_ser>0, 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlKqdUwUy72J"
      },
      "source": [
        "# Get Metrics on Lexicon Sentiment Classifier\n",
        "\n",
        "lexicon_metrics(y, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdP1zLpY6lm_"
      },
      "source": [
        "### **HuLiu (aka Bing)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ab9YA2o3_UX"
      },
      "source": [
        "lexicon = 'huliu'\n",
        "\n",
        "# !wget https://github.com/trinker/lexicon/blob/master/data/hash_sentiment_huliu.rda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhXd0Frq3_UY"
      },
      "source": [
        "# Get Lexicon from SentimentR github repo\n",
        "\n",
        "url = \"https://github.com/trinker/lexicon/blob/master/data/hash_sentiment_huliu.rda?raw=true\"\n",
        "dst_path = \"huliu.rda\"\n",
        "dst_path_again = pyreadr.download_file(url, dst_path)\n",
        "res = pyreadr.read_r(dst_path)\n",
        "print(f'type(res): {type(res)}\\n')\n",
        "res\n",
        "\n",
        "# Convert to DataFrame\n",
        "lexicon_huliu_df = res['hash_sentiment_huliu']\n",
        "lexicon_huliu_df.head()\n",
        "lexicon_huliu_df.info()\n",
        "\n",
        "# Reshape into Dictionary[word] = sentiment\n",
        "lexicon_huliu_df.set_index('x', inplace=True)\n",
        "lexicon_huliu_dt = lexicon_huliu_df.to_dict()['y']\n",
        "\n",
        "# Set to working lexicon\n",
        "lexicon_dt = lexicon_huliu_dt\n",
        "\n",
        "aword = 'berserk'\n",
        "print('\\n')\n",
        "print(f'The word: [{aword}] has a [{lexicon}] sentiment value of [{lexicon_huliu_dt[aword]}]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYDUfbI93_Ua"
      },
      "source": [
        "training_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXzjPjtC3_Ub"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Note: 4.17s (huliu)\n",
        "\n",
        "training_df['huliu'] = training_df['text_clean'].apply(lambda x: lexicon_sentiment(lexicon_dt, x))\n",
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0QuOk3t3_Uc"
      },
      "source": [
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63pHp1Yl3_Ud"
      },
      "source": [
        "# Extract Polarity float values as pd.Series\n",
        "\n",
        "sentiment_tup, polarity_tup = zip(*training_df.huliu)\n",
        "polarity_ser = pd.Series(polarity_tup)\n",
        "polarity_ser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTYxL29l3_Ue"
      },
      "source": [
        "# Get Lexicon predictions\n",
        "\n",
        "y_pred = np.where(polarity_ser>0, 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_DmHK595eQs"
      },
      "source": [
        "# Get Metrics on Lexicon Sentiment Classifier\n",
        "\n",
        "lexicon_metrics(y, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXHUQV-f63j_"
      },
      "source": [
        "### **NRC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8gxsZsk5-pU"
      },
      "source": [
        "lexicon = 'nrc'\n",
        "\n",
        "# !wget https://github.com/trinker/lexicon/blob/master/data/hash_sentiment_nrc.rda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYhPBh-D5-pV"
      },
      "source": [
        "# Get Lexicon from SentimentR github repo\n",
        "\n",
        "url = \"https://github.com/trinker/lexicon/blob/master/data/hash_sentiment_nrc.rda?raw=true\"\n",
        "dst_path = \"nrc.rda\"\n",
        "dst_path_again = pyreadr.download_file(url, dst_path)\n",
        "res = pyreadr.read_r(dst_path)\n",
        "print(f'type(res): {type(res)}\\n')\n",
        "res\n",
        "\n",
        "# Convert to DataFrame\n",
        "lexicon_nrc_df = res['hash_sentiment_nrc']\n",
        "lexicon_nrc_df.head()\n",
        "lexicon_nrc_df.info()\n",
        "\n",
        "# Reshape into Dictionary[word] = sentiment\n",
        "lexicon_nrc_df.set_index('x', inplace=True)\n",
        "lexicon_nrc_dt = lexicon_nrc_df.to_dict()['y']\n",
        "\n",
        "# Set to working lexicon\n",
        "lexicon_dt = lexicon_nrc_dt\n",
        "\n",
        "aword = 'berserk'\n",
        "print('\\n')\n",
        "print(f'The word: [{aword}] has a [{lexicon}] sentiment value of [{lexicon_nrc_dt[aword]}]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXCgVvDD5-pW"
      },
      "source": [
        "training_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLi-7xVw5-pW"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Note: 3.02s (huliu)\n",
        "\n",
        "training_df['nrc'] = training_df['text_clean'].apply(lambda x: lexicon_sentiment(lexicon_dt, x))\n",
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmFKWy4z5-pX"
      },
      "source": [
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0H4locK5-pY"
      },
      "source": [
        "# Extract Polarity float values as pd.Series\n",
        "\n",
        "sentiment_tup, polarity_tup = zip(*training_df.nrc)\n",
        "polarity_ser = pd.Series(polarity_tup)\n",
        "polarity_ser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTynq1YC5-pZ"
      },
      "source": [
        "# Get Lexicon predictions\n",
        "\n",
        "y_pred = np.where(polarity_ser>0, 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yKJITFs7Lcq"
      },
      "source": [
        "# Get Metrics on Lexicon Sentiment Classifier\n",
        "\n",
        "lexicon_metrics(y, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_TKBGnF6ooO"
      },
      "source": [
        "### **SentiWord**\n",
        "\n",
        "* https://www.sentic.net/sentic-patterns.pdf\n",
        "* https://www.quora.com/Sentiment-Analysis-How-does-CLiPS-Pattern-calculate-the-polarity-of-a-sentence-What-is-the-maths-involved-in-it \n",
        "* https://github.com/clips/pattern/wiki/pattern-en#sentiment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVIUDTYT7fb8"
      },
      "source": [
        "lexicon = 'sentiword'\n",
        "\n",
        "# !wget https://github.com/trinker/lexicon/blob/master/data/hash_sentiment_sentiword.rda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJsqV4r_7fb9"
      },
      "source": [
        "# Get Lexicon from SentimentR github repo\n",
        "\n",
        "url = \"https://github.com/trinker/lexicon/blob/master/data/hash_sentiment_sentiword.rda?raw=true\"\n",
        "dst_path = \"sentiword.rda\"\n",
        "dst_path_again = pyreadr.download_file(url, dst_path)\n",
        "res = pyreadr.read_r(dst_path)\n",
        "print(f'type(res): {type(res)}\\n')\n",
        "res\n",
        "\n",
        "# Convert to DataFrame\n",
        "lexicon_sentiword_df = res['hash_sentiment_sentiword']\n",
        "lexicon_sentiword_df.head()\n",
        "lexicon_sentiword_df.info()\n",
        "\n",
        "# Reshape into Dictionary[word] = sentiment\n",
        "lexicon_sentiword_df.set_index('x', inplace=True)\n",
        "lexicon_sentiword_dt = lexicon_sentiword_df.to_dict()['y']\n",
        "\n",
        "# Set to working lexicon\n",
        "lexicon_dt = lexicon_sentiword_dt\n",
        "\n",
        "aword = 'angry'\n",
        "print('\\n')\n",
        "print(f'The word: [{aword}] has a [{lexicon}] sentiment value of [{lexicon_sentiword_dt[aword]}]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CodKyqY27fb9"
      },
      "source": [
        "training_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOmmAnyx7fb-"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Note: 3.28s (huliu)\n",
        "\n",
        "training_df['sentiword'] = training_df['text_clean'].apply(lambda x: lexicon_sentiment(lexicon_dt, x))\n",
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlpcLOlK7fb-"
      },
      "source": [
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0YULd6d7fb_"
      },
      "source": [
        "# Extract Polarity float values as pd.Series\n",
        "\n",
        "sentiment_tup, polarity_tup = zip(*training_df.sentiword)\n",
        "polarity_ser = pd.Series(polarity_tup)\n",
        "polarity_ser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvrXNBHS7fb_"
      },
      "source": [
        "# Get Lexicon predictions\n",
        "\n",
        "y_pred = np.where(polarity_ser>0, 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzfHono67fcA"
      },
      "source": [
        "# Get Metrics on Lexicon Sentiment Classifier\n",
        "\n",
        "lexicon_metrics(y, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igCCPduG6vjZ"
      },
      "source": [
        "### **SenticNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrUzdUw-7gdy"
      },
      "source": [
        "lexicon = 'senticnet'\n",
        "\n",
        "# !wget https://github.com/trinker/lexicon/blob/master/data/hash_sentiment_senticnet.rda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4osvl6P7gdz"
      },
      "source": [
        "# Get Lexicon from SentimentR github repo\n",
        "\n",
        "url = \"https://github.com/trinker/lexicon/blob/master/data/hash_sentiment_senticnet.rda?raw=true\"\n",
        "dst_path = \"senticnet.rda\"\n",
        "dst_path_again = pyreadr.download_file(url, dst_path)\n",
        "res = pyreadr.read_r(dst_path)\n",
        "print(f'type(res): {type(res)}\\n')\n",
        "res\n",
        "\n",
        "# Convert to DataFrame\n",
        "lexicon_huliu_df = res['hash_sentiment_senticnet']\n",
        "lexicon_huliu_df.head()\n",
        "lexicon_huliu_df.info()\n",
        "\n",
        "# Reshape into Dictionary[word] = sentiment\n",
        "lexicon_huliu_df.set_index('x', inplace=True)\n",
        "lexicon_huliu_dt = lexicon_huliu_df.to_dict()['y']\n",
        "\n",
        "# Set to working lexicon\n",
        "lexicon_dt = lexicon_huliu_dt\n",
        "\n",
        "aword = 'angry'\n",
        "print('\\n')\n",
        "print(f'The word: [{aword}] has a [{lexicon}] sentiment value of [{lexicon_huliu_dt[aword]}]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgECXwe77gdz"
      },
      "source": [
        "training_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CMd00_R7gd0"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Note: 3.29s (senticnet)\n",
        "\n",
        "training_df['senticnet'] = training_df['text_clean'].apply(lambda x: lexicon_sentiment(lexicon_dt, x))\n",
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnPhvBxD7gd0"
      },
      "source": [
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgSkwEAX7gd1"
      },
      "source": [
        "# Extract Polarity float values as pd.Series\n",
        "\n",
        "sentiment_tup, polarity_tup = zip(*training_df.senticnet)\n",
        "polarity_ser = pd.Series(polarity_tup)\n",
        "polarity_ser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl3II0r77gd1"
      },
      "source": [
        "# Get Lexicon predictions\n",
        "\n",
        "y_pred = np.where(polarity_ser>0, 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzJYTVz17gd2"
      },
      "source": [
        "# Get Metrics on Lexicon Sentiment Classifier\n",
        "\n",
        "lexicon_metrics(y, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7QotExQ6xBB"
      },
      "source": [
        "### **Loughran-McDonald**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqz72VAI7hxg"
      },
      "source": [
        "lexicon = 'lmcd'\n",
        "\n",
        "# !wget https://github.com/trinker/lexicon/blob/master/data/hash_sentiment_loughran_mcdonald.rda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKUueAey7hxh"
      },
      "source": [
        "# Get Lexicon from SentimentR github repo\n",
        "\n",
        "url = \"https://github.com/trinker/lexicon/blob/master/data/hash_sentiment_loughran_mcdonald.rda?raw=true\"\n",
        "dst_path = \"lmcd.rda\"\n",
        "dst_path_again = pyreadr.download_file(url, dst_path)\n",
        "res = pyreadr.read_r(dst_path)\n",
        "print(f'type(res): {type(res)}\\n')\n",
        "res\n",
        "\n",
        "# Convert to DataFrame\n",
        "lexicon_huliu_df = res['hash_sentiment_loughran_mcdonald']\n",
        "lexicon_huliu_df.head()\n",
        "lexicon_huliu_df.info()\n",
        "\n",
        "# Reshape into Dictionary[word] = sentiment\n",
        "lexicon_huliu_df.set_index('x', inplace=True)\n",
        "lexicon_huliu_dt = lexicon_huliu_df.to_dict()['y']\n",
        "\n",
        "# Set to working lexicon\n",
        "lexicon_dt = lexicon_huliu_dt\n",
        "\n",
        "aword = 'bad'\n",
        "print('\\n')\n",
        "print(f'The word: [{aword}] has a [{lexicon}] sentiment value of [{lexicon_huliu_dt[aword]}]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBcJ_sYS7hxh"
      },
      "source": [
        "training_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaH_5ni17hxh"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Note: 2.8s (lmcd)\n",
        "\n",
        "training_df['lmcd'] = training_df['text_clean'].apply(lambda x: lexicon_sentiment(lexicon_dt, x))\n",
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM8I-gZh7hxi"
      },
      "source": [
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW295Yj_7hxj"
      },
      "source": [
        "# Extract Polarity float values as pd.Series\n",
        "\n",
        "sentiment_tup, polarity_tup = zip(*training_df.lmcd)\n",
        "polarity_ser = pd.Series(polarity_tup)\n",
        "polarity_ser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZaWdSrc7hxj"
      },
      "source": [
        "# Get Lexicon predictions\n",
        "\n",
        "y_pred = np.where(polarity_ser>0, 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1wfyRIs7hxk"
      },
      "source": [
        "# Get Metrics on Lexicon Sentiment Classifier\n",
        "\n",
        "lexicon_metrics(y, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EdTcDNj67cK"
      },
      "source": [
        "### **MPQA**\n",
        "\n",
        "* https://mpqa.cs.pitt.edu/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9rae5Dm7AiG"
      },
      "source": [
        "!wget https://mpqa.cs.pitt.edu/corpora/mpqa_corpus/mpqa_corpus_3_0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vY4Wgq6vrZ5"
      },
      "source": [
        "!ls -altr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3drYoVZAvtsw"
      },
      "source": [
        "!head -n 10 mpqa_corpus_3_0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BIT9nhu69u_"
      },
      "source": [
        "### **LIWC**\n",
        "\n",
        "* https://github.com/search?q=LIWC\n",
        "* https://github.com/search?q=LIWC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfsQI5n66F8B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9mEYM-p6kL5"
      },
      "source": [
        "### **AFINN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO2VyxeN6f15"
      },
      "source": [
        "!pip install afinn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRF2b7BnwVC9"
      },
      "source": [
        "from afinn import Afinn\n",
        "afinn = Afinn(language='en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYGLCVjowetX"
      },
      "source": [
        "# Test\n",
        "\n",
        "asent = 'I hate terrible awful shit'\n",
        "asent_afinn_score = afinn.score(asent)\n",
        "print(f'AFINN raw sentiment: {asent_afinn_score}')\n",
        "\n",
        "afinn_lnorm = asent_afinn_score/len(asent.split())\n",
        "print(f'AFINN length-normed sentiment: {afinn_lnorm}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPl-uBXR_qhY"
      },
      "source": [
        "# Temp Cleanup\n",
        "\n",
        "# training_df.rename(columns={'afinn':'afinn_polarity'}, inplace=True)\n",
        "# training_df.drop(columns=['afinn_polarity', 'afinn_sentiment'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIffJgwf9ahd"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Note: 7m6s\n",
        "\n",
        "training_df['afinn_polarity'] = training_df['text_clean'].apply(lambda x: afinn.score(x))\n",
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecjyDJAX_1zl"
      },
      "source": [
        "# Create a tuple format to match all other model outputs\n",
        "\n",
        "training_df['afinn'] = training_df['afinn_polarity'].apply(lambda x: ('pos', x) if x>0 else ('neg', x))\n",
        "# training_df['afinn_sentiment'] = training_df['afinn_polarity'].apply(lambda x: 'pos' if x>0 else 'neg')\n",
        "training_df.drop(columns=['afinn_polarity'], inplace=True)\n",
        "\n",
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZI5LI659ahe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH7RVByt9ahe"
      },
      "source": [
        "# Extract Polarity float values as pd.Series\n",
        "\n",
        "sentiment_tup, polarity_tup = zip(*training_df.afinn)\n",
        "polarity_ser = pd.Series(polarity_tup)\n",
        "polarity_ser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJMJyh3F9ahf"
      },
      "source": [
        "# Get Lexicon predictions\n",
        "\n",
        "y_pred = np.where(polarity_ser>0, 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_3nehdm9ahf"
      },
      "source": [
        "# Get Metrics on Lexicon Sentiment Classifier\n",
        "\n",
        "lexicon_metrics(y, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaGpKk_E6ghe"
      },
      "source": [
        "### **Jockers (in %%R)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co_4g9dD3hPd"
      },
      "source": [
        "lexicon = 'jockersrinker'\n",
        "\n",
        "!wget https://github.com/trinker/lexicon/blob/master/data/hash_sentiment_jockers_rinker.rda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yB1SPPx3hF0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qFZfbdR3hAI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G93KIxEB3g5t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbEh07EW3g0Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhg6sWq13guc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bBBh7kx3goi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1N73pJT3gii"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsUmquIQ6f67"
      },
      "source": [
        "%%R\n",
        "\n",
        "install.packages('syuzhet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEpMWPCWy9cn"
      },
      "source": [
        "%%R\n",
        "\n",
        "library('syuzhet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4tpiIWIzGhh"
      },
      "source": [
        "%%R\n",
        "\n",
        "syuzhet_all_df$syuzhet <- syuzhet::get_sentiment(corpus_sents_v, method='syuzhet')\n",
        "syuzhet_all_df$bing <- syuzhet::get_sentiment(corpus_sents_v, method='bing')\n",
        "syuzhet_all_df$afinn <- syuzhet::get_sentiment(corpus_sents_v, method='afinn')\n",
        "syuzhet_all_df$nrc <- syuzhet::get_sentiment(corpus_sents_v, method='nrc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7s_OD2J_QHA"
      },
      "source": [
        "### **Save Checkpoint**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG7Vt04VzGcA"
      },
      "source": [
        "training_df.to_csv('sb_lexicons.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTP5p-jOzGXu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu4UuqK9y9W3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSACJ2N06MNf"
      },
      "source": [
        "## **Lexicons + Heuristics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQXGPyAT7CMk"
      },
      "source": [
        "### **VADER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCb8sbP16Gz0"
      },
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "vader_analyzer = SentimentIntensityAnalyzer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL005dfomKUE"
      },
      "source": [
        "# test\n",
        "\n",
        "# testimonial = TextBlob(training_df.iloc[0]['text_raw'])\n",
        "\n",
        "test_str = \"The food was great!\"\n",
        "\n",
        "\n",
        "vs = vader_analyzer.polarity_scores(test_str)\n",
        "print(\"{:-<65} {}\".format(test_str, str(vs)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHT0Mju7EbKt"
      },
      "source": [
        "# Temp Util\n",
        "\n",
        "# training_df.rename(columns={'vader_full':'vader_all'},inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECA58mcpmnxv"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Note: 6m18s\n",
        "\n",
        "training_df['vader_orig'] = training_df['text_clean'].apply(lambda x: vader_analyzer.polarity_scores(x))\n",
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VffQlr-PE1RH"
      },
      "source": [
        "# Check range of 'neu' to see if 'polarity' value should be normalized\n",
        "\n",
        "vader_neu_ser = training_df['vader_orig'].apply(lambda x: x['neu'])\n",
        "vader_neu_ser.rolling(500, center=True).mean().plot();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y6i6pGqCUfO"
      },
      "source": [
        "# Create a tuple format to match all other model outputs\n",
        "\n",
        "# TODO: Weight the pos/neg values by C(1/neu) factor\n",
        "\n",
        "training_df['vader'] = training_df['vader_orig'].apply(lambda x: ('pos', x['pos']) if x['compound']>0.05 else ('neg', x['neg']))\n",
        "# training_df['afinn_sentiment'] = training_df['afinn_polarity'].apply(lambda x: 'pos' if x>0 else 'neg')\n",
        "# training_df.drop(columns=['afinn_polarity'], inplace=True)\n",
        "\n",
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDxcmOHIKTyV"
      },
      "source": [
        "# Optional: Drop Original VADER values\n",
        "\n",
        "# training_df.drop(columns=['vader_orig'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCKpLrc8CUZ1"
      },
      "source": [
        "# Extract Polarity float values as pd.Series\n",
        "\"\"\"\n",
        "sentiment_tup, polarity_tup = zip(*training_df.vader)\n",
        "polarity_ser = pd.Series(polarity_tup)\n",
        "polarity_ser\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0sLz32iCyed"
      },
      "source": [
        "# Get Lexicon predictions\n",
        "\n",
        "# y_pred = np.where(polarity_ser>0.05, 1, 0)\n",
        "y_pred = training_df.vader.apply(lambda x: 1 if x[0] == 'pos' else 0)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDCRNs3qCyee"
      },
      "source": [
        "# Get Metrics on Lexicon Sentiment Classifier\n",
        "\n",
        "lexicon_metrics(y, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-eB2OIxGBbe"
      },
      "source": [
        "# Check large inbalance between classes\n",
        "\n",
        "vader_neu_ser = training_df['vader'].apply(lambda x: x[0])\n",
        "vader_neu_ser.hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuTvPoC97E_N"
      },
      "source": [
        "### **SentimentR (in %%R)**\n",
        "\n",
        "Python and R Together\n",
        "\n",
        "* https://dev.to/hkmoon/sharing-data-among-python-r-java-javascript-in-jupyter-notebook-p8k\n",
        "* https://github.com/rpy2/rpy2-arrow/blob/main/doc/notebooks/faster_rpy2_conversion.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNq7gfzh6GvE"
      },
      "source": [
        "%load_ext rpy2.ipython"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPGmriB2pBs3"
      },
      "source": [
        "training_db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI7KOVnep839"
      },
      "source": [
        "training_v = training_df['text_clean'].to_list()\n",
        "type(training_v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNdgqrtLmr8b"
      },
      "source": [
        "%%R\n",
        "\n",
        "install.packages('sentimentr')\n",
        "library('sentimentr')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRRSqQIupMak"
      },
      "source": [
        "%%R -i training_db\n",
        "\n",
        "# Set Output Sentiments Datafile names\n",
        "sentimentr_output_prefix = 'sum_sentiments_sentimentR_7models_sentimenttimeraw_'\n",
        "sentimentr_output_suffix = '.csv'\n",
        "sentimentr_output = trimws(paste0(sentimentr_output_prefix, training_db, sentimentr_output_suffix, sep=' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "konbuxe0mr1h"
      },
      "source": [
        "%%R -i training_v -o sentimentr_v\n",
        "\n",
        "sentimentr_v <- data.frame(sent_raw = training_v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPBQxQtSqjfy"
      },
      "source": [
        "sentimentr_v.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeQfSu96mrsH"
      },
      "source": [
        "%%R\n",
        "\n",
        "# Add other lexicon sentiments\n",
        "sentimentr_all_df$jockers_rinker <- sentimentr::sentiment(make_class(corpus_sents_v, \"get_sentences\", \"get_sentences_character\"), polarity_dt=lexicon::hash_sentiment_jockers_rinker, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "sentimentr_all_df$jockers <- sentimentr::sentiment(make_class(corpus_sents_v, \"get_sentences\", \"get_sentences_character\"), polarity_dt=lexicon::hash_sentiment_jockers, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "sentimentr_all_df$huliu <- sentimentr::sentiment(make_class(corpus_sents_v, \"get_sentences\", \"get_sentences_character\"), polarity_dt=lexicon::hash_sentiment_huliu, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "sentimentr_all_df$lmcd <- sentimentr::sentiment(make_class(corpus_sents_v, \"get_sentences\", \"get_sentences_character\"), polarity_dt=lexicon::hash_sentiment_loughran_mcdonald, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "sentimentr_all_df$nrc <- sentimentr::sentiment(make_class(corpus_sents_v, \"get_sentences\", \"get_sentences_character\"), polarity_dt=lexicon::hash_sentiment_nrc, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "sentimentr_all_df$senticnet <- sentimentr::sentiment(make_class(corpus_sents_v, \"get_sentences\", \"get_sentences_character\"), polarity_dt=lexicon::hash_sentiment_senticnet, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "sentimentr_all_df$sentiword <- sentimentr::sentiment(make_class(corpus_sents_v, \"get_sentences\", \"get_sentences_character\"), polarity_dt=lexicon::hash_sentiment_sentiword, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aqzdk3pmrm4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8YzTVvqmrjE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH0_9K_x7L1E"
      },
      "source": [
        "## **Embeddings**\n",
        "\n",
        "* https://neptune.ai/blog/document-classification-small-datasets\n",
        "* https://neptune.ai/blog/sentiment-analysis-python-textblob-vs-vader-vs-flair (TB,VADER,Flair)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJsKKRNT3jfI"
      },
      "source": [
        "### **FastText**\n",
        "\n",
        "* https://github.com/facebookresearch/fastText\n",
        "* https://medium.com/@lope.ai/sentiment-analysis-example-using-fasttext-6b1b4d334c53\n",
        "* https://colab.research.google.com/drive/1bb2OWQcDDolESwhkATD0el0RvF33fenZ#scrollTo=X5PWbhOzZ3ze\n",
        "* https://fasttext.cc/docs/en/english-vectors.html (embeddings)\n",
        "* https://github.com/RaRe-Technologies/gensim/blob/37e49971efa74310b300468a5b3cf531319c6536/docs/notebooks/Word2Vec_FastText_Comparison.ipynb\n",
        "* https://www.analyticsvidhya.com/blog/2017/07/word-representations-text-classification-using-fasttext-nlp-facebook/\n",
        "* https://github.com/jatinmandav/Neural-Networks/tree/master/Sentiment-Analysis (Universal Sentence Encoder 77%, fastText 69%, word2vec 69%)\n",
        "* https://github.com/search?q=fasttext+sentiment\n",
        "\n",
        "Code:\n",
        "* https://github.com/charlesmalafosse/FastText-sentiment-analysis-for-tweets/blob/master/betsentiment_sentiment_analysis_fasttext.py (tweets)\n",
        "* https://gist.github.com/hiteshn97/8f222a2773e11d6921b937abaa21ab75 (fastText,  keras)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueVJ4OdG3jMV"
      },
      "source": [
        "!wget https://github.com/facebookresearch/fastText/archive/v0.9.2.zip\n",
        "!unzip v0.9.2.zip\n",
        "%cd fastText-0.9.2\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOivPfK_4RAs"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWrTkxMS4aT7"
      },
      "source": [
        "!ls ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BJ2LBlT365R"
      },
      "source": [
        "%%time\n",
        "\n",
        "train = open('tweets.train','w')  \n",
        "test = open('tweets.valid','w')  \n",
        "# with open('../sentiment140.1600000.csv', mode='r', encoding = \"ISO-8859-1\") as csv_file:  \n",
        "with open('../sentiment140.csv', mode='r', encoding = \"ISO-8859-1\") as csv_file:  \n",
        "    csv_reader = csv.DictReader(csv_file, fieldnames=['target', 'id', 'date', 'flag', 'user', 'text'])\n",
        "    line = 0\n",
        "    for row in csv_reader:\n",
        "        # Clean the training data\n",
        "        # First we lower case the text\n",
        "        text = row[\"text\"].lower()\n",
        "        # remove links\n",
        "        text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',text)\n",
        "        #Remove usernames\n",
        "        text = re.sub('@[^\\s]+','', text)\n",
        "        # replace hashtags by just words\n",
        "        text = re.sub(r'#([^\\s]+)', r'\\1', text)\n",
        "        #correct all multiple white spaces to a single white space\n",
        "        text = re.sub('[\\s]+', ' ', text)\n",
        "        # Additional clean up : removing words less than 3 chars, and remove space at the beginning and teh end\n",
        "        text = re.sub(r'\\W*\\b\\w{1,3}\\b', '', text)\n",
        "        text = text.strip()\n",
        "        line = line + 1\n",
        "        # Split data into train and validation\n",
        "        if line%16 == 0:\n",
        "            print(f'__label__{row[\"target\"]} {text}', file=test)\n",
        "        else:\n",
        "            print(f'__label__{row[\"target\"]} {text}', file=train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyqYDJNp4t_0"
      },
      "source": [
        "%%time\n",
        "\n",
        "!./fasttext supervised -input tweets.train -output model_tweet\n",
        "# !./fasttext supervised -input tweets.train -output model_tweet -epoch 30 -lr 0.1\n",
        "# !./fasttext supervised -input tweets.train -output model_tweet -dim 300 -label __label__ -pretrainedVecctors wiki.ar.vec # Arabic for Netflix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W2OKSnx4t4y"
      },
      "source": [
        "%%time\n",
        "\n",
        "!./fasttext test model_tweet.bin tweets.valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29mKvcVm5iu7"
      },
      "source": [
        "!pip install fasttext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G78xUCbg4tzL"
      },
      "source": [
        "from fasttext import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwEoQbMu5gIb"
      },
      "source": [
        "classifier = load_model('model_tweet.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJyjaQ925gC3"
      },
      "source": [
        "text_ls = ['Ugghhh... Not happy at all! sorry', 'Happyyyyyyy', 'OH yeah! lets rock.']\n",
        "labels = classifier.predict(text_ls)\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz-EMuLT7n8-"
      },
      "source": [
        "with open('test.txt','w') as fp:\n",
        "  fp.write(\"\\n\".join(text_ls))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEXO_n957Aq-"
      },
      "source": [
        "!cat test.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsnuxOT68MaA"
      },
      "source": [
        "!./fasttext predict model_tweet.bin test.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G43FzjuP6tGs"
      },
      "source": [
        "!./fasttext predict-prob model_tweet.bin test.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zirGXVaF6OH8"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBVa-CKW6SQP"
      },
      "source": [
        "!ls ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYhVWbJ_6HKC"
      },
      "source": [
        "!head -n 10 tweets.train\n",
        "\n",
        "!cat tweets.train | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOLyKOgR82Az"
      },
      "source": [
        "# Load Different Embeddings\n",
        "\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQa8KVjB-3fS"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1dE0ZqO8158"
      },
      "source": [
        "!unzip crawl-300d-2M-subword.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYZCsiQx-nvE"
      },
      "source": [
        "!ls "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKiZtpQe81wZ"
      },
      "source": [
        "import io\n",
        "\n",
        "fname = 'crawl-300d-2M-subword.vec'\n",
        "\n",
        "def load_vectors(fname):\n",
        "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    n, d = map(int, fin.readline().split())\n",
        "    data = {}\n",
        "    for line in fin:\n",
        "        tokens = line.rstrip().split(' ')\n",
        "        data[tokens[0]] = map(float, tokens[1:])\n",
        "    return data\n",
        "\n",
        "load_vectors(fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFYH2ctz9Zls"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmQFnTNn6HEN"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRGZrCnB7NnW"
      },
      "source": [
        "### **TextBlob**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmg-Ru7jltY1"
      },
      "source": [
        "from textblob import TextBlob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY0rKd3j6GqH"
      },
      "source": [
        "# Test\n",
        "\n",
        "test_str = \"The food was great!\"\n",
        "\n",
        "testimonial = TextBlob(test_str)\n",
        "print(testimonial.sentiment)\n",
        "\n",
        "print('\\n\\n')\n",
        "TextBlob(test_str).sentiment.polarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoHoJtDuItcp"
      },
      "source": [
        "TextBlob(test_str).sentiment.subjectivity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH-m1kYKHaSt"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Note: 2m18s\n",
        "\n",
        "training_df['textblob_orig'] = training_df['text_clean'].apply(lambda x: (round(TextBlob(x).sentiment.polarity,4), round(TextBlob(x).sentiment.subjectivity,4)))\n",
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13iAYGJqHpdT"
      },
      "source": [
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FixU55RKHJhA"
      },
      "source": [
        "# Create a tuple format to match all other model outputs\n",
        "\n",
        "# TODO: Weight the pos/neg values by C(1/neu) factor\n",
        "\n",
        "training_df['textblob'] = training_df['textblob_orig'].apply(lambda x: ('pos', round(x[0],4)) if x[0]>0 else ('neg', round(x[0],4)))\n",
        "# training_df['afinn_sentiment'] = training_df['afinn_polarity'].apply(lambda x: 'pos' if x>0 else 'neg')\n",
        "# training_df.drop(columns=['afinn_polarity'], inplace=True)\n",
        "\n",
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTsNWQ-QHJWL"
      },
      "source": [
        "# Optional: Drop Original TextBlob values\n",
        "\n",
        "# training_df.drop(columns=['textblob_orig'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-AMkbJv7PDQ"
      },
      "source": [
        "### **Flair**\n",
        "\n",
        "* https://colab.research.google.com/drive/1tUr5t0ZJ-I4Ni40dkbjku92HAU5SyR_2?usp=sharing (TextBlob, Flair, VADER with UnivSentEmbd)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO-pQhl4el8K"
      },
      "source": [
        "%whos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PZRuwtceoin"
      },
      "source": [
        "# RESTART REQUIRED\n",
        "\n",
        "!pip install flair\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6h--uMK6GmL"
      },
      "source": [
        "from flair.models import TextClassifier\n",
        "from flair.data import Sentence\n",
        "\n",
        "classifier = TextClassifier.load('en-sentiment')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V57D2RfvfrXA"
      },
      "source": [
        "sentence = Sentence('The food was great!')\n",
        "classifier.predict(sentence)\n",
        "\n",
        "# print sentence with predicted labels\n",
        "print('Sentence above is: ', sentence.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA3bne65fw_E"
      },
      "source": [
        "sentence = Sentence(['I think the food kinda sucked really bad.', 'I hated it!'])\n",
        "classifier.predict(sentence)\n",
        "\n",
        "# print sentence with predicted labels\n",
        "print(f'Sentence above is: {sentence}')\n",
        "\n",
        "print(f'Sentence above is: {type(sentence.labels[0])}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h40CqSuB7z89"
      },
      "source": [
        "### **Google Universal Sentence Encoder**\n",
        "\n",
        "* https://tfhub.dev/google/universal-sentence-encoder/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1YbJ36B77Jy"
      },
      "source": [
        "## **Linguistic Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEhVfWRu79oI"
      },
      "source": [
        "### **Stanza**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AakXItbc74HS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0cBuDeT8ABx"
      },
      "source": [
        "### **Pattern**\n",
        "\n",
        "* https://github.com/clips/pattern/wiki/pattern-en#sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW0EnGst74Cm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-muOiNX18Ew0"
      },
      "source": [
        "## **Deep Neural Networks**\n",
        "\n",
        "* https://github.com/thoailinh/Sentiment-Analysis-using-BERT (Viet Comparison)\n",
        "\n",
        "* https://github.com/Feuoy/sentiment-analysis (Chinese Comparison)\n",
        "\n",
        "* https://www.kaggle.com/aditya6040/7-models-on-imdb-dataset-best-score-88-2/notebook#CNN-Model\n",
        "* https://github.com/bentrevett/pytorch-sentiment-analysis\n",
        "\n",
        "* https://github.com/nileshsah/deep-text-classifier/blob/master/inshorts_notebook.ipynb\n",
        "* https://github.com/saurabhrathor/InceptionModel_SentimentAnalysis (fasttext emb CNN+LSTM) BB_twtr SemEval2017\n",
        "* https://github.com/kaliahinartem/twitter_sentiment_analysis\n",
        "* https://github.com/leelaylay/TweetSemEval\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLVXPTokkcbd"
      },
      "source": [
        "### **Common Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dyXFbMUohfV"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYbbXlASkeHJ"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import LSTM,Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import LSTM, Conv1D, MaxPooling1D, Dropout\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbJuiBZakhgX"
      },
      "source": [
        "def plot_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'b', label='Training acc')\n",
        "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eln2U453nXfm"
      },
      "source": [
        "training_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsJ3uB-zkohV"
      },
      "source": [
        "# Split labeled dataset into training, validation and test sets\n",
        "# e.g. for IMDB 50k reviews: Out of 50k dataset, 36k for training, 4k for Validationa and 10k for testing\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(training_df['text_raw'], training_df['polarity'],test_size=0.2, random_state=0)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train,test_size=0.1, random_state=0)\n",
        "\n",
        "[x.shape for x in [X_train,X_valid,X_test]]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DN8r_7lNB0C"
      },
      "source": [
        "X_train.shape\n",
        "print('\\n')\n",
        "type(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vEbTnMvSim8"
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaDIHBBJSfcG"
      },
      "source": [
        "X_train[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRda68cYkuyk"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Tokenize text\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(training_df.text_raw)\n",
        "\n",
        "X_train1 = tokenizer.texts_to_sequences(X_train)\n",
        "X_valid1 = tokenizer.texts_to_sequences(X_valid)\n",
        "X_test1 = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
        "\n",
        "print(X_train[2])\n",
        "print(X_train1[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPP78tSoNpQy"
      },
      "source": [
        "type(X_train1)\n",
        "print('\\n')\n",
        "X_train1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRTtHS72NRPW"
      },
      "source": [
        "corpus_sents_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in-_if34TBG3"
      },
      "source": [
        "corpus_sents_df['sent_clean'] = corpus_sents_df['sent_clean'].astype('string')\n",
        "X_corpus_ser = corpus_sents_df['sent_clean']\n",
        "type(X_corpus_ser)\n",
        "X_corpus_ser[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj3td2_6Th6b"
      },
      "source": [
        "X_corpus1 = tokenizer.texts_to_sequences(X_corpus_ser)\n",
        "type(X_corpus1)\n",
        "X_corpus_ser[4]\n",
        "X_corpus1[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLmBRBaKPJ5U"
      },
      "source": [
        "\"\"\"\n",
        "X_corpus = np.asarray(tokenizer.texts_to_sequences(X_corpus_ser)) # , dtype=int)\n",
        "X_corpus.shape\n",
        "type(X_corpus)\n",
        "X_corpus\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDvn8SidQrDJ"
      },
      "source": [
        "\"\"\"\n",
        "X_corpus = np.array(tokenizer.texts_to_sequences(corpus_sents_df['sent_clean'])) # , dtype=int)\n",
        "X_corpus.shape\n",
        "type(X_corpus)\n",
        "X_corpus\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FNX2ulWQX5Y"
      },
      "source": [
        "\"\"\"\n",
        "tokens_ls_ls = tokenizer.texts_to_sequences(corpus_sents_df['sent_clean'])\n",
        "X_corpus_ar = np.array([np.array(lsi) for lsi in tokens_ls_ls])\n",
        "X_corpus_ar\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7TOagh9M7Px"
      },
      "source": [
        "\"\"\"\n",
        "X_corpus = np.asarray(tokenizer.texts_to_sequences(corpus_sents_df['sent_clean'])) # , dtype=int)\n",
        "# X_corpus = X_corpus.astype('int32')\n",
        "# npa = np.asarray(someListOfLists, dtype=np.float32)\n",
        "X_corpus[:3]\n",
        "print('\\n')\n",
        "type(X_corpus)\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRpVqkKXkuuM"
      },
      "source": [
        "print(X_train[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zktxzNIcntgd"
      },
      "source": [
        "seq_lens = [len(s) for s in X_train1]\n",
        "print(\"average length: %0.1f\" % np.mean(seq_lens))\n",
        "print(\"max length: %d\" % max(seq_lens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxELvkWwUfsA"
      },
      "source": [
        "seq_lens = [len(s) for s in X_corpus1]\n",
        "print(\"average length: %0.1f\" % np.mean(seq_lens))\n",
        "print(\"max length: %d\" % max(seq_lens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y5wpugcntYY"
      },
      "source": [
        "# Set max sequence and pad where necessary\n",
        "\n",
        "maxlen = 150\n",
        "\n",
        "X_train1 = pad_sequences(X_train1, padding='post', maxlen=maxlen)\n",
        "X_valid1 = pad_sequences(X_valid1, padding='post', maxlen=maxlen)\n",
        "X_test1 = pad_sequences(X_test1, padding='post', maxlen=maxlen)\n",
        "\n",
        "print(X_train1[2, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlWQpSPmUotH"
      },
      "source": [
        "X_corpus1 = pad_sequences(X_corpus1, padding='post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA-Lhx4IntTY"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qTZDoL-8IWk"
      },
      "source": [
        "### **Fully Connected Networks (FCN)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2vNqoEKn1aA"
      },
      "source": [
        "# Build the Network\n",
        "\n",
        "embedding_dim = 50\n",
        "callback = EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtYjLvgon1VK"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Train the Network\n",
        "\n",
        "history = model.fit(X_train1, y_train,epochs=10,verbose=True,validation_data=(X_valid1, y_valid),batch_size=1000,callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCwahEGlIPBG"
      },
      "source": [
        "y_test1_pred = model.predict(X_test1)\n",
        "y_test1_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYJKBS_UIhum"
      },
      "source": [
        "y_test1_pred.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkO-EI39LUFB"
      },
      "source": [
        "y_test1_pred_bin = np.where(y_test1_pred > 0.5, 1, 0)\n",
        "y_test1_pred_bin = y_test1_pred_bin.squeeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAdpanp_L2fK"
      },
      "source": [
        "type(y_test1_pred_bin[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV5KsOSvLPY9"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3ftUPxgIs9w"
      },
      "source": [
        "y_test_fl = y_test.apply(lambda x: float(x))\n",
        "y_test_fl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFC7sK2eI8D4"
      },
      "source": [
        "y_test_ar = np.array(y_test_fl, dtype=np.float32)\n",
        "type(y_test_ar)\n",
        "print('\\n')\n",
        "y_test_ar.shape\n",
        "print('\\n')\n",
        "y_test_ar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBCVQ5NgJjpO"
      },
      "source": [
        "type(y_test1_pred)\n",
        "print('\\n')\n",
        "y_test1_pred = y_test1_pred.squeeze()\n",
        "y_test1_pred.shape\n",
        "print('\\n')\n",
        "y_test1_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQqWHoKin1Q_"
      },
      "source": [
        "accuracy_score(y_test, y_test1_pred_bin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_vBXX6y73-x"
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlqHceOEpHpN"
      },
      "source": [
        "plt.figure(figsize=(4,4))\n",
        "# sns.heatmap(confusion_matrix(y_test, model.predict(X_test1)),annot=True,cmap='coolwarm',xticklabels=[0,1],fmt='d',annot_kws={\"fontsize\":19})\n",
        "sns.heatmap(confusion_matrix(y_test, y_test1_pred_bin),annot=True,cmap='coolwarm',xticklabels=[0,1],fmt='d',annot_kws={\"fontsize\":19})\n",
        "plt.xlabel(\"Predicted\",fontsize=16)\n",
        "plt.ylabel(\"Actual\",fontsize=16)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZA8tG_hpHjh"
      },
      "source": [
        "y_corpus1_pred = model.predict(X_corpus1)\n",
        "type(y_corpus1_pred)\n",
        "print('\\n')\n",
        "print(y_corpus1_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BwCcLOhVBAy"
      },
      "source": [
        "fcn_ar = y_corpus1_pred.squeeze()\n",
        "fcn_ar.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwVgkZAiVPbC"
      },
      "source": [
        "corpus_sents_df['fcn'] = pd.Series(fcn_ar)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEfY-rKyVPK_"
      },
      "source": [
        "# corpus_sents_df['fcn'].apply(lambda x: 6*(x-0.3)).rolling(900, center=True).mean().plot(label='Fully Connected Neural Net')\n",
        "corpus_sents_df['fcn'].apply(lambda x: 8*(x-0.55)).rolling(900, center=True).mean().plot(label='Fully Connected Neural Net')\n",
        "corpus_sents_df['sentimentr_stdscaler'].rolling(900, center=True).mean().plot(label='SentimentR')\n",
        "corpus_sents_df['vader_stdscaler'].rolling(900, center=True).mean().plot(label='VADER')\n",
        "plt.legend(loc='best');\n",
        "plt.title(f'{CORPUS_FULL}\\nFully Connected Neural Net (Default w/IMDB) SMA=10%');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-PeeJ2O8Mku"
      },
      "source": [
        "### **RNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmUYoHoN8IGq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7lppwbU8PnC"
      },
      "source": [
        "### **LSTM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7cIk8Zd5sce"
      },
      "source": [
        "**Ref: https://www.kaggle.com/derrelldsouza/imdb-sentiment-analysis-eda-ml-lstm-bert#4.-Predictive-Modelling-using-Machine-Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyfL7-yh5Agm"
      },
      "source": [
        "def plotLearningCurve(history,epochs):\n",
        "  epochRange = range(1,epochs+1)\n",
        "  fig , ax = plt.subplots(1,2,figsize = (10,5))\n",
        "  \n",
        "  ax[0].plot(epochRange,history.history['accuracy'],label = 'Training Accuracy')\n",
        "  ax[0].plot(epochRange,history.history['val_accuracy'],label = 'Validation Accuracy')\n",
        "  ax[0].set_title('Training and Validation accuracy')\n",
        "  ax[0].set_xlabel('Epoch')\n",
        "  ax[0].set_ylabel('Accuracy')\n",
        "  ax[0].legend()\n",
        "  ax[1].plot(epochRange,history.history['loss'],label = 'Training Loss')\n",
        "  ax[1].plot(epochRange,history.history['val_loss'],label = 'Validation Loss')\n",
        "  ax[1].set_title('Training and Validation loss')\n",
        "  ax[1].set_xlabel('Epoch')\n",
        "  ax[1].set_ylabel('Loss')\n",
        "  ax[1].legend()\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsv_NlzP5Eu5"
      },
      "source": [
        "#set up the tokenizer\n",
        "MAX_VOCAB_SIZE = 10000\n",
        "tokenizer = Tokenizer(num_words = MAX_VOCAB_SIZE,oov_token=\"<oov>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "#print(word_index)\n",
        "V = len(word_index)\n",
        "print(\"Vocabulary of the dataset is : \",V)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-InuwbHq5Epy"
      },
      "source": [
        "##create sequences of reviews\n",
        "seq_train = tokenizer.texts_to_sequences(X_train)\n",
        "seq_test =  tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwYYamks5Q_A"
      },
      "source": [
        "#choice of maximum length of sequences\n",
        "seq_len_list = [len(i) for i in seq_train + seq_test]\n",
        "\n",
        "#if we take the direct maximum then\n",
        "max_len=max(seq_len_list)\n",
        "print('Maximum length of sequence in the list: {}'.format(max_len))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htoHmhnq5Q5U"
      },
      "source": [
        "# when setting the maximum length of sequence, variability around the average is used.\n",
        "max_seq_len = np.mean(seq_len_list) + 2 * np.std(seq_len_list)\n",
        "max_seq_len = int(max_seq_len)\n",
        "print('Maximum length of the sequence when considering data only two standard deviations from average: {}'.format(max_seq_len))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN29x-_u5Q0V"
      },
      "source": [
        "perc_covered = np.sum(np.array(seq_len_list) < max_seq_len) / len(seq_len_list)*100\n",
        "print('The above calculated number coveres approximately {} % of data'.format(np.round(perc_covered,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr_pKFPM5bd3"
      },
      "source": [
        "#create padded sequences\n",
        "pad_train=pad_sequences(seq_train,truncating = 'post', padding = 'pre',maxlen=max_seq_len)\n",
        "pad_test=pad_sequences(seq_test,truncating = 'post', padding = 'pre',maxlen=max_seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ystbZw-n5bYR"
      },
      "source": [
        "#Splitting training set for validation purposes\n",
        "Xtrain,Xval,ytrain,yval=train_test_split(pad_train,y_train, test_size=0.2,random_state=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u940z0na6DBx"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense,Input, Embedding,LSTM,Dropout,Conv1D, MaxPooling1D, GlobalMaxPooling1D,Dropout,Bidirectional,Flatten,BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnnRQv-m5bT2"
      },
      "source": [
        "def lstm_model(Xtrain,Xval,ytrain,yval,V,D,maxlen,epochs):\n",
        "\n",
        "    print(\"----Building the model----\")\n",
        "    i = Input(shape=(maxlen,))\n",
        "    x = Embedding(V + 1, D,input_length = maxlen)(i)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Conv1D(32,5,activation = 'relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = MaxPooling1D(2)(x)\n",
        "    x = Bidirectional(LSTM(128,return_sequences=True))(x)\n",
        "    x = LSTM(64)(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(i, x)\n",
        "    model.summary()\n",
        "\n",
        "    #Training the LSTM\n",
        "    print(\"----Training the network----\")\n",
        "    model.compile(optimizer= Adam(0.0005),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "    \n",
        "#     #early_stop = EarlyStopping(monitor='val_accuracy', \n",
        "#                                mode='min', \n",
        "#                                patience = 2 )\n",
        "#     #checkpoints= ModelCheckpoint(filepath='./',\n",
        "#                             monitor=\"val_accuracy\",\n",
        "#                             verbose=0,\n",
        "#                             save_best_only=True\n",
        "#                            )\n",
        "  #  callbacks = [checkpoints,early_stop]\n",
        "    r = model.fit(Xtrain,ytrain, \n",
        "                  validation_data = (Xval,yval), \n",
        "                  epochs = epochs, \n",
        "                  verbose = 2,\n",
        "                  batch_size = 32)\n",
        "                  #callbacks = callbacks\n",
        "    print(\"Train score:\", model.evaluate(Xtrain,ytrain))\n",
        "    print(\"Validation score:\", model.evaluate(Xval,yval))\n",
        "    n_epochs = len(r.history['loss'])\n",
        "    \n",
        "    return r,model,n_epochs "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eez3ILE050f7"
      },
      "source": [
        "%%time\n",
        "\n",
        "# NOTE: 3m51s\n",
        "\n",
        "D = 64 #embedding dims\n",
        "epochs = 5\n",
        "r,model,n_epochs = lstm_model(Xtrain,Xval,ytrain,yval,V,D,max_seq_len,epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdfAE3bu50bG"
      },
      "source": [
        "#Plot accuracy and loss\n",
        "\n",
        "plotLearningCurve(r,n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss3yg0lU6aGc"
      },
      "source": [
        "print(\"Evaluate Model Performance on Test set\")\n",
        "result = model.evaluate(pad_test,y_test)\n",
        "print(dict(zip(model.metrics_names, result)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK3_YwOF6aCS"
      },
      "source": [
        "#Generate predictions for the test dataset\n",
        "ypred = model.predict(pad_test)\n",
        "ypred = ypred>0.5\n",
        "#Get the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, ypred)\n",
        "sns.heatmap(cf_matrix,annot = True,fmt ='g', cmap='Blues')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s41pz7yNYPIO"
      },
      "source": [
        "X_corpus_ser = corpus_sents_df['sent_clean']\n",
        "type(X_corpus_ser)\n",
        "X_corpus_ser[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEanWgXsZllz"
      },
      "source": [
        "type(X_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt0PHX5rY3hG"
      },
      "source": [
        "##create sequences of reviews\n",
        "seq_corpus = tokenizer.texts_to_sequences(X_corpus_ser)\n",
        "# seq_test =  tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahgDGIwmZtzj"
      },
      "source": [
        "type(seq_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-glUVGRY3hI"
      },
      "source": [
        "#choice of maximum length of sequences\n",
        "seq_len_list = [len(i) for i in seq_corpus]\n",
        "\n",
        "#if we take the direct maximum then\n",
        "max_len=max(seq_len_list)\n",
        "print('Maximum length of sequence in the list: {}'.format(max_len))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fv7Uz3QY3hJ"
      },
      "source": [
        "# when setting the maximum length of sequence, variability around the average is used.\n",
        "max_seq_len = np.mean(seq_len_list) + 2 * np.std(seq_len_list)\n",
        "max_seq_len = int(max_seq_len)\n",
        "print('Maximum length of the sequence when considering data only two standard deviations from average: {}'.format(max_seq_len))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up_PGoC0Y3hK"
      },
      "source": [
        "perc_covered = np.sum(np.array(seq_len_list) < max_seq_len) / len(seq_len_list)*100\n",
        "print('The above calculated number coveres approximately {} % of data'.format(np.round(perc_covered,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tdyh1vjzanUu"
      },
      "source": [
        "max_seq_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R3IQhUTYvX6"
      },
      "source": [
        "#create padded sequences\n",
        "pad_corpus=pad_sequences(seq_corpus,truncating = 'post', padding = 'pre',maxlen=584) # max_seq_len)\n",
        "# pad_test=pad_sequences(seq_test,truncating = 'post', padding = 'pre',maxlen=max_seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIqghbZhaVHi"
      },
      "source": [
        "#Generate predictions for the corpus dataset\n",
        "y_corpus_pred = model.predict(pad_corpus)\n",
        "y_corpus_pred.shape\n",
        "y_corpus_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g0ye0WpYvQE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTxr6TUIa54k"
      },
      "source": [
        "lstm_ar = y_corpus_pred.squeeze()\n",
        "lstm_ar.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ModO5-mBa54n"
      },
      "source": [
        "corpus_sents_df['lstm'] = pd.Series(lstm_ar)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48-PFUTqa54q"
      },
      "source": [
        "corpus_sents_df['fcn'].apply(lambda x: 8*(x-0.55)).rolling(900, center=True).mean().plot(label='Fully Connected Neural Net')\n",
        "corpus_sents_df['lstm'].apply(lambda x: 5*(x-0.47)).rolling(900, center=True).mean().plot(label='LSTM Neural Net')\n",
        "corpus_sents_df['sentimentr_stdscaler'].rolling(900, center=True).mean().plot(label='SentimentR')\n",
        "corpus_sents_df['vader_stdscaler'].rolling(900, center=True).mean().plot(label='VADER')\n",
        "plt.legend(loc='best');\n",
        "plt.title(f'{CORPUS_FULL}\\nLSTM Neural Net (Default w/IMDB) SMA=10%');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NrEG7Z0c62N"
      },
      "source": [
        "corpus_root_filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Qps8ecocyet"
      },
      "source": [
        "corpus_sents_df.to_csv(f'sum_4andDNN_{corpus_root_filename}.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-fDw_6w5wwO"
      },
      "source": [
        "**Ref: https://www.kaggle.com/aditya6040/7-models-on-imdb-dataset-best-score-88-2/notebook#CNN-Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTSn2QQR8IC-"
      },
      "source": [
        "embedding_vecor_length = 32\n",
        "callback = EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O52tFKAjpf-D"
      },
      "source": [
        "model.fit(X_train1, y_train, epochs=10, batch_size=256,verbose = 1,validation_data=(X_valid1,y_valid),callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6W0pNrHpf4W"
      },
      "source": [
        "accuracy_score(y_test, model.predict(X_test1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk7FcX-mpfy2"
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vqg9rTOpfsw"
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FufBJTkbppAf"
      },
      "source": [
        "plt.figure(figsize=(4,4))\n",
        "sns.heatmap(confusion_matrix(y_test, model.predict(X_test1)),annot=True,cmap='coolwarm',xticklabels=[0,1],fmt='d',annot_kws={\"fontsize\":19})\n",
        "plt.xlabel(\"Predicted\",fontsize=16)\n",
        "plt.ylabel(\"Actual\",fontsize=16)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2m5RBxppo8O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9ZNqxlA8RWK"
      },
      "source": [
        "### **CNN**\n",
        "\n",
        "* https://github.com/bentrevett/pytorch-sentiment-analysis (CNN w/GLoVE and IMDB)\n",
        "\n",
        "* https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMIrZkmj8H8f"
      },
      "source": [
        "embedding_vecor_length = 32\n",
        "callback = EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4yqkemapuyH"
      },
      "source": [
        "%%time\n",
        "\n",
        "# NOTE: \n",
        "\n",
        "model.fit(X_train1, y_train, epochs=10, batch_size=256,verbose = 1,validation_data=(X_valid1,y_valid),callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZy5hT67pus-"
      },
      "source": [
        "accuracy_score(y_test, model.predict_classes(X_test1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxjdLVp9punq"
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KBSDjJhdRs4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWCJM742dRir"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHfsEmzN6oYf"
      },
      "source": [
        "### **BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua1As3UJpuii"
      },
      "source": [
        "# https://www.kaggle.com/derrelldsouza/imdb-sentiment-analysis-eda-ml-lstm-bert#5.-Predictive-Modelling-using-Deep-Learning\n",
        "\n",
        "#Perform tokenization\n",
        "# automatically download the vocab used during pretraining or fine-tuning a given model,use from_pretrained() method\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YcSOql2pudG"
      },
      "source": [
        "#pass our texts to the tokenizer\n",
        "\n",
        "Xtrain_enc = tokenizer(Xtrain.tolist(), max_length=max_seq_len, \n",
        "                         truncation=True, padding='max_length', \n",
        "                         add_special_tokens=True, return_tensors='np') #return numpy object\n",
        "Xval_enc = tokenizer(Xval.tolist(), max_length=max_seq_len, \n",
        "                         truncation=True, padding='max_length', \n",
        "                         add_special_tokens=True, return_tensors='np') #return numpy object\n",
        "Xtest_enc = tokenizer(Xtest.tolist(), max_length=max_seq_len, \n",
        "                         truncation=True, padding='max_length', \n",
        "                         add_special_tokens=True, return_tensors='np') #return numpy object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVviZDtmpuY2"
      },
      "source": [
        "#preparing our datasets\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(Xtrain_enc),\n",
        "    ytrain\n",
        "))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(Xval_enc),\n",
        "    yval\n",
        "))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(Xtest_enc),\n",
        "    ytest\n",
        "))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvOYExK969Bi"
      },
      "source": [
        "def bert_model(train_dataset,val_dataset,transformer,max_len,epochs):\n",
        "    print(\"----Building the model----\")\n",
        "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "    attention_mask = Input(shape=(max_len,),dtype=tf.int32,name = 'attention_mask') #attention mask\n",
        "    sequence_output = transformer(input_ids,attention_mask)[0]\n",
        "    cls_token = sequence_output[:, 0, :]\n",
        "    x = Dense(512, activation='relu')(cls_token)\n",
        "    x = Dropout(0.1)(x)\n",
        "    y = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=[input_ids,attention_mask], outputs=y)\n",
        "    model.summary()\n",
        "    model.compile(Adam(lr=2e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    r = model.fit(train_dataset.batch(32),batch_size = 32,\n",
        "                  validation_data = val_dataset.batch(32),epochs = epochs)\n",
        "                  #callbacks = callbacks\n",
        "    print(\"Train score:\", model.evaluate(train_dataset.batch(32)))\n",
        "    print(\"Validation score:\", model.evaluate(val_dataset.batch(32)))\n",
        "    n_epochs = len(r.history['loss'])\n",
        "    \n",
        "    return r,model,n_epochs "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjXBoci4688U"
      },
      "source": [
        "transformer = transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNSErWp57AsC"
      },
      "source": [
        "epochs = 2\n",
        "max_len = max_seq_len\n",
        "r,model,n_epochs = bert_model(train_dataset,val_dataset,transformer,max_len,epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_gh_lqY7Ami"
      },
      "source": [
        "#Plot accuracy and loss\n",
        "plotLearningCurve(r,n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY-9_U257G47"
      },
      "source": [
        "print(\"Evaluate Model Performance on Test set\")\n",
        "result = model.evaluate(test_dataset.batch(32))\n",
        "print(dict(zip(model.metrics_names, result)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pIqOGTi7GzN"
      },
      "source": [
        "#Generate predictions for the test dataset\n",
        "ypred = model.predict(test_dataset.batch(32))\n",
        "ypred = ypred>0.5\n",
        "#Get the confusion matrix\n",
        "cf_matrix = confusion_matrix(ytest, ypred)\n",
        "sns.heatmap(cf_matrix,annot = True,fmt ='g', cmap='Blues')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKWimdXSq4KB"
      },
      "source": [
        "## **AutoKeras**\n",
        "\n",
        "* https://autokeras.com/tutorial/text_classification/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVhrU7nOriiz"
      },
      "source": [
        "# RESTART RUNTIME\n",
        "\n",
        "!pip install autokeras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrtoVghPrB5I"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_files\n",
        "\n",
        "import autokeras as ak"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUCSp_9Kq3ZS"
      },
      "source": [
        "dataset = tf.keras.utils.get_file(\n",
        "    fname=\"aclImdb.tar.gz\",\n",
        "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
        "    extract=True,\n",
        ")\n",
        "\n",
        "# set path to dataset\n",
        "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
        "\n",
        "classes = [\"pos\", \"neg\"]\n",
        "train_data = load_files(\n",
        "    os.path.join(IMDB_DATADIR, \"train\"), shuffle=True, categories=classes\n",
        ")\n",
        "test_data = load_files(\n",
        "    os.path.join(IMDB_DATADIR, \"test\"), shuffle=False, categories=classes\n",
        ")\n",
        "\n",
        "x_train = np.array(train_data.data)\n",
        "y_train = np.array(train_data.target)\n",
        "x_test = np.array(test_data.data)\n",
        "y_test = np.array(test_data.target)\n",
        "\n",
        "print(x_train.shape)  # (25000,)\n",
        "print(y_train.shape)  # (25000, 1)\n",
        "print(x_train[0][:50])  # this film was just brilliant casting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2gamB_CrHfk"
      },
      "source": [
        "# Initialize the text classifier.\n",
        "clf = ak.TextClassifier(\n",
        "    overwrite=True, max_trials=1\n",
        ")  # It only tries 1 model as a quick demo.\n",
        "\n",
        "# Feed the text classifier with training data.\n",
        "clf.fit(x_train, y_train, epochs=2)\n",
        "\n",
        "# Predict with the best model.\n",
        "predicted_y = clf.predict(x_test)\n",
        "\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TwcFG-vrHXo"
      },
      "source": [
        "clf.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    # Split the training data and use the last 15% as validation data.\n",
        "    validation_split=0.15,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p78W87xsrt7O"
      },
      "source": [
        "\"\"\"\n",
        "split = 5000\n",
        "x_val = x_train[split:]\n",
        "y_val = y_train[split:]\n",
        "x_train = x_train[:split]\n",
        "y_train = y_train[:split]\n",
        "\n",
        "clf.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=2,\n",
        "    # Use your own validation set.\n",
        "    validation_data=(x_val, y_val),\n",
        ")\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X458PVj1rtyJ"
      },
      "source": [
        "input_node = ak.TextInput()\n",
        "output_node = ak.TextBlock(block_type=\"ngram\")(input_node)\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "clf = ak.AutoModel(\n",
        "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
        ")\n",
        "clf.fit(x_train, y_train, epochs=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGe1OgqcoHL5"
      },
      "source": [
        "## **Pytorch-Optimize**\n",
        "\n",
        "* https://github.com/jettify/pytorch-optimizer (20210705 2k)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58WpZNZooG45"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6KRUi49nuT9"
      },
      "source": [
        "## **Keras-Tuner**\n",
        "\n",
        "* https://github.com/keras-team/keras-tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZb_79A59c8r"
      },
      "source": [
        "# **END**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWRZ7aHOd0R3"
      },
      "source": [
        "# **[OLD STARTING POINT]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiapgHzZdm4x"
      },
      "source": [
        "groups_ls = ['models_baseline_ls',\n",
        "                'models_sentimentr_ls',\n",
        "                'models_syuzhetr_ls',\n",
        "                'models_transformer_ls']\n",
        "\n",
        "# Could add suffix '_sst2' if classifiers trained on SST2 (currently requires 30m on Colab Pro/GPU+RAM)\n",
        "models_supervised_ls = ['linreg_imdb50k',\n",
        "                   'svc_imdb50k',\n",
        "                   'logreg_imdb50k',\n",
        "                   'dforest_imdb50k',\n",
        "                   'multinb_imdb50k']\n",
        "\n",
        "models_baseline_ls = ['sentimentr',\n",
        "                      'syuzhet',\n",
        "                      'bing',\n",
        "                      'sentiword',\n",
        "                      'senticnet',\n",
        "                      'nrc',\n",
        "                      'afinn',\n",
        "                      'vader',\n",
        "                      'textblob',\n",
        "                      'flair',\n",
        "                      'pattern',\n",
        "                      'stanza']\n",
        "\n",
        "models_sentimentr_ls = ['jockers_rinker',\n",
        "                        'jockers',\n",
        "                        'huliu',\n",
        "                        'senticnet',\n",
        "                        'sentiword',\n",
        "                        'nrc',\n",
        "                        'lmcd']\n",
        "\n",
        "models_syuzhetr_ls = ['syuzhet',\n",
        "                      'bing',\n",
        "                      'afinn',\n",
        "                      'nrc']\n",
        "\n",
        "models_transformer_ls = ['roberta15lg', \n",
        "                         'nlptown', \n",
        "                         'yelp', \n",
        "                         'hinglish',\n",
        "                         'imdb2way', \n",
        "                         'huggingface', \n",
        "                         't5imdb50k', \n",
        "                         'robertaxml8lang']\n",
        "\n",
        "# Temporarily redefine from English to French Transformer Models\n",
        "# models_transformer_ls = ['flaubert', 'nlptown', 'robertaxml8lang']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOPa6HH-OjZp"
      },
      "source": [
        "**Install Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drpZJilASHUN"
      },
      "source": [
        "# fast detection of character set encoding for text/files\n",
        "\n",
        "!pip install cchardet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA7Nw-SA_si1"
      },
      "source": [
        "!pip install pysbd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEjSzsusOOJ-"
      },
      "source": [
        "# common ML code\n",
        "\n",
        "!pip install sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ0UVdasuTTS"
      },
      "source": [
        "%pip install contractions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MbHfUCz6qTQ"
      },
      "source": [
        "!pip install pysbd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENUk4UsK6qTV"
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4Nis-KA6qTY"
      },
      "source": [
        "import pysbd\n",
        "import spacy\n",
        "from pysbd.utils import PySBDFactory\n",
        "\n",
        "# Conditionally loads english or french PySBD/NLTK Sentence tokenizers \n",
        "#   in parags2sents()\n",
        "\n",
        "# nlp = spacy.blank('en')\n",
        "\n",
        "# nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "# explicitly adding component to pipeline\n",
        "# (recommended - makes it more readable to tell what's going on)\n",
        "# nlp.add_pipe(PySBDFactory(nlp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxLPTsA_6qTa"
      },
      "source": [
        "\n",
        "\n",
        "# or you can use it implicitly with keyword\n",
        "# pysbd = nlp.create_pipe('pysbd')\n",
        "# nlp.add_pipe(pysbd)\n",
        "\n",
        "# doc = nlp('My name is Jonas E. Smith. Please turn to p. 55.')\n",
        "# print(list(doc.sents))\n",
        "# [My name is Jonas E. Smith., Please turn to p. 55.]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmtqmvu6OlR9"
      },
      "source": [
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7bf4lfgwMEz"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import io\n",
        "import glob\n",
        "import json\n",
        "import contextlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOmyq4h7OOFi"
      },
      "source": [
        "# IMPORT LIBRARIES\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OslLdEsvOuFU"
      },
      "source": [
        "import re\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YelenXz5BcmE"
      },
      "source": [
        "from itertools import cycle  # For plotly\n",
        "\n",
        "import collections\n",
        "from collections import OrderedDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Suximbjnw8D"
      },
      "source": [
        "# Import libraries for logging\n",
        "\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import time                     # (TODO: check no dependencies and delete)\n",
        "from time import gmtime, strftime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPZmScjVDYyw"
      },
      "source": [
        "import nltk\n",
        "\n",
        "# Download for sentence tokenization\n",
        "import nltk.data\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Download for nltk/VADER sentiment analysis\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u34kPKO0_xF_"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm') # Load the English Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMl2mfF8Haw8"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler   # To normalize time series\n",
        "from sklearn.preprocessing import StandardScaler # To Standardize time series: center(sub mean) and rescale within 1 SD (only for well-behaved guassian distributions)\n",
        "from sklearn.preprocessing import RobustScaler   # To Standardize time series: center(sub median) and rescale within 25%-75% (1st-3rd) IQR (better for noisy, outliers distributions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nckwluDXwa1c"
      },
      "source": [
        "minmax_scaler = MinMaxScaler()\n",
        "mean_std_scaler = StandardScaler()\n",
        "median_iqr_scaler = RobustScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U589lvKXmFV-"
      },
      "source": [
        "# Zoom interpolates new datapoints between existing datapoints to expand a time series \n",
        "\n",
        "from scipy.ndimage.interpolation import zoom"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wcZfSOuBlW7"
      },
      "source": [
        "from scipy import interpolate\n",
        "from scipy.interpolate import CubicSpline\n",
        "from scipy import signal\n",
        "from scipy.signal import argrelextrema"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY3UyvYjAvDN"
      },
      "source": [
        "from statsmodels.nonparametric.smoothers_lowess import lowess as sm_lowess\n",
        "from statsmodels import robust"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02LJQlYpgQGs"
      },
      "source": [
        "corpus_sects_df = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcSc4jsggSy2"
      },
      "source": [
        "**Define Library-Dependent Objects**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjGN2sN3uRpN"
      },
      "source": [
        "import contractions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AllIwMngDGC3"
      },
      "source": [
        "# Necessary to define before defining Utility Functions using these DataFrames\n",
        "\n",
        "corpus_sents_df = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwl0MBDyOwtX"
      },
      "source": [
        "**Configure Jupyter Notebook**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APCau-T26XQ3"
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def my_css():\n",
        "   display(HTML(\"\"\"<style>table.dataframe td{white-space: nowrap;}</style>\"\"\"))\n",
        "\n",
        "get_ipython().events.register('pre_run_cell', my_css)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD1cyqWsfjxA"
      },
      "source": [
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzfybE5kfmE-"
      },
      "source": [
        "# Configure matplotlib and seaborn\n",
        "\n",
        "# Plotting pretty figures and avoid blurry images\n",
        "# %config InlineBackend.figure_format = 'retina'\n",
        "# Larger scale for plots in notebooks\n",
        "# sns.set_context('talk')\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = [16, 8]\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.rc('figure', facecolor='white')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIIjSbyeP2fg"
      },
      "source": [
        "# Configure Jupyter\n",
        "\n",
        "# Enable multiple outputs from one code cell\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "from IPython.display import display\n",
        "from ipywidgets import widgets, interactive\n",
        "\n",
        "# Configure Google Colab\n",
        "\n",
        "%load_ext google.colab.data_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS_El2PiQlyP"
      },
      "source": [
        "# Text wrap\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuM_qnOHUil5"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import plotly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxQtrH196gl3"
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def my_css():\n",
        "   display(HTML(\"\"\"<style>table.dataframe td{white-space: nowrap;}</style>\"\"\"))\n",
        "\n",
        "get_ipython().events.register('pre_run_cell', my_css)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIPzbt5Ikldp"
      },
      "source": [
        "# with pd.option_context('display.max_colwidth', None):\n",
        "#   display(corpus_transformer_df['sent_raw'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDR54Pbg5zqz"
      },
      "source": [
        "# with pd.option_context('display.max_colwidth', None):\n",
        "#   display(corpus_sentimentr_df.iloc[:10]['sent_raw'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dLkfn4KFmDf"
      },
      "source": [
        "**Configuration Details Snapshot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FNPovQBFZky"
      },
      "source": [
        "# Snap Shot of Time, Machine, Data and Library/Version Blueprint\n",
        "# TODO:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBPCBVkuzw_2"
      },
      "source": [
        "!pip list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HKj6KbIzoyM"
      },
      "source": [
        "# !pip install watermark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpMRnqjzzjS5"
      },
      "source": [
        "# %load_ext watermark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5uwS7H_zhaC"
      },
      "source": [
        "# %watermark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wiSBHxoOGZz"
      },
      "source": [
        "# **Delete/Reset Main DataStructure**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZXoa5lANBCM"
      },
      "source": [
        "%whos DataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3b35AXqNF7w"
      },
      "source": [
        "# %reset_selective corpus_sents_df corpus_parags_df corpus_sects_df corpus_chaps_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRiqyCInNOnY"
      },
      "source": [
        "# %reset_selective corpus_sentimentr corpus_syuzhetr_df corpus_transformer_df corpus_unified_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP8j6XqSNbhr"
      },
      "source": [
        "# %reset_selective temp_baseline_df temp_df temp_sentimentr_df temp_syuzhetr_df temp_transformer_df unified_crux_df corr_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji9GwSuNZRdi"
      },
      "source": [
        "# **Connect to Corpus Text files**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KRfiXXQOZcq"
      },
      "source": [
        "## **Option (a): Connect to Google gDrive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G64etjAUOOSm"
      },
      "source": [
        "# Connect to Google gDrive\n",
        "\n",
        "# Flag to indicate first run through code \n",
        "flag_first_run = True\n",
        "\n",
        "from google.colab import drive, files\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0fvFZq-eFaw"
      },
      "source": [
        "# Select the Corpus subdirectory on your Google gDrive\n",
        "\n",
        "# Done\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/imcewan_machineslikeme\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/cdickens_greatexpectations\" #@param {type:\"string\"}\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/ddefoe_robinsoncrusoe\" #@param {type:\"string\"}\n",
        "gdrive_subdir = \"./research/2021/sa_book_code/books_sa/emforster_howardsend\" #@param {type:\"string\"}\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/fdouglass_narrativelifeslave\" #@param {type:\"string\"}\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/fscottfitzgerald_thegreatgatsby\" #@param {type:\"string\"}\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/geliot_middlemarch\" #@param {type:\"string\"}\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/hjames_portraitofalady\" #@param {type:\"string\"}\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/homer_odyssey\" #@param {type:\"string\"}\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/jconrad_heartofdarkness\" #@param {type:\"string\"} \n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/jjoyce_portraitoftheartist\" #@param {type:\"string\"}\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/jkrowling_harrypotter\" #@param {type:\"string\"}\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/mproust_time\" #@param {type:\"string\"}\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/staugustine_confessions\" #@param {type:\"string\"}\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/tmorrison_beloved\" #@param {type:\"string\"}\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/vwoolf_tothelighthouse\" #@param {type:\"string\"}\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/vwoolf_mrsdalloway\" #@param {type:\"string\"}\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/vwoolf_thewaves\" #@param {type:\"string\"}\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/vwoolf_orlando\" #@param {type:\"string\"}\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/vnabokov_palefire\" #@param {type:\"string\"}\n",
        "\n",
        "# Current\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/homer_odyssey\" #@param {type:\"string\"}\n",
        "\n",
        "# To do\n",
        "# gdrive_subdir = \"./research/2021/sa_book_code/books_sa/geliot_middlemarch\" #@param {type:\"string\"}\n",
        "\n",
        "CORPUS_SUBDIR = gdrive_subdir\n",
        "corpus_filename = CORPUS_SUBDIR\n",
        "\n",
        "# Change to working subdirectory\n",
        "if flag_first_run == True:\n",
        "  full_path_str = gdrive_subdir\n",
        "  flag_first_run = False\n",
        "else:\n",
        "  full_path_str = f'/gdrive/MyDrive{gdrive_subdir[1:]}'\n",
        "\n",
        "%cd $full_path_str\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKV1uMBEO8TR"
      },
      "source": [
        "## **Option (b): Upload Corpus Textfile**\n",
        "\n",
        "***Only do this if your Google subdirectory doesn't already contain a plain text file of your Corpus or you wish to overwrite it and use a newer version***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH6dlB2fO6Ln"
      },
      "source": [
        "# Execute this code cell to upload plain text file of corpus\n",
        "#   Should be *.txt format with paragraphs separated by at least 2 newlines\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3LORQ4fRGBW"
      },
      "source": [
        "# Verify file was uploaded\n",
        "\n",
        "# Get uploaded filename\n",
        "corpus_filename = list(uploaded.keys())[0]\n",
        "print(f'Uploaded Corpus filename is: {corpus_filename}')\n",
        "CORPUS_FILENAME = corpus_filename\n",
        "\n",
        "!ls -al $corpus_filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bsm8awD4AZ8O"
      },
      "source": [
        "# **Configuration (Manual)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfilGg6Mkxnd"
      },
      "source": [
        "# Verify subdirectory change\n",
        "\n",
        "!pwd\n",
        "!ls -altr *\n",
        "\n",
        "# TODO: Intelligently automate the filling of form based upon directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP3WLEv_g5aq"
      },
      "source": [
        "# CORPUS_TITLE = 'Beloved' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Toni Morrison\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"tmorrison_beloved.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/tmorrison_belovedy\"  #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'Confessions' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Saint Augustine\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"staugustine_confessions.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/staugustine_confessions\"  #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'Great Expectations' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Charles Dickens\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"cdickens_greatexpectations.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/cdickens_greatexpectations\" #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'Heart of Darkness' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Joseph Conrad\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"jconrad_heartofdarkness.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/jconrad_heartofdarkness\" #@param {type:\"string\"}\n",
        "\n",
        "CORPUS_TITLE = 'Howards End' #@param {type:\"string\"}\n",
        "CORPUS_AUTHOR = \"EM Forster\" #@param {type:\"string\"}\n",
        "CORPUS_FILENAME = \"emforster_howardsend.txt\" #@param {type:\"string\"}\n",
        "CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/emforster_howardsend\" #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'Machines Like Me' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Ian McEwan\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"imcewan_machineslikeme.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/imcewan_machineslikeme\" #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'Middlemarch' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"George Eliot\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"geliot_middlemarch_wprelude.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/geliot_middlemarch\"  #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'Mrs. Dalloway' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Virginia Woolf\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"vwoolf_mrsdalloway.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/vwoolf_mrsdalloway\" #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'Narrative Life of Frederick Douglass' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Frederick Douglass\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"fdouglass_narrative.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/fdouglass_narrativelifeslave\"  #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'Orlando' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Virginia Woolf\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"vwoolf_orlando.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/vwoolf_orlando\" #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'Palefire - Commentary' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Vladimir Nabokov\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"vnabokov_palefire_commentary.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/vnabokov_palefire\" #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'Portrait of a Lady' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Henry James\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"hjames_portraitofalady.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/hjames_portraitofalady\" #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'Portrait of the Artist as a Young Man' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"James Joyce\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"jjoyce_portraitoftheartist.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/jjoyce_portraitoftheartist\" #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'Robinson Crusoe' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Daniel Defoe\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"ddefoe_robinsoncrusoe.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/ddefoe_robinsoncrusoe\" #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'The Great Gatsby' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"F. Scott Fitzgerald\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"fscottfitzgerald_thegreatgatsby.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/fscottfitzgerald_thegreatgatsby\" #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'The Socerers Stone' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"J.K. Rowling\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"hpotter1_sorcerersstone.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/jkrowling_harrypotter\" #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'The Waves' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Virginia Woolf\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"vwoolf_thewaves.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/vwoolf_thewaves\" #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'To The Lighthouse' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Virginia Woolf\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"vwoolf_tothelighthouse.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/vwoolf_tothelighthouse\" #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'The Odyssey' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Homer SButler\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"sbutler_odyssey.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/sbutler_odyssey\"  #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'The Odyssey' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Homer EWilson\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"ewilson_odyssey.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/homer_odyssey\"  #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'The Guermantes Way - English' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Marcel Proust\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"mproust_3guermantesway_mtreharne_en.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/mproust_time\"  #@param {type:\"string\"}\n",
        "\n",
        "# CORPUS_TITLE = 'The Guermantes Way - French' #@param {type:\"string\"}\n",
        "# CORPUS_AUTHOR = \"Marcel Proust\" #@param {type:\"string\"}\n",
        "# CORPUS_FILENAME = \"mproust_guermantes_fr.txt\" #@param {type:\"string\"}\n",
        "# CORPUS_SUBDIR = \"./research/2021/sa_book_code/books_sa/mproust_time\"  #@param {type:\"string\"}\n",
        "\n",
        "CORPUS_LANGUAGE = \"English\" #@param [\"English\", \"French\"]\n",
        "\n",
        "CHAPTER_HEADINGS = \"CHAPTER\" #@param [\"CHAPTER\", \"BOOK\", \"None\"]\n",
        "CHAPTER_NUMBERING = \"Roman (I,II,...)\" #@param [\"Arabic (1,2,...)\", \"Roman (I,II,...)\"]\n",
        "SECTION_HEADINGS = \"None\" #@param [\"SECTION (ArabicNo)\", \"SECTION (RomanNo)\", \"----- (Hyphens)\", \"None\"]\n",
        "\n",
        "LEXICONS_SUBDIR = \"./research/2021/sa_book_code/books_sa/lexicons\" #@param {type:\"string\"}\n",
        "\n",
        "CORPUS_FULL = f'{CORPUS_TITLE} by: {CORPUS_AUTHOR}'\n",
        "\n",
        "PLOT_OUTPUT = \"Major\" #@param [\"None\", \"Major\", \"All\"]\n",
        "\n",
        "FILE_OUTPUT = \"Major\" #@param [\"None\", \"Major\", \"All\"]\n",
        "\n",
        "\n",
        "gdrive_subdir = CORPUS_SUBDIR\n",
        "corpus_filename = CORPUS_FILENAME\n",
        "CORPUS_LANGUAGE = CORPUS_LANGUAGE.lower()\n",
        "author_str = ''.join(CORPUS_AUTHOR.split()).lower()\n",
        "author_abbr_str = (CORPUS_AUTHOR.split(' ')[0][0]+CORPUS_AUTHOR.split(' ')[1]).lower()\n",
        "title_str = ''.join(CORPUS_TITLE.split()).lower()\n",
        "title_str = re.sub(r'[^A-Za-z0-9]','', title_str).lower()\n",
        "\n",
        "print(f'\\nWorking Corpus Datafile: ------------------------------ \\n\\n    {CORPUS_SUBDIR}')\n",
        "print(f'\\nFull Corpus Title/Author: ------------------------------ \\n\\n    {CORPUS_FULL}')\n",
        "\n",
        "\n",
        "if CHAPTER_HEADINGS == 'CHAPTER':\n",
        "  if CHAPTER_NUMBERING == \"Arabic (1,2,...)\":\n",
        "    # pattern_chap = r'CHAPTER [0123456789]{1,2} ' # [\\.]?[^\\n]*'\n",
        "    pattern_chap = r'CHAPTER [0123456789]{1,2}[.]?[^\\n]*' # [os.return]*'\n",
        "  elif CHAPTER_NUMBERING == \"Roman (I,II,...)\":\n",
        "    pattern_chap = r'CHAPTER[\\s]{1,5}[IVXL]{1,10}[.:]?[\\s]+' # [^\\n]+'\n",
        "    # pattern_chap = r'CHAPTER[\\s]{1,}[IVXL]{1,10}[.:]?[^\\n\\r]*'\n",
        "  else:\n",
        "    print(f'ERROR: Illegal CHAPTER_NUMBERING value = {CHAPTER_NUMBERING}')\n",
        "\n",
        "elif CHAPTER_HEADINGS == 'BOOK':\n",
        "  if CHAPTER_NUMBERING == \"Arabic (1,2,...)\":\n",
        "    pattern_chap = r'BOOK [0123456789]{1,2}[.]?[^\\n]*'\n",
        "  elif CHAPTER_NUMBERING == \"Roman (I,II,...)\":\n",
        "    pattern_chap = r'[\\s]*BOOK[\\s]{1,5}[IVXL]{1,10}[.:]?[\\s]+' # [.:]?[\\s]*[^\\n]*[\\n\\r]+' # ]{0,1}[^\\n]*' # [^\\n]*' # Problems with embedded 'Book'\n",
        "  else:\n",
        "    print(f'ERROR: Illegal CHAPTER_NUMBERING value = {CHAPTER_NUMBERING}')\n",
        "\n",
        "elif CHAPTER_HEADINGS == \"None\":\n",
        "  pattern_chap = r'CHAPTER [0123456789]{1,2}[.]?[^\\n]*'\n",
        "\n",
        "else:\n",
        "  print(f'ERROR: Illegal CHAPTER_HEADINGS value = {CHAPTER_HEADINGS}')\n",
        "\n",
        "# Default Section RegEx Pattern\n",
        "pattern_sect = 'SECTION [0123456789]{1,2}[^\\n]*'\n",
        "\n",
        "if SECTION_HEADINGS == 'SECTION (ArabicNo)':\n",
        "  # pattern_sect = r'SECTION [0-9]{1,2} [^\\n]*'\n",
        "  # TODO: [^\\n] gets parsed into [^\\\\n] causing problems, so simplify\n",
        "  pattern_sect = r'SECTION [0123456789]{1,2}[.:]?[^\\n]*'\n",
        "elif SECTION_HEADINGS == 'SECTION (RomanNo)':\n",
        "  pattern_sect = r'SECTION [IVXL]{1,10}[.:]?[^\\n\\r]+' # } [A-Z \\.-:—;-’\\'\"]*[\\n]*'\n",
        "elif SECTION_HEADINGS == '----- (Hyphens)':\n",
        "  pattern_sect = r'^[- ]{3,}[^\\n]*'\n",
        "elif SECTION_HEADINGS == 'None':\n",
        "  pass\n",
        "else:\n",
        "  print(f'ERROR: Illegal SECTION_HEADING value = {SECTION_HEADINGS}')\n",
        "\n",
        "print(f'\\nCHAPTER Headings: ------------------------------ \\n\\n    {CHAPTER_HEADINGS}')\n",
        "\n",
        "print(f'\\nSECTION Headings: ------------------------------ \\n\\n    {SECTION_HEADINGS}')\n",
        "\n",
        "\n",
        "print(f'\\nCorpus file information: ------------------------------ \\n')\n",
        "!ls -al $CORPUS_FILENAME\n",
        "\n",
        "# Verify contents of Corpus File is Correctly Formatted\n",
        "#   \n",
        "# TODO: ./utils/verify_format.py\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnWBZCGMT-0G"
      },
      "source": [
        "corpus_filename\n",
        "print('\\n')\n",
        "CORPUS_FULL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8owpM75RILKn"
      },
      "source": [
        "# **Utility Functions (Auto)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMLbyx6gIPqj"
      },
      "source": [
        "## **File Manipulations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBOvvP-BSIiC"
      },
      "source": [
        "# https://dev.to/bowmanjd/character-encodings-and-detection-with-python-chardet-and-cchardet-4hj7\n",
        "\n",
        "import cchardet as chardet\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "def get_file_encoding(filename):\n",
        "    \"\"\"Detect encoding and return decoded text, encoding, and confidence level.\"\"\"\n",
        "    filepath = Path(filename)\n",
        "\n",
        "    # We must read as binary (bytes) because we don't yet know encoding\n",
        "    blob = filepath.read_bytes()\n",
        "\n",
        "    detection = chardet.detect(blob)\n",
        "    encoding = detection[\"encoding\"]\n",
        "    confidence = detection[\"confidence\"]\n",
        "    text = blob.decode(encoding)\n",
        "\n",
        "    return text, encoding, confidence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09qXAWa0jStn"
      },
      "source": [
        "# re.split(r'SECTION', 'There is one SECTION in this. - can you SECTION string', flags=re.I)\n",
        "\n",
        "re.split(r'SECTION', 'There is one string', flags=re.I)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CEiOZzv5lw9"
      },
      "source": [
        "## **Text Wrangling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQJdrsbpkSSw"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxh27xfMkXDN"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer \n",
        "\n",
        "# Init the Wordnet Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Lemmatize Single Word\n",
        "print(lemmatizer.lemmatize(\"bats\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIjRdm3rlw85"
      },
      "source": [
        "test_str = \"I love eating bats and driving many cars.\" #  around the darken town at night.\"\n",
        "\n",
        "doc = nlp(test_str)\n",
        "\n",
        "# Extract the lemma for each token and join\n",
        "\" \".join([token.lemma_ for token in doc])\n",
        "#> 'the strip bat be hang on -PRON- foot for good'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v374fE0tIrea"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "def stem_str(text_str):\n",
        "  '''\n",
        "  Given a text string\n",
        "  Return the same string with all tokens stemmed where possible\n",
        "  '''\n",
        "\n",
        "  from nltk.stem import WordNetLemmatizer # For stemming the sentence\n",
        "  from nltk.stem import SnowballStemmer # For stemming the sentence\n",
        "\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZaL4cZbg3td"
      },
      "source": [
        "def lemmatize_str(text_str):\n",
        "  '''\n",
        "  Given a text string\n",
        "  Return the same string with all tokens lemmatized where possible\n",
        "  '''\n",
        "\n",
        "  # NOTE: depends upon Setup above importing minimal SpaCy pipeline defined as [nlp]\n",
        "\n",
        "  # Lemmaitization MAY help performance, but depends on SA Model and Corpus (see below)\n",
        "  # https://opendatagroup.github.io/data%20science/2019/03/21/preprocessing-text.html \n",
        "  # Which library: NLTK, SpaCy, TextBlob, CLiPS Pattern, gensim, Stanford OpenNLP/Stanza, Flair, etc.\n",
        "  # https://www.machinelearningplus.com/nlp/lemmatization-examples-python/\n",
        "  # Spelling, Contractions, etc\n",
        "  # https://cnvrg.io/sentiment-analysis-python/\n",
        "\n",
        "  text_lemma_ls = []\n",
        "\n",
        "  token_ls = text_str.split()\n",
        "\n",
        "  for atoken in token_ls:\n",
        "    if len(atoken) > 2:\n",
        "      print(f'lemmatizing: {atoken}')\n",
        "      atoken_lemma = lemmatizer.lemmatize(atoken)\n",
        "      print(f'    lemma: {atoken_lemma}')\n",
        "      text_lemma_ls.append(atoken_lemma)\n",
        "    else:\n",
        "      print(f'skip lemmatizing')\n",
        "      text_lemma_ls.append(atoken)\n",
        "\n",
        "  text_lemma_str = ' '.join(text_lemma_ls)\n",
        "\n",
        "  return text_lemma_str.strip()\n",
        "\n",
        "# Test\n",
        "\n",
        "test_str = \"I love eating bats and driving many cars.\" #  around the darken town at night.\"\n",
        "\n",
        "test_lemma_str = lemmatize_str(test_str)\n",
        "print(f'test_lemma_str: {test_lemma_str}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAl8P6zSkzBM"
      },
      "source": [
        "lemmatizer.lemmatize('eating')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGje9LyN5hx4"
      },
      "source": [
        "def del_leadroman(str_raw):\n",
        "  '''\n",
        "  Given a text string\n",
        "  Return the string with any possible leaning roman numerals removed [IVXLCM]\n",
        "  '''\n",
        "\n",
        "\n",
        "  # Rule 1: consecutive 'i' tokens indicate a roman numeral followed by 'I' pronoun\n",
        "  pattern_doublei = re.compile(r'\\b[iI][\\s]+[iI]\\b')\n",
        "  str_clean1 = re.sub(pattern_doublei, \"i\", str_raw)\n",
        "\n",
        "  # Rule 2: any [vxlcm]-only tokens are stray roman numerals\n",
        "  pattern_romanno = re.compile(r'\\b[vxlcm]{1,10}\\b')\n",
        "  str_clean2 = re.sub(pattern_romanno, \"\", str_clean1)\n",
        "\n",
        "  return str_clean2\n",
        "\n",
        "\n",
        "# Test\n",
        "\n",
        "test_str = \"\"\"I I was born in Tuckahoe, near Hillsborough, and about twelve miles from Easton, in Talbot county, Maryland. I have no accurate knowledge of my age, never having seen any authentic record containing it. By far the larger part of the slaves know as little of their ages as horses know of theirs, and it is the wish of most masters within my knowledge to keep their slaves thus ignorant. I do not remember to have ever met a slave who could tell of his birthday. They seldom come nearer to it than planting-time, harvest-time, cherry-time, spring-time, or fall-time. A want of information concerning my own was a source of unhappiness to me even during childhood. The white children could tell their ages. I could not tell why I ought to be deprived of the same privilege. I was not allowed to make any inquiries of my master concerning it. He deemed all such inquiries on the part of a slave improper and impertinent, and evidence of a restless spirit. The nearest estimate I can give makes me now between twenty-seven and twenty-eight years of age. I come to this, from hearing my master say, some time during 1835, I was about seventeen years old.\n",
        "\n",
        "My mother was named Harriet Bailey. She was the daughter of Isaac and Betsey Bailey, both colored, and quite dark. My mother was of a darker complexion than either my grandmother or grandfather.\n",
        "\"\"\"\n",
        "\n",
        "print(f\"\\n\\nRESULT:\\n\\n{del_leadroman(test_str)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rMQwo0cKHS4"
      },
      "source": [
        "# Defined for clean_text()\n",
        "\n",
        "from unicodedata import normalize\n",
        "\n",
        "# prepare regex for char filtering\n",
        "re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "# prepare translation table for removing punctuation\n",
        "table = str.maketrans('', '', string.punctuation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MMyldysrOMv"
      },
      "source": [
        "# CORPUS_LANGUAGE = 'french'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7b75qK_Uzfv"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuhSaXnFU9hY"
      },
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "541lpDXaU_P0"
      },
      "source": [
        "# Create WordNetLemmatizer object\n",
        "wnl = WordNetLemmatizer()\n",
        "  \n",
        "# single word lemmatization examples\n",
        "list1 = ['kites', 'babies', 'dogs', 'flying', 'smiling', \n",
        "         'driving', 'died', 'tried', 'feet']\n",
        "for words in list1:\n",
        "    print(words + \" ---> \" + wnl.lemmatize(words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsPbZyHhVu-q"
      },
      "source": [
        "type(nlp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "802sQm-GWyRK"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "  \n",
        "# Create a Doc object\n",
        "doc = nlp(u'the bats saw the cats with best stripes hanging upside down by their feet')\n",
        "  \n",
        "# Create list of tokens from given string\n",
        "tokens = []\n",
        "for token in doc:\n",
        "    tokens.append(token)\n",
        "  \n",
        "print(tokens)\n",
        "#> [the, bats, saw, the, cats, with, best, stripes, hanging, upside, down, by, their, feet]\n",
        "  \n",
        "lemmatized_sentence = \" \".join([token.lemma_ for token in doc])\n",
        "  \n",
        "print(lemmatized_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ0v_zfHt6Nz"
      },
      "source": [
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg48zQwecr7g"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords_en = stopwords.words(\"english\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtPCs5C3ctgL"
      },
      "source": [
        "stopwords_custom = ['bazinga', 'hoohaw', 'pating']\n",
        "stopwords_en.extend(stopwords_custom)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaFLzGy0Rdlm"
      },
      "source": [
        "def clean_stemlemma_text(text, stem_fl =False, lemma_fl=True, punct_fl=True, stopword_ls=stopwords_en):\n",
        "  '''\n",
        "  Given a text string, flags for stemming or lemmatizing and \n",
        "  Return a clened version of the sting\n",
        "\n",
        "  Preprocess a string.\n",
        "  :parameter\n",
        "      :param text: string - name of column containing text\n",
        "      :param lst_stopwords: list - list of stopwords to remove\n",
        "      :param stem_fl: bool - whether stemming is to be applied\n",
        "      :param lemma_fl: bool - whether lemmitisation is to be applied\n",
        "  :return\n",
        "      cleaned tex\n",
        "  '''\n",
        "  # https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794\n",
        "\n",
        "  ## clean (convert to lowercase then strip)\n",
        "  text = str(text).lower().strip()\n",
        "\n",
        "  ## Punctuation (remove -ing, -ly, ...)\n",
        "  if punct_fl == True:\n",
        "      text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "  ## Tokenize (convert from string to list)\n",
        "  text_ls = text.split()    ## remove Stopwords\n",
        "  if stopword_ls is not None:\n",
        "      text_ls = [word for word in text_ls if word not in stopword_ls]\n",
        "  \n",
        "  ## Stemming (remove -ing, -ly, ...)\n",
        "  if stem_fl == True:\n",
        "      ps = nltk.stem.porter.PorterStemmer()\n",
        "      text_ls = [ps.stem(word) for word in text_ls]\n",
        "              \n",
        "  ## Lemmatisation (convert the word into root word)\n",
        "  # https://www.geeksforgeeks.org/python-lemmatization-approaches-with-examples/ \n",
        "  if lemma_fl == True:\n",
        "      # lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "      # text_ls = [lem.lemmatize(word) for word in text_ls]\n",
        "      text_str = ' '.join(text_ls)\n",
        "      doc = nlp(text_str)\n",
        "      text_ls = [token.lemma_ for token in doc]\n",
        "          \n",
        "  ## back to string from list\n",
        "  text = \" \".join(text_ls)\n",
        "  \n",
        "  return text\n",
        "\n",
        "# Test\n",
        "\n",
        "clean_stemlemma_text('I going to have a interesting dinner party this coming Saturday.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9FDtpQ6QaEJ"
      },
      "source": [
        "# This function converts to lower-case, removes square bracket, removes numbers/punctuation, end of line hyphens\n",
        "\n",
        "# https://towardsdatascience.com/nlp-building-text-cleanup-and-preprocessing-pipeline-eba4095245a0\n",
        "# https://machinelearningmastery.com/prepare-french-english-dataset-machine-translation/ \n",
        "\n",
        "def clean_text(text):\n",
        "\n",
        "  # normalize unicode characters\n",
        "  #   library [normalize] imported in Setup above\n",
        "\n",
        "  if CORPUS_LANGUAGE == 'english':\n",
        "    text = normalize('NFD', text).encode('ascii', 'ignore')\n",
        "    text = text.decode('UTF-8')\n",
        "\n",
        "    # remove non-printable chars form each token\n",
        "    # regex pattern [re_print] defined in Setup above\n",
        "    text = re_print.sub('', text)\n",
        "\n",
        "    # to lower\n",
        "    text = text.lower()\n",
        "\n",
        "    # Spelling correction\n",
        "    # from autocorrect import Speller #correcting the spellings\n",
        "    \n",
        "    # Adjust apostrophes and contractions\n",
        "    # from contractions import contractions_dict # to solve contractions\n",
        "    text = contractions.fix(text)  # Expand contrations\n",
        "    # TODO: Problem with The Great Gatsby [I'm] -> [I' ]\n",
        "    text = re.sub(\"\\\\'s\", \" own\", text)  # After expanding normal apostrophes, expand possessive apostrophes \"Mary's car\" -> \"Mary own car\"\n",
        "\n",
        "    # Join end of line words split by continuation hyphens \n",
        "    text = re.sub(\"-\\n\", \" \", text)       \n",
        "    text = re.sub(\"-\\n\\r\", \" \", text)\n",
        "    text = re.sub(\"-\\r\", \" \", text)\n",
        "    text = re.sub(\"\\[.*?\\]\", \" \", text)\n",
        "\n",
        "    text = re.sub(\"-\", \" \", text)  # Special care for hypenated words well-known: choose option (a)\n",
        "                                    # (a) 'well known', (b) 'wellknown' (c) 'well known' and 'wellknown' cf: https://datascience.stackexchange.com/questions/81072/how-to-process-the-hyphenated-english-words-for-any-nlp-problem\n",
        "\n",
        "    text = re.sub(\"/\", \" \", text)  # sociability/conversation/interesting -> sociability conversation interesting                             \n",
        "\n",
        "    # Split string into tokens\n",
        "    line = text.split()\n",
        "\n",
        "    # remove punctuation from each token\n",
        "    line = [word.translate(table) for word in line]\n",
        "    # OLD string way: text = re.sub(\"[%s]\" % re.escape(string.punctuation), \" \", text)\n",
        "\n",
        "    # remove tokens with numbers in them\n",
        "    line = [word for word in line if word.isalpha()]    \n",
        "    # OLD stirng way: text = re.sub(\"\\w*\\d\\w*\", \" \", text)\n",
        "\n",
        "    # collapse/replace any whitespace(s) with a single hard space\n",
        "    # OLD string way: text = re.sub(\"[\\n]\", \" \", text)  # Replace newline with space\n",
        "    # reassemble tokens into single string to return\n",
        "    text_cleaned = ' '.join(line)\n",
        "\n",
        "  elif CORPUS_LANGUAGE == 'french':\n",
        "    # FRENCH: Minimal processing to preserve accents for Transformers\n",
        "    # text = normalize('NFD', text).encode('ascii', 'ignore')\n",
        "    # text = text.decode('UTF-8')\n",
        "\n",
        "    # remove non-printable chars form each token\n",
        "    # regex pattern [re_print] defined in Setup above\n",
        "    # text = re_print.sub('', text)\n",
        "\n",
        "    # to lower\n",
        "    text = text.lower()\n",
        "\n",
        "    # Spelling correction\n",
        "    # from autocorrect import Speller #correcting the spellings\n",
        "    \n",
        "    # Adjust apostrophes and contractions\n",
        "    # from contractions import contractions_dict # to solve contractions\n",
        "    # text = contractions.fix(text)  # Expand contrations\n",
        "    # TODO: Problem with The Great Gatsby [I'm] -> [I' ]\n",
        "    # text = re.sub(\"\\\\'s\", \" own\", text)  # After expanding normal apostrophes, expand possessive apostrophes \"Mary's car\" -> \"Mary own car\"\n",
        "\n",
        "    # Join end of line words split by continuation hyphens \n",
        "    text = re.sub(\"-\\n\", \" \", text)       \n",
        "    text = re.sub(\"-\\n\\r\", \" \", text)\n",
        "    text = re.sub(\"-\\r\", \" \", text)\n",
        "    text = re.sub(\"\\[.*?\\]\", \" \", text)\n",
        "\n",
        "    text = re.sub(\"-\", \" \", text)  # Special care for hypenated words well-known: choose option (a)\n",
        "                                    # (a) 'well known', (b) 'wellknown' (c) 'well known' and 'wellknown' cf: https://datascience.stackexchange.com/questions/81072/how-to-process-the-hyphenated-english-words-for-any-nlp-problem\n",
        "\n",
        "    text = re.sub(\"/\", \" \", text)  # sociability/conversation/interesting -> sociability conversation interesting                             \n",
        "\n",
        "    # Split string into tokens\n",
        "    line = text.split()\n",
        "\n",
        "    # remove punctuation from each token\n",
        "    # line = [word.translate(table) for word in line]\n",
        "    # OLD string way: text = re.sub(\"[%s]\" % re.escape(string.punctuation), \" \", text)\n",
        "\n",
        "    # remove tokens with numbers in them\n",
        "    line = [word for word in line if word.isalpha()]    \n",
        "    # OLD stirng way: text = re.sub(\"\\w*\\d\\w*\", \" \", text)\n",
        "\n",
        "    # collapse/replace any whitespace(s) with a single hard space\n",
        "    # OLD string way: text = re.sub(\"[\\n]\", \" \", text)  # Replace newline with space\n",
        "    # reassemble tokens into single string to return\n",
        "    text_cleaned = ' '.join(line)\n",
        "\n",
        "  else:\n",
        "    print(f'ERROR: CORPUS_LANG must be [english|french] but was set to: {CORPUS_LANG}')\n",
        "\n",
        "  return text_cleaned\n",
        "\n",
        "# Test\n",
        "\n",
        "print(clean_text(\"Le pépiement matinal des oiseaux semblait insipide à Françoise. I'm going to eat at Sloppy Joes's Place tonight.\"))\n",
        "\"\"\"\n",
        "\n",
        "# clean a list of lines\n",
        "def clean_lines(lines):\n",
        "\tcleaned = list()\n",
        "\t# prepare regex for char filtering\n",
        "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "\t# prepare translation table for removing punctuation\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\tfor line in lines:\n",
        "\t\t# normalize unicode characters\n",
        "\t\tline = normalize('NFD', line).encode('ascii', 'ignore')\n",
        "\t\tline = line.decode('UTF-8')\n",
        "\t\t# tokenize on white space\n",
        "\t\tline = line.split()\n",
        "\t\t# convert to lower case\n",
        "\t\tline = [word.lower() for word in line]\n",
        "\t\t# remove punctuation from each token\n",
        "\t\tline = [word.translate(table) for word in line]\n",
        "\t\t# remove non-printable chars form each token\n",
        "\t\tline = [re_print.sub('', w) for w in line]\n",
        "\t\t# remove tokens with numbers in them\n",
        "\t\tline = [word for word in line if word.isalpha()]\n",
        "\t\t# store as string\n",
        "\t\tcleaned.append(' '.join(line))\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZFUOC43UL2E"
      },
      "source": [
        "import string\n",
        "string.punctuation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQjBZrzCUHo8"
      },
      "source": [
        "test_str = 'what the @#$*(! do you mean!??'\n",
        "print(test_str.strip(string.punctuation))\n",
        "\n",
        "res = re.sub(r'[^\\w\\s]', '', test_str)\n",
        "print(f\"res = {' '.join(res.split())}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxqqtrotUAPI"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "import string\n",
        "p = re.compile(\"[\" + re.escape(string.punctuation) + \"]\")\n",
        "print(p.sub(\"\", \"\\\"hello world!\\\", he's told me.\"))\n",
        "\n",
        "import string\n",
        "string.punctuation\n",
        "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
        "'!Hello.'.strip(string.punctuation)\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZSXxliIZOJS"
      },
      "source": [
        "test_str = 'CHAPTER 1. -  HELLO\\n\\n  '\n",
        "# test_str = 'The rain in Spain\\n\\n  '\n",
        "\n",
        "test_str.isupper()\n",
        "\n",
        "test_str.islower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7m6cUZVXuBw"
      },
      "source": [
        "test_str = 'CHAPTER 1. HELLOa'\n",
        "\n",
        "res_str = re.sub(r'[^\\s\\w]','', test_str)\n",
        "print(f'res_str: {res_str}')\n",
        "print(True == re.match(r'[A-Z]', res_str))\n",
        "\n",
        "if (re.match(r'[^A-Z]', re.sub(r'[^\\s\\w]','', test_str))):\n",
        "  print('True')\n",
        "else:\n",
        "  print('False')\n",
        "\n",
        "if (re.match(r'[^A-Z]', re.sub(r'[^\\s\\w]','', test_str))):\n",
        "  print('True')\n",
        "else:\n",
        "  print('False')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2ozSRonDhhV"
      },
      "source": [
        "def del_sectchap_headers(text_raw_ls, text_type='section'):\n",
        "  '''\n",
        "  Given a list of either Chapter or Section texts (with possible embedded SECTION or CHAPTER lines)\n",
        "  Return 2 lists free of all SECTION and CHAPTER lines, with the _clean_ version passed through clean_text(text_raw)\n",
        "  '''\n",
        "\n",
        "  print(f'Entered clean_sectchap() with text_type: {text_type} and text_raw_ls len: {len(text_raw_ls)}')\n",
        "  text_filtered_ls = []\n",
        "  text_headers_ls = []\n",
        "\n",
        "  if text_type == 'chapter':\n",
        "    text_min_len = MIN_CHAP_LEN\n",
        "  elif text_type == 'section':\n",
        "    text_min_len = MIN_SECT_LEN\n",
        "  else:\n",
        "    print(f\"ERROR: In clean_sectchap() with text_type={text_type}, must be ['section'|'chapter']\")\n",
        "    return [-99], [-99], [-99], [-99], [-99], '-99' # Return with ERROR condition\n",
        "\n",
        "\n",
        "  # Strip off whitespace\n",
        "  text_raw_ls = [x.strip() for x in text_raw_ls]\n",
        "\n",
        "  # Filter out chapters that are empty or shorter than MIN_PARAG_LEN\n",
        "  text_raw_ls = [x for x in text_raw_ls if not (len(x.strip()) <= text_min_len)]\n",
        "\n",
        "  # Filter out SECTION/CHAPTER lines (could be embedded or leading)\n",
        "  corpus_segs_filtered_ls = []\n",
        "\n",
        "  if text_type == 'chapter':\n",
        "    # Remove possible SECTION lines within Chapter text segments\n",
        "    print(f'Removing any SECTION headers from Chapters')\n",
        "\n",
        "    for i, achap_raw in enumerate(text_raw_ls):  #  (corpus_chaps_raw_ls):\n",
        "      print(f'  In Chapter #{i}: {achap_raw[:50]}\\n')\n",
        "      achap_nosectheads_ls = []\n",
        "      if bool(re.match(rf\"{pattern_sect}\", achap_raw)):\n",
        "        print(f'    Before filtering SECTION line, len: {len(achap_raw)}')\n",
        "        achap_nosectheads_ls = re.split(rf'{pattern_sect}', achap_raw, flags=re.I) # , flags=re.I)\n",
        "        achap_nosectheads_ls = [x.strip() for x in achap_nosectheads_ls]\n",
        "        achap_nosectheads_ls = [x for x in achap_nosectheads_ls if len(x) > text_min_len]\n",
        "        achap_sects_noheads_str = '\\n\\n'.join([x.strip() for x in achap_nosectheads_ls])\n",
        "        achap_nosectheads_ls = [x.strip() for x in achap_nosectheads_ls]\n",
        "        print(f'    After filtering SECTION line, len: {len(achap_sects_noheads_str)}')\n",
        "        print(f'                                  {len(achap_nosectheads_ls)} SECTION headers in Chapter #{i}')\n",
        "      else:\n",
        "        print(f'    No filtering needed')\n",
        "        achap_sects_noheads_str = achap_raw.strip()\n",
        "      text_filtered_ls.append(achap_sects_noheads_str)\n",
        "\n",
        "    print(f'  Chapter #{i} filtered of any SECTION lines')\n",
        "\n",
        "  elif text_type == 'section':\n",
        "    # Remove possible CHAPTER lines within Section text segments\n",
        "    print(f'Removing any CHAPTER headers from Sections')\n",
        "\n",
        "    for i, asect_raw in enumerate(text_raw_ls):  #  (corpus_sects_raw_ls):\n",
        "      print(f'  In Section #{i}: {asect_raw[:50]}\\n')\n",
        "      asect_nochapheads_ls = []\n",
        "      if bool(re.match(rf\"{pattern_chap}\", asect_raw)):\n",
        "        print(f'    Before filtering CHAPTER line, len: {len(asect_raw)}')\n",
        "        asect_nochapheads_ls = re.split(rf'{pattern_chap}', asect_raw, flags=re.I) # , flags=re.I)\n",
        "        asect_nochapheads_ls = [x for x in asect_nochapheads_ls if not re.escape(x).isupper()]  # TODO: Don't Assume CHAPTER X. TITLE IN ALL CAPS\n",
        "        asect_nochapheads_ls = [x.strip() for x in asect_nochapheads_ls]\n",
        "        asect_nochapheads_ls = [x for x in asect_nochapheads_ls if len(x) > text_min_len]\n",
        "        asect_chaps_noheads_str = '\\n\\n'.join([x.strip() for x in asect_nochapheads_ls])\n",
        "        asect_nochapheads_ls = [x.strip() for x in asect_nochapheads_ls]\n",
        "        print(f'    After filtering CHAPTER line, len: {len(asect_chaps_noheads_str)}')\n",
        "        print(f'                                       {len(asect_nochapheads_ls)} CHAPTER headers in Section #{i}')\n",
        "      else:\n",
        "        print(f'    No filtering needed')\n",
        "        asect_chaps_noheads_str = asect_raw.strip()\n",
        "      text_filtered_ls.append(asect_chaps_noheads_str)\n",
        "\n",
        "    print(f'  Section #{i} filtered of any CHAPTER lines')\n",
        "\n",
        "  # Collapse multiple whitespaces down to one\n",
        "  text_filtered_ls = [re.sub(r'[ ]{2,}',' ', x) for x in text_filtered_ls] # ' '.join(x.split()).strip() for x in corpus_segs_raw_ls]\n",
        "\n",
        "  # Filter out chapters that are empty or shorter than MIN_PARAG_LEN\n",
        "  text_filtered_ls = [x for x in text_filtered_ls if not (len(x.strip()) <= text_min_len)]\n",
        "\n",
        "  # Call clean_text on text sgements (Chapters/Segments)\n",
        "  # text_raw_ls = [clean_text(x) for x in text_filtered_ls]\n",
        "\n",
        "  print(f'  Returning from clean_sectchap() with text_filtered_ls: {len(text_filtered_ls)}')\n",
        "  \n",
        "  return text_filtered_ls, text_raw_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4Fsqx1iXTPY"
      },
      "source": [
        "def delete_multiple_element(list_object, indices):\n",
        "  '''\n",
        "  Given a list of objects and a list of indicies into that list \n",
        "  Remove all the objects in the list and return the resulting shortened list\n",
        "    being careful to remove all objects at the original index positions \n",
        "\n",
        "  Ref: https://thispointer.com/python-remove-elements-from-list-by-index/\n",
        "  '''\n",
        "\n",
        "  indices = sorted(indices, reverse=True)\n",
        "  for idx in indices:\n",
        "    if idx < len(list_object):\n",
        "      list_object.pop(idx)\n",
        "\n",
        "  return list_object\n",
        "\n",
        "# Test\n",
        "list_of_num = [51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
        "list_of_indices = [4, 2, 6]\n",
        "\n",
        "# Remove elements from list_of_num at index 4,2 and 6\n",
        "delete_multiple_element(list_of_num, list_of_indices)\n",
        "print(list_of_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS_zBObiIVoM"
      },
      "source": [
        "test_ls = ['one','two','three','four','five']\n",
        "\n",
        "[i for i, word in enumerate(test_ls) if len(word) == 4 ]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzv7H9KXbzRa"
      },
      "source": [
        "def corpus2chapsect(corpus_source, corpus_type='file'):\n",
        "  '''\n",
        "  Given a corpus_source and a corpus_type=['file'|'string'] that tells how to to extract the corpus from corpus_source\n",
        "    (if 'file' type, assume already %cd into correct subdir)\n",
        "  Return a lists of Chapters and Section texts, raw or minimally processed \n",
        "  '''\n",
        "\n",
        "  # corpus_chaps_raw_ls, corpus_chaps_clean_ls, corpus_sects_raw_ls, corpus_sects_clean_ls, sect_chapno_ls, corpus_raw_str = corpus2chapsect(corpus_filename)\n",
        "\n",
        "  # Return variables\n",
        "  corpus_chaps_raw_ls = []      #\n",
        "  corpus_chaps_filtered_ls = [] # List of raw/filtered/clean Chapter text segments extracted from Corpus\n",
        "  corpus_chaps_clean_ls = []    #      length = 1 if no Chapter structure\n",
        "  corpus_sects_raw_ls = []      # \n",
        "  corpus_sects_filtered_ls = [] # List of raw/filtered/clean Section text segments extracted from Chapters\n",
        "  corpus_sects_clean_ls = []    #      length = 1 if no Chapter or Section structure\n",
        "                                #      length = Chapter segments length if no Section structure\n",
        "  \n",
        "  sect_chapno_ls = []           # List of Chapter numbers sequenced by unique Section number in Corpus\n",
        "  corpus_raw_str = ''           # String with Corpus as raw string\n",
        "  \n",
        "  # This extra layer corpus source (file/string) allows the corpus text to have an\n",
        "  #   additional layer optionally preprocessed after reading from file\n",
        "  #   which could be useful for special text types (e.g. non-Latin encoding, tweets, etc)\n",
        "  if corpus_type == 'file':\n",
        "    # with open(corpus_filename, \"r\", encoding=CORPUS_ENCODING) as infp:\n",
        "    #   corpus_raw_str = infp.read()\n",
        "\n",
        "    encoding_type='cp1252'\n",
        "    encoding_type='utf-8'\n",
        "    encoding_type=''\n",
        "\n",
        "    # with open(corpus_source, \"r\", encoding=CORPUS_ENCODING) as infp:\n",
        "    with open(corpus_source, \"r\", errors='ignore') as infp:\n",
        "      corpus_raw_str = infp.read()\n",
        "  else:\n",
        "    corpus_raw_str = corpus_source\n",
        "\n",
        "\n",
        "\n",
        "  # Strip out non-printing characters\n",
        "  # corpus_clean_str = re.sub(f'[^{re.escape(string.printable)}]', ' ', corpus_raw_str)\n",
        "  # corpus_clean_str = corpus_raw_str\n",
        "\n",
        "  # normalize unicode characters\n",
        "  #   library [normalize] imported in Setup above\n",
        "  if CORPUS_LANGUAGE == 'english':\n",
        "    corpus_raw_str = normalize('NFD', corpus_raw_str).encode('ascii', 'ignore')\n",
        "    corpus_raw_str = corpus_raw_str.decode('UTF-8')\n",
        "  elif CORPUS_LANGUAGE == 'french':\n",
        "    pass\n",
        "  else:\n",
        "    print(f'ERROR: CORPUS_LANGUAGE must be [english|french] but was set to: {CORPUS_LANGUAGE}')\n",
        "\n",
        "  # remove non-printable chars form each token\n",
        "  #   regex pattern [re_print] defined in Setup above\n",
        "  if CORPUS_LANGUAGE == 'english':\n",
        "    corpus_clean_str = re_print.sub('', corpus_raw_str)\n",
        "  elif CORPUS_LANGUAGE == 'french':\n",
        "    corpus_clean_str = corpus_raw_str\n",
        "  else:\n",
        "    print(f'ERROR: CORPUS_LANGUAGE must be [english|french] but was set to: {CORPUS_LANGUAGE}')\n",
        "\n",
        "\n",
        "  print(f'BEFORE regex extraction of CHAPTER/SECTION: {len(corpus_clean_str)}')\n",
        "\n",
        "  # Check if a Chapter structure is found in this corpus\n",
        "  print(f'Using RegEx pattern_chap: {pattern_chap}')\n",
        "  corpus_chaps_raw_ls = re.split(rf'{pattern_chap}', corpus_clean_str) # , flags=re.I)\n",
        "  corpus_chap_flag = len(corpus_chaps_raw_ls) > 1\n",
        "  # print(f'Do Chapters exist in Corpus? {corpus_chap_flag} (Chapter count = {len(corpus_chaps_raw_ls)})')\n",
        "\n",
        "  # Check if a Section structure is found in this corpus\n",
        "  print(f'Using RegEx pattern_sect: {pattern_sect}')\n",
        "  corpus_sects_raw_ls = re.split(rf'{pattern_sect}', corpus_clean_str, flags=re.I) # , flags=re.I)\n",
        "  corpus_sect_flag = len(corpus_sects_raw_ls) > 1\n",
        "  # print(f'Do Sections exist in Corpus? {corpus_sect_flag} (Section count = {len(corpus_sects_raw_ls)})')\n",
        "\n",
        "  print(f'The Corpus at {corpus_filename}:')\n",
        "  print(f'    Has Chapters? {corpus_chap_flag} (Count: {len(corpus_chaps_raw_ls)})')\n",
        "  print(f'    Has Sections? {corpus_sect_flag} (Count: {len(corpus_sects_raw_ls)})')\n",
        "\n",
        "\n",
        "\n",
        "  # TEST A: Does Chapter structure exist in Corpus?\n",
        "\n",
        "  if corpus_chap_flag == True:\n",
        "    # If a Chapter structure is found, filter out SECTION headers from all Chapters  corpus_chaps_raw_ls\n",
        "    corpus_chaps_filtered_ls, corpus_chaps_clean_ls = del_sectchap_headers(corpus_chaps_raw_ls, text_type='chapter')\n",
        "    print(f'TEST A (False): {len(corpus_chaps_filtered_ls)} Chapters in Corpus')\n",
        "\n",
        "    # Create list of Chapter Numbers\n",
        "    corpus_chapno_ls = list(range(len(corpus_chaps_filtered_ls)))\n",
        "\n",
        "    # TEST B: Does Section structure exist in Corpus with Chapter struture? (TEST A: Chapter structure exists == True)\n",
        "\n",
        "    if corpus_sect_flag == True:    \n",
        "      # TODO: Verify with manual seeting SECTION_HEADINGS != \"None\":\n",
        "      # TEST B: (True) Yes Section/Yes Chapter\n",
        "      #         Process Sections\n",
        "\n",
        "      # NOTE: Could call del_sectchap_headers to segment original Corpus into Segments, but if Chapter structure exists\n",
        "      #       it is safer to directly segement already parsed Chapters due to edge cases in various Corpora\n",
        "      # corpus_sects_raw_ls, corpus_sects_clean_ls = del_sectchap_headers(corpus_sects_raw_ls, text_type='section')\n",
        "\n",
        "      print(f'  TEST A(True)/TEST B(True): {len(corpus_sects_raw_ls)} Sections in Corpus') # Chapters = True, Sections = True')  del_sectchap_headers\n",
        "      corpus_sectno = 0\n",
        "      corpus_sects_dt = {}       # Dictionary of key=SectionNo, value=SectionText\n",
        "      achap_sectchapno_ls = []  # list of ChapterNo corresponding to counting sequence of SectionNo     \n",
        "      achap_sects_raw_ls = []    # List of raw Sections extracted from current Chapter\n",
        "      # achap_sects_clean_ls = []  # List of clean Sections extracted from current Chapter\n",
        "      for achap_no, achap_filtered_str in enumerate(corpus_chaps_filtered_ls):\n",
        "        # Split current filtered Chapter into multiple Sections\n",
        "        print(f'Calling del_sectchap_headers() with text_type=section and len of Chaps: {len(achap_filtered_str)}')\n",
        "        # Split current Chapter at Section lines\n",
        "        achap_sects_raw_ls = re.split(rf'{pattern_sect}', achap_filtered_str, flags=re.I) # , flags=re.I)\n",
        "        print(f'Calling del_sectchap_headers() with {len(achap_sects_raw_ls)} SECTIONS in Chapter #{achap_no}')\n",
        "        achap_sects_filtered_ls, achap_sects_clean_ls = del_sectchap_headers(achap_sects_raw_ls, text_type='section')\n",
        "        print(f'  Found {len(achap_sects_filtered_ls)} Sections in Chapter #{achap_no}')\n",
        "\n",
        "        # For each Section extracted from the current Chapter, store details\n",
        "        achap_sects_ct = len(achap_sects_filtered_ls)\n",
        "        for achap_asect_no, achap_asect_filtered_str in enumerate(achap_sects_raw_ls):\n",
        "          print(f'Processed: Chapter #{achap_no}, Section #{achap_asect_no}')\n",
        "          corpus_sects_dt[corpus_sectno] = achap_sects_filtered_ls[achap_asect_no]     # Store Section text in Dict indexed by Corpus Section No\n",
        "          corpus_sectno += 1\n",
        "          print(f'Section #{corpus_sectno} is in Chapter #{achap_no}')\n",
        "          sect_chapno_ls.append(achap_no)                              # Store Chapter No corresponding to sequence of Sections in List\n",
        "\n",
        "        corpus_sects_filtered_ls += achap_sects_filtered_ls\n",
        "        corpus_sects_clean_ls += achap_sects_clean_ls\n",
        "        # sect_chapno_ls += achap_sectchapno_ls\n",
        "\n",
        "        # # use index to identify objects to remove from parallel data structures\n",
        "\n",
        "    else:\n",
        "      # corpus_sect_flat == False:\n",
        "      # TEST B: (False) No Section/Yes Chapter stucture\n",
        "\n",
        "      # Create pseudo-Sections by copying Chapters to Sections\n",
        "      # Note, Sections much be at least as fine-grained as Chapters\n",
        "      #       cannot have multiple Chapters with one/no Sections \n",
        "      #       because Sections are used to mark Corpus boundaries in Plots\n",
        "\n",
        "      print(f'  TEST A(True)/TEST B(False): {len(corpus_sects_raw_ls)} Sections in Corpus') # Chapters = True, Sections = True')\n",
        "      # print('Chapters = True, Sections = False')\n",
        "      corpus_sects_filtered_ls = [x for x in corpus_chaps_filtered_ls]\n",
        "      corpus_sects_clean_ls = [x for x in corpus_chaps_clean_ls]\n",
        "      # Create list of Chapter Numbers for each Section\n",
        "      sect_chapno_ls = [x for x in corpus_chapno_ls]\n",
        "\n",
        "\n",
        "  else:\n",
        "    # TEST A: (False) No Chapter structure in Corpus\n",
        "    print(f'TEST A (False): {len(corpus_chaps_raw_ls)} Chapters in Corpus')\n",
        "\n",
        "    # TEST B: Does Section structure exists within Corpus without Chapter structure? (TEST A: Chapter structure exists == False)\n",
        "    if corpus_sect_flag == True:    \n",
        "      # TODO: Verify with manual seeting SECTION_HEADINGS != \"None\":\n",
        "\n",
        "      # TEST B: (True) Yes Section/No Chapter\n",
        "      #         Create Sections with multiple entires, but dummy Chapter with just one row\n",
        "      # If a chapter structure is found, process it\n",
        "      print(f'  TEST A(False)/TEST B(True): {len(corpus_sects_raw_ls)} Sections in Corpus') # Chapters = True, Sections = True')\n",
        "      # print('Chapters = False, Sections = True')\n",
        "      corpus_sects_filtered_ls, corpus_sects_clean_ls = del_sectchap_headers(corpus_sects_raw_ls, text_type='section')\n",
        "      # Create list of Chapter numbers for each Section (trivial since no Chapter structure)\n",
        "      sect_chapno_ls = list(range(len(corpus_sects_filtered_ls)))\n",
        "      # Pad out empty Chapter structure\n",
        "      corpus_chaps_raw_ls = [corpus_raw_str]\n",
        "      corpus_chaps_filtered_ls = [corpus_raw_str]\n",
        "      corpus_chaps_clean_ls = [clean_text(corpus_raw_str)]\n",
        "\n",
        "    else:\n",
        "      # TEST B: (False) No Section/No Chapter\n",
        "      #         Create same dummy Section/Chapter DataFrame with just one row\n",
        "      print(f'  TEST A(False)/TEST B(False): {len(corpus_sects_raw_ls)} Sections in Corpus') # Chapters = True, Sections = True')  achp_no\n",
        "      # print('Chapters = False, Sections = False')\n",
        "      corpus_chaps_raw_ls = [corpus_raw_str]\n",
        "      corpus_chaps_filtered_ls = [corpus_raw_str]\n",
        "      corpus_chaps_clean_ls = [clean_text(corpus_raw_str)]\n",
        "      corpus_sects_raw_ls = [corpus_raw_str]\n",
        "      corpus_sects_filtered_ls = [corpus_raw_str]\n",
        "      corpus_sects_clean_ls = [clean_text(corpus_raw_str)]\n",
        "      sect_chapno_ls = [1]\n",
        "      \n",
        "\n",
        "  print(f'corpus_chaps_raw_ls: {len(corpus_chaps_raw_ls)}')\n",
        "  print(f'corpus_chaps_clean_ls: {len(corpus_chaps_clean_ls)}')\n",
        "  print(f'corpus_sects_raw_ls: {len(corpus_sects_raw_ls)}')\n",
        "  print(f'corpus_sects_clean_ls: {len(corpus_sects_clean_ls)}')\n",
        "  print(f'sect_chapno_ls: {len(sect_chapno_ls)}')\n",
        "\n",
        "\n",
        "  # Last step is to remove strings that are too short/null, \n",
        "  #   removal has to be synchronized with removal across parallel lists containing related data\n",
        "\n",
        "  if corpus_chap_flag == True:\n",
        "    #  get indicies of too short Chapters to delete\n",
        "    chaps_del_idx = [i for i, achap in enumerate(corpus_chaps_raw_ls) if len(achap) < MIN_CHAP_LEN]\n",
        "    print(f'  Deleting {len(chaps_del_idx)} shorth/null Chapters')\n",
        "    # use index to identify objects to remove from parallel data structure\n",
        "    corpus_chaps_raw_ls = delete_multiple_element(corpus_chaps_raw_ls, chaps_del_idx)\n",
        "    print(f'    returned with {len(corpus_chaps_raw_ls)} Chapters left')\n",
        "    # corpus_chaps_clean_ls = delete_multiple_element(corpus_chaps_clean_ls, chaps_del_idx)\n",
        "    # delete_multiple_element(chapno_ls, chaps_del_idx) \n",
        "\n",
        "  if corpus_sect_flag == True:\n",
        "    # get indicies of too short Sections to be removed\n",
        "    sects_del_idx = [i for i, asect in enumerate(corpus_sects_raw_ls) if len(asect) < MIN_SECT_LEN]  \n",
        "    print(f'  Deleting {len(sects_del_idx)} shorth/null Sections')\n",
        "    # use index to identify objects to remove from parallel data structures\n",
        "    corpus_sects_raw_ls = delete_multiple_element(corpus_sects_raw_ls, sects_del_idx)\n",
        "    corpus_sects_clean_ls = delete_multiple_element(corpus_sects_clean_ls, sects_del_idx)\n",
        "    sect_chapno_ls = delete_multiple_element(sect_chapno_ls, sects_del_idx)\n",
        "\n",
        "  # TODO: Redundance check for null/empty elements after last cleaning pass\n",
        "  corpus_sects_clean_ls = [clean_text(x) for x in corpus_sects_clean_ls]\n",
        "  corpus_chaps_clean_ls = [clean_text(x) for x in corpus_chaps_clean_ls]\n",
        "\n",
        "  print(f'corpus_chaps_raw_ls: {len(corpus_chaps_raw_ls)}')\n",
        "  print(f'corpus_chaps_clean_ls: {len(corpus_chaps_clean_ls)}')\n",
        "  print(f'corpus_sects_raw_ls: {len(corpus_sects_raw_ls)}')\n",
        "  print(f'corpus_sects_clean_ls: {len(corpus_sects_clean_ls)}')\n",
        "  print(f'sect_chapno_ls: {len(sect_chapno_ls)}')\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # parag_sents_ls = list(doc.sents)\n",
        "\n",
        "  \n",
        "  # Naive method will not work, does not maintain order and synchronization across parellel data structures\n",
        "  corpus_chaps_raw_ls = [x for x in corpus_chaps_raw_ls if len(x) > MIN_CHAP_LEN]    \n",
        "  corpus_chaps_clean_ls = [x for x in corpus_chaps_clean_ls if len(x) > MIN_CHAP_LEN]  \n",
        "  chaps_del_idx = [i for i, achap in enumerate(corpus_chaps_raw_ls) if len(achap) < MIN_CHAP_LEN]\n",
        "  #  get indicies of too short Sections to be removed\n",
        "  corpus_sects_raw_ls = [x for x in corpus_sects_raw_ls if len(x) > MIN_CHAP_LEN]    \n",
        "  corpus_sects_clean_ls = [x for x in corpus_sects_clean_ls if len(x) > MIN_CHAP_LEN] \n",
        "  sects_del_idx = [i for i, asect in enumerate(corpus_sects_raw_ls if len(asect) < MIN_SECT_LEN]\n",
        "  \"\"\";\n",
        "\n",
        "  return corpus_chaps_raw_ls, corpus_chaps_clean_ls, corpus_sects_raw_ls, corpus_sects_clean_ls, sect_chapno_ls, corpus_raw_str\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AceDrCdU7vLB"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "corpus_chaps_raw_ls, corpus_chaps_clean_ls, corpus_sects_raw_ls, corpus_sects_clean_ls, sect_chapno_ls, corpus_raw_str = corpus2chapsect(corpus_filename)\n",
        "\n",
        "# Create list of Chapter Numbers\n",
        "corpus_chapno_ls = list(range(len(corpus_chaps_raw_ls)))\n",
        "\n",
        "# print('\\n')\n",
        "# print(f'Chapter #{achap_no} Ch Length: {len(achap_str)}')\n",
        "print(f'\\n             Chapters:  {len(corpus_chaps_raw_ls)}')\n",
        "print('\\n')\n",
        "print(f'        First Chapter:\\n    {corpus_chaps_raw_ls[0][:500]}\\n')\n",
        "print(f'       Second Chapter:\\n    {corpus_chaps_raw_ls[1][:500]}')\n",
        "print('\\n')\n",
        "print(f'  Second-Last Chapter:\\n    {corpus_chaps_raw_ls[-2][:500]}\\n')\n",
        "print(f'         Last Chapter:\\n    {corpus_chaps_raw_ls[-1][:500]}')\n",
        "print('\\n')\n",
        "\n",
        "# print('\\n')\n",
        "# print(f'Chapter #{achap_no} Ch Length: {len(achap_str)}')\n",
        "print(f'\\n             Sections:  {len(corpus_sects_raw_ls)}')\n",
        "print('\\n')\n",
        "print(f'        First Section:\\n    {corpus_sects_raw_ls[0][:500]}\\n')\n",
        "print(f'       Second Section:\\n    {corpus_sects_raw_ls[1][:500]}')\n",
        "print('\\n')\n",
        "print(f'  Second-Last Section:\\n    {corpus_sects_raw_ls[-2][:500]}\\n')\n",
        "print(f'         Last Section:\\n    {corpus_sects_raw_ls[-1][:500]}')\n",
        "print('\\n')\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9ObfIZA_i27"
      },
      "source": [
        "test_raw_str = \"\"\"\n",
        "CHAPTER 0.\n",
        "\n",
        "Many friends have helped me in writing this book. \n",
        "\n",
        "CHAPTER 1.\n",
        "\n",
        "Some are dead and so illustrious that I scarcely dare name them, yet no one can read or write without being perpetually in the debt of Defoe, Sir Thomas Browne, Sterne, Sir Walter Scott, Lord Macaulay, Emily Bronte, De Quincey, and Walter Pater,--to name the first that come to mind. \n",
        "\n",
        "CHAPTER 2.\n",
        "\n",
        "Others are alive, and though perhaps as illustrious in their own way, are less formidable for that very reason. I am specially indebted to Mr C.P. Sanger\n",
        "\"\"\"\n",
        "\n",
        "len(test_raw_str)\n",
        "print('\\n')\n",
        "test_raw_str = re.sub(f'[^{re.escape(string.printable)}]', ' ', test_raw_str)\n",
        "\n",
        "test_chaps_raw_ls, test_chaps_clean_ls, test_sects_raw_ls, test_sects_clean_ls, test_sect_chapno_ls, test_raw_str = corpus2chapsect(test_raw_str, corpus_type='string')\n",
        "\n",
        "\"\"\"\n",
        "pattern = r'CHAPTER [0123456789]{1,2}[.]+[\\w]*[os.return]*'\n",
        "test_raw_ls = re.split(rf'{pattern}', test_raw_str, flags=re.I) # , flags=re.I)\n",
        "print(f'{len(test_raw_ls)} Chapters found in this corpus.\\n')\n",
        "print(f'Chapter 0 len is {len(test_raw_ls[0])}')\n",
        "\"\"\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JPk7404_iyz"
      },
      "source": [
        "# test_raw_ls[1].strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_nBxtq6-J8l"
      },
      "source": [
        "def filter_nonprintable(text):\n",
        "    import itertools\n",
        "    # Use characters of control category\n",
        "    nonprintable = itertools.chain(range(0x00,0x20),range(0x7f,0xa0))\n",
        "    # Use translate to remove all non-printable characters\n",
        "    return text.translate({character:None for character in nonprintable})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB3OrR5g8VYQ"
      },
      "source": [
        "# build a table mapping all non-printable characters to None\n",
        "\n",
        "NOPRINT_TRANS_TABLE = {\n",
        "    i: None for i in range(0, sys.maxunicode + 1) if not chr(i).isprintable()\n",
        "}\n",
        "\n",
        "def make_printable(s):\n",
        "    \"\"\"Replace non-printable characters in a string.\"\"\"\n",
        "\n",
        "    # the translate method on str removes characters\n",
        "    # that map to None from the string\n",
        "    return s.translate(NOPRINT_TRANS_TABLE)\n",
        "\n",
        "\n",
        "assert make_printable('Café') == 'Café'\n",
        "assert make_printable('\\x00\\x11Hello') == 'Hello'\n",
        "assert make_printable('') == ''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woDWvRZHjU2E"
      },
      "source": [
        "\"\"\"\n",
        "def corpus2chunks(corpus_filename, sent_tok='pysbd'):\n",
        "  '''\n",
        "  Given a corpus filename (assuming already %cd into correct subdir) \n",
        "    and a sentence tokeniziation method in ['pysbd'(default)|'both'|'nltk']\n",
        "  Return 6 lists and a string of the raw corpus:\n",
        "    4 Paragraph length lists -----\n",
        "    parag_raw_ls : list of raw text for each paragraph\n",
        "    parag_clean_ls : list of clean text for each sentence\n",
        "\n",
        "    parag_sentno_start_ls : list of the Sentence Number at the start of every Paragraph\n",
        "    parag_sentno_end_ls : list of the Sentence Number at the end of every Paragraph\n",
        "\n",
        "    2 Sentence length lists -----\n",
        "    sent_raw_ls : list of raw text for each sentence\n",
        "    sent_clean_ls : list of clean text for each sentence\n",
        "  '''\n",
        "\n",
        "  # Load PySBD if necessary\n",
        "  if (sent_tok == 'pysbd') | (sent_tok == 'both'):\n",
        "    from pysbd.utils import PySBDFactory\n",
        "    nlp = spacy.blank('en')\n",
        "    # explicitly adding component to pipeline\n",
        "    # (recommended - makes it more readable to tell what's going on)\n",
        "    nlp.add_pipe(PySBDFactory(nlp))\n",
        "    # pysbd = nlp.create_pipe('pysbd')\n",
        "    # nlp.add_pipe(pysbd)\n",
        "    # doc = nlp('My name is Jonas E. Smith. Please turn to p. 55.')\n",
        "    # print(list(doc.sents))\n",
        "\n",
        "  # Read file into raw text string\n",
        "  with open(corpus_filename, \"r\", encoding=CORPUS_ENCODING) as infp:\n",
        "    corpus_raw_str = infp.read()\n",
        "\n",
        "  # Split into Raw Paragraphs\n",
        "  print(f'BEFORE stripping out headings len: {len(corpus_raw_str)}')\n",
        "  corpus_parags_raw_ls = re.split(r'[\\n]{2,}', corpus_raw_str)\n",
        "  print(f'Corpus Paragraph Raw Count: {len(corpus_parags_ls)}')\n",
        "\n",
        "\n",
        "  # Copy/Clean Paragraphs into new list\n",
        "  # Filter out numbers(often footnotes) from Paragraphs\n",
        "  corpus_parags_ls = [re.sub(r'[0-9]','',x) for x in corpus_parags_raw_ls]\n",
        "\n",
        "  # Filter out empty lines Paragraphs\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if (len(x.strip()) >= MIN_PARAG_LEN)]\n",
        "\n",
        "  # Strip out non-printing characters\n",
        "  corpus_parags_ls = [re.sub(f'[^{re.escape(string.printable)}]', '', x) for x in corpus_parags_ls]\n",
        "\n",
        "  print(f'   Parag count before processing sents: {len(corpus_parags_ls)}')\n",
        "  # FIRST PASS at Sentence Tokenization with PySBD\n",
        "  corpus_sents_all_ls = []\n",
        "  for i, aparag in enumerate(corpus_parags_ls):\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMA-040nIypX"
      },
      "source": [
        "def corpus2lines(corpus_filename, pysbd_only=False):\n",
        "  '''\n",
        "  Given a corpus_filename (assuming already %cd into correct subdir)\n",
        "  Return a list of every line defined by puncutation/NLTK.sent_tokenize or newlines [\\n]{2,}\n",
        "  '''\n",
        "\n",
        "  from pysbd.utils import PySBDFactory\n",
        "  nlp = spacy.blank('en')\n",
        "  # explicitly adding component to pipeline\n",
        "  # (recommended - makes it more readable to tell what's going on)\n",
        "  nlp.add_pipe(PySBDFactory(nlp))\n",
        "  # pysbd = nlp.create_pipe('pysbd')\n",
        "  # nlp.add_pipe(pysbd)\n",
        "  # doc = nlp('My name is Jonas E. Smith. Please turn to p. 55.')\n",
        "  # print(list(doc.sents))\n",
        "\n",
        "  with open(corpus_filename, \"r\", encoding=CORPUS_ENCODING) as infp:\n",
        "    corpus_raw_str = infp.read()\n",
        "\n",
        "  print(f'BEFORE stripping out headings len: {len(corpus_raw_str)}')\n",
        "\n",
        "  corpus_parags_ls = re.split(r'[\\n]{2,}', corpus_raw_str)\n",
        "  print(f'Corpus Paragraph Raw Count: {len(corpus_parags_ls)}')\n",
        "\n",
        "  # Strip off whitespace from Paragraphs\n",
        "  corpus_parags_ls = [x.strip() for x in corpus_parags_ls]\n",
        "\n",
        "  # Filter out numbers(often footnotes) from Paragraphs\n",
        "  corpus_parags_ls = [re.sub(r'[0-9]','',x) for x in corpus_parags_ls]\n",
        "\n",
        "  # Filter out empty lines Paragraphs\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if (len(x.strip()) >= MIN_PARAG_LEN)]\n",
        "\n",
        "  # Strip out non-printing characters\n",
        "  corpus_parags_ls = [re.sub(f'[^{re.escape(string.printable)}]', '', x) for x in corpus_parags_ls]\n",
        "\n",
        "  print(f'   Parag count before processing sents: {len(corpus_parags_ls)}')\n",
        "  # FIRST PASS at Sentence Tokenization with PySBD\n",
        "  corpus_sents_all_ls = []\n",
        "  for i, aparag in enumerate(corpus_parags_ls):\n",
        "\n",
        "    # Generally PySBD outperforms NLTK and SpaCy, \n",
        "    #   but for Samuel Butler's 1900 translation of Homer's Odyssey\n",
        "    #   it failed in many cases so we combine/stack PySBD with NLTK\n",
        "    #   (exception to rule: NLTK > SpaCy for SentTokenization circa 2020\n",
        "    #    https://www.kaggle.com/questions-and-answers/130344)\n",
        "\n",
        "    # NLTK Sentence Tokenization\n",
        "    # 3605 lines with 'To the Lighthouse' by V.Woolf\n",
        "    # aparag_sents_ls = (sent_tokenize(aparag))\n",
        "    \n",
        "    # SpaCy Sentence Tokenization\n",
        "    # TODO: Speed up my specializaing pipe\n",
        "    # 3968 lines for 'To the Lighthouse' by V.Woolf\n",
        "    # doc = nlp(aparag)   \n",
        "    # aparag_sents_ls = [sent for sent in doc.sents]\n",
        "    # aparag_sents_ls = [x for x in doc]\n",
        "\n",
        "    # FIRST, tokenize with PySBD\n",
        "    # PySBD Sentence Tokenization\n",
        "    # 3457 lines for 'To the Lighthouse' by V.Woolf\n",
        "    # using pysbd and SpaCy\n",
        "    # or you can use it implicitly with keyword\n",
        "    \n",
        "\n",
        "    aparag_nonl = re.sub('[\\n]{1,}', ' ', aparag)\n",
        "    doc = nlp(aparag_nonl)\n",
        "    aparag_sents_first_ls = list(doc.sents)\n",
        "    print(f'pysbd found {len(aparag_sents_first_ls)} Sentences in Paragraph #{i}')\n",
        "\n",
        "    # Strip off whitespace from Sentences\n",
        "    aparag_sents_first_ls = [str(x).strip() for x in aparag_sents_first_ls]\n",
        "\n",
        "    # Filter out empty line Sentences\n",
        "    aparag_sents_first_ls = [x for x in aparag_sents_first_ls if (len(x.strip()) > MIN_SENT_LEN)]\n",
        "\n",
        "    print(f'      {len(aparag_sents_first_ls)} Sentences remain after cleaning')\n",
        "\n",
        "    corpus_sents_all_ls += aparag_sents_first_ls\n",
        "\n",
        "  # (OPTIONAL) SECOND PASS as Sentence Tokenization with NLTK\n",
        "  if pysbd_only == True:\n",
        "    # Only do one pass at Sentence tokenization with PySBD above\n",
        "    corpus_sents_all_ls = aparag_sents_first_ls\n",
        "  else:\n",
        "    # Do second pass, tokenize again with NLTK to catch any Sentence tokenization missed by PySBD\n",
        "    corpus_sents_all_second_ls = []\n",
        "    aparag_sents_second_ls = []\n",
        "    for asent_first in corpus_sents_all_ls:\n",
        "      aparag_sents_second_ls = sent_tokenize(asent_first)\n",
        "\n",
        "      # Strip off whitespace from Sentences\n",
        "      aparag_sents_second_ls = [str(x).strip() for x in aparag_sents_second_ls]\n",
        "\n",
        "      # Filter out empty line Sentences\n",
        "      aparag_sents_second_ls = [x for x in aparag_sents_second_ls if (len(x.strip()) > MIN_SENT_LEN)]\n",
        "\n",
        "      corpus_sents_all_second_ls += aparag_sents_second_ls\n",
        "\n",
        "    corpus_sents_all_ls = corpus_sents_all_second_ls\n",
        "\n",
        "  # Filter out lines containing only punctuation (e.g. '\"', '.', '...', etc)\n",
        "  # parag_before_punctstrip_ct = len(corpus_parags_ls)\n",
        "  # corpus_parags_ls = [x for x in corpus_parags_ls if len((re.sub(r'[^\\w\\s]','',x)).strip()) > MIN_PARAG_LEN]\n",
        "  # print(f'Punctuation only Paragraph Count: {len(corpus_parags_ls) - parag_before_punctstrip_ct}')\n",
        "\n",
        "  # Filter out the Section separator '-----' lines\n",
        "  # corpus_parags_ls = [x for x in corpus_parags_ls if not (x.strip().startswith('----- '))]\n",
        "\n",
        "  # Filter out the Section separator 'SECTION ' lines\n",
        "  # for i,temp_str in enumerate(corpus_parags_ls):\n",
        "  #   if temp_str.startswith('SECTION '):\n",
        "  #     print(f'Parag #{i}: {temp_str}')\n",
        "  # corpus_parags_ls = [x for x in corpus_parags_ls if not (x.startswith('SECTION '))]\n",
        "\n",
        "  # Filter out any possible embedded 'SECTION ' lines\n",
        "  # for i,temp_str in enumerate(corpus_parags_ls):\n",
        "  #   if 'SECTION' in temp_str:   # .contains('SECTION '):\n",
        "  #     print(f'Parag #{i}: {temp_str}')\n",
        "  # corpus_parags_ls = del_substrs_list(corpus_parags_ls, pattern_sect) # [re.sub(rf'{pattern_sect}', '', x) for x in corpus_parags_ls]\n",
        "\n",
        "  # Filter out the Chapter separator 'CHAPTER ' lines\n",
        "  # for i,temp_str in enumerate(corpus_parags_ls):\n",
        "  #   if temp_str.startswith('CHAPTER '):\n",
        "  #     print(f'Parag #{i}: {temp_str}')\n",
        "  # corpus_parags_ls = [x for x in corpus_parags_ls if not (x.startswith('CHAPTER '))]\n",
        "\n",
        "  print(f'About to return corpus_sents_all_ls with len = {len(corpus_sents_all_ls)}')\n",
        "  return corpus_sents_all_ls, corpus_raw_str\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5nrHLut8AEl"
      },
      "source": [
        "def corpus2sects(corpus_filename):\n",
        "  '''\n",
        "  Given a corpus_filename (assuming already %cd into correct subdir)\n",
        "  Return a 3 lists: First, the list of Section text strings\n",
        "                    Second, a list of tuples that match (Sentence No, Segment No)\n",
        "                    Third, a list of Sentences that not found in any Section \n",
        "  '''\n",
        "\n",
        "  corpus_sects_ls = []\n",
        "\n",
        "\n",
        "  # encoding = CORPUS_ENCODING,  'windows-1252', 'utf-8', 'cp1252', 'iso-8859-1'\n",
        "  with open(corpus_filename, \"r\", encoding=CORPUS_ENCODING) as infp:\n",
        "    corpus_raw_str = infp.read()\n",
        "\n",
        "  # pattern_sect = 'SECTION [\\d]{1,2}[.]?[^\\n]*'\n",
        "  # pattern_sect = 'SECTION [0123456789]{1,2}[^\\n]*'\n",
        "  # corpus_sects_ls = re.split(r'SECTION [\\d]{1,2}[.]* [A-Z \\.-:—;-’\\'\"]*[\\n]*', corpus_raw_str flags=re.I) # , flags=re.I)\n",
        "  corpus_sects_ls = re.split(rf'{pattern_sect}', corpus_raw_str, flags=re.I) # , flags=re.I)\n",
        "  # corpus_sects_ls = re.split(rf'{pattern_sect}', corpus_raw_str, flags=re.I) # , flags=re.I)\n",
        "  print(f'len(corpus_raw_str: {len(corpus_raw_str)}')\n",
        "  print(f'len(corpus_sects_ls): {len(corpus_sects_ls)}')\n",
        "  print(f'    First section: Length={len(corpus_sects_ls[0])}\\n    {corpus_sects_ls[0][:500]}')\n",
        "  print(f'    Second section: {corpus_sects_ls[1][:500]}')\n",
        "  print('\\n')\n",
        "  print(f'    Second-Last section: {corpus_sects_ls[-2][:500]}')\n",
        "  print(f'    Last section: {corpus_sects_ls[-1][:500]}')\n",
        "\n",
        "\n",
        "\n",
        "  # Strip off whitespace \n",
        "  corpus_sects_ls = [x.strip() for x in corpus_sects_ls]\n",
        "\n",
        "  # Filter out empty lines\n",
        "  corpus_sects_ls = [x for x in corpus_sects_ls if not (len(x.strip()) <= MIN_SECT_LEN)]\n",
        "\n",
        "  # Filter out the Section separator '-----' lines\n",
        "  corpus_sects_ls = [x for x in corpus_sects_ls if not (x.strip().startswith('----- '))]\n",
        "\n",
        "  # Filter out the Section separator 'SECTION ' lines\n",
        "  corpus_sects_ls = [x for x in corpus_sects_ls if not (x.strip().startswith('SECTION '))]\n",
        "\n",
        "  # Filter out any possible embedded 'CHAPTER ' lines\n",
        "  # TODO: Zeroing out corpus_sects_ls\n",
        "  # corpus_sects_ls = del_substrs_list(corpus_sects_ls, pattern_chap) # corpus_sects_ls = [re.sub(rf'{pattern_sect}', '', x) for x in corpus_sects_ls]\n",
        "\n",
        "  # Filter out the Chapter separator 'CHAPTER ' lines\n",
        "  # Keep for now, messy but enables proper SECTION assignments to appropraite CHAPTERs\n",
        "  # corpus_sects_ls = [x for x in corpus_sects_ls if not (x.strip().startswith('CHAPTER '))]\n",
        "\n",
        "\n",
        "  print(f'About to process {len(corpus_sects_ls)} Sections')\n",
        "  # Filter out Sentences in Section that don't have a corresponding Sentence in corpus_sents_df \n",
        "  # Old Strategy: Filter out lines containing embedded SECTION or CHAPTER RegEx patterns \n",
        "\n",
        "  sect_sentences_match_ls = []\n",
        "  sect_sentences_unmatch_ls = []\n",
        "  sect_sentences_unmatch_ct = 0\n",
        "  corpus_sentence_current = 0\n",
        "\n",
        "\n",
        "  for asect_no, asection in enumerate(corpus_sects_ls):\n",
        "    # sect_sentences_ls = []\n",
        "\n",
        "    # NLTK Sentence Tokenization\n",
        "    # 3605 lines with 'To the Lighthouse' by V.Woolf\n",
        "    # asect_sents_ls = (sent_tokenize(asect))\n",
        "    \n",
        "    # SpaCy Sentence Tokenization\n",
        "    # TODO: Speed up my specializaing pipe\n",
        "    # 3968 lines for 'To the Lighthouse' by V.Woolf\n",
        "    # doc = nlp(asect)   \n",
        "    # asect_sents_ls = [sent for sent in doc.sents]\n",
        "    # asect_sents_ls = [x for x in doc]\n",
        "\n",
        "    # PySBD Sentence Tokenization\n",
        "    # 3457 lines for 'To the Lighthouse' by V.Woolf\n",
        "    # using pysbd and SpaCy\n",
        "    from pysbd.utils import PySBDFactory\n",
        "    nlp = spacy.blank('en')\n",
        "    # explicitly adding component to pipeline\n",
        "    # (recommended - makes it more readable to tell what's going on)\n",
        "    nlp.add_pipe(PySBDFactory(nlp))\n",
        "    # or you can use it implicitly with keyword\n",
        "    # pysbd = nlp.create_pipe('pysbd')\n",
        "    # nlp.add_pipe(pysbd)\n",
        "    # doc = nlp('My name is Jonas E. Smith. Please turn to p. 55.')\n",
        "    # print(list(doc.sents))\n",
        "    doc = nlp(asection)\n",
        "    asect_sents_ls = list(doc.sents)\n",
        "\n",
        "    # Create a normalized/no puncutation list of Corpus sentences for clean test comparisions filtered\n",
        "    corpus_sents_nopunct_ls = [re.sub(r'[^A-Za-z0-9]', ' ',x) for x in corpus_sents_ls]\n",
        "    # corpus_sents_nopunct_ls = [x for x in corpus_sents_nopunct_ls if x.isalnum()]\n",
        "    corpus_sents_nopunct_strip_ls = [x.strip() for x in corpus_sents_nopunct_ls]\n",
        "\n",
        "    for j, asection_sentence_raw in enumerate(asect_sents_ls):\n",
        "      asection_sentence_str = str(asection_sentence_raw)\n",
        "      asection_sentence_nopunct_str = re.sub(r'[^A-Za-z0-9]', ' ', asection_sentence_str)\n",
        "      asection_sentence_nopunct_strip_str = asection_sentence_nopunct_str.strip()\n",
        "      # This 'in' test is not sufficient, need to strip out punctuation/normalize\n",
        "      if asection_sentence_nopunct_strip_str in corpus_sents_nopunct_strip_ls:\n",
        "        sect_sentences_match_ls.append((asect_no, asection_sentence_str))\n",
        "        print(f'  Matched Segment Sent')\n",
        "      else:\n",
        "        sect_sentences_unmatch_ct += 1\n",
        "        print(f'  UNMATCHED Corpus Sentence #[{corpus_sentence_current}]\\n           Segment Sentence #{j}: [{asection_sentence_str}]\\n            [{asection_sentence_nopunct_strip_str}]')\n",
        "        sect_sentences_unmatch_ls.append(asection_sentence_str)\n",
        "\n",
        "      corpus_sentence_current += 1\n",
        "\n",
        "    # section_str = ' '.join(sect_sentences_ls)\n",
        "    # sect_sentences_match_ls.append(section_str)\n",
        "\n",
        "    # if re.search(rf'{pattern_chap}', asect):\n",
        "    #   print(f'In Section #{i} removing embedded CHAPTER:\\n\\n    {asect}')\n",
        "    #   asect = re.sub(rf'{pattern_chap}', ' ', asect)\n",
        "\n",
        "  return corpus_sects_ls, sect_sentences_match_ls, sect_sentences_unmatch_ls\n",
        "\n",
        "\n",
        "# return corpus_sects_ls, corpus_raw_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8z8ZY5n8BRs"
      },
      "source": [
        "def corpus2parags(corpus_filename):\n",
        "  '''\n",
        "  Given a corpus_filename (assuming already %cd into correct subdir)\n",
        "  Return a list of min preprocessed raw paragraphs (corpus_parags_ls)\n",
        "  '''\n",
        "\n",
        "  # parag_sents_ls = list(doc.sents)\n",
        "  \n",
        "  with open(corpus_filename, \"r\", encoding=CORPUS_ENCODING) as infp:\n",
        "    corpus_raw_str = infp.read()\n",
        "\n",
        "  corpus_parags_ls = re.split(r'[\\n]{2,}', corpus_raw_str)\n",
        "  print(f'Corpus Paragraph Raw Count: {len(corpus_parags_ls)}')\n",
        "\n",
        "  # Strip off whitespace\n",
        "  corpus_parags_ls = [x.strip() for x in corpus_parags_ls]\n",
        "\n",
        "  # Filter out numbers(often footnotes) from Paragraphs\n",
        "  corpus_parags_ls = [re.sub(r'[0-9]',' ',x) for x in corpus_parags_ls]\n",
        "\n",
        "  # Filter out the Section separator '-----' lines\n",
        "  # Redundant, filed by punctuation only filter above\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if not (x.strip().startswith('----- '))]\n",
        "\n",
        "  # Filter out the Chapter/Section header lines\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if not (x.startswith('CHAPTER '))]\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if not (x.startswith('SECTION '))]\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if not (x.startswith('BOOK '))]\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if not (re.match(r\"^[ ]*[0-9]{1,3}[\\.]?[ ]*$\", x))]\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if not (re.match(r\"^[ ]*[IVXLC]{1,10}[\\.]?[ ]*$\", x))]\n",
        "\n",
        "  # Filter out lines containing only punctuation (e.g. '\"', '.', '...', etc)\n",
        "  parag_before_punctstrip_ct = len(corpus_parags_ls)\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if len((re.sub(r'[^\\w\\s]','',x)).strip()) > MIN_PARAG_LEN]\n",
        "  print(f'Punctuation only Paragraph Count: {len(corpus_parags_ls) - parag_before_punctstrip_ct}')\n",
        "\n",
        "  # Filter out empty lines Paragraphs\n",
        "  corpus_parags_ls = [x for x in corpus_parags_ls if (len(x.strip()) >= MIN_PARAG_LEN)]\n",
        "\n",
        "  # Made a deepcopy of the original raw paragraphs after simple cleaning while continuing to clean the original\n",
        "  corpus_parags_raw_ls = [x for x in corpus_parags_ls]\n",
        "\n",
        "  # Strip out non-printing characters\n",
        "  corpus_parags_ls = [re.sub(f'[^{re.escape(string.printable)}]', ' ', x) for x in corpus_parags_ls]\n",
        "\n",
        "  # Condense multiple whitespaces down into one\n",
        "  corpus_parags_ls = [' '.join(x.split()).strip() for x in corpus_parags_ls]\n",
        "\n",
        "  # Verify no Chapter/Section header lines remain\n",
        "  for i,temp_str in enumerate(corpus_parags_ls):\n",
        "    if temp_str.startswith('CHAPTER '):\n",
        "      print(f'Parag #{i}: {temp_str}')\n",
        "\n",
        "  return corpus_parags_ls, corpus_parags_raw_ls, corpus_raw_str\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxTYt6xsD5Iq"
      },
      "source": [
        "def sect2parags(sect_str):\n",
        "  '''\n",
        "  Given a Section as a text string\n",
        "  Return a list of raw Paragraphs and a raw Section text string\n",
        "  '''\n",
        "\n",
        "  if CORPUS_LANGUAGE == 'english':\n",
        "    sect_clean_str = re.sub(f'[^{re.escape(string.printable)}]', ' ', sect_str)\n",
        "  elif CORPUS_LANGUAGE == 'french':\n",
        "    sect_clean_str = sect_str \n",
        "  else:\n",
        "    print(f'ERROR: CORPUS_LANGUAGE must be [english|french] but was set to {CORPUS_LANGUAGE}')\n",
        "\n",
        "  sect_parags_raw_ls = re.split(r'[\\n]{2,}', sect_clean_str)\n",
        "  # print(f'Section Paragraph Raw Count: {len(sect_parags_raw_ls)}')\n",
        "\n",
        "  # parag_sents_ls = list(doc.sents)\n",
        "  \n",
        "  # Strip off whitespace\n",
        "  sect_parags_raw_ls = [x.strip() for x in sect_parags_raw_ls]\n",
        "\n",
        "  # Filter out numbers(often footnotes) from Paragraphs\n",
        "  sect_parags_raw_ls = [re.sub(r'[0-9]',' ',x) for x in sect_parags_raw_ls]\n",
        "\n",
        "  # Filter out the Section separator '-----' lines\n",
        "  # Redundant, filed by punctuation only filter above\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (x.strip().startswith('----- '))]\n",
        "\n",
        "  # Filter out the Chapter/Section header lines\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (x.startswith('CHAPTER '))]\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (x.startswith('SECTION '))]\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (x.startswith('BOOK '))]\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (re.match(r\"^[ ]*[0-9]{1,3}[\\.]?[ ]*$\", x))]\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (re.match(r\"^[ ]*[IVXLC]{1,10}[\\.]?[ ]*$\", x))]\n",
        "\n",
        "  # Filter out lines containing only punctuation (e.g. '\"', '.', '...', etc)\n",
        "  parag_before_punctstrip_ct = len(sect_parags_raw_ls)\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if len((re.sub(r'[^\\w\\s]','',x)).strip()) > MIN_PARAG_LEN]\n",
        "  # print(f'Punctuation only Paragraph Count: {len(sect_parags_raw_ls) - parag_before_punctstrip_ct}')\n",
        "\n",
        "  # Filter out Paragraphs that are empty or shorter than MIN_PARAG_LEN\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if (len(x.strip()) >= MIN_PARAG_LEN)]\n",
        "\n",
        "  # Made a clean copy of the original raw paragraphs after simple cleaning while continuing to clean the original\n",
        "  sect_parags_clean_ls = [clean_text(x) for x in sect_parags_raw_ls]\n",
        "\n",
        "  # Verify no Chapter/Section header lines remain\n",
        "  for i,temp_str in enumerate(sect_parags_raw_ls):\n",
        "    if temp_str.startswith('CHAPTER '):\n",
        "      print(f'ERROR: CHAPTERS not filtered\\n    Parag #{i}: {temp_str}')\n",
        "\n",
        "  return sect_parags_raw_ls, sect_clean_str\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on9yiXYxcnJQ"
      },
      "source": [
        "test_str = \"\"\"\n",
        "CHAPTER 2.\n",
        "\n",
        "The biographer is now faced with a difficulty which it is better perhaps to confess than to gloss over. Up to this point in telling the story of Orlando's life, documents, both private and historical, have made it possible to fulfil the first duty of a biographer, which is to plod, without looking to right or left, in the indelible footprints of truth; unenticed by flowers; regardless of shade; on and on methodically till we fall plump into the grave and write finis on the tombstone above our heads. But now we come to an episode which lies right across our path, so that there is no ignoring it. Yet it is dark, mysterious, and undocumented; so that there is no explaining it. Volumes might be written in interpretation of it; whole religious systems founded upon the signification of it. Our simple duty is to state the facts as far as they are known, and so let the reader make of them what he may.\n",
        "\n",
        "In the summer of that disastrous winter which saw the frost, the flood, the deaths of many thousands, and the complete downfall of Orlando's hopes--for he was exiled from Court; in deep disgrace with the most powerful nobles of his time; the Irish house of Desmond was justly enraged; the King had already trouble enough with the Irish not to relish this further addition--in that summer Orlando retired to his great house in the country and there lived in complete solitude. One June morning--it was Saturday the 18th--he failed to rise at his usual hour, and when his groom went to call him he was found fast asleep. Nor could he be awakened. He lay as if in a trance, without perceptible breathing; and though dogs were set to bark under his window; cymbals, drums, bones beaten perpetually in his room; a gorse bush put under his pillow; and mustard plasters applied to his feet, still he did not wake, take food, or show any sign of life for seven whole days. On the seventh day he woke at his usual time (a quarter before eight, precisely) and turned the whole posse of caterwauling wives and village soothsayers out of his room, which was natural enough; but what was strange was that he showed no consciousness of any such trance, but dressed himself and sent for his horse as if he had woken from a single night's slumber. Yet some change, it was suspected, must have taken place in the chambers of his brain, for though he was perfectly rational and seemed graver and more sedate in his ways than before, he appeared to have an imperfect recollection of his past life. He would listen when people spoke of the great frost or the skating or the carnival, but he never gave any sign, except by passing his hand across his brow as if to wipe away some cloud, of having witnessed them himself. When the events of the past six months were discussed, he seemed not so much distressed as puzzled, as if he were troubled by confused memories of some time long gone or were trying to recall stories told him by another. It was observed that if Russia was mentioned or Princesses or ships, he would fall into a gloom of an uneasy kind and get up and look out of the window or call one of the dogs to him, or take a knife and carve a piece of cedar wood. But the doctors were hardly wiser then than they are now, and after prescribing rest and exercise, starvation and nourishment, society and solitude, that he should lie in bed all day and ride forty miles between lunch and dinner, together with the usual sedatives and irritants, diversified, as the fancy took them, with possets of newt's slobber on rising, and draughts of peacock's gall on going to bed, they left him to himself, and gave it as their opinion that he had been asleep for a week.\n",
        "\n",
        "But if sleep it was, of what nature, we can scarcely refrain from asking, are such sleeps as these? Are they remedial measures--trances in which the most galling memories, events that seem likely to cripple life for ever, are brushed with a dark wing which rubs their harshness off and gilds them, even the ugliest and basest, with a lustre, an incandescence? Has the finger of death to be laid on the tumult of life from time to time lest it rend us asunder? Are we so made that we have to take death in small doses daily or we could not go on with the business of living? And then what strange powers are these that penetrate our most secret ways and change our most treasured possessions without our willing it? Had Orlando, worn out by the extremity of his suffering, died for a week, and then come to life again? And if so, of what nature is death and of what nature life? Having waited well over half an hour for an answer to these questions, and none coming, let us get on with the story.\n",
        "\n",
        "Now Orlando gave himself up to a life of extreme solitude. His disgrace at Court and the violence of his grief were partly the reason of it, but as he made no effort to defend himself and seldom invited anyone to visit him (though he had many friends who would willingly have done so) it appeared as if to be alone in the great house of his fathers suited his temper. Solitude was his choice. How he spent his time, nobody quite knew. The servants, of whom he kept a full retinue, though much of their business was to dust empty rooms and to smooth the coverlets of beds that were never slept in, watched, in the dark of the evening, as they sat over their cakes and ale, a light passing along the galleries, through the banqueting-halls, up the staircase, into the bedrooms, and knew that their master was perambulating the house alone. None dared follow him, for the house was haunted by a great variety of ghosts, and the extent of it made it easy to lose one's way and either fall down some hidden staircase or open a door which, should the wind blow it to, would shut upon one for ever--accidents of no uncommon occurrence, as the frequent discovery of the skeletons of men and animals in attitudes of great agony made evident. Then the light would be lost altogether, and Mrs Grimsditch, the housekeeper, would say to Mr Dupper, the chaplain, how she hoped his Lordship had not met with some bad accident. Mr Dupper would opine that his Lordship was on his knees, no doubt, among the tombs of his ancestors in the Chapel, which was in the Billiard Table Court, half a mile away on the south side. For he had sins on his conscience, Mr Dupper was afraid; upon which Mrs Grimsditch would retort, rather sharply, that so had most of us; and Mrs Stewkley and Mrs Field and old Nurse Carpenter would all raise their voices in his Lordship's praise; and the grooms and the stewards would swear that it was a thousand pities to see so fine a nobleman moping about the house when he might be hunting the fox or chasing the deer; and even the little laundry maids and scullery maids, the Judys and the Faiths, who were handing round the tankards and cakes, would pipe up their testimony to his Lordship's gallantry; for never was there a kinder gentleman, or one more free with those little pieces of silver which serve to buy a knot of ribbon or put a posy in one's hair; until even the Blackamoor whom they called Grace Robinson by way of making a Christian woman of her, understood what they were at, and agreed that his Lordship was a handsome, pleasant, darling gentleman in the only way she could, that is to say by showing all her teeth at once in a broad grin. In short, all his serving men and women held him in high respect, and cursed the foreign Princess (but they called her by a coarser name than that) who had brought him to this pass.\n",
        "\n",
        "But though it was probably cowardice, or love of hot ale, that led Mr Dupper to imagine his Lordship safe among the tombs so that he need not go in search of him, it may well have been that Mr Dupper was right. Orlando now took a strange delight in thoughts of death and decay, and, after pacing the long galleries and ballrooms with a taper in his hand, looking at picture after picture as if he sought the likeness of somebody whom he could not find, would mount into the family pew and sit for hours watching the banners stir and the moonlight waver with a bat or death's head moth to keep him company. Even this was not enough for him, but he must descend into the crypt where his ancestors lay, coffin piled upon coffin, for ten generations together. The place was so seldom visited that the rats made free with the lead work, and now a thigh bone would catch at his cloak as he passed, or he would crack the skull of some old Sir Malise as it rolled beneath his foot. It was a ghastly sepulchre; dug deep beneath the foundations of the house as if the first Lord of the family, who had come from France with the Conqueror, had wished to testify how all pomp is built upon corruption; how the skeleton lies beneath the flesh: how we that dance and sing above must lie below; how the crimson velvet turns to dust; how the ring (here Orlando, stooping his lantern, would pick up a gold circle lacking a stone, that had rolled into a corner) loses its ruby and the eye which was so lustrous shines no more. 'Nothing remains of all these Princes', Orlando would say, indulging in some pardonable exaggeration of their rank, 'except one digit,' and he would take a skeleton hand in his and bend the joints this way and that. 'Whose hand was it?' he went on to ask. 'The right or the left? The hand of man or woman, of age or youth? Had it urged the war horse, or plied the needle? Had it plucked the rose, or grasped cold steel? Had it--' but here either his invention failed him or, what is more likely, provided him with so many instances of what a hand can do that he shrank, as his wont was, from the cardinal labour of composition, which is excision, and he put it with the other bones, thinking how there was a writer called Thomas Browne, a Doctor of Norwich, whose writing upon such subjects took his fancy amazingly.\n",
        "\n",
        "So, taking his lantern and seeing that the bones were in order, for though romantic, he was singularly methodical and detested nothing so much as a ball of string on the floor, let alone the skull of an ancestor, he returned to that curious, moody pacing down the galleries, looking for something among the pictures, which was interrupted at length by a veritable spasm of sobbing, at the sight of a Dutch snow scene by an unknown artist. Then it seemed to him that life was not worth living any more. Forgetting the bones of his ancestors and how life is founded on a grave, he stood there shaken with sobs, all for the desire of a woman in Russian trousers, with slanting eyes, a pouting mouth and pearls about her neck. She had gone. She had left him. He was never to see her again. And so he sobbed. And so he found his way back to his own rooms; and Mrs Grimsditch, seeing the light in the window, put the tankard from her lips and said Praise be to God, his Lordship was safe in his room again; for she had been thinking all this while that he was foully murdered.\n",
        "\n",
        "Orlando now drew his chair up to the table; opened the works of Sir Thomas Browne and proceeded to investigate the delicate articulation of one of the doctor's longest and most marvellously contorted cogitations.\n",
        "\n",
        "For though these are not matters on which a biographer can profitably enlarge it is plain enough to those who have done a reader's part in making up from bare hints dropped here and there the whole boundary and circumference of a living person; can hear in what we only whisper a living voice; can see, often when we say nothing about it, exactly what he looked like; know without a word to guide them precisely what he thought--and it is for readers such as these that we write--it is plain then to such a reader that Orlando was strangely compounded of many humours--of melancholy, of indolence, of passion, of love of solitude, to say nothing of all those contortions and subtleties of temper which were indicated on the first page, when he slashed at a dead nigger's head; cut it down; hung it chivalrously out of his reach again and then betook himself to the windowseat with a book. The taste for books was an early one. As a child he was sometimes found at midnight by a page still reading. They took his taper away, and he bred glow-worms to serve his purpose. They took the glow-worms away, and he almost burnt the house down with a tinder. To put it in a nutshell, leaving the novelist to smooth out the crumpled silk and all its implications, he was a nobleman afflicted with a love of literature. Many people of his time, still more of his rank, escaped the infection and were thus free to run or ride or make love at their own sweet will. But some were early infected by a germ said to be bred of the pollen of the asphodel and to be blown out of Greece and Italy, which was of so deadly a nature that it would shake the hand as it was raised to strike, and cloud the eye as it sought its prey, and make the tongue stammer as it declared its love. It was the fatal nature of this disease to substitute a phantom for reality, so that Orlando, to whom fortune had given every gift--plate, linen, houses, men-servants, carpets, beds in profusion--had only to open a book for the whole vast accumulation to turn to mist. The nine acres of stone which were his house vanished; one hundred and fifty indoor servants disappeared; his eighty riding horses became invisible; it would take too long to count the carpets, sofas, trappings, china, plate, cruets, chafing dishes and other movables often of beaten gold, which evaporated like so much sea mist under the miasma. So it was, and Orlando would sit by himself, reading, a naked man.\n",
        "\n",
        "The disease gained rapidly upon him now in his solitude. He would read often six hours into the night; and when they came to him for orders about the slaughtering of cattle or the harvesting of wheat, he would push away his folio and look as if he did not understand what was said to him. This was bad enough and wrung the hearts of Hall, the falconer, of Giles, the groom, of Mrs Grimsditch, the housekeeper, of Mr Dupper, the chaplain. A fine gentleman like that, they said, had no need of books. Let him leave books, they said, to the palsied or the dying. But worse was to come. For once the disease of reading has laid upon the system it weakens it so that it falls an easy prey to that other scourge which dwells in the inkpot and festers in the quill. The wretch takes to writing. And while this is bad enough in a poor man, whose only property is a chair and a table set beneath a leaky roof--for he has not much to lose, after all--the plight of a rich man, who has houses and cattle, maidservants, asses and linen, and yet writes books, is pitiable in the extreme. The flavour of it all goes out of him; he is riddled by hot irons; gnawed by vermin. He would give every penny he has (such is the malignity of the germ) to write one little book and become famous; yet all the gold in Peru will not buy him the treasure of a well-turned line. So he falls into consumption and sickness, blows his brains out, turns his face to the wall. It matters not in what attitude they find him. He has passed through the gates of Death and known the flames of Hell.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "sect_parags_raw_ls, sect_clean_str =sect2parags(test_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QndUpmJac5xa"
      },
      "source": [
        "len(sect_parags_raw_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWw618b3vQmJ"
      },
      "source": [
        "from pysbd.utils import PySBDFactory\n",
        "nlp = spacy.blank('en')\n",
        "# explicitly adding component to pipeline\n",
        "# (recommended - makes it more readable to tell what's going on)\n",
        "nlp.add_pipe(PySBDFactory(nlp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b38jIZ-7cyQ"
      },
      "source": [
        "# parag_sents_raw_ls, parag_clean_str = parag2sents(aparag_raw)\n",
        "'''\n",
        "test_str = \"\"\"\n",
        "As they neared the shore each bar rose, heaped itself, broke and swept a thin veil of white water across the sand. The wave paused, and then drew out again, sighing like a sleeper whose breath comes and goes unconsciously. Gradually the dark bar on the horizon became clear as if the sediment in an old wine-bottle had sunk and left the glass green. Behind it, too, the sky cleared as if the white sediment there had sunk, or as if the arm of a woman couched beneath the horizon had raised a lamp and flat bars of white, green and yellow spread across the sky like the blades of a fan. Then she raised her lamp higher and the air seemed to become fibrous and to tear away from the green surface flickering and flaming in red and yellow fibres like the smoky fire that roars from a bonfire. Gradually the fibres of the burning bonfire were fused into one haze, one incandescence which lifted the weight of the woollen grey sky on top of it and turned it to a million atoms of soft blue. The surface of the sea slowly became transparent and lay rippling and sparkling until the dark stripes were almost rubbed out. Slowly the arm that held the lamp raised it higher and then higher until a broad flame became visible; an arc of fire burnt on the rim of the horizon, and all round it the sea blazed gold.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "aparag_sents_raw_ls, aparag_clean_str = parag2sents(test_str)\n",
        "''';"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6dIS33zw5vB"
      },
      "source": [
        "# Configure the appropriate Sentence tokenizers according to CORPUS_LANGUAGE\n",
        "\n",
        "if CORPUS_LANGUAGE == 'english':\n",
        "  nlp = spacy.blank('en')\n",
        "  sent_tokenize = nltk.data.load('tokenizers/punkt/PY3/english.pickle')\n",
        "elif CORPUS_LANGUAGE == 'french':\n",
        "  # default NLTK/french deletes necessary accented characters, disable until fix found\n",
        "  sent_tok = 'pysbd'\n",
        "  nlp = spacy.blank('fr')\n",
        "  sent_tokenize = nltk.data.load('tokenizers/punkt/PY3/french.pickle')\n",
        "else:\n",
        "  print(f'ERROR: CORPUS_LANGUAGE must be [english|french] but was set to: {CORPUS_LANGUAGE}')\n",
        "\n",
        "# explicitly adding component to pipeline\n",
        "# (recommended - makes it more readable to tell what's going on)\n",
        "nlp.add_pipe(PySBDFactory(nlp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAvPMXPS2ELh"
      },
      "source": [
        "# Test Sentence tokinzer in English or French\n",
        "\n",
        "test_en_str = \"My name is Jonas E. Smith. Please turn to p. 55.\"\n",
        "\n",
        "test_fr_str = \"Le pépiement matinal des oiseaux semblait insipide à Françoise. Chaque parole des «bonnes» la faisait sursauter; incommodée par tous leurs pas, elle s'interrogeait sur eux; 'est que nous avions déménagé. Certes les domestiques ne remuaient pas moins, dans le «sixième» de notre ancienne demeure; mais elle les connaissait; elle avait fait de leurs allées et venues des choses amicales. Maintenant elle portait au silence même une attention douloureuse.\"\n",
        "\n",
        "# doc = nlp(test_fr_str)\n",
        "# print(list(doc.sents))\n",
        "# [My name is Jonas E. Smith., Please turn to p. 55.]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e0OnfrGJ_GB"
      },
      "source": [
        "def parag2sents(parag_str, sent_tok='pysbd'):\n",
        "  '''\n",
        "  Given a Paragraph as a long string and a Sentence tokenizer engine ['pysbd'(default)|'both'|'nltk']\n",
        "  Return a list of every Sentence within the given Paragraph\n",
        "  '''\n",
        "\n",
        "  # Load PySBD if necessary\n",
        "  \"\"\"\n",
        "  if (sent_tok == 'pysbd') | (sent_tok == 'both'):\n",
        "    from pysbd.utils import PySBDFactory\n",
        "    nlp = spacy.blank('en')\n",
        "    # explicitly adding component to pipeline\n",
        "    # (recommended - makes it more readable to tell what's going on)\n",
        "    nlp.add_pipe(PySBDFactory(nlp))\n",
        "    # pysbd = nlp.create_pipe('pysbd')\n",
        "    # nlp.add_pipe(pysbd)\n",
        "    # doc = nlp('My name is Jonas E. Smith. Please turn to p. 55.')\n",
        "    # print(list(doc.sents))\n",
        "  \"\"\";\n",
        "\n",
        "  # Minimally clean Paragraph string of non-printing characters\n",
        "  if CORPUS_LANGUAGE == 'english':\n",
        "    parag_clean_str = re.sub(f'[^{re.escape(string.printable)}]', ' ', parag_str).strip()\n",
        "  elif CORPUS_LANGUAGE == 'french':\n",
        "    parag_clean_str = parag_str.strip()\n",
        "  else:\n",
        "    print(f'ERROR: CORPUS_LANGUAGE must be [english|french] but was set to: {CORPUS_LANGUAGE}')\n",
        "\n",
        "  # Replace embedded \\n with spaces\n",
        "  parag_clean_str = re.sub('[\\n]{1,}', ' ', parag_clean_str)\n",
        "\n",
        "  # Replaces mulitple whitespaces with one space\n",
        "  parag_clean_str = ' '.join(parag_clean_str.split())\n",
        "\n",
        "  # parag_sents_ls = list(doc.sents)\n",
        "\n",
        "\n",
        "  # TOKENIZE with 1 of 3 ways\n",
        " \n",
        "  # TODO: Try simple/fast RegEx Tokenizer in lieu of NTLK to complement PyBSD\n",
        "\n",
        "  # ONE: Tokenize with PyBSD and NLTK \n",
        "  if (sent_tok == 'both'):\n",
        "    doc = nlp(parag_clean_str)\n",
        "    parag_sents_first_ls = list(doc.sents)\n",
        "    for asent_temp in parag_sents_first_ls:\n",
        "      asent_tokenized_temp = sent_tokenize(asent_temp)\n",
        "      parag_sents_ls.append(asent_tokenized_temp)\n",
        "    # print(f'  BOTH: {len(parag_sents_ls)} Sentences found in Paragraph')\n",
        "\n",
        "  # TWO: Tokenize with PyBSD\n",
        "  elif (sent_tok == 'pysbd'):\n",
        "    doc = nlp(parag_clean_str)\n",
        "    parag_sents_ls = list(doc.sents)\n",
        "    # print(f' PySBD: {len(parag_sents_ls)} Sentences found in Paragraph')\n",
        "\n",
        "  # THREE: Tokenize with NLTK\n",
        "  elif (sent_tok == 'nltk'):\n",
        "    parag_sents_ls = sent_tokenize(parag_clean_str)\n",
        "    # print(f' NLTK: {len(parag_sents_ls)} Sentences found in Paragraph')\n",
        "\n",
        "  # ERROR\n",
        "  else:\n",
        "    print(f'ERROR: sent_tok={sent_tok} but must be [pysbd(default)|both|nltk]')\n",
        "\n",
        "\n",
        "  # CLEAN Sentences\n",
        "\n",
        "  # Strip off whitespace from Sentences\n",
        "  parag_sents_ls = [str(x).strip() for x in parag_sents_ls]\n",
        "\n",
        "  # Copy/Clean Sentences into new list\n",
        "  # Filter out numbers(often footnotes) from Sentences\n",
        "  parag_sents_ls = [re.sub(r'[0-9]',' ',x) for x in parag_sents_ls]\n",
        "\n",
        "  # Filter out the Chapter/Section header lines\n",
        "  parag_sents_ls = [x for x in parag_sents_ls if not (re.match(r\"^[\\s]*CHAPTER[\\s]*$\", x))]\n",
        "  parag_sents_ls = [x for x in parag_sents_ls if not (re.match(r\"^[\\s]*SECTION[\\s]*$\", x))]\n",
        "  parag_sents_ls = [x for x in parag_sents_ls if not (re.match(r\"^[\\s]BOOK[\\s]*$\", x))]\n",
        "  parag_sents_ls = [x for x in parag_sents_ls if not (re.match(r\"^[\\s]*[0-9]{1,3}[\\.]?[\\s]*$\", x))]\n",
        "  parag_sents_ls = [x for x in parag_sents_ls if not (re.match(r\"^[\\s]*[IVXLC]{1,10}[\\.]?[\\s]*$\", x))]\n",
        "\n",
        "  # Filter out lines containing only punctuation (e.g. '\"', '.', '...', etc)\n",
        "  parag_before_punctstrip_ct = len(parag_sents_ls)\n",
        "  parag_sents_ls = [x for x in parag_sents_ls if len((re.sub(r'[^\\w\\s]','',x)).strip()) > MIN_PARAG_LEN]\n",
        "  # print(f'Punctuation only Paragraph Count: {len(parag_sents_ls) - parag_before_punctstrip_ct}')\n",
        "\n",
        "  # Condense multiple consecutive whitespaces down to one whitespace\n",
        "  parag_sents_ls = [' '.join(x.split()) for x in parag_sents_ls]\n",
        "\n",
        "\n",
        "  # Filter Sentences that are empty or shorter than MIN_SENT_LEN\n",
        "  parag_sents_ls = [x for x in parag_sents_ls if (len(x.strip()) >= MIN_SENT_LEN)]\n",
        "\n",
        "  return parag_sents_ls, parag_clean_str\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX1gjU7S8esY"
      },
      "source": [
        "\"\"\"\n",
        "def parag2sents(parag_str, sent_tok='py'):\n",
        "  '''\n",
        "  Given a Paragraph as a string,\n",
        "  Return a list of raw Sentences and a raw text Paragraph string\n",
        "  '''\n",
        "\n",
        "  parag_clean_str = re.sub(f'[^{re.escape(string.printable)}]', '', parag_str)\n",
        "  parag_parags_raw_ls = re.split(r'[\\n]{2,}', parag_clean_str)\n",
        "  print(f'Section Paragraph Raw Count: {len(parag_parags_raw_ls)}')\n",
        "\n",
        "  # Strip off whitespace\n",
        "  parag_parags_raw_ls = [x.strip() for x in parag_parags_raw_ls]\n",
        "\n",
        "  # Filter out numbers(often footnotes) from Paragraphs\n",
        "  sect_parags_raw_ls = [re.sub(r'[0-9]','',x) for x in sect_parags_raw_ls]\n",
        "\n",
        "  # Filter out the Section separator '-----' lines\n",
        "  # Redundant, filed by punctuation only filter above\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (x.strip().startswith('----- '))]\n",
        "\n",
        "  # Filter out the Chapter/Section header lines\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (x.startswith('CHAPTER '))]\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (x.startswith('SECTION '))]\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (x.startswith('BOOK '))]\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (re.match(r\"^[ ]*[0-9]{1,3}[\\.]?[ ]*$\", x))]\n",
        "  sect_parags_raw_ls = [x for x in sect_parags_raw_ls if not (re.match(r\"^[ ]*[IVXLC]{1,10}[\\.]?[ ]*$\", x))]\n",
        "\n",
        "\n",
        "  parag_no = 0\n",
        "  # sent_base = 0\n",
        "  corpus_sents_ls = []\n",
        "  for parag_no,aparag in enumerate(corpus_parags_ls):\n",
        "    sents_ls = sent_tokenize(aparag)\n",
        "    # Delete (whitespace only) sentences\n",
        "    sents_ls = [x.strip() for x in sents_ls if len(x.strip()) > MIN_SENT_LEN]\n",
        "    # Delete (punctuation only) sentences\n",
        "    sents_ls = [x for x in sents_ls if len((re.sub(r'[^\\w\\s]','',x)).strip()) > MIN_SENT_LEN]\n",
        "    # Delete numbers (int or float) sentences\n",
        "    sents_ls = [x for x in sents_ls if not (x.strip().isnumeric())]\n",
        "\n",
        "    # Filter out leading SECTION separator 'SECTION ' lines\n",
        "    for i,temp_str in enumerate(sents_ls):\n",
        "      if temp_str.startswith('SECTION '):\n",
        "        print(f'Sentence #{i}: {temp_str}')\n",
        "    sents_ls = [x for x in sents_ls if not (x.startswith('SECTION '))]\n",
        "\n",
        "    # Filter out leading Chapter separator 'CHAPTER ' lines\n",
        "    for i,temp_str in enumerate(sents_ls):\n",
        "      if temp_str.startswith('CHAPTER '):\n",
        "        print(f'Sentence #{i}: {temp_str}')\n",
        "    sents_ls = [x for x in sents_ls if not (x.startswith('CHAPTER '))]\n",
        "    \n",
        "    # Filter out lines containing embedded SECTION or CHAPTER RegEx patterns \n",
        "    for i,temp_str in enumerate(sents_ls):\n",
        "      # TODO: More specific, robust filtering mechnism \n",
        "      if (re.search(rf'{pattern_sect}', temp_str)):\n",
        "        pass\n",
        "      if (re.search(rf'{pattern_chap}', temp_str)):\n",
        "        pass\n",
        "      else:\n",
        "        corpus_sents_ls.append([sent_no, parag_no, temp_str])\n",
        "        sent_no += 1\n",
        "\n",
        "    # print(f'Returning with corpus_sents_ls length = {len(corpus_sents_ls)}')\n",
        "  \n",
        "  return corpus_sents_ls\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRopU4e3IQ2R"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "def parag2sents(corpus_parags_ls):\n",
        "  '''\n",
        "  Given a list of paragraphs,\n",
        "  Return a list of lists of Sentences [sent_no, parag_no, asent(text)]\n",
        "  '''\n",
        "\n",
        "  sent_no = 0\n",
        "  # sent_base = 0\n",
        "  corpus_sents_ls = []\n",
        "  for parag_no,aparag in enumerate(corpus_parags_ls):\n",
        "    sents_ls = sent_tokenize(aparag)\n",
        "    # Delete (whitespace only) sentences\n",
        "    sents_ls = [x.strip() for x in sents_ls if len(x.strip()) > MIN_SENT_LEN]\n",
        "    # Delete (punctuation only) sentences\n",
        "    sents_ls = [x for x in sents_ls if len((re.sub(r'[^\\w\\s]','',x)).strip()) > MIN_SENT_LEN]\n",
        "    # Delete numbers (int or float) sentences\n",
        "    sents_ls = [x for x in sents_ls if not (x.strip().isnumeric())]\n",
        "\n",
        "    # Filter out leading SECTION separator 'SECTION ' lines\n",
        "    for i,temp_str in enumerate(sents_ls):\n",
        "      if temp_str.startswith('SECTION '):\n",
        "        print(f'Sentence #{i}: {temp_str}')\n",
        "    sents_ls = [x for x in sents_ls if not (x.startswith('SECTION '))]\n",
        "\n",
        "    # Filter out leading Chapter separator 'CHAPTER ' lines\n",
        "    for i,temp_str in enumerate(sents_ls):\n",
        "      if temp_str.startswith('CHAPTER '):\n",
        "        print(f'Sentence #{i}: {temp_str}')\n",
        "    sents_ls = [x for x in sents_ls if not (x.startswith('CHAPTER '))]\n",
        "    \n",
        "    # Filter out lines containing embedded SECTION or CHAPTER RegEx patterns \n",
        "    for i,temp_str in enumerate(sents_ls):\n",
        "      # TODO: More specific, robust filtering mechnism \n",
        "      if (re.search(rf'{pattern_sect}', temp_str)):\n",
        "        pass\n",
        "      if (re.search(rf'{pattern_chap}', temp_str)):\n",
        "        pass\n",
        "      else:\n",
        "        corpus_sents_ls.append([sent_no, parag_no, temp_str])\n",
        "        sent_no += 1\n",
        "\n",
        "    # print(f'Returning with corpus_sents_ls length = {len(corpus_sents_ls)}')\n",
        "  \n",
        "  return corpus_sents_ls\n",
        "\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-adBsfM38eo0"
      },
      "source": [
        "# corpus_sents_ls = parag2sents(corpus_parags_ls)\n",
        "# len(corpus_sents_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaRD7RL9IOeg"
      },
      "source": [
        "# Generate full path and timestamp for new filepath/filename\n",
        "\n",
        "def gen_pathfiletime(file_str, subdir_str=''):\n",
        "\n",
        "  # Geenreate compressed author and title substrings\n",
        "  author_raw_str = ''.join(CORPUS_AUTHOR.split()).lower()\n",
        "  title_raw_str = ''.join(CORPUS_TITLE.split()).lower()\n",
        "\n",
        "  # Generate current/unique datetime string\n",
        "  datetime_str = str(datetime.now().strftime('%Y%m%d%H%M%S'))\n",
        "\n",
        "  # Built fullpath+filename string\n",
        "  file_base, file_ext = file_str.split('.')\n",
        "\n",
        "  author_str = re.sub('[^A-Za-z0-9]+', '', author_raw_str)\n",
        "  title_str = re.sub('[^A-Za-z0-9]+', '', title_raw_str)\n",
        "\n",
        "  full_filepath_str = f'{subdir_str}{file_base}_{author_str}_{title_str}_{datetime_str}.{file_ext}'\n",
        "\n",
        "  # print(f'Returning from gen_savepath() with full_filepath={full_filepath}')\n",
        "\n",
        "  return full_filepath_str\n",
        "\n",
        "# Test\n",
        "# pathfilename_str = gen_pathfiletime('hist_paraglen.png')\n",
        "# print(pathfilename_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAxQW9IolZjr"
      },
      "source": [
        "# corpus_sents_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lYUmVuvl2OK"
      },
      "source": [
        "def save_dataframes(df_ls=['baseline','sentimentr','syuzhetr','transformer','mlsuperivsed','combined','subset','everything']):\n",
        "  '''\n",
        "  Given a list of DataFrame groups to save\n",
        "  Save all DataFrames associated with that group\n",
        "  '''\n",
        "\n",
        "  # Save Preprocessed Corpus Sentences DataFrame\n",
        "\n",
        "  # author_str = ''.join(CORPUS_AUTHOR.split()).lower()\n",
        "  # title_str = ''.join(CORPUS_TITLE.split()).lower()\n",
        "  title_str = ''.join(CORPUS_FILENAME.split('.')[0]).lower()\n",
        "  datetime_now = datetime.utcnow().strftime(\"%Y%m%d_%H%M\")\n",
        "\n",
        "  if ('baseline' in df_ls) | ('everything' in df_ls):\n",
        "    # Sentences Raw\n",
        "    corpus_sents_filename = f'corpus_text_sents_raw_{title_str}.csv'\n",
        "    print(f'Saving Raw Sentences to file: {corpus_sents_filename}')\n",
        "    corpus_sents_df['sent_raw'].to_csv(corpus_sents_filename)\n",
        "\n",
        "    # Sentences Clean\n",
        "    corpus_sents_filename = f'corpus_text_sents_clean_{title_str}.csv'\n",
        "    print(f'Saving Clean Sentences to file: {corpus_sents_filename}')\n",
        "    corpus_sents_df['sent_clean'].to_csv(corpus_sents_filename)\n",
        "\n",
        "    # Sentence DataFrame\n",
        "    corpus_sents_filename = f'corpus_sents_baseline_{title_str}.csv'\n",
        "    print(f'Saving Sentences DataFrame to file: {corpus_sents_filename}')\n",
        "    corpus_sents_df.to_csv(corpus_sents_filename)\n",
        "\n",
        "    # Paragraph DataFrame\n",
        "    corpus_parags_filename = f'corpus_parags_baseline_{title_str}.csv'\n",
        "    print(f'Saving Paragraph DataFrame to file: {corpus_parags_filename}')\n",
        "    corpus_parags_df.to_csv(corpus_parags_filename)\n",
        "\n",
        "    # if SECTION_HEADINGS != 'None':  # Even if no Sections, save dummy placeholder   \n",
        "    #                                   filled with Chapter data\n",
        "    # Section DataFrame\n",
        "    corpus_sects_filename = f'corpus_sects_baseline_{title_str}.csv'\n",
        "    print(f'Saving Section DataFrame to file: {corpus_sects_filename}')\n",
        "    corpus_sects_df.to_csv(corpus_sects_filename)\n",
        "\n",
        "    # Chapter DataFrame\n",
        "    corpus_chaps_filename = f'corpus_chaps_baseline_{title_str}.csv'\n",
        "    print(f'Saving Chapter DataFrame to file: {corpus_chaps_filename}')\n",
        "    corpus_chaps_df.to_csv(corpus_chaps_filename)\n",
        "\n",
        "  if ('syuzhetr' in df_ls) | ('everything' in df_ls):\n",
        "    # SyuzhetR DataFrame\n",
        "    corpus_sents_filename = f'sum_sentiments_sents_syuzhetr_{title_str}.csv'\n",
        "    print(f'Saving Sentences DataFrame to file: {corpus_sents_filename}')\n",
        "    corpus_syuzhetr_df.to_csv(corpus_sents_filename)\n",
        "\n",
        "  if ('sentimentr' in df_ls) | ('everything' in df_ls):\n",
        "    # SyuzhetR DataFrame\n",
        "    corpus_sents_filename = f'sum_sentiments_sents_sentimentr_{title_str}.csv'\n",
        "    print(f'Saving Sentences DataFrame to file: {corpus_sents_filename}')\n",
        "    corpus_sentimentr_df.to_csv(corpus_sents_filename)\n",
        "\n",
        "  if ('transformer' in df_ls) | ('everything' in df_ls):\n",
        "    # SyuzhetR DataFrame\n",
        "    corpus_sents_filename = f'sum_sentiments_sents_transformer_{title_str}.csv'\n",
        "    print(f'Saving Sentences DataFrame to file: {corpus_sents_filename}')\n",
        "    corpus_transformer_df.to_csv(corpus_sents_filename)\n",
        "\n",
        "\n",
        "  # if ('mlsupervised' in df_ls) | ('everything' in df_ls):\n",
        "  #   # Supervised statistical ML DataFrame\n",
        "  #   corpus_sents_filename = f'sum_sentiments_sents_mlsupervised_{title_str}.csv'\n",
        "  #   print(f'Saving Sentences DataFrame to file: {corpus_sents_filename}')\n",
        "  #   corpus_mlsup_df.to_csv(corpus_sents_filename)\n",
        "\n",
        "\n",
        "  if ('combined' in df_ls) | ('everything' in df_ls):\n",
        "    # Save StandardizedScaled SMA Sentences of ALL Models from the Unified DataFrame\n",
        "    corpus_sents_filename = f'sum_sentiments_all31_sents_{author_abbr_str}_{title_str}.csv' # _{datetime_now}.csv'\n",
        "    print(f'Saving Sentence Unified Models to file: {corpus_sents_filename}')\n",
        "    corpus_unified_df.to_csv(corpus_sents_filename)\n",
        "\n",
        "    # Save Crux Points in Subset of Unified DataFrame (StdScaler/SMA 10% Sentences)\n",
        "    # corpus_sents_filename = f'crux_table_unified_subset_{author_abbr_str}_{title_str}.csv' # _{datetime_now}.csv'\n",
        "    # print(f'Saving Cruxes found in Subset of Unified Models to file: {corpus_sents_filename}')\n",
        "    # unified_crux_df.to_csv(corpus_sents_filename)\n",
        "\n",
        "  return\n",
        "\n",
        "# Test\n",
        "# save_dataframes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuHkcWnHQfLj"
      },
      "source": [
        "type(groups_ls[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQtqkm0iO0rI"
      },
      "source": [
        "# flat_list = [amodel for sublist in groups_ls for amodel in sublist]\n",
        "for sublist in groups_ls:\n",
        "  for amodel in globals()[sublist]:\n",
        "    print(amodel)\n",
        "# flat_list = [''.join(amodel) for sublist in groups_ls for str(amodel) in sublist]\n",
        "# flat_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7H42rn8OqSV"
      },
      "source": [
        "groups_ls = ['models_baseline_ls',\n",
        "                'models_sentimentr_ls',\n",
        "                'models_syuzhetr_ls',\n",
        "                'models_transformer_ls']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hJbmeyoOm5Z"
      },
      "source": [
        "corpus_sentimentr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOeF2B6JOgUf"
      },
      "source": [
        "corpus_unified_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D84wkIlCgVn"
      },
      "source": [
        "# Used in function any_alphachar()\n",
        "\n",
        "pattern_alpha = re.compile(r'[A-Za-z]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRrwu2x3_TgB"
      },
      "source": [
        "def any_alphachar(raw_str):\n",
        "  '''\n",
        "  Given a string\n",
        "  Return a boolean True if there is any alpha char [A-Za-z] in it, else False\n",
        "  '''\n",
        "  \n",
        "  result_obj = re.search(pattern_alpha, raw_str)\n",
        "\n",
        "  if str(result_obj) == 'None':\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "\n",
        "# Test\n",
        "  \n",
        "test_str = '$1.00 ---'\n",
        "\n",
        "if (any_alphachar(test_str)):\n",
        "  print(f'alphachar TRUE: {test_str}')\n",
        "else:\n",
        "  print(f'alphachar FALSE: {test_str}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUvKJEybUIeP"
      },
      "source": [
        "## **Sentiment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOsfpOS4uHGX"
      },
      "source": [
        "def list2stdscaler(tseries_ls):\n",
        "  '''\n",
        "  Given a list of floating point number\n",
        "  Return a pd.Series that has been Standardized Scaled\n",
        "  '''\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "\n",
        "  tseries_np = np.array(tseries_ls)\n",
        "  \n",
        "  tseries_np = tseries_np.reshape((len(tseries_np), 1))\n",
        "\n",
        "  scaler = scaler.fit(tseries_np)\n",
        "  print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, np.sqrt(scaler.var_)))\n",
        "  tseries_xform_np = scaler.transform(tseries_np)\n",
        "\n",
        "  return pd.Series(tseries_xform_np.flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z0jQoBlfPir"
      },
      "source": [
        "def standardize_tsls(ts_df, col_ls):\n",
        "  '''\n",
        "  Given a DataFrame and list of Columns in that DataFrame\n",
        "  Create 4 new Standardized Columns for each given Columns\n",
        "  '''\n",
        "\n",
        "  # Create 4 new column names for each column provided\n",
        "  for amodel in col_ls:\n",
        "    # col_meanstd = f'{amodel}_meanstd'\n",
        "    col_medianiqr = f'{amodel}_medianiqr'\n",
        "    col_stdscaler = f'{amodel}_stdscaler'\n",
        "    col_lnorm_meanstd = f'{amodel}_lnorm_meanstd'\n",
        "    col_lnorm_medianiqr = f'{amodel}_lnorm_medianiqr'\n",
        "\n",
        "    # Standardize each column provided using Standard Scaler and  MedianIQRScaling\n",
        "    ts_df[col_stdscaler]  = list2stdscaler(ts_df[amodel])\n",
        "    ts_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(ts_df[amodel]).reshape(-1, 1))\n",
        "    # Normalize the Sentence Sentiment by dividing by Chapter Length\n",
        "    text_len_ls = list(ts_df['token_len'])\n",
        "    text_sentiment_ls = list(ts_df[amodel])\n",
        "    textsentiment_norm_ls = [text_sentiment_ls[i]/text_len_ls[i] for i in range(len(text_len_ls))]\n",
        "    # RobustStandardize Sentence sentiment values\n",
        "    ts_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(text_sentiment_norm_ls)).reshape(-1, 1))\n",
        "    ts_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(text_sentiment_norm_ls)).reshape(-1, 1))\n",
        "\n",
        "  return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPELi99z_sWx"
      },
      "source": [
        "# corpus_sents_df.iloc[0]['sent_clean']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLASKwzZF-Lh"
      },
      "source": [
        "def get_sentiments(model_base, sentiment_fn, sentiment_type='lexicon', text_prep='clean'):\n",
        "  '''\n",
        "  Given a model_base name and sentiment evaluation function\n",
        "  Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "  '''\n",
        "\n",
        "  # Calculate Sentiment Polarities\n",
        "\n",
        "  if sentiment_type == 'lexicon':\n",
        "    if text_prep == 'clean':\n",
        "      print(f'Processing Lexicon Sentiments/Sentences...')\n",
        "      corpus_sents_df[model_base] = corpus_sents_df['sent_clean'].apply(lambda text: sentiment_fn(str(text)))  # TODO: Verify raw/clean choice here\n",
        "      print(f'Processing Lexicon Sentiments/Paragraphs...')\n",
        "      corpus_parags_df[model_base] = corpus_parags_df['parag_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "      print(f'Processing Lexicon Sentiments/Sections...')\n",
        "      corpus_sects_df[model_base] = corpus_sects_df['sect_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "      print(f'Processing Lexicon Sentiments/Chapters...')\n",
        "      corpus_chaps_df[model_base] = corpus_chaps_df['chap_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "    elif text_prep == 'raw':\n",
        "      print(f'Processing Lexicon Sentiments/Sentences...')\n",
        "      corpus_sents_df[model_base] = corpus_sents_df['sent_raw'].apply(lambda text: sentiment_fn(str(text)))\n",
        "      print(f'Processing Lexicon Sentiments/Paragraphs...')\n",
        "      corpus_parags_df[model_base] = corpus_parags_df['parag_raw'].apply(lambda text: sentiment_fn(str(text)))\n",
        "      print(f'Processing Lexicon Sentiments/Sections...')\n",
        "      corpus_sects_df[model_base] = corpus_sects_df['sect_raw'].apply(lambda text: sentiment_fn(str(text)))\n",
        "      print(f'Processing Lexicon Sentiments/Chapters...')\n",
        "      corpus_chaps_df[model_base] = corpus_chaps_df['chap_raw'].apply(lambda text: sentiment_fn(str(text)))\n",
        "    else:\n",
        "      print(f'ERROR: text_prep must be [clean|raq] but was set to {text_prep}')\n",
        "      return -99\n",
        "  \n",
        "  elif sentiment_type == 'compound':\n",
        "    # VADER\n",
        "\n",
        "    # Calculate dictionary of {neg/neu/pos/compound} values for sent_clean\n",
        "    if text_prep == 'clean':\n",
        "      print(f'Processing Compound Sentiments/Sentences...')\n",
        "      corpus_sents_df['scores'] = corpus_sents_df['sent_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "      print(f'Processing Compound Sentiments/Paragraphs...')\n",
        "      corpus_parags_df['scores'] = corpus_parags_df['parag_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "      print(f'Processing Compound Sentiments/Sections...')\n",
        "      corpus_sects_df['scores'] = corpus_sects_df['sect_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "      print(f'Processing Compound Sentiments/Chapters...')\n",
        "      corpus_chaps_df['scores'] = corpus_chaps_df['chap_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "    elif text_prep == 'raw':\n",
        "      print(f'Processing Compound Sentiments/Sentences...')\n",
        "      corpus_sents_df['scores'] = corpus_sents_df['sent_raw'].apply(lambda text: sentiment_fn(str(text)))\n",
        "      print(f'Processing Compound Sentiments/Paragraphs...')\n",
        "      corpus_parags_df['scores'] = corpus_parags_df['parag_raw'].apply(lambda text: sentiment_fn(str(text)))\n",
        "      print(f'Processing Compound Sentiments/Sections...')\n",
        "      corpus_sects_df['scores'] = corpus_sects_df['sect_raw'].apply(lambda text: sentiment_fn(str(text)))\n",
        "      print(f'Processing Compound Sentiments/Chapters...')\n",
        "      corpus_chaps_df['scores'] = corpus_chaps_df['chap_raw'].apply(lambda text: sentiment_fn(str(text)))\n",
        "    else:\n",
        "      print(f'ERROR: text_prep must be [clean|raq] but was set to {text_prep}')\n",
        "      return -99\n",
        "\n",
        "    # Extract Compound Sentiment\n",
        "    corpus_sents_df[model_base]  = corpus_sents_df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
        "    corpus_parags_df[model_base]  = corpus_parags_df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
        "    corpus_sects_df[model_base]  = corpus_sects_df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
        "    corpus_chaps_df[model_base]  = corpus_chaps_df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
        "\n",
        "  elif sentiment_type == 'function':\n",
        "    # TextBlob\n",
        "\n",
        "    if text_prep == 'clean':\n",
        "      # Calculate dictionary of {neg/neu/pos/compound} values for sent_clean parag_clean\n",
        "      print(f'Processing Function Sentiments/Sentences...')\n",
        "      corpus_sents_df[model_base] = corpus_sents_df['sent_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "      print(f'Processing Function Sentiments/Paragraphs...')\n",
        "      corpus_parags_df[model_base] = corpus_parags_df['parag_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "      print(f'Processing Function Sentiments/Sections...')\n",
        "      corpus_sects_df[model_base] = corpus_sects_df['sect_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "      print(f'Processing Function Sentiments/Chapters...')\n",
        "      corpus_chaps_df[model_base] = corpus_chaps_df['chap_clean'].apply(lambda text: sentiment_fn(str(text)))\n",
        "    elif text_prep == 'raw':\n",
        "      # Calculate dictionary of {neg/neu/pos/compound} values for sent_clean parag_clean\n",
        "      print(f'Processing Function Sentiments/Sentences...')\n",
        "      corpus_sents_df[model_base] = corpus_sents_df['sent_raw'].apply(lambda text: sentiment_fn(str(text)))\n",
        "      print(f'Processing Function Sentiments/Paragraphs...')\n",
        "      corpus_parags_df[model_base] = corpus_parags_df['parag_raw'].apply(lambda text: sentiment_fn(str(text)))\n",
        "      print(f'Processing Function Sentiments/Sections...')\n",
        "      corpus_sects_df[model_base] = corpus_sects_df['sect_raw'].apply(lambda text: sentiment_fn(str(text)))\n",
        "      print(f'Processing Function Sentiments/Chapters...')\n",
        "      corpus_chaps_df[model_base] = corpus_chaps_df['chap_raw'].apply(lambda text: sentiment_fn(str(text)))\n",
        "    else:\n",
        "      print(f'ERROR: text_prep must be [clean|raq] but was set to {text_prep}')\n",
        "      return -99\n",
        "\n",
        "  else:\n",
        "    print(f'ERROR: sentiment_type={sentiment_type} but must be one of (lexicon, compound, function)')\n",
        "    return\n",
        "\n",
        "  # Create new column names\n",
        "  # col_meanstd = f'{model_base}_meanstd'\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_stdscaler = f'{model_base}_stdscaler'\n",
        "  # col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_stdscaler = f'{model_base}_lnorm_stdscaler'\n",
        "\n",
        "\n",
        "  print('Standardizing Chapters')\n",
        "  # Get Chapter Robust Standardization with Standard Scaler and  MedianIQRScaling\n",
        "  corpus_chaps_df[col_stdscaler]  = list2stdscaler(corpus_chaps_df[model_base])\n",
        "  corpus_chaps_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(corpus_chaps_df[model_base]).reshape(-1, 1))\n",
        "  # Normalize the Chapter Sentiment by dividing by Chapter Length\n",
        "  chaps_len_ls = list(corpus_chaps_df['token_len'])\n",
        "  chaps_sentiment_ls = list(corpus_chaps_df[model_base])\n",
        "  chaps_sentiment_norm_ls = [chaps_sentiment_ls[i]/chaps_len_ls[i] for i in range(len(chaps_len_ls))]\n",
        "  # RobustStandardize Chapter sentiment values\n",
        "  # corpus_chaps_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(chaps_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  corpus_chaps_df[col_lnorm_stdscaler]  = mean_std_scaler.fit_transform(np.array(pd.Series(chaps_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  corpus_chaps_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(chaps_sentiment_norm_ls)).reshape(-1, 1))\n",
        "\n",
        "  print('Standardizing Sections')\n",
        "  # Get Section Robust Standardization with Standard Scaler and  MedianIQRScaling\n",
        "  # corpus_sects_df[col_stdscaler]  = mean_std_scaler.fit_transform(np.array(corpus_sects_df[model_base]).reshape(-1, 1))\n",
        "  corpus_sects_df[col_stdscaler]  = list2stdscaler(corpus_sects_df[model_base])\n",
        "  corpus_sects_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(corpus_sects_df[model_base]).reshape(-1, 1))\n",
        "  # Normalize the Section Sentiment by dividing by Section Length\n",
        "  sects_len_ls = list(corpus_sects_df['token_len'])\n",
        "  sects_sentiment_ls = list(corpus_sects_df[model_base])\n",
        "  sects_sentiment_norm_ls = [sects_sentiment_ls[i]/sects_len_ls[i] for i in range(len(sects_len_ls))]\n",
        "  # RobustStandardize Section sentiment values\n",
        "  # corpus_sects_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(sects_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  corpus_chaps_df[col_lnorm_stdscaler]  = mean_std_scaler.fit_transform(np.array(pd.Series(chaps_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  corpus_sects_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(sects_sentiment_norm_ls)).reshape(-1, 1))\n",
        "\n",
        "  print('Standardizing Paragraphs')\n",
        "  # Get Paragraph Robust Standardization with Standard Scaler and  MedianIQRScaling\n",
        "  corpus_parags_df[col_stdscaler]  = list2stdscaler(corpus_parags_df[model_base])\n",
        "  corpus_parags_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(corpus_parags_df[model_base]).reshape(-1, 1))\n",
        "  # Normalize the Paragraph Sentiment by dividing by Chapter Length\n",
        "  parags_len_ls = list(corpus_parags_df['token_len'])\n",
        "  parags_sentiment_ls = list(corpus_parags_df[model_base])\n",
        "  parags_sentiment_norm_ls = [parags_sentiment_ls[i]/parags_len_ls[i] for i in range(len(parags_len_ls))]\n",
        "  # RobustStandardize Paragraph sentiment values\n",
        "  # corpus_parags_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(parags_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  corpus_parags_df[col_lnorm_stdscaler]  = mean_std_scaler.fit_transform(np.array(corpus_parags_df[model_base]).reshape(-1, 1))\n",
        "  corpus_parags_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(parags_sentiment_norm_ls)).reshape(-1, 1))\n",
        "\n",
        "  print('Standardizing Sentences')\n",
        "  # Get Sentence Robust Standardization with Standard Scaler and  MedianIQRScaling\n",
        "  corpus_sents_df[col_stdscaler]  = list2stdscaler(corpus_sents_df[model_base])\n",
        "  corpus_sents_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(corpus_sents_df[model_base]).reshape(-1, 1))\n",
        "  # Normalize the Sentence Sentiment by dividing by Chapter Length\n",
        "  sents_len_ls = list(corpus_sents_df['token_len'])\n",
        "  sents_sentiment_ls = list(corpus_sents_df[model_base])\n",
        "  sents_sentiment_norm_ls = [sents_sentiment_ls[i]/sents_len_ls[i] for i in range(len(sents_len_ls))]\n",
        "  # RobustStandardize Sentence sentiment values\n",
        "  # corpus_sents_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(sents_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  # corpus_sents_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(sents_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  corpus_sents_df[col_lnorm_stdscaler]  = mean_std_scaler.fit_transform(np.array(corpus_sents_df[model_base]).reshape(-1, 1))\n",
        "  corpus_sents_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(sents_sentiment_norm_ls)).reshape(-1, 1))\n",
        "\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJNepWBIkVjm"
      },
      "source": [
        "# Read in lexicon at given path into Dict[word]=polarity\n",
        "\n",
        "def get_lexicon(lexicon_name, lexicon_format=2):\n",
        "    \"\"\"\n",
        "    Read sentiment lexicon.csv file at lexicon_path\n",
        "    into appropriate Dict[word]=polarity\n",
        "\n",
        "    1. lexicon_dt[word] = <polarity value>\n",
        "\n",
        "    Args:\n",
        "        sa_lib (str, optional): [description]. Defaults to 'syuzhet'.\n",
        "    \"\"\"\n",
        "    \n",
        "    # global lexicon_df\n",
        "\n",
        "    lexicon_df = pd.DataFrame()\n",
        "    \n",
        "    # print(os.getcwd())\n",
        "\n",
        "    \n",
        "    try:\n",
        "      lexicon_df = pd.read_csv(lexicon_name)\n",
        "      lexicon_df.info()\n",
        "      # lexicon_df = lexicon_tmp_df.copy()\n",
        "      # print(lexicon_df.head())\n",
        "      return lexicon_df\n",
        "    except:\n",
        "      print(f'ERROR: Cannot read lexicon.csv at {lexicon_name}')\n",
        "      return -1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWdzLF0jwI-u"
      },
      "source": [
        "# Sentence to Sentiment Polarity according to passed in Lexicon Dictionary\n",
        "\n",
        "def text2sentiment(text_str, lexicon_dt):\n",
        "  '''\n",
        "  Given a text_str and lexicon_dt, calculate \n",
        "  the sentimety polarity.\n",
        "  '''\n",
        "\n",
        "  # Remove all not alphanumeric and whitespace characters\n",
        "  text_str = re.sub(r'[^\\w\\s]', '', text_str) \n",
        "\n",
        "  text_str = text_str.strip().lower()\n",
        "  if (len(text_str) < 1):\n",
        "      print(f\"ERROR: text2sentiment() given empty/null/invalid string: {text_str}\")\n",
        "\n",
        "  text_ls = text_str.split()\n",
        "  # print(f'text_ls: {text_ls}')\n",
        "\n",
        "  # Accumulated Total Sentiment Polarity for entire Sentence\n",
        "  text_sa_tot = 0.0\n",
        "\n",
        "  for aword in text_ls:\n",
        "      # print(f'getting sa for word: {aword}')\n",
        "      try:\n",
        "          word_sa_fl = float(lexicon_dt[aword])\n",
        "          text_sa_tot += word_sa_fl\n",
        "          # print(f\">>{aword} has a sentiment value of {word_sa_fl}\")\n",
        "      except TypeError: # KeyError:\n",
        "          # aword is not in lexicon so it adds 0 to the sentence sa sum\n",
        "          # print(f\"TypeError: cannot convert {lexicon_dt[aword]} to float\")\n",
        "          continue\n",
        "      except KeyError:\n",
        "          # print(f\"KeyError: missing key {aword} in defaultdict syuzhet_dt\")\n",
        "          continue\n",
        "      except:\n",
        "          e = sys.exc_info()[0]\n",
        "          # print(f\"ERROR {e}: sent2lex_sa() cannot catch aword indexing into syuzhet_dt error\")\n",
        "  \n",
        "  # print(f\"Leaving sent2lex_sa() with sentence sa value = {str(text_sa_tot)}\")\n",
        "  \n",
        "  return text_sa_tot\n",
        "\n",
        "\n",
        "# Test\n",
        "\n",
        "# sent2sentiment('I hate and despise and abhor and dislike and am disgusted by Mondays.', lexicon_jockersrinker_dt)\n",
        "# sent2sentiment('hate Mondays.', lexicon_jockersrinker_dt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6AEBZzvEz4a"
      },
      "source": [
        "def plot_smas(section_view=True, model_name='vader', text_unit='sentence', wins_ls=[20], alpha=0.5, subtitle_str='', y_height=0, save2file=False):\n",
        "  '''\n",
        "  Given a model, text_unit\n",
        "  Plot a SMA using default values and wrapping the function get_smas()\n",
        "  '''\n",
        "\n",
        "  if (section_view == True) and not any(x == text_unit for x in ['sentence', 'paragraph']):\n",
        "    print(f'ERROR: You can only plot SMA within a Section with Sentence or Paragraph text units')\n",
        "    return -99\n",
        "\n",
        "  if text_unit == 'sentence':\n",
        "    if section_view == False:\n",
        "      ts_df = corpus_sents_df\n",
        "    else:\n",
        "      ts_df = section_sents_df\n",
        "    wins_ls = [5,10,20]\n",
        "  elif text_unit == 'paragraph':\n",
        "    if section_view == False:\n",
        "      ts_df = corpus_parags_df\n",
        "    else:\n",
        "      ts_df = section_parags_df\n",
        "    wins_ls = [5,10,20]\n",
        "  elif text_unit == 'section':\n",
        "    ts_df = corpus_sects_df\n",
        "    wins_ls=[20]\n",
        "  else:\n",
        "    print(f'ERROR: {text_unit} must be sentence, paragraph or section')\n",
        "\n",
        "  sectno_loc = ts_df[model_name].min()\n",
        "\n",
        "  if section_view ==False:\n",
        "    # At Section boundries draw blue vertical lines \n",
        "    section_boundries_ls = list(corpus_sects_df['sent_no_start'])\n",
        "    for i, sent_no in enumerate(section_boundries_ls):\n",
        "      plt.text(sent_no, y_height, f'Sec#{i}', alpha=0.2, rotation=90)\n",
        "      plt.axvline(sent_no, color='blue', alpha=0.1)\n",
        "      # 'BigNews1', xy=(sent_no, 0.5), xytext=(-10, 25), textcoords='offset points',                   rotation=90, va='bottom', ha='center', annotation_clip=True)\n",
        "\n",
        "      # plt.text(sent_no, -.5, 'goodbye',rotation=90, zorder=0)\n",
        "\n",
        "    # At Chapter boundaries draw red vertical lines\n",
        "    chapter_boundries_ls = list(corpus_chaps_df['sent_no_start'])\n",
        "    for i, sent_no in enumerate(chapter_boundries_ls):\n",
        "      plt.axvline(sent_no, color='navy', alpha=0.1)\n",
        "      # plt.text(sent_no, .5, 'hello', rotation=90, zorder=0)\n",
        "\n",
        "  get_smas(ts_df, model_name=model_name, text_unit=text_unit, wins_ls=wins_ls, alpha=alpha, subtitle_str=subtitle_str, save2file=save2file)\n",
        "\n",
        "  if (save2file == True):\n",
        "    # Save graph to file.\n",
        "    plot_filename = f'plot_sma_sents_{model_name}.png'\n",
        "    plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "    plt.savefig(plotpathfilename_str, format='png', dpi=300)\n",
        "    print(f'Plot saved: {plot_filename}');\n",
        "\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcAMyjyn8ugj"
      },
      "source": [
        "# SMA 5% Sentiment of Sentence Sentiment\n",
        "\n",
        "def get_smas(ts_df, model_name, text_unit='sentence', wins_ls=[5,10], alpha=0.5, scale_factor=1., subtitle_str='', mean_adj=0., do_plot=True, save2file=False):\n",
        "  '''\n",
        "  Given a model_name and time series DataFrame and list of win_rolls in percentages\n",
        "  Return the rolling means of the time series using the window sizes in win_rolls\n",
        "  '''\n",
        "\n",
        "  temp_roll_df = pd.DataFrame() # TODO: save sma rolling values into temp_df and return this value\n",
        "\n",
        "  win_1per = int(ts_df.shape[0]*0.01)\n",
        "  if text_unit ==  'sentence':\n",
        "    # win_1per = win_s1per\n",
        "    x_idx = 'sent_no'\n",
        "    fname_abbr = 'sents'\n",
        "  elif text_unit == 'paragraph':\n",
        "    # win_1per = win_p1per\n",
        "    x_idx = 'parag_no'\n",
        "    fname_abbr = 'parags'\n",
        "  elif text_unit == 'section':\n",
        "    win_1per = 1\n",
        "    wins_ls = [int(0.1 * corpus_sects_df.shape[0])]  # Edge case to deal with very few Section data points\n",
        "    x_idx = 'sect_no'\n",
        "    fname_abbr = 'sects'\n",
        "  else:\n",
        "    print(f'ERROR: text_unit={text_unit} but must be either sentence, paragraph or section')\n",
        "  \n",
        "  for i, awin_size in enumerate(wins_ls):\n",
        "    if len(str(awin_size)) == 1:\n",
        "      awin_str = '0' + str(awin_size)\n",
        "    else:\n",
        "      awin_str = str(awin_size) \n",
        "    col_roll_str = f'{model_name}_mean_roll{awin_str}'\n",
        "    win_size = awin_size*win_1per\n",
        "    ts_df[col_roll_str] = ts_df[model_name].rolling(window=win_size, center=True).mean()\n",
        "  \n",
        "    if do_plot == True:\n",
        "      alabel = f'{model_name} (win={awin_size})'\n",
        "      ts_df['y_scaled'] = ts_df[col_roll_str]*scale_factor + mean_adj \n",
        "      sns.lineplot(data=ts_df, x=x_idx, y='y_scaled', legend='brief', label=alabel, alpha=alpha)\n",
        "      \n",
        "  plt.title(f'{CORPUS_FULL} (Model: {model_name}: {subtitle_str}) \\nSMA Smoothed {text_unit} Sentiment Plot (windows={wins_ls})')\n",
        "  # plt.legend(loc='best')\n",
        "\n",
        "  if save2file == True:\n",
        "    # Save graph to file.\n",
        "    plot_filename = f'plot_{fname_abbr}_sa_mean_050100sma.png'\n",
        "    plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "    plt.savefig(plotpathfilename_str, format='png', dpi=300)\n",
        "    print(f'Plot saved: {plot_filename}');\n",
        "\n",
        "  return temp_roll_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULzfHeDK8udN"
      },
      "source": [
        "def get_lexstats(ts_df, model_name, text_unit='sentence'):\n",
        "  '''\n",
        "  Given a model name\n",
        "  calculate, store and return time series stats\n",
        "  '''\n",
        "  \n",
        "  global corpus_lexicons_stats_dt\n",
        "\n",
        "  temp_dt = {}\n",
        "  \n",
        "  if text_unit == 'sentence':\n",
        "    stat_idx = f'{model_name}_sents'\n",
        "  elif text_unit == 'paragraph':\n",
        "    stat_idx = f'{model_name}_parags'\n",
        "  elif text_unit == 'section':\n",
        "    stat_idx = f'{model_name}_sects'\n",
        "  elif text_unit == 'chapter':\n",
        "    stat_idx = f'{model_name}_chaps'\n",
        "  else:\n",
        "    print(f'ERROR: {text_unit} must either be sentence, paragraph, or section')\n",
        "\n",
        "  sentiment_min = ts_df[model_name].min()\n",
        "  sentiment_max = ts_df[model_name].max()\n",
        "\n",
        "  temp_dt = {'sentiment_min' : sentiment_min,\n",
        "             'sentiment_max' : sentiment_max}\n",
        "\n",
        "  corpus_lexicons_stats_dt[stat_idx] = temp_dt\n",
        "                                     \n",
        "  return \n",
        "\n",
        "# Test\n",
        "# get_lexstats('afinn')\n",
        "# corpus_lexicons_stats_dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltdJn-7ePNM9"
      },
      "source": [
        "def lex_discrete2continous_sentiment(text, lexicon):\n",
        "  '''\n",
        "  Given a plain text string, give it to\n",
        "    Stanford Stanza (OpenNLP) to calculate sentiment for each word on a 3 point scale 0-2\n",
        "  Return a sentiment value for the entire sentence (sum of word sentiments/log(len of sentence)) \n",
        "    that approximates a normal distribution for all values\n",
        "    In order to get more fine grained measure of overall Sentence sentiment\n",
        "    Sentiment values will be Normalized/Standardized so absolute precision is not required\n",
        "  '''\n",
        "  text_sentiment_tot = 0.\n",
        "  text_ls = text.split()\n",
        "  text_len = len(text_ls)\n",
        "  for aword in text_ls:\n",
        "    word_sentiment = text2sentiment(str(aword), lexicon)\n",
        "    text_sentiment_tot += word_sentiment\n",
        "  text_sentiment_norm = text_sentiment_tot/(np.log(text_len)+0.01)\n",
        "\n",
        "  return text_sentiment_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6xMI98l8uaH"
      },
      "source": [
        "\"\"\"\n",
        "def clip_outliers(floats_ser):\n",
        "  '''\n",
        "  Given a pd.Series of float values\n",
        "  Return a list with outliers removed, values limited within 3 median absolute deviations from median\n",
        "  '''\n",
        "  # https://www.statsmodels.org/stable/generated/statsmodels.robust.scale.mad.html#statsmodels.robust.scale.mad\n",
        "\n",
        "  # Old mean/std, less robust\n",
        "  # ser_std = floats_ser.std()\n",
        "  # ser_median = floats_ser.mean() # TODO: more robust: asym/outliers -> median/IQR or median/median abs deviation\n",
        "\n",
        "  floats_np = np.array(floats_ser)\n",
        "  ser_median = floats_ser.median()\n",
        "  ser_mad = robust.mad(floats_np)\n",
        "  print(f'ser_median = {ser_median}')\n",
        "  print(f'ser_mad = {ser_mad}')\n",
        "\n",
        "  if ser_mad == 0:\n",
        "    # for TS with small ranges (e.g. -1.0 to +1.0) Median Abs Deviation = 0\n",
        "    #   so pass back the original time series\n",
        "    floats_clip_ls = list(floats_ser)\n",
        "\n",
        "  else:\n",
        "    ser_oldmax = floats_ser.max()\n",
        "    ser_oldmin = floats_ser.min()\n",
        "    print(f'ser_max = {ser_oldmax}')\n",
        "    print(f'ser_min = {ser_oldmin}')\n",
        "\n",
        "    ser_upperlim = ser_median + 2.5*ser_mad\n",
        "    ser_lowerlim = ser_median - 2.5*ser_mad\n",
        "    print(f'ser_upperlim = {ser_upperlim}')\n",
        "    print(f'ser_lowerlim = {ser_lowerlim}')\n",
        "\n",
        "    # Clip outliers to max or min values\n",
        "    floats_clip_ls = np.clip(floats_np, ser_lowerlim, ser_upperlim)\n",
        "    # print(f'max floast_ls {floats_ls.max()}')\n",
        "\n",
        "    # def map2range(value, low, high, new_low, new_high):\n",
        "    #   '''map a value from one range to another'''\n",
        "    #   return value * 1.0 / (high - low + 1) * (new_high - new_low + 1)\n",
        "\n",
        "    # Map all float values to range [-1.0 to 1.0]\n",
        "    # floats_clip_sig_ls = [map2range(i, ser_oldmin, ser_oldmax, ser_upperlim, ser_lowerlim) for i in floats_clip_ls]\n",
        "\n",
        "    # listmax_fl = float(max(floats_ls))\n",
        "    # floats_ls = [i/listmax_fl for i in floats_ls]\n",
        "    #floats_ls = [1/(1+math.exp(-i)) for i in floats_ls]\n",
        "\n",
        "  return floats_clip_ls  # floats_clip_sig_ls\n",
        "\"\"\";\n",
        "\n",
        "# Test\n",
        "# Will not work on first run as corpus_sents_df is not defined yet\n",
        "'''\n",
        "data = np.array([1, 4, 4, 7, 12, 13, 16, 19, 22, 24])\n",
        "test_ls = clip_outliers(corpus_sents_df['vader'])\n",
        "print(f'new min is {min(test_ls)}')\n",
        "print(f'new max is {max(test_ls)}')\n",
        "''';"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXwKR4gA8Ouk"
      },
      "source": [
        "## **Pandas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8Hf8nU98uXI"
      },
      "source": [
        "\"\"\"\n",
        "def rename_cols(ts_df, col_old_ls, suffix_str='_raw'):\n",
        "  '''\n",
        "  Given a DataFrame, list of columns in DataFrame and a suffix,\n",
        "  Return a Dictionary mapping old col names to new col name (orig+suffix)\n",
        "  '''\n",
        "\n",
        "  col_new_ls = []\n",
        "  for acol in col_old_ls:\n",
        "    acol_new = acol + suffix_str\n",
        "    col_new_ls.append(acol_new)\n",
        "\n",
        "  # Create dict for col mapping: keys=old col names, value=new col names\n",
        "  col_rename_dt = dict(zip(col_old_ls, col_new_ls))\n",
        "\n",
        "  # ts_df.rename(columns=col_rename_dt, errors=\"raise\")\n",
        "\n",
        "  return col_rename_dt\n",
        "\n",
        "# test_ls = [col for col in corpus_sents_df.columns if not(renaming_fun(col) is None)]\n",
        "# print(f'test_ls: {test_ls}')\n",
        "\n",
        "# Test\n",
        "# col_rename_dt = rename_cols(corpus_sents_df, sentiment_only_cols_ls)\n",
        "# col_rename_dt\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YJJcvDVnUuT"
      },
      "source": [
        "## **Time Series**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY-1_xWAGz0q"
      },
      "source": [
        "def process_timeseries(ts_df, col_models_ls, col_mod):\n",
        "  '''\n",
        "  Given a DataFrame, a list of columns to process and a modification to perform on these columns\n",
        "\n",
        "  Return a new DataFrame with the following new columns inserted from each original Model column:\n",
        "\n",
        "    1. Length-Normed (col_mod='lnorm'])\n",
        "       a. {base_model}_lnorm\n",
        "\n",
        "    2. Standardized (col_mod='std-[mean,median,minmix]')\n",
        "       a. {base_model}_stdscaler\n",
        "       b. {base_model}_medianiqr \n",
        "       a. {base_model_lnorm}_stdscaler\n",
        "       b. {base_model_lnorm}_medianiqr \n",
        "\n",
        "    3. Length-Normed Standardized (col_mod='roll[dd]') # where dd = 01 to 20 indicating rolling window width as % of corpus length\n",
        "       a. {base_model}_roll\n",
        "       b. {base_model}_roll \n",
        "       a. {base_model_lnorm}_roll\n",
        "       b. {base_model_lnorm}_roll \n",
        "       a. {base_model_lnorm_stdscaler}_roll\n",
        "       b. {base_model_lnorm_medianiqr}_roll\n",
        " \n",
        "  '''\n",
        "\n",
        "  temp_df = pd.DataFrame()  # ts_df.filter(['sent_no','sent_raw'], axis=1)\n",
        "  # print(f'temp_df is {temp_df}')\n",
        "\n",
        "  # Prerequisite: token_len column must exists\n",
        "  if 'token_len' not in ts_df.columns:\n",
        "    ts_df['token_len'] = ts_df['sent_raw'].apply(lambda x: len(x.strip().split()))\n",
        "    ts_df['char_len'] = ts_df['sent_raw'].apply(lambda x: len(x))\n",
        "\n",
        "\n",
        "  # OPOTION 1: Apply (token) Length-Normalization to specified time series\n",
        "  if col_mod == 'lnorm':\n",
        "\n",
        "    # Apply lnorm operation on all specificed columns\n",
        "    for anold_model_no, anold_model in enumerate(col_models_ls):\n",
        "\n",
        "      # lnorm (Length normalization of sentiment values using token_len) operation can only be applied to base model time series\n",
        "      # rule: disallowed substrings in anold_model name if applying lnorm (anew_mod)\n",
        "      rule_badsubstr_lnorm = ['lnorm', 'stdscaler', 'medianiqr', 'roll']\n",
        "      if any(map(anold_model.__contains__, rule_badsubstr_lnorm)):\n",
        "        print(f'ERROR: Length-Normalization (lnorm) operation cannot be applied to {anold_model}\\n    any columns containing {rule_badsubstr_lnorm}')\n",
        "        return -99  # Return ERROR condition\n",
        "      else:\n",
        "        # Normalize specified sentiment time series by dividing by text length\n",
        "\n",
        "        # TODO: replace 'sent_raw'/'sent_clean' with 'text_raw'/'text_clean' for Sentence, Paragraph, Section and Chapter DataFrames\n",
        "\n",
        "        print(f'Applying function=[{col_mod}] on time series [{anold_model}]\\n') \n",
        "\n",
        "        text_len_ls = list(ts_df['token_len'])\n",
        "        text_sentiment_ls = list(ts_df[anold_model])\n",
        "        text_sentiment_norm_ls = [text_sentiment_ls[i]/text_len_ls[i] for i in range(len(text_len_ls))]\n",
        "        col_mod_name = f'{anold_model}_{col_mod}'\n",
        "        # ts_df = ts_df.assign(acol_mod_name = pd.Series(text_sentiment_norm_ls).values)\n",
        "        temp_df[col_mod_name] = pd.Series(text_sentiment_norm_ls)\n",
        "\n",
        "\n",
        "  # OPTION 2: Apply (Robust) Standardization to specified time series\n",
        "  if col_mod.startswith('std'):\n",
        "\n",
        "    # Apply lnorm operation on all specificed columns\n",
        "    for anold_model_no, anold_model in enumerate(col_models_ls):\n",
        "\n",
        "      # std (Standardization) operation can only be applied to base model time series\n",
        "      # rule: disallowed substrings in anold_model name if applying std to existing rolling averages or already standardized time series\n",
        "      rule_badsubstr_std = ['minmax', 'stdscaler', 'medianiqr', 'roll']\n",
        "      if any(map(anold_model.__contains__, rule_badsubstr_std)):\n",
        "        print(f'ERROR: Standardization (std) operation cannot be applied to {anold_model}\\n    any columns containing {rule_badsubstr_std}')\n",
        "        return -99  # Return ERROR condition\n",
        "      else:\n",
        "        # Standardize specificied sentiment time series by dividing by applying (Robust)Standization also configured in code below\n",
        "\n",
        "        # TODO: replace 'sent_raw'/'sent_clean' with 'text_raw'/'text_clean' for Sentence, Paragraph, Section and Chapter DataFrames\n",
        "\n",
        "        print(f'Applying function=[{col_mod}] on time series [{anold_model}]\\n')\n",
        "\n",
        "        # Must set any invalid (E.g. NaN cells to 0)\n",
        "      \n",
        "\n",
        "        if col_mod == 'std-minmax':\n",
        "\n",
        "          col_mod_minmax = f'{anold_model}_minmax'\n",
        "          temp_minmax_np = minmax_scaler.fit_transform(np.array(ts_df[anold_model]).reshape(-1, 1))\n",
        "          temp_df[col_mod_minmax] = pd.Series(temp_minmax_np.ravel())\n",
        "\n",
        "        elif col_mod == 'std-stdscaler':\n",
        "\n",
        "          col_mod_minmax = f'{anold_model}_stdscaler'\n",
        "          temp_minmax_np = mean_std_scaler.fit_transform(np.array(ts_df[anold_model]).reshape(-1, 1))\n",
        "          temp_df[col_mod_minmax] = pd.Series(temp_minmax_np.ravel())\n",
        "\n",
        "        elif col_mod == 'std-medianiqr':\n",
        "\n",
        "          col_mod_minmax = f'{anold_model}_medianiqr'\n",
        "          temp_minmax_np = median_iqr_scaler.fit_transform(np.array(ts_df[anold_model]).reshape(-1, 1))\n",
        "          temp_df[col_mod_minmax] = pd.Series(temp_minmax_np.ravel())\n",
        "\n",
        "        else:\n",
        "          print(f\"ERROR: modification fn (col_mod): {col_mod}, but must be one of ['std-minmax','std-stdscaler','std-medianiqr']\\n\")\n",
        "\n",
        "\n",
        "  # OPTION 3: Apply Simple Rolling Mean to specified time series\n",
        "  if col_mod.startswith('roll'):\n",
        "\n",
        "    roll_per = 0\n",
        "\n",
        "    # Check for roll argument against several rules and return detailed error message if fail to pass any combination of rules\n",
        "    roll_err_ls = []\n",
        "    roll_arg_len = len(col_mod)\n",
        "    if (roll_arg_len != 6):\n",
        "      roll_err_ls.append(f'ERROR: argument roll[dd]={col_mod} is too long with {roll_arg_len} characters (must be 6)')\n",
        "    roll_arg_2last = col_mod[-2:]\n",
        "\n",
        "    if (roll_arg_2last.isdigit() == False):\n",
        "      roll_err_ls.append(f'ERROR: argument roll[dd]={col_mod} last 2 chars {roll_arg_2last} must be both be digits [0-9]')\n",
        "    else:\n",
        "      # print(f'BEFORE: roll_arg_2last={roll_arg_2last}')\n",
        "      roll_per = int(roll_arg_2last)\n",
        "      # print(f'AFTER: roll_per={roll_per}')\n",
        "      if (roll_per > 20):\n",
        "        roll_err_ls.append(f'ERROR: argument roll[dd]={col_mod} last 2 chars {roll_arg_2last} must be integers between 01 and 20')\n",
        "\n",
        "    if len(roll_err_ls) > 0:\n",
        "      print(f'ERROR in process_timeseries() due to invalid argument roll[dd] = {col_mod}\\n\\n')\n",
        "      for anerror_str in roll_err_ls:\n",
        "        # print(f'    {anerror_str}')\n",
        "        return -99  # Return ERROR condition\n",
        "\n",
        "    # Apply lnorm operation on all specificed columns\n",
        "    for anold_model_no, anold_model in enumerate(col_models_ls):\n",
        "\n",
        "      # roll (Simple Rolling Average with specificed window size as 2-digit percentage of corpus length (01-20%)\n",
        "      # rule: disallowed substrings in anold_model name applying roll operation more than once to existing time series\n",
        "      rule_badsubstr_roll = ['roll']\n",
        "      if any(map(anold_model.__contains__, rule_badsubstr_roll)):\n",
        "        print(f'ERROR: Rolling Mean (roll) operation cannot be applied to {anold_model}\\n    any columns containing {rule_badsubstr_roll}')\n",
        "        return -99 # Return ERROR condition\n",
        "\n",
        "      else:\n",
        "          # Compute Rolling Mean with the given window size (extracted above as an int in roll_per) for the specificied sentiment time series\n",
        "\n",
        "          # TODO: replace 'sent_raw'/'sent_clean' with 'text_raw'/'text_clean' for Sentence, Paragraph, Section and Chapter DataFrames\n",
        "\n",
        "          print(f'Applying function=[{col_mod}] on time series [{anold_model}]\\n')\n",
        "\n",
        "          col_mod_roll = f'{anold_model}_{col_mod}'\n",
        "          # print(f'  for col_mod: {col_mod} and roll_per: {roll_per}')\n",
        "          roll_win = int(ts_df.shape[0]*roll_per/100)\n",
        "          # print(f'    and roll_win: {roll_win}')\n",
        "          temp_df[col_mod_roll] = ts_df[anold_model].rolling(roll_win, center=True).mean()\n",
        "\n",
        "  return temp_df  # Return SUCCESS condition\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIo6-zGKnZps"
      },
      "source": [
        "\"\"\"\n",
        "def norm2negpos1(data_ser):\n",
        "  '''\n",
        "  Given a series of floating number\n",
        "  Return a a list of same values normed between -1.0 and +1.0\n",
        "  '''\n",
        "  # data_np = np.matrix(data_ser)\n",
        "\n",
        "  scaler=MinMaxScaler(feature_range=(-1.0, 1.0))\n",
        "  temp_ser = scaler.fit_transform(np.matrix(data_ser))\n",
        "  \n",
        "  return temp_ser\n",
        "\"\"\";\n",
        "\n",
        "# Test\n",
        "'''\n",
        "temp_np = norm2negpos1(corpus_all_df[['xlnet_sst5']])\n",
        "print(type(temp_np))\n",
        "temp_np.shape\n",
        "''';"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ylt_kLuEFDrj"
      },
      "source": [
        "# This must be defined AFTER the corpus_sects_df DataFrame is created in the Preprocessing Step below\n",
        "# Raw Plot of Section Sentiments (Adjusted for (x-axis) mid-Section Sentence No and (y-axis) Sentiment weighted by Section length )\n",
        "# corpus_sects_df = pd.DataFrame()  # Create empty early as required by some utility functions\n",
        "\n",
        "def plot_crux_sections(model_names_ls, semantic_type='section', subtitle_str='', label_token_ct=0, title_xpos = 0.8, title_ypos=0.2, sec_y_height=0, save2file=False):\n",
        "  '''\n",
        "  Given a Sections DataFrame, model_name and semantic type,\n",
        "  Return a Plot of the Cruxes\n",
        "  '''\n",
        "\n",
        "  crux_points_dt = {}\n",
        "  model_stand_names_ls = []\n",
        "  section_boundries_ls = []\n",
        "\n",
        "\n",
        "  # print(f'Using model_names: {model_names_ls}')\n",
        "\n",
        "  # sns.lineplot(data=ts_df, x='sent_no_mid', y=amodel_stand, markers=['o'], alpha=0.5, label=amodel_stand); # .set_title(f'{CORPUS_FULL} \\n Plot Section Sentiment (Bing Lexicon)')\n",
        "\n",
        "\n",
        "  # At Section boundries draw blue vertical lines \n",
        "  section_boundries_ls = list(corpus_sects_df['sent_no_start'])\n",
        "  for i, sent_no in enumerate(section_boundries_ls):\n",
        "    plt.text(sent_no, sec_y_height, f'Sec#{i}', alpha=0.2, rotation=90)\n",
        "    plt.axvline(sent_no, color='blue', alpha=0.1);\n",
        "\n",
        "  # At Chapter boundaries draw red vertical lines\n",
        "  chapter_boundries_ls = list(corpus_chaps_df['sent_no_start'])\n",
        "  for i, sent_no in enumerate(chapter_boundries_ls):\n",
        "    plt.axvline(sent_no, color='navy', alpha=0.1);\n",
        "\n",
        "  # Error check and assign DataFrame associated with each semantic_type\n",
        "  if semantic_type == 'section':\n",
        "    # Get midpoints of each Section\n",
        "    ts_df=corpus_sects_df\n",
        "    midpoints_ls = list(corpus_sects_df['sent_no_mid'])\n",
        "  elif semantic_type == 'chapter':\n",
        "    # Get midpoints of each Chapter\n",
        "    ts_df=corpus_chaps_df\n",
        "    midpoints_ls = list(corpus_chaps_df['sent_no_mid'])\n",
        "  else:\n",
        "    print(f\"ERROR: semantic_type={semantic_type} must be either 'section' or 'chapter'\")\n",
        "    return -1\n",
        "\n",
        "  # How many sentiment time series are we plotting?\n",
        "  if len(model_names_ls) == 1:\n",
        "    \n",
        "    # Plotting only one model\n",
        "    model_name_full = str(model_names_ls[0])\n",
        "    model_name_root = model_name_full.split('_')[0]\n",
        "    print(f'model_name_full: {model_name_full} and model_name_root: {model_name_root}')\n",
        "    if model_name_root in MODELS_LS:\n",
        "      # Plot\n",
        "      print(f'about to sns.lineplot model: ') # {ts_df}')\n",
        "      g = sns.lineplot(data=ts_df, x='sent_no_mid', y=model_name_full, markers=['o'], alpha=0.5, label=model_name_full) # .set_title(f'{CORPUS_FULL} \\n Plot Section Sentiment and Cruxes (Model: {models_names_ls[0].capitalize()})')\n",
        "      # g._legend.remove()\n",
        "      # print(f'model_name_full={model_name_full}')\n",
        "      # plt.plot(ts_df.sent_no_mid, ts_df[model_name_full], markers=\"o\", alpha=0.5, label=model_name_full)\n",
        "    else:\n",
        "      print(f'ERROR: model_names_ls[0]={model_name_root} is invalid,\\n    must be one of {MODELS_LS}')\n",
        "      return -1\n",
        "\n",
        "    # If plotting only one model, add labels\n",
        "    midpoints_sentiment_ls = list(ts_df[model_name_full])\n",
        "    sect_ct = 0\n",
        "    for x,y in zip(midpoints_ls, midpoints_sentiment_ls): \n",
        "      label_token_int = int(label_token_ct)\n",
        "      if label_token_int < 0:\n",
        "        label = ''\n",
        "      elif label_token_int == 0:\n",
        "        # if arg label_token_ct == 0, just print sent_no\n",
        "        label = f\"#{x}({sect_ct})\"\n",
        "      else:\n",
        "        # if arg label_token_ct > 0, print the first label_token_ct words of sentence at crux point\n",
        "        label = f\"#{x}({sect_ct}) {' '.join(corpus_sents_df.iloc[x-1]['sent_raw'].split()[:label_token_int])}\"; # \\nPolarity: {y:.2f}'\n",
        "\n",
        "      # Save Crux point in crux_points_dt Dictionary if plotting Cruxes for a single/specific Model\n",
        "      crux_full_str = ' '.join(corpus_sents_df.iloc[x]['sent_raw'].split())\n",
        "      crux_points_dt[x] = [y, crux_full_str]\n",
        "\n",
        "      plt.annotate(label,\n",
        "                   (x,y),\n",
        "                   textcoords='offset points',\n",
        "                   xytext=(0,10),\n",
        "                   ha='center',\n",
        "                   rotation=90)\n",
        "      sect_ct += 1\n",
        "\n",
        "    plt.title(f'{CORPUS_FULL} \\n Plot {semantic_type.capitalize()} Sentiment ({model_name_full.capitalize()})\\n{subtitle_str}', x=title_xpos, y=title_ypos);\n",
        "    # Plot\n",
        "    plt.plot(midpoints_ls, midpoints_sentiment_ls, marker=\"o\", ms=6) # , markevery=[0,1])\n",
        "\n",
        "  else:\n",
        "    # If plotting multiple models\n",
        "    model_names_str = 'Multiple Models'\n",
        "    for i, model_name_full in enumerate(model_names_ls):\n",
        "      # Error check and assign correct model names\n",
        "      model_name_root = model_name_full.split('_')[0]\n",
        "      if model_name_root in MODELS_LS:\n",
        "        # Plot\n",
        "        g = sns.lineplot(data=ts_df, x='sent_no_mid', y=model_name_full, markers=['o'], alpha=0.5, label=model_name_full) # .set_title(f'{CORPUS_FULL} \\n Plot Section Sentiment and Cruxes (Model: {models_names_ls[0].capitalize()})')\n",
        "        # g._legend.remove()\n",
        "        # plt.plot(ts_df.sent_no_mid, ts_df[model_name_full], marker=\"o\", alpha=0.5, label=model_name_full)\n",
        "      else:\n",
        "        print(f'ERROR: model_names_ls[]={model_name_root} is invalid,\\n    must be one of {MODELS_LS}')\n",
        "        return -1\n",
        "\n",
        "      # Plot\n",
        "      g = sns.lineplot(data=ts_df, x='sent_no_mid', y=model_name_full, markers=['o'], alpha=0.5, label=model_name_full) # .set_title(f'{CORPUS_FULL} \\n Plot Section Sentiment and Cruxes (Model: {models_names_ls[0].capitalize()})')\n",
        "      # g._legend.remove()\n",
        "\n",
        "    plt.title(f'{CORPUS_FULL} \\n Plot {semantic_type.capitalize()} Sentiment (Standardized Models)\\n{subtitle_str}', x=title_xpos, y=title_ypos)\n",
        "\n",
        "  # plt.legend(loc='best');\n",
        "\n",
        "  if (save2file == True):\n",
        "    # Save graph to file.\n",
        "    models_names_ls = [x[:2] for x in model_names_ls]\n",
        "    models_names_str = ''.join(models_names_ls)\n",
        "    plot_filename = f'plot_cruxes_{semantic_type}_{models_names_str}_{models_names_str}.png'\n",
        "    plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "    plt.savefig(plotpathfilename_str, format='png', dpi=300)\n",
        "    print(f'Plot saved: {plot_filename}');\n",
        "\n",
        "  return crux_points_dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUNMIlJKHyz3"
      },
      "source": [
        "def plot_histogram(model_name='vader', text_unit='sentence', save2file=False):\n",
        "  '''\n",
        "  Given a model, text_unit\n",
        "  Plot a Histogram using the default DataFrame\n",
        "  '''\n",
        "\n",
        "  if text_unit == 'sentence':\n",
        "    ts_df = corpus_sents_df\n",
        "\n",
        "  elif text_unit == 'paragraph':\n",
        "    ts_df = corpus_parags_df\n",
        "\n",
        "  elif text_unit == 'section':\n",
        "    ts_df = corpus_sects_df\n",
        "\n",
        "  elif text_unit == 'chapter':\n",
        "    ts_df = corpus_chaps_df\n",
        "\n",
        "  else:\n",
        "    print(f'ERROR: {text_unit} must be sentence, paragraph or section')\n",
        "\n",
        "  sns.histplot(ts_df[model_name], kde=True).set_title(f'{CORPUS_FULL} \\n Histogram {text_unit.capitalize()} Sentiment (Model {model_name.capitalize()})')\n",
        "  # get_smas(ts_df, model_name=model_name, text_unit=text_unit, win_ls=wins_def_ls)\n",
        "\n",
        "  if (save2file == True):\n",
        "    # Save graph to file.\n",
        "    plot_filename = f'plot_hist_{text_unit}_{model_name}.png'\n",
        "    plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "    plt.savefig(plotpathfilename_str, format='png', dpi=300)\n",
        "    print(f'Plot saved: {plot_filename}');\n",
        "\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGTkfsSWFCeO"
      },
      "source": [
        "# Raw Plot of Section Sentiments (Not scaled by mid-Section Sentence No to match Sentence/Paragraph x-axes)\n",
        "\n",
        "def plot_raw_sections(ts_df='corpus_sents_df', model_name='vader', semantic_type='sentence', save2file=False):\n",
        "  '''\n",
        "  Given a DataFrame, model_name column, semantic_type \n",
        "  Plot the raw sentiment types\n",
        "  Options to save2file\n",
        "  ''' \n",
        "  \n",
        "  # if (PLOT_OUTPUT == 'All') | (PLOT_OUTPUT == 'Major'):\n",
        "  sns.lineplot(data=ts_df, x='sect_no', y=model_name, alpha=0.5).set_title(f'{CORPUS_FULL} \\n Plot {semantic_type} Sentiment (Raw {model_name.capitalize()})')\n",
        "\n",
        "  if save2file == True:\n",
        "    # Save graph to file.\n",
        "    plot_filename = f'plot_nostand_sects_{model_name}.png'\n",
        "    plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "    plt.savefig(plotpathfilename_str, format='png', dpi=300)\n",
        "    print(f'Plot saved: {plot_filename}');\n",
        "\n",
        "  return\n",
        "\n",
        "# Test\n",
        "# plot_raw_sections(ts_df=corpus_sects_df, model_name='pattern', semantic_type='section', save2file=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmrtifYoIjOT"
      },
      "source": [
        "# Raw Plot of Section Sentiments (Not scaled by mid-Section Sentence No to match Sentence/Paragraph x-axes)\n",
        "\n",
        "def plot_raw_sentiments(model_name='vader', semantic_type='sentence', save2file=False):\n",
        "  '''\n",
        "  Given a DataFrame, model_name column, semantic_type \n",
        "  Plot the raw sentiment types\n",
        "  Options to save2file\n",
        "  ''' \n",
        "  \n",
        "  if semantic_type == 'sentence':\n",
        "    ts_df = corpus_sents_df\n",
        "    x_units = 'sent_no'\n",
        "  elif semantic_type == 'paragraph':\n",
        "    ts_df = corpus_parags_df\n",
        "    x_units = 'parag_no'\n",
        "  elif (semantic_type == 'section') | (semantic_type == 'section_stand'):\n",
        "    ts_df = corpus_sects_df\n",
        "    x_units = 'sect_no'\n",
        "  elif (semantic_type == 'chapter') | (semantic_type == 'chapter_stand'):\n",
        "    ts_df = corpus_chaps_df\n",
        "    x_units = 'chap_no'\n",
        "    \n",
        "  else:\n",
        "    print(f'ERROR: {semantic_type} must be sentence, paragraph or section')\n",
        "\n",
        "\n",
        "  # if (PLOT_OUTPUT == 'All') | (PLOT_OUTPUT == 'Major'):\n",
        "  sns.lineplot(data=ts_df, x=x_units, y=model_name, alpha=0.5, label=model_name).set_title(f'{CORPUS_FULL} \\n Plot {semantic_type} Sentiment (Raw {model_name.capitalize()})')\n",
        "  \n",
        "  plt.legend(loc='best')\n",
        "\n",
        "  if save2file == True:\n",
        "    # Save graph to file.\n",
        "    plot_filename = f'plot_raw_sentiments_{semantic_type}_{model_name}.png'\n",
        "    plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "    plt.savefig(plotpathfilename_str, format='png', dpi=300)\n",
        "    print(f'Plot saved: {plot_filename}');\n",
        "\n",
        "  return\n",
        "\n",
        "# Test\n",
        "# plot_raw_sections(ts_df=corpus_sects_df, model_name='pattern', semantic_type='section', save2file=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FR3G1QH-CAW"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def get_lowess_ts(data, f=2./3., pts=None, itn=3, order=1):\n",
        "    \"\"\"Fits a nonparametric regression curve to a scatterplot.\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : pandas.Series\n",
        "        Data points in the scatterplot. The\n",
        "        function returns the estimated (smooth) values of y.\n",
        "    **Optionals**\n",
        "    f : float\n",
        "        The fraction of the data set to use for smoothing. A\n",
        "        larger value for f will result in a smoother curve.\n",
        "    pts : int\n",
        "        The explicit number of data points to be used for\n",
        "        smoothing instead of f.\n",
        "    itn : int\n",
        "        The number of robustifying iterations. The function will run\n",
        "        faster with a smaller number of iterations.\n",
        "    order : int\n",
        "        The order of the polynomial used for fitting. Defaults to 1\n",
        "        (straight line). Values < 1 are made 1. Larger values should be\n",
        "        chosen based on shape of data (# of peaks and valleys + 1)\n",
        "    Returns\n",
        "    -------\n",
        "    pandas.Series containing the smoothed data.\n",
        "    \"\"\"\n",
        "    # Authors: Alexandre Gramfort <alexandre.gramfort@telecom-paristech.fr>\n",
        "    #            original\n",
        "    #          Dan Neuman <https://github.com/dneuman>\n",
        "    #            converted to Pandas series and extended to polynomials\n",
        "    # License: BSD (3-clause)\n",
        "\n",
        "    x = np.array(data.index, dtype=float)\n",
        "    # condition x-values to be between 0 and 1 to reduce errors in linalg\n",
        "    x = x - x.min()\n",
        "    x = x / x.max()\n",
        "    y = data.values\n",
        "    n = len(data)\n",
        "    if pts is None:\n",
        "        f = np.min([f, 1.0])\n",
        "        r = int(np.ceil(f * n))\n",
        "    else:  # allow use of number of points to determine smoothing\n",
        "        r = int(np.min([pts, n]))\n",
        "    r = min([r, n-1])\n",
        "    order = max([1, order])\n",
        "    # Create matrix of 1, x, x**2, x**3, etc, by row\n",
        "    xm = np.array([x**j for j in range(order+1)])\n",
        "    # Create weight matrix, one column per data point\n",
        "    h = [np.sort(np.abs(x - x[i]))[r] for i in range(n)]\n",
        "    w = np.clip(np.abs((x[:, None] - x[None, :]) / h), 0.0, 1.0)\n",
        "    w = (1 - w ** 3) ** 3\n",
        "    # Set up output\n",
        "    yEst = np.zeros(n)\n",
        "    delta = np.ones(n)  # Additional weights for iterations\n",
        "    for iteration in range(itn):\n",
        "        for i in range(n):\n",
        "            weights = delta * w[:, i]\n",
        "            xw = np.array([weights * x**j for j in range(order+1)])\n",
        "            b = xw.dot(y)\n",
        "            a = xw.dot(xm.T)\n",
        "            beta = np.linalg.solve(a, b)\n",
        "            yEst[i] = sum([beta[j] * x[i]**j for j in range(order+1)])\n",
        "        # Set up weights to reduce effect of outlier points on next iteration\n",
        "        residuals = y - yEst\n",
        "        s = np.median(np.abs(residuals))\n",
        "        delta = np.clip(residuals / (6.0 * s), -1, 1)\n",
        "        delta = (1 - delta ** 2) ** 2\n",
        "\n",
        "    return pd.Series(yEst, index=data.index, name='Trend')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l26W_YY2_whD"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "print(*corpus_sents_df.columns, sep='\\n')\n",
        "\n",
        "temp_ls = [f'{x}_stdscaler' for x in models_baseline_ls]\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "for amodel in temp_ls:\n",
        "  corpus_sents_df['temp_ts'] = Lowess(corpus_sents_df[amodel], f=0.1)\n",
        "  g = sns.lineplot(\n",
        "      # data=fmri.query(\"region == 'frontal'\"),\n",
        "      data=corpus_sents_df,\n",
        "      x=\"sent_no\", y='temp_ts', # hue=\"event\", units=\"subject\",\n",
        "      estimator=None, lw=1,\n",
        "      legend=False\n",
        "  )\n",
        "plt.title(f'{CORPUS_FULL}\\n LOWESS')\n",
        "plt.legend(loc='best');\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeSIwArU-Khu"
      },
      "source": [
        "# _ = get_lowess(corpus_sents_df, models_ls=['vader_stdscaler','bing_stdscaler','textblob_stdscaler','flair_stdscaler','stanza_stdscaler'], text_unit='sentence', afrac=1./20);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCP2BR-H_XWv"
      },
      "source": [
        "# _ = get_lowess(corpus_sents_df, models_ls=['vader_lnorm_stdscaler','bing_lnorm_stdscaler','textblob_lnorm_stdscaler','flair_lnorm_stdscaler','stanza_lnorm_stdscaler'], text_unit='sentence', afrac=1./20);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB8ibstaeiVd"
      },
      "source": [
        "# TODO: must plot in order to save, cannot save without first plotting\n",
        "\n",
        "def get_lowess(ts_df='corpus_parags_df', models_ls=MODELS_LS, text_unit='paragraph', plot_subtitle='', alabel='', afrac=1./10, ait=5, alpha=0.5, do_plot=True, save2file=False):\n",
        "  '''\n",
        "  Given a DataFrame, list of column to plot, LOWESS params fraction and iterations,\n",
        "  Return a DataFrame with LOWESS values\n",
        "  If 'plot=True', also output plot\n",
        "  '''\n",
        "\n",
        "  # global corpus_all_df\n",
        "\n",
        "  lowess_df = pd.DataFrame()\n",
        "\n",
        "  # Step 1: Calculate LOWESS smoothed values\n",
        "  for i,acol in enumerate(models_ls):\n",
        "    sm_x, sm_y = sm_lowess(endog=ts_df[acol].values, exog=ts_df.index.values, frac=afrac, it=ait, return_sorted = True).T\n",
        "    col_new = f'{acol}_lowess'\n",
        "    lowess_df[col_new] = pd.Series(sm_y)\n",
        "    # Optionally plot LOWESS for all models\n",
        "    if do_plot:\n",
        "      if alabel == '':\n",
        "        alabel == acol\n",
        "      plt.plot(sm_x, sm_y, label=acol, alpha=alpha, linewidth=2)\n",
        "\n",
        "  lowess_df['median'] = lowess_df.median(axis=1) # sm_y # corpus_all_df[df_cols_ls].median(axis=1)\n",
        "  \n",
        "  # Step 2: Optionally plot LOWESS for median\n",
        "  if do_plot:\n",
        "    # sm_x, sm_y = sm_lowess(endog=lowess_df.median, exog=lowess_df.index.values,  frac=afrac, it=ait, return_sorted = True).T\n",
        "    # plt.plot(sm_x, sm_y, label='median', alpha=0.9, linewidth=2, color='black')\n",
        "    \n",
        "    frac_str = str(round(100*afrac))\n",
        "    plt.title(f'{CORPUS_FULL} \\n {plot_subtitle} {text_unit} Standardized Sentiment Smoothed with LOWESS (frac={frac_str})')\n",
        "    plt.legend() # (title='Sentiment Model', loc='best')\n",
        "\n",
        "  # Step 3: Optionally save to file\n",
        "  if save2file:\n",
        "    # Save Plot to file.\n",
        "    plot_filename = f'plot_{text_unit}_lowess_{plot_subtitle.split()[0].lower()}_{author_abbr_str}_{title_str}.png'\n",
        "    # plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "    plt.savefig(plot_filename, format='png', dpi=300)\n",
        "    print(f'Plot saved: {plot_filename}');\n",
        "\n",
        "\n",
        "  return lowess_df\n",
        "\n",
        "\n",
        "# Test\n",
        "'''\n",
        "new_lowess_col = f'{sa_model}_lowess'\n",
        "my_frac = 1./10\n",
        "my_frac_per = round(100*my_frac)\n",
        "new_lowess_col = f'{sa_model}_lowess_{my_frac_per}'\n",
        "corpus_all_df[new_lowess_col] = plot_lowess(corpus_all_df, [sa_model], afrac=my_frac)\n",
        "corpus_all_df.head()\n",
        "''';"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cANCC2iz6nwo"
      },
      "source": [
        "def get_sent2dets(sent_no):\n",
        "  '''\n",
        "  Given a Sentence Number\n",
        "  Return the corresponding Paragraph, Section and Chapter Numbers that contain it\n",
        "  '''\n",
        "\n",
        "  # Get Paragraph No containing given Sentence No\n",
        "  sent_parag_no = int(corpus_sents_df[corpus_sents_df['sent_no']==sent_no]['parag_no'])\n",
        "\n",
        "  # Get Section No containing given Sentence No.\n",
        "  corpus_sects_ls = list(corpus_sects_df['sect_no'])\n",
        "  for asect_no in corpus_sects_ls:\n",
        "    if (int(corpus_sects_df[corpus_sects_df['sect_no'] == asect_no]['sent_no_start']) > sent_no):\n",
        "      break\n",
        "    sent_sect_no = asect_no\n",
        "    # print(f'asect={asect_no}')\n",
        "\n",
        "  # Get Chapter No containing given Sentence No.\n",
        "  corpus_chaps_ls = list(corpus_chaps_df['chap_no'])\n",
        "  for achap_no in corpus_chaps_ls:\n",
        "    if (int(corpus_chaps_df[corpus_chaps_df['chap_no'] == achap_no]['sent_no_start']) > sent_no):\n",
        "      break\n",
        "    sent_chap_no = achap_no\n",
        "    # print(f'achap={achap_no}')\n",
        "\n",
        "\n",
        "  return sent_parag_no, sent_sect_no, sent_chap_no\n",
        "\n",
        "# Test\n",
        "# sent_parag_no, sent_sect_no, sent_chap_no = get_sent2dets(1408)\n",
        "# print(f'sent_parag_no={sent_parag_no}\\nsent_sect_no={sent_sect_no}\\nsent_chap_no={sent_chap_no}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6liffwhYtSw"
      },
      "source": [
        "# get_sentnocontext_report(the_sent_no=sent_no, the_n_sideparags=n_sideparags, the_sent_highlight=sentence_highlight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sijR4OknJive"
      },
      "source": [
        "def get_sentnocontext(timeser_df, sent_no=1, n_sideparags=1, sent_highlight=True):\n",
        "  '''\n",
        "  Given a sentence number in the Corpus\n",
        "  Return the containing paragraph and n-paragraphs on either side\n",
        "  (e.g. if n=2, return 2+1+2=5 paragraphs)\n",
        "  '''\n",
        "\n",
        "  # print(f'just entered get_sentnocontext withsent_no: {sent_no} and  timeser_df:\\n\\n    {timeser_df}')\n",
        "  timeser_indx = timeser_df['sent_no'] == sent_no\n",
        "  parag_target_no = int(timeser_df[timeser_df['sent_no'] == sent_no]['parag_no'])\n",
        "  # print(f'parag_target_no = {parag_target_no} and type: {type(parag_target_no)}')\n",
        "\n",
        "  if n_sideparags == 0:\n",
        "    parags_context_ls = list(corpus_parags_df[corpus_parags_df['parag_no'] == parag_target_no]['parag_raw'])\n",
        "\n",
        "  else:\n",
        "    parag_start = parag_target_no - n_sideparags\n",
        "    parag_end = parag_target_no + n_sideparags + 1\n",
        "    parags_context_ls = list(corpus_parags_df.iloc[parag_start:parag_end]['parag_raw'])\n",
        "\n",
        "\n",
        "  if sent_highlight == True:\n",
        "    parag_match_str = str(parags_context_ls[n_sideparags])\n",
        "    # print(f'parag_match_str:\\n  {parag_match_str}') parag_no\n",
        "    sent_idx = sent_no\n",
        "    sent_str = (timeser_df[timeser_df['sent_no']==sent_idx]['sent_raw'].values)[0]\n",
        "    sent_str_up = sent_str.upper()\n",
        "    # print(f'sent_str:\\n  {sent_str}')\n",
        "    # parags_context_ls[n_sideparags] \n",
        "    parags_context_ls[n_sideparags] = parag_match_str.replace(sent_str, sent_str_up)\n",
        "\n",
        "  return parags_context_ls\n",
        "\n",
        "# Te\n",
        "# context_highlighted = get_sentnoparags(sent_no=1051, n_sideparags=1)\n",
        "# print(context_highlighted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM_I8uDfJztH"
      },
      "source": [
        "corpus_sents_df = pd.DataFrame()\n",
        "\n",
        "def get_sentnocontext_report(ts_df = corpus_sents_df, the_sent_no=7, the_n_sideparags=1, the_sent_highlight=True):\n",
        "  '''\n",
        "  Wrapper function around  get_sentnocontext()   Paragraph(s) Context\n",
        "  Prints a nicely formatted context report\n",
        "  '''\n",
        "\n",
        "  context_noparags = the_n_sideparags*2+1\n",
        "  # tsdf\n",
        "  # print('-------------------------------------------------------------')\n",
        "  print(f'The {context_noparags} Paragraph(s) Context around the Sentence #{the_sent_no} Crux Point:')\n",
        "  # print(f'ts_df = {ts_df}')\n",
        "  print('-------------------------------------------------------------')\n",
        "  print(f\"\\nCrux Sentence #{the_sent_no} Raw Text: -------------------------------\\n\\n    {str(ts_df[ts_df['sent_no'] == the_sent_no]['sent_raw'].values[0])}\\n\") # iloc[the_sent_no]['sent_raw']}\")\n",
        "\n",
        "  sent_parag_no, sent_sect_no, sent_chap_no = get_sent2dets(the_sent_no)\n",
        "  print(f\"\\nCrux Sentence #{the_sent_no} is Contained in: ---------------------------\\n\\n    Paragraph #{sent_parag_no}\\n      Section #{sent_sect_no}\\n      Chapter #{sent_chap_no}\\n\")\n",
        "\n",
        "  print(f\"\\n{context_noparags} Paragraph(s) Context: ------------------------------\")\n",
        "  # print('calling get_sentnocontext')\n",
        "  # context_parags_ls = get_sentnocontext(timeser_df = ts_df, sent_no=the_sent_no, n_sideparags=the_n_sideparags, sent_highlight=the_sent_highlight)\n",
        "  context_parags_ls = get_sentnocontext(timeser_df = corpus_sents_df, sent_no=the_sent_no, n_sideparags=the_n_sideparags, sent_highlight=the_sent_highlight)\n",
        "  context_len = len(context_parags_ls)\n",
        "  context_mid = context_len//2\n",
        "  for i, aparag in enumerate(context_parags_ls):\n",
        "    if i==context_mid:\n",
        "      # print(f'\\n>>> Paragraph #{i}: <<< Crux Point Sentence CAPITALIZED within this Paragraph\\n\\n    {aparag}') \n",
        "      print(f'\\n<*> {aparag}')\n",
        "    else:\n",
        "      # print(f'\\n    Paragraph #{i}:\\n\\n    {aparag}')\n",
        "      print(f'\\n    {aparag}')\n",
        "\n",
        "  return\n",
        "\n",
        "# Test\n",
        "# get_sentnocontext_report(sent_no=1051, n_sideparags=1, sent_highlight=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y04GiohGypNX"
      },
      "source": [
        "def get_section_timeseries(sect_no):\n",
        "  '''\n",
        "  Given a Section No in the current Corpus\n",
        "  Return the start,mid and ending Sent No for this Section as well as the Sentiment Time Series between the start/end Sentence for this Section\n",
        "  '''\n",
        "  \n",
        "  section_count = corpus_sects_df.shape[0]\n",
        "\n",
        "  # Compute the start, mid and end Sentence numbers for the selected Section\n",
        "  if Select_Section_No >= section_count:\n",
        "    print(f'ERROR: You picked Section #{Select_Section_No}.\\n  Section for this Corpus must be between 0 and {section_count-1}')\n",
        "    return -1\n",
        "\n",
        "  else:\n",
        "\n",
        "    # Get the starting and middle Sentence No of this Section\n",
        "    sect_sent_start = int(corpus_sects_df[corpus_sects_df['sect_no'] == Select_Section_No]['sent_no_start'].values)\n",
        "    # sect_sent_mid = int(corpus_sects_df[corpus_sects_df['sect_no'] == Select_Section_No]['sent_no_mid'].values)\n",
        "\n",
        "    # Calculate last Sentence No of this Section\n",
        "    if Select_Section_No == (section_count-1):   \n",
        "      print(f'You selected the last Section of this Corpus')\n",
        "      sect_sent_end = corpus_sents_df.shape[0] - 1\n",
        "    else:\n",
        "      sect_sent_end = int(corpus_sects_df[corpus_sects_df['sect_no'] == Select_Section_No+1]['sent_no_start'].values) # - 1\n",
        "      \n",
        "    print(f'Section #{sect_no}:----------')\n",
        "    print(f'\\nsect_sent_start: {sect_sent_start}')\n",
        "    # print(f'sect_sent_mid: {sect_sent_mid}')\n",
        "    print(f'sect_sent_end: {sect_sent_end}')\n",
        "\n",
        "\n",
        "  # Comput the start, and end Paragraph numbers for the selected Section\n",
        "  sect_parag_start = int(corpus_sents_df[corpus_sents_df['sent_no'] == sect_sent_start]['parag_no'].values)\n",
        "  sect_parag_end = int(corpus_sents_df[corpus_sents_df['sent_no'] == sect_sent_end]['parag_no'].values)\n",
        "\n",
        "  print(f'\\nsect_parag_start: {sect_parag_start}')\n",
        "  print(f'sect_parag_end: {sect_parag_end}')\n",
        "\n",
        "\n",
        "  # Extract and Return both a Sentence and Paragraph DataFrame for this Section \n",
        "\n",
        "  section_sents_df = corpus_sents_df.iloc[sect_sent_start:sect_sent_end]\n",
        "\n",
        "  section_parags_df = corpus_parags_df.iloc[sect_parag_start:sect_parag_end]\n",
        "\n",
        "\n",
        "  return section_sents_df, section_parags_df\n",
        "\n",
        "# Test\n",
        "\n",
        "# section_sents_df, section_parags_df = get_section_timeseries(Select_Section_No)\n",
        "\n",
        "# section_sents_df.head()\n",
        "\n",
        "# print(f'\\nsection_sents_df.shape: {section_sents_df.shape}')\n",
        "# print(f'section_parags_df.shape: {section_parags_df.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgFMgdQ3X33F"
      },
      "source": [
        "def get_lowess_cruxes(ts_df, col_series, text_type='sentence', win_lowess=5, sec_y_height=0, subtitle_str=' ', do_plot=True, save2file=False):\n",
        "  '''\n",
        "  Given a DataFrame and a Time Series Column within it and a LOWESS window\n",
        "  Return a list of Min/Max Crux Point (x,y) coordinate tuples for that Column Time Series\n",
        "  '''\n",
        "\n",
        "  crux_ls = []\n",
        "\n",
        "  series_len = ts_df.shape[0]\n",
        "\n",
        "  sent_no_min = ts_df.sent_no.min()\n",
        "  sent_no_max = ts_df.sent_no.max()\n",
        "  # print(f'sent_no_min {sent_no_min}')\n",
        "\n",
        "  sm_x = ts_df.index.values\n",
        "  sm_y = ts_df[col_series].values\n",
        "\n",
        "  half_win = int((win_lowess/100)*series_len)\n",
        "\n",
        "  # Find peaks(max).\n",
        "  # peak_indexes = signal.argrelextrema(sm_y, np.greater, order=half_win, mode='wrap') argrelextrema will not detect flat peaks\n",
        "  peak_indexes = signal.find_peaks(sm_y, distance=half_win) # np.greater, order=half_win, mode='wrap')\n",
        "  # peak_indexes = peak_indexes + sent_no_min\n",
        "  # print(f'peak_indexes[0]: {peak_indexes_np[0]}')\n",
        "  # print(f'peak_indexes type: {type(peak_indexes_np[0])}')\n",
        "  # peak_indexes_np = peak_indexes_np + sent_no_min\n",
        "  peak_indexes = peak_indexes[0]\n",
        "\n",
        "  peak_x_ls = list(peak_indexes)\n",
        "  peak_y_ls = list(sm_y[peak_indexes])\n",
        "\n",
        "  # Find valleys(min).\n",
        "  # valley_indexes = signal.argrelextrema(sm_y, np.less, order=half_win, mode='clip')\n",
        "  valley_indexes = signal.find_peaks(-sm_y, distance=half_win)\n",
        "  valley_indexes = valley_indexes[0]\n",
        "  \n",
        "  valley_x_ls = list(valley_indexes)\n",
        "  valley_y_ls = list(sm_y[valley_indexes])\n",
        "\n",
        "  # Save all peaks/valleys as list of (x,y) coordinate tuples\n",
        "  # print(f'type peak_x_ls is: {type(peak_x_ls)}')\n",
        "  x_all_ls = peak_x_ls + valley_x_ls\n",
        "  # readjust starting Sentence No to start with first sentence in segement window\n",
        "  x_all_ls = [x+sent_no_min for x in x_all_ls]\n",
        "  y_all_ls = peak_y_ls + valley_y_ls\n",
        "  crux_coord_ls = tuple(zip(x_all_ls, y_all_ls)) \n",
        "\n",
        "  # print(f'Original Series length={series_len} vs LOWESS Series length={len(x_all_ls)}')\n",
        "\n",
        "\n",
        "  if do_plot == True:\n",
        "    # Plot main graph.\n",
        "    (fig, ax) = plt.subplots()\n",
        "    ax.plot(sm_x, sm_y)\n",
        "\n",
        "    if text_type == 'sentence':\n",
        "      paragraph_boundries_ls = list(section_sents_df['parag_no'].unique())\n",
        "      for i, aparag in enumerate(paragraph_boundries_ls):\n",
        "        if i%5 == 0:\n",
        "          # Plot every 5th paragraph\n",
        "          sent_no = section_sents_df[section_sents_df['parag_no'] == aparag]['sent_no'].min()\n",
        "          plt.text(sent_no, sec_y_height, f'Paragraph #{aparag}', alpha=0.2, rotation=90)\n",
        "          plt.axvline(sent_no, color='blue', alpha=0.1)\n",
        "    elif text_type == 'paragraph':\n",
        "      paragraph_boundries_ls = list(section_sents_df['parag_no'].unique())\n",
        "      for i, aparag_no in enumerate(paragraph_boundries_ls):\n",
        "        if i%5 == 0:\n",
        "          # Plot every 5th paragraph\n",
        "          sent_no = section_sents_df[section_sents_df['parag_no'] == aparag]['sent_no'].min()\n",
        "          plt.text(aparag_no, sec_y_height, f'Paragraph #{aparag_no}', alpha=0.2, rotation=90)\n",
        "          plt.axvline(aparag_no, color='blue', alpha=0.1)    \n",
        "    else:\n",
        "      print(f\"ERROR: text_type is {text_type} but must be either 'sentence' or 'paragarph'\")\n",
        "\n",
        "    win_half = 0 # 2500\n",
        "\n",
        "    # Plot peaks.\n",
        "    # ax.plot(peak_x + win_half, peak_y, marker='o', linestyle='none', color='green', label=\"Peaks\")\n",
        "\n",
        "    # readjust starting Sentence No to start with first sentence in segement window\n",
        "    peak_x_ls = [x+sent_no_min for x in peak_x_ls]\n",
        "    ax.scatter(peak_x_ls, peak_y_ls)\n",
        "    for i, txt in enumerate(list(peak_x_ls)):\n",
        "        ax.annotate(f'  Sent #{txt}', (peak_x_ls[i], peak_y_ls[i]), rotation=90, annotation_clip=True)\n",
        "\n",
        "    # Plot valleys.\n",
        "    # ax.plot(valley_x + win_half, valley_y, marker='o', linestyle='none', color='red', label=\"Valleys\")\n",
        "    # readjust starting Sentence No to start with first sentence in segement window\n",
        "    valley_x_ls = [x+sent_no_min for x in valley_x_ls]\n",
        "    ax.scatter(valley_x_ls, valley_y_ls)\n",
        "    for i, txt in enumerate(list(valley_x_ls)):\n",
        "        ax.annotate(f'Sent #{txt}', (valley_x_ls[i], valley_y_ls[i]), rotation=270, xytext=(valley_x_ls[i], valley_y_ls[i]-4))\n",
        "\n",
        "    # for i, txt in enumerate(list(valley_x_ls)):\n",
        "    #     ax.annotate(f'\\n\\n\\nSent No.\\n   {txt}', (valley_x_ls[i], valley_y_ls[i]))\n",
        "    # plt.plot(x, y, 'bo')\n",
        "    # texts = [plt.text(valley_x_ls[i], valley_y_ls[i], 'Sent No.\\n   %s' %valley_x_ls[i], ha='right', va='top') for i in range(len(valley_x_ls))]\n",
        "    # adjust_text(texts)\n",
        "\n",
        "    # Confidence Interval (Min/Max Range)\n",
        "    # plt.fill_between(sentiment_lowess_df['x_value'], sentiment_lowess_df['min'], sentiment_lowess_df['max'], alpha=.3, color='lightskyblue')\n",
        "\n",
        "    plt.title(f'{CORPUS_FULL} Raw Sentence Crux Detection in Section #{Select_Section_No}\\nLOWESS Smoothed {subtitle_str} and SciPy find_peaks')\n",
        "    plt.xlabel(f'Sentence No within selected Section #{Select_Section_No}')\n",
        "\n",
        "    # locs, labels = xticks()  # Get the current locations and labels.\n",
        "    # plt.xticks(np.arange(sent_no_min, sent_no_max, step=10))  # Set label locations.\n",
        "\n",
        "    plt.ylabel(f'Sentiment Value')\n",
        "    plt.legend(loc='best');\n",
        "  \n",
        "  if save2file == True:\n",
        "    # Save graph to file.\n",
        "    plt.title(f'{BOOK_TITLE_FULL} \\n LOWESS Smoothed Median Sentiment Curve with Crux Points via SciPy.argrelextrema')\n",
        "    plt.legend(loc='best')\n",
        "    plt.savefig('argrelextrema.png')\n",
        "\n",
        "  return crux_coord_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv376c5_bfrg"
      },
      "source": [
        "def crux_sortsents(crux_ls, corpus_df=corpus_sents_df, atop_n=3, get_peaks=True, sort_key='sent_no'):\n",
        "  '''\n",
        "  Given a list of tuples (sent_no, sentiment value), atop_n cruxes to retrieve and bool flag get_peaks\n",
        "  Return a sorted list of peaks/valleys (sentiment_value, sent_no, sent_raw) from greatest down for top_n items\n",
        "  '''\n",
        "  # print(f'Entered crux_sortsents with crux_ls={crux_ls}\\natop_n={atop_n}')\n",
        "\n",
        "  crux_old_ls = []\n",
        "  crux_new_ls = []\n",
        "\n",
        "  # TODO: Error check for null/invalid corpus_df/crus_ls sent_no\n",
        "\n",
        "  if sort_key == 'sent_no':\n",
        "    crux_old_ls = sorted(crux_ls, key=lambda tup: (tup[0]))\n",
        "  else:\n",
        "    crux_old_ls = sorted(crux_ls, key=lambda tup: (tup[1]), reverse=get_peaks)\n",
        "\n",
        "  \"\"\"\n",
        "  if get_peaks == True:\n",
        "    crux_old_ls = [x for x in crux_old_ls if x[1] > 0]\n",
        "  else:\n",
        "    crux_old_ls = [x for x in crux_old_ls if x[1] < 0]\n",
        "  \"\"\";\n",
        "\n",
        "  # Return only the n_top cruxes if more cruxes than n_top else return all cruxes\n",
        "  if (sort_key != 'sent_no') & (len(crux_old_ls) >= atop_n):\n",
        "    # trim crux list if user asked for less than total number\n",
        "    crux_old_ls = crux_old_ls[:atop_n]\n",
        "\n",
        "  # Retrieve the Sentence raw text for each Crux and add as Tuple(sent_no, sentiment_val, raw_text) to return List\n",
        "  for asent_no, asentiment_val in crux_old_ls:\n",
        "    # print(f'  Retrieving Sentence #{asent_no} with Sentiment Value {asentiment_val} from DataFrame {corpus_df}')\n",
        "    asent_int = int(asent_no)\n",
        "    # print(f\"                      asent_int is type: {type(asent_int)} and Sentence Text:\\n\\n     {corpus_df.iloc[asent_int]['sent_raw']}\")\n",
        "\n",
        "    asent_raw = str(corpus_df[corpus_df['sent_no'] == asent_int]['sent_raw'].values[0])\n",
        "    crux_new_ls.append((int(asent_no), float(f'{asentiment_val:.3f}'), str(asent_raw),)) # Append a Tuple to return List\n",
        "\n",
        "  return crux_new_ls\n",
        "\n",
        "# Test\n",
        "# crux_n_top_ls = crux_sortsents(section_crux_ls, atop_n=3, get_peaks=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjb60CVnz5SF"
      },
      "source": [
        "## **crux_sortsents_report**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_7wlJjq2QUo"
      },
      "source": [
        "%whos DataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFDjK1o8gnQ0"
      },
      "source": [
        "def crux_sortsents_report(crux_ls, ts_df=corpus_sents_df, library_type='baseline', top_n=3, get_peaks=True, sort_by='sent_no', n_sideparags=1, sentence_highlight=True):\n",
        "  '''\n",
        "  Wrapper function to produce report based upon 'crux_sortsents() described as:\n",
        "    Given a list of tuples (sent_no, sentiment value), top_n cruxes to retrieve and bool flag get_peaks\n",
        "    Return a sorted list of peaks/valleys (sentiment_value, sent_no, sent_raw) from greatest down for top_n items\n",
        "\n",
        "    # get_sentnocontext_report\n",
        "  '''\n",
        "\n",
        "  if get_peaks == True:\n",
        "    crux_label = 'Peak'\n",
        "  else:\n",
        "    crux_label = 'Valley'\n",
        "\n",
        "  # Filter and keep only the desired crux type in List crux_subset_ls\n",
        "  crux_subset_ls = []\n",
        "  for acrux_tup in crux_ls:\n",
        "    crux_type, crux_x_coord, crux_y_coord = acrux_tup\n",
        "    if crux_type.lower() == crux_label.lower():\n",
        "      crux_subset_ls.append((crux_x_coord,crux_y_coord)) # Append a Tuple to List\n",
        "\n",
        "  flag_2few_cruxes = False\n",
        "\n",
        "  # Check to see if asked for more Cruxes than were found \n",
        "  top_n_found = len(crux_subset_ls)\n",
        "  if top_n_found < top_n:\n",
        "    flag_2few_cruxes = True\n",
        "    print(f'\\n\\nWARNING: You asked for {top_n} {crux_label}s\\n         but there only {top_n_found} were found above.\\n')\n",
        "    print(f'             Displaying as many {crux_label}s as possible,')\n",
        "    print(f'             to retrieve more, go back to the previous code cells and re-run with wider Crux Window.\\n\\n')\n",
        "\n",
        "\n",
        "  # Get Sentence no and raw text for appropriate Crux subset\n",
        "  # print(f'Calling crux_n_top_ls with crux_subset_ls={crux_subset_ls}\\ntop_n={top_n}\\nget_peaks={get_peaks}')\n",
        "  crux_n_top_ls = crux_sortsents(corpus_df = ts_df, crux_ls=crux_subset_ls, atop_n=top_n, get_peaks=get_peaks, sort_key=sort_by)\n",
        "  # print(f'Returning crux_n_top_ls = {crux_n_top_ls}')\n",
        "\n",
        "  # Print appropriate header Select_Section_No sent_no\n",
        "  print('------------------------------')\n",
        "  # print(f'library_type: {library_type}')\n",
        "  if library_type in ['baseline','sentimentr','syuzhetr','transformer','unified']:\n",
        "    if (sort_by != 'sent_no') & (flag_2few_cruxes == False):\n",
        "      print(f'Library: {library_type.capitalize()} ALL Top {top_n} {crux_label}s Found\\n')\n",
        "    else:\n",
        "      print(f'Library #{library_type.capitalize()} ONLY Top {top_n_found} {crux_label}s Found\\n')\n",
        "  else:\n",
        "    if (sort_by != 'sent_no') & (flag_2few_cruxes == False):\n",
        "      print(f'Section #{Select_Section_No} ALL Top {top_n} {crux_label}s Found\\n')\n",
        "    else:\n",
        "      print(f'Section #{Select_Section_No} ONLY Top {top_n_found} {crux_label}s Found\\n')\n",
        "\n",
        "  # Print summary of subset Cruxes\n",
        "  for i,crux_sent_tup in enumerate(crux_n_top_ls):\n",
        "    # crux_type, crux_x_coord, crux_y_coord = crux_sent_tup\n",
        "    crux_x_coord, crux_y_coord, crux_sent_raw = crux_sent_tup\n",
        "    print(f'   {crux_label} #{i} at Sentence #{crux_x_coord} with Sentiment Value {crux_y_coord}')\n",
        "  # print('------------------------------\\n')\n",
        "  # print('Sent_No  Sentiment   Sentence (Raw Text)\\n')\n",
        "  \n",
        "  # Print details of each Crux in subset\n",
        "  for sent_no, sent_pol, sent_raw in crux_n_top_ls: \n",
        "    sent_no = int(sent_no)\n",
        "    print('\\n\\n-------------------------------------------------------------')\n",
        "    print(f'Sentence #{sent_no}   Sentiment: {sent_pol:.3f}\\n') #     {sent_raw}\\n')\n",
        "    # print('------------------------------')\n",
        "    get_sentnocontext_report(ts_df=ts_df, the_sent_no=sent_no, the_n_sideparags=n_sideparags, the_sent_highlight=sentence_highlight)\n",
        "    # get_sentnocontext(sent_no=sent_no, the_n_sideparags=n_sideparags, the_sent_highlight=sentence_highlight)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJw2WDlwHH5y"
      },
      "source": [
        "# For the selected Section, create an expanded Paragraph DataFrame to match the number of Sentences in the Section\n",
        "\n",
        "def expand_parags2sents(parags_df='corpus_parags_df', sents_df='corpus_sents_df', model_name='vader_lnorm_medianiqr'):\n",
        "  '''\n",
        "  Given a Corpus Paragraph DataFrame and a longer Sentence DataFrame that cover the same Section of a Corpus\n",
        "  Return an expanded version of the Paragraph DataFrame of equal length to the Sentence DataFrame so they can be plotted/compared along the same x-axis\n",
        "  '''\n",
        "\n",
        "  parag_sentiment_expanded_ls = []\n",
        "  parags_midpoint_ls = []\n",
        "  sent_sum = 0\n",
        "  parag_start = section_parags_df.parag_no.min()\n",
        "  print(f'parag_start: {parag_start}')\n",
        "  parag_end = section_parags_df.parag_no.max() + 1 # shape[0] + 3\n",
        "  print(f'parag_end: {parag_end}')\n",
        "  parags_range_ls = list(range(parag_start, parag_end, 1))\n",
        "  print(f'parags_range_ls: {parags_range_ls}')\n",
        "  for i, aparag_no in enumerate(parags_range_ls):\n",
        "    aparag_sentiment_fl = float(corpus_parags_df[corpus_parags_df['parag_no']==aparag_no][model_name])\n",
        "    sent_ct = len(corpus_sents_df[corpus_sents_df.parag_no == aparag_no])\n",
        "    parag_midpoint_int = int(sent_ct//2 + sent_sum)\n",
        "    parags_midpoint_ls.append(parag_midpoint_int)\n",
        "    for asent in range(sent_ct):\n",
        "      parag_sentiment_expanded_ls.append(aparag_sentiment_fl)\n",
        "    sent_sum += sent_ct\n",
        "    print(f'#{i}: Paragraph #{aparag_no} has {sent_ct} Sentences and Avg Sentiment: {aparag_sentiment_fl:.3f}')\n",
        "\n",
        "  print(f'\\nSentence Total: {sent_sum} vs Original section_sents_df: {section_sents_df.shape[0]}')\n",
        "  print(f'  Paragraph Sentiment length: {len(parag_sentiment_expanded_ls)}')\n",
        "\n",
        "  # section_sents_parags_df = section_sents_df.copy()\n",
        "  \n",
        "  # section_sents_parags_df.head(1);\n",
        "\n",
        "  # corpus_sents_df['']\n",
        "\n",
        "  return parag_sentiment_expanded_ls, parags_midpoint_ls\n",
        "\n",
        "# Test\n",
        "# section_sents_df['vader_lnorm_medianiqr_parag'] = expand_parags2sents(parags_df='corpus_parags_df', sents_df='corpus_sents_df')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXRq54NQwI7D"
      },
      "source": [
        "def get_crux_points(ts_df, col_series, text_type='sentence', win_per=5, sec_y_labels=True, sec_y_height=0, subtitle_str=' ', do_plot=True, save2file=False):\n",
        "  '''\n",
        "  Given a DataFrame and a Time Series Column within it and a LOWESS window\n",
        "  Return a list of Min/Max Crux Point (x,y) coordinate tuples for that Column Time Series\n",
        "  '''\n",
        "\n",
        "  # print('entered get_crux_points') \n",
        "  crux_ls = []\n",
        "\n",
        "  series_len = ts_df.shape[0]\n",
        "  # print(f'series_len = {series_len}')\n",
        "\n",
        "  sent_no_min = ts_df.sent_no.min()\n",
        "  sent_no_max = ts_df.sent_no.max()\n",
        "  # print(f'sent_no_min {sent_no_min}')\n",
        "\n",
        "  sm_x = ts_df.index.values\n",
        "  sm_y = ts_df[col_series].values.flatten()\n",
        "\n",
        "  half_win = int((win_per/100)*series_len)\n",
        "  # print(f'half_win = {half_win}')\n",
        "  # print(f'sm_y type = {type(sm_y)}')\n",
        "\n",
        "  # Find peaks(max).\n",
        "  # peak_indexes = signal.argrelextrema(sm_y, np.greater, order=half_win, mode='wrap') argrelextrema will not detect flat peaks\n",
        "  peak_indexes = signal.find_peaks(sm_y, distance=half_win) # np.greater, order=half_win, mode='wrap')\n",
        "  # peak_indexes = peak_indexes + sent_no_min\n",
        "  # print(f'peak_indexes[0]: {peak_indexes_np[0]}')\n",
        "  # print(f'peak_indexes type: {type(peak_indexes_np[0])}')\n",
        "  # peak_indexes_np = peak_indexes_np + sent_no_min\n",
        "  # print(f'peak_indexes type = {type(peak_indexes)}') # sent_no_start sent\n",
        "  peak_indexes = peak_indexes[0]\n",
        "\n",
        "  peak_x_ls = list(peak_indexes)\n",
        "  peak_x_adj_ls = [x+sent_no_min for x in peak_x_ls]\n",
        "\n",
        "  peak_y_ls = list(sm_y[peak_indexes])\n",
        "\n",
        "  peak_label_ls = ['peak'] * len(peak_y_ls)\n",
        "  peak_coord_ls = tuple(zip(peak_label_ls, peak_x_adj_ls, peak_y_ls))\n",
        "\n",
        "  # peak_y_all_ls = peak_y_ls + valley_y_ls\n",
        "  # crux_coord_ls = tuple(zip(x_all_ls, y_all_ls)) \n",
        "\n",
        "  # Find valleys(min).\n",
        "  # valley_indexes = signal.argrelextrema(sm_y, np.less, order=half_win, mode='clip')\n",
        "  valley_indexes = signal.find_peaks(-sm_y, distance=half_win)\n",
        "  valley_indexes = valley_indexes[0]\n",
        "  \n",
        "  valley_x_ls = list(valley_indexes)\n",
        "  valley_x_adj_ls = [x+sent_no_min for x in valley_x_ls]\n",
        "\n",
        "  valley_y_ls = list(sm_y[valley_indexes])\n",
        "\n",
        "  valley_label_ls = ['valley'] * len(valley_y_ls)\n",
        "  valley_coord_ls = tuple(zip(valley_label_ls, valley_x_adj_ls, valley_y_ls))\n",
        "\n",
        "  # Combine Peaks and Valley Coordinates into List of Tuples(label, x_coord, y_coord)\n",
        "  crux_coord_ls = peak_coord_ls + valley_coord_ls\n",
        "\n",
        "  # Save all peaks/valleys as list of (x,y) coordinate tuples\n",
        "  # print(f'type peak_x_ls is: {type(peak_x_ls)}')\n",
        "  #  x_all_ls = peak_x_ls + valley_x_ls\n",
        "  # readjust starting Sentence No to start with first sentence in segement window\n",
        "  #  x_all_ls = [x+sent_no_min for x in x_all_ls]\n",
        "  #  y_all_ls = peak_y_ls + valley_y_ls\n",
        "  # crux_coord_ls = tuple(zip(x_all_ls, y_all_ls)) \n",
        "\n",
        "  # print(f'Original Series length={series_len} vs LOWESS Series length={len(x_all_ls)}')\n",
        "\n",
        "\n",
        "  if do_plot == True:\n",
        "    # Plot main graph.\n",
        "    (fig, ax) = plt.subplots()\n",
        "    ax.plot(sm_x, sm_y)\n",
        "\n",
        "    if sec_y_labels == True:\n",
        "      section_sent_no_boundries_ls = list(corpus_sects_df['sent_no_start'])\n",
        "      section_no_ls = list(corpus_sects_df['sect_no'])\n",
        "      for i, asect_no in enumerate(section_sent_no_boundries_ls):\n",
        "        # Plot vertical lines for section boundries\n",
        "        plt.text(asect_no, sec_y_height, f'Section #{section_no_ls[i]}', alpha=0.2, rotation=90)\n",
        "        plt.axvline(asect_no, color='blue', alpha=0.1)    \n",
        "\n",
        "\n",
        "    win_half = 0 # 2500\n",
        "\n",
        "    # Plot peaks.\n",
        "    # ax.plot(peak_x + win_half, peak_y, marker='o', linestyle='none', color='green', label=\"Peaks\")\n",
        "\n",
        "    # readjust starting Sentence No to start with first sentence in segement window\n",
        "    peak_x_ls = [x+sent_no_min for x in peak_x_ls]\n",
        "    ax.scatter(peak_x_ls, peak_y_ls)\n",
        "    for i, txt in enumerate(list(peak_x_ls)):\n",
        "        ax.annotate(f'  Sent #{txt}', (peak_x_ls[i], peak_y_ls[i]), rotation=90, annotation_clip=True)\n",
        "\n",
        "    # Plot valleys.\n",
        "    # ax.plot(valley_x + win_half, valley_y, marker='o', linestyle='none', color='red', label=\"Valleys\")\n",
        "    # readjust starting Sentence No to start with first sentence in segement window\n",
        "    valley_x_ls = [x+sent_no_min for x in valley_x_ls]\n",
        "    ax.scatter(valley_x_ls, valley_y_ls)\n",
        "    for i, txt in enumerate(list(valley_x_ls)):\n",
        "        ax.annotate(f'Sent #{txt}', (valley_x_ls[i], valley_y_ls[i]), rotation=270, annotation_clip=True) # xytext=(valley_x_ls[i], valley_y_ls[i]-4))\n",
        "\n",
        "    # for i, txt in enumerate(list(valley_x_ls)):\n",
        "    #     ax.annotate(f'\\n\\n\\nSent No.\\n   {txt}', (valley_x_ls[i], valley_y_ls[i]))\n",
        "    # plt.plot(x, y, 'bo')\n",
        "    # texts = [plt.text(valley_x_ls[i], valley_y_ls[i], 'Sent No.\\n   %s' %valley_x_ls[i], ha='right', va='top') for i in range(len(valley_x_ls))]\n",
        "    # adjust_text(texts)\n",
        "\n",
        "    # Confidence Interval (Min/Max Range)\n",
        "    # plt.fill_between(sentiment_lowess_df['x_value'], sentiment_lowess_df['min'], sentiment_lowess_df['max'], alpha=.3, color='lightskyblue')\n",
        "\n",
        "    plt.title(f'{CORPUS_FULL} SMA Smoothed Sentence Sentiment Arcs Crux Detection\\n{subtitle_str} Models: {col_series}')\n",
        "    plt.xlabel(f'Sentence No') # within selected Section #{Select_Section_No}')\n",
        "\n",
        "    # locs, labels = xticks()  # Get the current locations and labels.\n",
        "    # plt.xticks(np.arange(sent_no_min, sent_no_max, step=10))  # Set label locations.\n",
        "\n",
        "    plt.ylabel(f'Sentiment Value')\n",
        "    plt.legend(loc='best');\n",
        "  \n",
        "  if save2file == True:\n",
        "    # Save graph to file.\n",
        "    plt.title(f'{BOOK_TITLE_FULL} \\n SMA Smoothed Sentence Sentiment Arcs Crux Points')\n",
        "    # plt.legend(loc='best')\n",
        "    plt.savefig(f\"{CORPUS_FILENAME.split('.')[0]}_find_peaks.png\")\n",
        "\n",
        "  return crux_coord_ls;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNdJQGtghS_X"
      },
      "source": [
        "def get_standardscaler(series_name, values_ser):\n",
        "  '''\n",
        "  Given a Series of values\n",
        "  Return a list of StandardSclar transformations on that input Series\n",
        "  '''\n",
        "\n",
        "  scaler = StandardScaler()  \n",
        "\n",
        "  # Convert to np.array\n",
        "  values_np = np.array(values_ser)\n",
        "  \n",
        "  values_flat_np = values_np.reshape((len(values_np), 1))\n",
        "\n",
        "  scaler = scaler.fit(values_flat_np)\n",
        "  print(f'Model: {series_name}\\n       Mean: {scaler.mean_}, StandardDeviation: {np.sqrt(scaler.var_)}') # % (scaler.mean_, np.sqrt(scaler.var_)))\n",
        "  values_flat_xform_np = scaler.transform(values_flat_np)\n",
        "\n",
        "  return values_flat_xform_np.flatten().tolist()\n",
        "\n",
        "# Test\n",
        "# stdscaler_series_ls = get_standardscaler('vader_lnorm_medianiqr_roll100', corpus_sents_df['vader_lnorm_medianiqr_roll100'])\n",
        "# corpus_sents_df['vader_roll100_stdscaler'] = pd.Series(stdscaler_series_ls)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABW4oQ4xJT4R"
      },
      "source": [
        "def plot_models(models_subset_ls, models_type='baseline', text_unit='sent_no', win_per=10):\n",
        "  '''\n",
        "  Given a DataFrame and list of correponding Models in that DataFrame\n",
        "  Plot the Sentiment Arcs for the stdscaler with the rolling window \n",
        "  '''\n",
        "\n",
        "  Mean_All_Arc = True\n",
        "\n",
        "  if models_type == 'baseline':\n",
        "    models_ls = models_baseline_ls\n",
        "  elif models_type == 'sentimentr':\n",
        "    models_ls = models_sentimentr_ls\n",
        "  elif models_type == 'syuzhetr':\n",
        "    models_ls = models_syuzhetr_ls\n",
        "  elif models_type == 'transformer':\n",
        "    models_ls = models_transformer_ls\n",
        "  else:\n",
        "    print(f'ERROR: model_type={model_type} must be one of: baseline, sentimentr, syuzhetr or transformer')\n",
        "\n",
        "\n",
        "  if (models_type == 'baseline') | (models_type == 'transformers'):\n",
        "    # Have Corpus data in 4 DataFrames: corpus_[sents|parags|sects|chaps]_df\n",
        "    if text_unit == 'sent_no':\n",
        "      ts_df = corpus_sents_df\n",
        "      text_raw = 'sent_raw'\n",
        "      text_type = 'Sentence'\n",
        "      win_roll = int(corpus_sents_df.shape[0]* win_per/100)\n",
        "    elif text_unit == 'parag_no':\n",
        "      ts_df = corpus_parags_df\n",
        "      text_raw = 'parag_raw'\n",
        "      text_type = 'Paragraph'\n",
        "      win_roll = int(corpus_parags_df.shape[0]* win_per/100)\n",
        "    elif text_unit == 'sect_no':\n",
        "      ts_df = corpus_sects_df\n",
        "      text_raw = 'sect_raw'\n",
        "      text_type = 'Section'\n",
        "      win_roll = int(corpus_sects_df.shape[0]* win_per/100)\n",
        "    elif text_unit == 'chap_no':\n",
        "      ts_df = corpus_chaps_df\n",
        "      text_raw = 'chap_raw'\n",
        "      text_type = 'Chapter'\n",
        "      win_roll = int(corpus_chaps_df.shape[0]* win_per/100)\n",
        "    else:\n",
        "      print(f'ERROR: text_unit={text_unit} must be one of: sent_no, parag_no, sect_no or chap_no')\n",
        "\n",
        "  elif (models_type == 'sentimentr') | (models_type == 'syuzhetr'):\n",
        "\n",
        "    # Only have Corpus Sentence data in one DataFrame: corpus_sentimentr_df or corpus_syuzhetr_df\n",
        "    text_raw = 'sent_raw'\n",
        "    text_type = 'Sentence'\n",
        "\n",
        "    if models_type == 'sentimentr':\n",
        "      ts_df = corpus_sentimentr_df\n",
        "      win_roll = int(corpus_sentimentr_df.shape[0]*win_per/100)\n",
        "    else:\n",
        "      ts_df = corpus_syuzhetr_df\n",
        "      win_roll = int(corpus_syuzhetr_df.shape[0]*win_per/100)\n",
        "\n",
        "  else:\n",
        "    print(f'ERROR: model_type = {model_type} but must be one of 4: [baseline|transformer|sentimentr|syuzhet]')\n",
        "\n",
        "\n",
        "  # Get Rolling Window String\n",
        "  if len(str(win_per)) == 1:\n",
        "    roll_str = 'roll' + '0' + str(win_per)\n",
        "  else:\n",
        "    roll_str = 'roll' + str(win_per%100)\n",
        "\n",
        "\n",
        "  # Translate base model name into _stdscaler_rollxxx derivative\n",
        "  all_stdscaler_roll_ls = []\n",
        "  subset_stdscaler_roll_ls = []\n",
        "  for amodel in models_ls:\n",
        "    # Create a Rolling SMA Series from the stdscaler version of model sentiment values\n",
        "    amodel_stdscaler = f'{amodel}_stdscaler'\n",
        "    col_stdscaler_rollwin = f'{amodel}_stdscaler_{roll_str}'\n",
        "    ts_df[col_stdscaler_rollwin] = ts_df[amodel_stdscaler].rolling(win_roll, center=True).mean()\n",
        "    all_stdscaler_roll_ls.append(col_stdscaler_rollwin)\n",
        "    if amodel in models_subset_ls:\n",
        "      subset_stdscaler_roll_ls.append(col_stdscaler_rollwin)\n",
        "    # col_name_roll = f'{amodel}_lnorm_medianiqr_{roll_str}'\n",
        "\n",
        "  # Compute the Mean of All\n",
        "  mean_all_col = 'mean_stdscaler_' + roll_str\n",
        "  col_stdscaler_roll_ls = [f'{x}_stdscaler_{roll_str}' for x in models_ls] #  if ('mean' not in x)]\n",
        "  # print(f'Computing Mean based upon:\\n    {col_stdscaler_roll_ls}')\n",
        "  ts_df[mean_all_col] = ts_df[all_stdscaler_roll_ls].mean(axis=1)\n",
        "\n",
        "\n",
        "  palette = cycle(px.colors.qualitative.Safe)\n",
        "  # palette = cycle(px.colors.sequential.PuBu)\n",
        "\n",
        "  my_layout = go.Layout(\n",
        "      autosize=False,\n",
        "      width=1600,\n",
        "      height=800,\n",
        "      margin=go.layout.Margin(\n",
        "          l=10,\n",
        "          r=50,\n",
        "          b=100,\n",
        "          t=100,\n",
        "          pad = 1\n",
        "      )\n",
        "  )\n",
        "\n",
        "\n",
        "  fig = go.Figure(layout=my_layout)\n",
        "\n",
        "  # add traces\n",
        "  for i,amodel_stdscaler_roll in enumerate(subset_stdscaler_roll_ls):\n",
        "    # print(f'adding trace: {amodel_stdscaler_roll}')\n",
        "    fig.add_traces(go.Line(x = ts_df[text_unit],\n",
        "                          y = ts_df[amodel_stdscaler_roll],\n",
        "                          text = ts_df[text_raw],\n",
        "                          name = amodel_stdscaler_roll,\n",
        "                          hovertemplate = \"Model: <b>\"+amodel_stdscaler_roll+\"</b><br>\"+text_type+\" #<b>%{x}</b><br>Polarity <b>%{y}</b><br>Text: <b><i>%{text}</i></b>\", \n",
        "                          marker_color=next(palette)))\n",
        "  \"\"\"\n",
        "  if Mean_Subset_Arc == True:\n",
        "    mean_subset_col = 'mean_subset_'+roll_str\n",
        "    corpus_sents_df[mean_subset_col] = corpus_sents_df[model_baseline_subset_ls].mean(axis=1)\n",
        "    fig.add_traces(go.Line(x=corpus_sents_df['sent_no'],\n",
        "                          y = corpus_sents_df[mean_subset_col],\n",
        "                          line=dict(\n",
        "                                # color='#000000',\n",
        "                                width=5\n",
        "                                ),\n",
        "                          text = 'NA', # corpus_sents_df['sent_raw'],\n",
        "                          name = 'Mean of Selected Models',\n",
        "                          hovertemplate = \"Model <b>%{mean_subset_col}</b><br>Sentence #<b>%{x}</b><br>Polarity <b>%{y}</b>\", \n",
        "                          marker_color=next(palette)))\n",
        "\n",
        "  \"\"\";\n",
        "\n",
        "  if Mean_All_Arc == True:\n",
        "    # mean_all_col = 'mean_all_stdscaler_'+roll_str\n",
        "    # ts_df[mean_all_col] = ts_df[col_stdscaler_rollwin_ls].mean(axis=1)\n",
        "    fig.add_traces(go.Line(x=ts_df[text_unit],\n",
        "                          y = ts_df[mean_all_col],\n",
        "                          line=dict(\n",
        "                                color='#000000',\n",
        "                                width=5,\n",
        "                                dash='dot',\n",
        "                                ),\n",
        "                          text = 'NA', # ts_df['sent_raw'],\n",
        "                          name = 'Mean of All Models',\n",
        "                          hovertemplate = \"Model <b>%{mean_all_col}</b><br>Paragraph #<b>%{x}</b><br>Polarity <b>%{y}</b>\", \n",
        "                          marker_color=next(palette)))\n",
        "\n",
        "\n",
        "  fig.update_layout(\n",
        "      title=f\"{CORPUS_FULL}\\n{text_type} {models_type.capitalize()} Models<b><i> \" + roll_str.upper() + \"</i></b>\",\n",
        "      xaxis_title=text_type + \" Number\",\n",
        "      yaxis_title=\"StdScaler Sentiment Value\",\n",
        "      hoverlabel=dict(\n",
        "          bgcolor=\"white\",\n",
        "          font_size=16,\n",
        "          font_family=\"Rockwell\"\n",
        "      ),\n",
        "      font=dict(\n",
        "          family=\"Courier New, monospace\",\n",
        "          size=18,\n",
        "          color=\"RebeccaPurple\"\n",
        "      )\n",
        "  )\n",
        "\n",
        "  fig.show();\n",
        "\n",
        "# Test\n",
        "\n",
        "# plot_models(models_subset_ls = ['vader','stanza'], models_type='baseline', text_unit='sent_no', win_per=10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4ehet9JjOsK"
      },
      "source": [
        "def standardize_ts_ls(ts_df, col_ls):\n",
        "  '''\n",
        "  Given a DataFrame and list of Columns in that DataFrame\n",
        "  Create 4 new Standardized Columns for each given Columns\n",
        "  '''\n",
        "\n",
        "  # Create 4 new column names for each column provided\n",
        "  for amodel in col_ls:\n",
        "    # col_meanstd = f'{amodel}_meanstd'\n",
        "    col_medianiqr = f'{amodel}_medianiqr'\n",
        "    col_stdscaler = f'{amodel}_stdscaler'\n",
        "    col_lnorm_stdscaler = f'{amodel}_lnorm_stdscaler'\n",
        "    col_lnorm_medianiqr = f'{amodel}_lnorm_medianiqr'\n",
        "\n",
        "    # Standardize each column provided using Standard Scaler and  MedianIQRScaling\n",
        "    ts_df[col_stdscaler]  = list2stdscaler(ts_df[amodel])\n",
        "    ts_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(ts_df[amodel]).reshape(-1, 1))\n",
        "    # Normalize the Sentence Sentiment by dividing by Chapter Length\n",
        "    text_len_ls = list(ts_df['token_len'])\n",
        "    text_sentiment_ls = list(ts_df[amodel])\n",
        "    text_sentiment_norm_ls = [text_sentiment_ls[i]/(text_len_ls[i]+0.01) for i in range(len(text_len_ls))]\n",
        "    # RobustStandardize Sentence sentiment values\n",
        "    ts_df[col_lnorm_stdscaler]  = mean_std_scaler.fit_transform(np.array(pd.Series(text_sentiment_norm_ls)).reshape(-1, 1))\n",
        "    ts_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(text_sentiment_norm_ls)).reshape(-1, 1))\n",
        "\n",
        "  return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daEzvNu6huM-"
      },
      "source": [
        "# **Either (a) Load Precomputed DataFrames or (b) Create Corpus DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnWJCkqDhA5L"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "len(sections_ls)\n",
        "min(sections_ls, key=len) \n",
        "\n",
        "# TODO: Spell check and correct common OCR errors\n",
        "\n",
        "# SymSpellPy\n",
        "# JamSpell\n",
        "# OCR - https://github.com/Alvant/MIL-OCR\n",
        "\n",
        "# !pip install -U symspellpy\n",
        "\n",
        "# Did not need these\n",
        "# dictionary_path = pkg_resources.resource_filename(\"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
        "# bigram_path = pkg_resources.resource_filename(\"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\")\n",
        "\n",
        "\n",
        "import pkg_resources\n",
        "from symspellpy import SymSpell, Verbosity\n",
        "\n",
        "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
        "dictionary_path = pkg_resources.resource_filename(\n",
        "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
        "# term_index is the column of the term and count_index is the\n",
        "# column of the term frequency\n",
        "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
        "\n",
        "# lookup suggestions for single-word input strings\n",
        "input_term = \"memebers\"  # misspelling of \"members\"\n",
        "input_term = \"summermorning\"\n",
        "# max edit distance per lookup\n",
        "# (max_edit_distance_lookup <= max_dictionary_edit_distance)\n",
        "suggestions = sym_spell.lookup(input_term, Verbosity.CLOSEST,\n",
        "                               max_edit_distance=2)\n",
        "# display suggestion term, term frequency, and edit distance\n",
        "for suggestion in suggestions:\n",
        "    print(suggestion)\n",
        "\n",
        "\n",
        "\n",
        "import pkg_resources\n",
        "from symspellpy.symspellpy import SymSpell\n",
        "\n",
        "# Set max_dictionary_edit_distance to avoid spelling correction\n",
        "sym_spell = SymSpell(max_dictionary_edit_distance=0, prefix_length=7)\n",
        "dictionary_path = pkg_resources.resource_filename(\n",
        "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
        "# term_index is the column of the term and count_index is the\n",
        "# column of the term frequency\n",
        "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
        "\n",
        "# a sentence without any spaces\n",
        "input_term = \"thequickbrownfoxjumpsoverthelazydog\"\n",
        "input_term = \"summermorning\"\n",
        "result = sym_spell.word_segmentation(input_term)\n",
        "print(\"{}, {}, {}\".format(result.corrected_string, result.distance_sum,\n",
        "                          result.log_prob_sum))\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI5Tg1bFiERD"
      },
      "source": [
        "### **(a) Load Corpus DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg4NGPlCGffp"
      },
      "source": [
        "!ls -altr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL_i7AkGGjHB"
      },
      "source": [
        "title_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxCBdYNTiDrC"
      },
      "source": [
        "# Read Preprocessed Corpus Sentences DataFrame\n",
        "\n",
        "# author_str = ''.join(CORPUS_AUTHOR.split()).lower()\n",
        "# title_str = ''.join(CORPUS_TITLE.split()).lower()\n",
        "title_str = ''.join(CORPUS_FILENAME.split('.')[0]).lower()\n",
        "datetime_now = datetime.utcnow().strftime(\"%Y%m%d_%H%M\")\n",
        "\n",
        "# Sentence DataFrame\n",
        "corpus_sents_filename = f'corpus_sents_baseline_{title_str}.csv'\n",
        "print(f'Reading from file: {corpus_sents_filename}')\n",
        "corpus_sents_df = pd.read_csv(corpus_sents_filename)\n",
        "\n",
        "# Paragraph DataFrame\n",
        "corpus_parags_filename = f'corpus_parags_baseline_{title_str}.csv'\n",
        "print(f'Reading from file: {corpus_parags_filename}')\n",
        "corpus_parags_df = pd.read_csv(corpus_parags_filename)\n",
        "\n",
        "# Section DataFrame\n",
        "corpus_sects_filename = f'corpus_sects_baseline_{title_str}.csv'\n",
        "print(f'Reading from file: {corpus_sects_filename}')\n",
        "corpus_sects_df = pd.read_csv(corpus_sects_filename)\n",
        "\n",
        "# Chapter DataFrame\n",
        "corpus_chaps_filename = f'corpus_chaps_baseline_{title_str}.csv'\n",
        "print(f'Reading from file: {corpus_chaps_filename}')\n",
        "corpus_chaps_df = pd.read_csv(corpus_chaps_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqsUHiF9K_5L"
      },
      "source": [
        "# Verify Sentences\n",
        "\n",
        "corpus_sents_df.head(2)\n",
        "corpus_sents_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3fD5CpfKJnw"
      },
      "source": [
        "# corpus_sents_df = corpus_sents_df.loc[:, ~corpus_sents_df.columns.str.contains('^Unnamed')]\n",
        "\n",
        "corpus_sents_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "corpus_sents_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl3hwS0wLEeR"
      },
      "source": [
        "# Verify Paragraphs\n",
        "\n",
        "corpus_parags_df.head(2)\n",
        "corpus_parags_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzP_CrO3J0gd"
      },
      "source": [
        "# corpus_parags_df = corpus_parags_df.loc[:, ~corpus_parags_df.columns.str.contains('^Unnamed')]\n",
        "\n",
        "corpus_parags_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "corpus_parags_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZR54xIPJvm-"
      },
      "source": [
        "# Verify Sections\n",
        "\n",
        "# corpus_sects_df.head(2)\n",
        "corpus_sects_df.info(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmlXbKnbL1N7"
      },
      "source": [
        "corpus_sects_df.rename(columns={'Unnamed: 0':'sect_no','chap_raw':'sect_raw','chap_clean':'sect_clean'}, inplace=True)\n",
        "# corpus_sects_df = corpus_sects_df.loc[:, ~corpus_sects_df.columns.str.contains('^Unnamed')]\n",
        "# corpus_sects_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "corpus_sects_df = corpus_sects_df.loc[:, ~corpus_sects_df.columns.duplicated()]\n",
        "# corpus_sects_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "\n",
        "corpus_sects_df.info () # [: corpus_sects_df.columns.like('_no')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb2DYmbqMEF-"
      },
      "source": [
        "# Verfiy Chapters\n",
        "\n",
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmfsseAz2F8T"
      },
      "source": [
        "# corpus_chaps_df = corpus_chaps_df.loc[:, ~corpus_chaps_df.columns.str.contains('^Unnamed')]\n",
        "\n",
        "corpus_chaps_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9X5gfDoi_d0"
      },
      "source": [
        "# Verify all 4 semantic unit DataFrame shapes\n",
        "\n",
        "print(f'corpus_sents_df.shape: {corpus_sents_df.shape}')\n",
        "print(f'corpus_parags_df.shape: {corpus_parags_df.shape}')\n",
        "print(f'corpus_sects_df.shape: {corpus_sects_df.shape}')\n",
        "print(f'corpus_chaps_df.shape: {corpus_chaps_df.shape}')\n",
        "\n",
        "\"\"\"\n",
        "SButler Odyssey\n",
        "\n",
        "corpus_sents_df.shape: (2445, 8)\n",
        "corpus_parags_df.shape: (1051, 8)\n",
        "corpus_sects_df.shape: (24, 8)\n",
        "corpus_chaps_df.shape: (24, 8)\n",
        "\"\"\";\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZizvsnBrhAvh"
      },
      "source": [
        "corpus_sents_df.iloc[1618]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQYjye-v9XMY"
      },
      "source": [
        "### **(b) Create Corpus DataFrames**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6qZH_qAVPQD"
      },
      "source": [
        "#### **Try to Automatically Detected File/Text Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtWVf1cJUeSW"
      },
      "source": [
        "!pwd\n",
        "!ls -altr *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW3HwuvBv1un"
      },
      "source": [
        "# files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4TH13cFUErD"
      },
      "source": [
        "# Try to automatically discover Corpus text Encoding scheme (default to 'utf-8', but often 'iso-8859-1', 'windows-1252', 'cp1252', or 'ascii')\n",
        "\n",
        "CORPUS_ENCODING = 'utf-8' # Python3 default encoding\n",
        "\n",
        "corpus_str, corpus_encode, encoding_confidence = get_file_encoding(CORPUS_FILENAME)\n",
        "CORPUS_ENCODING = str(corpus_encode).lower()\n",
        "\n",
        "if encoding_confidence > 0.8:\n",
        "  print(f'Setting file/text encoding to {CORPUS_ENCODING}\\n')\n",
        "  print(f\"    {encoding_confidence*100:.2f}% confidence Encoding = '{CORPUS_ENCODING}' for '{CORPUS_FILENAME}'\")\n",
        "else:\n",
        "  print(f\"WARNING: Less than 80% confidence estimating Encoding scheme for '{CORPUS_FILENAME}'\\n\")\n",
        "  print(f\"         Only {encoding_confidence*100:.2f}% confidence Encoding = '{CORPUS_ENCODING}'\")\n",
        "  print(f\"         Manually verify corpus file '{CORPUS_FILENAME}' encoding, set as GLOBAL_CONSTATANT and rerun\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMkihxoY6T6U"
      },
      "source": [
        "#### **Create Chapter and Section DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaAZSbN8t537"
      },
      "source": [
        "corpus_filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ydj8ITnTE1D"
      },
      "source": [
        "!head -n 10 $corpus_filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qULnmeVG0Le"
      },
      "source": [
        "corpus_chaps_filtered_ls, corpus_chaps_clean_ls, corpus_sects_filtered_ls, corpus_sects_clean_ls, sect_chapno_ls, corpus_raw_str = corpus2chapsect(corpus_filename, corpus_type='file')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz0uqmK8G1lj"
      },
      "source": [
        "print(f'Corpus Filtered:\\n    {corpus_chaps_filtered_ls[0][:500]}')\n",
        "print('\\n')\n",
        "print(f'Corpus Cleaned:\\n    {corpus_chaps_clean_ls[0][:500]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUQ5-o3HbrMq"
      },
      "source": [
        "# Parse out raw/clean Chapters/Sections from Corpus text file\n",
        "\n",
        "corpus_chaps_filtered_ls, corpus_chaps_clean_ls, corpus_sects_filtered_ls, corpus_sects_clean_ls, sect_chapno_ls, corpus_raw_str = corpus2chapsect(corpus_filename, corpus_type='file')\n",
        "\n",
        "# Remove problematic leading ROMAN numerials if they exist\n",
        "corpus_chaps_filtered_ls = [del_leadroman(x) for x in corpus_chaps_filtered_ls]\n",
        "corpus_chaps_clean_ls =  [del_leadroman(x) for x in corpus_chaps_clean_ls]\n",
        "corpus_sects_filtered_ls = [del_leadroman(x) for x in corpus_sects_filtered_ls]\n",
        "corpus_sects_clean_ls = [del_leadroman(x) for x in corpus_sects_clean_ls]\n",
        "\n",
        "corpus_raw_str = del_leadroman(corpus_raw_str)\n",
        "\n",
        "len(corpus_chaps_filtered_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhTAWxFUrg6V"
      },
      "source": [
        "corpus_chaps_filtered_ls[0][:500]\n",
        "print('\\n')\n",
        "corpus_chaps_clean_ls[0][:500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilQv-883wl6_"
      },
      "source": [
        "# Test\n",
        "\n",
        "# test_ls = [x for x in corpus_chaps_filtered_ls if 'I have no' in x]\n",
        "# test_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jcx-zqsXSKSE"
      },
      "source": [
        "# Verify Chapter/Section count and sample\n",
        "\n",
        "if type(corpus_chaps_filtered_ls[0]) is not str:\n",
        "\n",
        "  print(f'\\nERROR: Could not parse Corpus file into Chapters and Sections correctly\\n       Edit Corpus file and re-run')\n",
        "\n",
        "else:\n",
        "\n",
        "  print(f'\\n{len(corpus_chaps_filtered_ls)} Chapters found in this Corpus')\n",
        "\n",
        "  print(f'\\n{len(corpus_sects_filtered_ls)} Sections found in this Corpus')\n",
        "\n",
        "\n",
        "  print(f'\\n\\n----------{len(corpus_chaps_filtered_ls)} CHAPTERS ----------')\n",
        "  chap_sample_no = 0\n",
        "  print(f'First 500 character sample from Chapter #{chap_sample_no}\\n\\n     {corpus_chaps_filtered_ls[chap_sample_no][:500]}')\n",
        "\n",
        "  print(f'\\n\\n----------{len(corpus_sects_filtered_ls)} SECTIONS ----------')\n",
        "  sect_sample_no = 0\n",
        "  print(f'First 500 character sample from Section #{sect_sample_no}\\n\\n    {corpus_sects_filtered_ls[sect_sample_no][:500]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roEQ9qkWbLew"
      },
      "source": [
        "!lsb_release -a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyY6gwR4Goy6"
      },
      "source": [
        "# Verify shortest Chapter\n",
        "\n",
        "min(corpus_chaps_filtered_ls, key=len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPgOUT6-Urs2"
      },
      "source": [
        "len(corpus_chaps_filtered_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhKXKE-vTzSD"
      },
      "source": [
        "# BUGFIX: Second Pass CHAPTER split on Chapter text segments\n",
        "#         Fix Chapters thats re.split() couldn't split apart with manual second pass\n",
        "#\n",
        "#  re.split does not work for 4 of 55 Chapters\n",
        "#     on Henry James, Portrait of a Lady, Cannot re.split(rf'{pattern_chap}',..)\n",
        "#     CHAPTER [V|X|XVIII|L]\n",
        "#  Attempts: cut-paste identical working CHAPTER text, encoding/ignore, RegEx minimization, etc\n",
        "# \n",
        "#  Colab Pro: No GPU/TPU, High-RAM\n",
        "#     Python: 3.7.11\n",
        "#    Unbuntu: 18.04.5 LTS (bionic) (!lsb_release -a)\n",
        "#\n",
        "# WORKAROUND: Have to use <string>.split('CHAPTER ') method and clean up variable parts after CHAPTER (e.g. V, X, XVIII, L)\n",
        "\n",
        "\n",
        "corpus_chaps_exp_ls = []\n",
        "for i, achap in enumerate(corpus_chaps_filtered_ls):\n",
        "  print(f'Chapter #{i}: Length: {len(achap)}\\n\\n')\n",
        "  if len(achap) > 50:\n",
        "    print(f'     {achap[:50]}\\n\\n')\n",
        "  if 'CHAPTER' in achap:\n",
        "    print(f'\\n\\n\\n============================\\n')\n",
        "    print(f'      FOUND: Chapter with remaining/embedded CHAPTER Heading\\n')\n",
        "\n",
        "    temp_chap_ls = achap.split('CHAPTER ')\n",
        "    print(f'      string.split(CHAPTER)')\n",
        "\n",
        "    # temp_chap_ls = re.split(r'^CHAPTER ', achap) #  [IVXL]{1,10}[\\s]*', achap)\n",
        "    # print(f'    RegEx = {pattern_chap}')\n",
        "\n",
        "    # temp_chap_ls = re.split(rf'{pattern_chap}', achap)\n",
        "    # print(f'    RegEx = [^CHAPTER [IVXL]{1,10}[\\s]*]')\n",
        "\n",
        "    print(f'      Split into {len(temp_chap_ls)}')\n",
        "    print('\\n=============================\\n\\n\\n')\n",
        "    # temp_chap_ls = [re.sub(r'[IVLX]{1,10}[\\s]{1,}','',x) for x in temp_chap_ls]\n",
        "    # temp_chap_ls = [re.sub(r'CHAPTER ','',x) for x in temp_chap_ls]\n",
        "    temp_chap_ls = [re.sub(rf'{pattern_chap}','',x) for x in temp_chap_ls]\n",
        "    temp_chap_ls = [x.strip() for x in temp_chap_ls]\n",
        "    temp_chap_ls = [del_leadroman(x).strip() for x in temp_chap_ls] \n",
        "    corpus_chaps_exp_ls.extend(temp_chap_ls)\n",
        "  else:\n",
        "    corpus_chaps_exp_ls.append(achap)\n",
        "\n",
        "  corpus_chaps_exp_ls = [x for x in corpus_chaps_exp_ls if len(x) > MIN_CHAP_LEN]\n",
        "\n",
        "print(f'         Old Chapter List had {len(corpus_chaps_filtered_ls)} Chapters')\n",
        "print(f'New Expanded Chapter List has {len(corpus_chaps_exp_ls)} Chapters')\n",
        "\n",
        "# Copy expanded Chapter structure to base/reference list\n",
        "corpus_chaps_filtered_ls = corpus_chaps_exp_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw_-X2MftagF"
      },
      "source": [
        "pattern_chap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEtHYm_Ytksg"
      },
      "source": [
        "corpus_chaps_exp_ls[0][:50]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKn3hT_axHdA"
      },
      "source": [
        "# Test\n",
        "\n",
        "# test_ls = [x for x in corpus_chaps_filtered_ls if 'I have no' in x]\n",
        "# test_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG9tnKz_dEVI"
      },
      "source": [
        "corpus_chaps_exp_ls[0][:500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pwfl-0axB1X"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "# Parse out raw/clean Chapters/Sections from Corpus text file\n",
        "\n",
        "corpus_chaps_filtered_ls, corpus_chaps_clean_ls, corpus_sects_filtered_ls, corpus_sects_clean_ls, sect_chapno_ls, corpus_raw_str = corpus2chapsect(corpus_filename)\n",
        "\n",
        "# Verify Paragraph count and sample\n",
        "\n",
        "if type(corpus_chaps_raw_ls[0]) is not str:\n",
        "\n",
        "  print(f'\\nERROR: Could not parse Corpus file into Chapters and Sections correctly\\n       Edit Corpus file and re-run')\n",
        "\n",
        "else:\n",
        "\n",
        "  print(f'\\n{len(corpus_chaps_raw_ls)} Chapters found in this Corpus')\n",
        "\n",
        "  print(f'\\n{len(corpus_sects_raw_ls)} Sections found in this Corpus')\n",
        "\n",
        "\n",
        "  print(f'\\n\\n----------{len(corpus_chaps_filtered_ls)} CHAPTERS ----------')\n",
        "  chap_sample_no = 0\n",
        "  print(f'First 500 character sample from Chapter #{chap_sample_no}\\n\\n     {corpus_chaps_filtered_ls[chap_sample_no][:500]}')\n",
        "\n",
        "  print(f'\\n\\n----------{len(corpus_sects_filtered_ls)} SECTIONS ----------')\n",
        "  sect_sample_no = 0\n",
        "  print(f'First 500 character sample from Section #{sect_sample_no}\\n\\n    {corpus_sects_filtered_ls[sect_sample_no][:500]}')\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19iueVUIg4Sh"
      },
      "source": [
        "# Check for extraneous CHAPTER or SECTION headers in either Chapter or Section lists\n",
        "\n",
        "print(f'\\n\\nChecking {len(corpus_chaps_filtered_ls)} Chapters for extraneous CHAPTER and SECTION headers')\n",
        "\n",
        "chaps_wchapheads_ls = [x for x in corpus_chaps_filtered_ls if 'CHAPTER ' in x]\n",
        "print(f'{len(chaps_wchapheads_ls)} Sections may still have a CHAPTER heading')\n",
        "\n",
        "chaps_wsectheads_ls = [x for x in corpus_chaps_filtered_ls if 'SECTION ' in x]\n",
        "print(f'{len(chaps_wsectheads_ls)} Sections may still have a SECTION heading')\n",
        "\n",
        "\n",
        "print(f'\\n\\n Checking {len(corpus_sects_filtered_ls)} Sections for extraneous CHAPTER and SECTION headers')\n",
        "\n",
        "sects_wchapheads_ls = [x for x in corpus_sects_filtered_ls if 'CHAPTER ' in x]\n",
        "print(f'{len(sects_wchapheads_ls)} Sections may still have a CHAPTER heading')\n",
        "\n",
        "sects_wsectheads_ls = [x for x in corpus_sects_filtered_ls if 'SECTION ' in x]\n",
        "print(f'{len(sects_wsectheads_ls)} Sections may still have a SECTION heading')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p7xiakRvHgq"
      },
      "source": [
        "# Verify Chapters and manually delete extraneous CHAPTER or SECTION Headers\n",
        "\n",
        "# TODO: Need to check for all 4 combinations of Chapter/Section existing/missing in Corpus\n",
        "\n",
        "corpus_chap_ct = len(corpus_chaps_filtered_ls)\n",
        "corpus_chaps_clean_ls = []\n",
        "\n",
        "# corpus_chaps_filtered_ls[0]\n",
        "\n",
        "if corpus_chap_ct > 1:\n",
        "  \n",
        "  # Remove the extraneous Chapter by Hand if necessary\n",
        "  corpus_chaps_filtered_ls = [x for x in corpus_chaps_filtered_ls if len(x.strip()) > MIN_CHAP_LEN]\n",
        "\n",
        "  # Clean the text\n",
        "  corpus_chaps_clean_ls = [clean_text(x) for x in corpus_chaps_filtered_ls]\n",
        "\n",
        "else:\n",
        "\n",
        "  print(f'WARNING: Corpus contains no CHAPTER structure')\n",
        "\n",
        "  if len(corpus_sects_filtered_ls) > 1:\n",
        "    # If Sections exists, copy Section structure to Chapter structure\n",
        "    print('         Copying SECTION structure to CHAPTER\\n\\n')\n",
        "    corpus_chaps_filtered_ls = corpus_sects_filtered_ls\n",
        "    corpus_chaps_clean_ls = corpus_sects_clean_ls\n",
        "    chapno_ls = list(range(len(corpus_chaps_filtered_ls)))\n",
        "\n",
        "  else:\n",
        "    # No Chapter nor Section structure, just plain text in Corpus without any headings\n",
        "    print('         No CHAPTER nor SECTION structure in this Corpus\\n\\n')\n",
        "    chapno_ls = [1]\n",
        "\n",
        "\n",
        "if len(corpus_chaps_filtered_ls) > 1:\n",
        "\n",
        "  # Verify\n",
        "  print(f'First Section of {len(corpus_chaps_filtered_ls)}:\\n\\n  Beginning: {corpus_chaps_filtered_ls[0][:50]}\\n\\n  Ending: {corpus_chaps_filtered_ls[0][-50:]}\\n\\n')\n",
        "\n",
        "  print('----------')\n",
        "\n",
        "  print(f'{corpus_chap_ct} Chapters found in this Corpus:\\n\\n')\n",
        "\n",
        "  print(f'First Section of {len(corpus_chaps_filtered_ls)}:\\n\\n  Beginning: {corpus_chaps_filtered_ls[0][:50]}\\n\\n  Ending: {corpus_chaps_filtered_ls[0][-50:]}\\n\\n')\n",
        "\n",
        "  print(f'Second Section of {len(corpus_chaps_filtered_ls)}:\\n\\n  Beginning: {corpus_chaps_filtered_ls[1][:50]}\\n\\n  Ending: {corpus_chaps_filtered_ls[1][-50:]}\\n\\n')\n",
        "\n",
        "  print(f'Second Last Section of {len(corpus_chaps_filtered_ls)}:\\n\\n  Beginning: {corpus_chaps_filtered_ls[-2][:50]}\\n\\n  Ending: {corpus_chaps_filtered_ls[-2][-50:]}\\n\\n')\n",
        "\n",
        "  print(f'Last Section of {len(corpus_chaps_filtered_ls)}:\\n\\n  Beginning: {corpus_chaps_filtered_ls[-1][:50]}\\n\\n  Ending: {corpus_chaps_filtered_ls[-1][-50:]}\\n\\n')\n",
        "\n",
        "  print('----------')\n",
        "\n",
        "else:\n",
        "\n",
        "  print('\\n\\nCorpus has no CHAPTER nor SECTION headers:')\n",
        "  print('  handle as one block to text above Paragraph/Sentence structural level')\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "import re\n",
        "\n",
        "mylist = [\"dog\", \"cat\", \"wildcat\", \"thundercat\", \"cow\", \"hooo\"]\n",
        "r = re.compile(\"CHAPTER [IVXL]{1,10}\")\n",
        "newlist = list(filter(r.match, mylist)) # Read Note below\n",
        "# print(newlist)\n",
        "\"\"\";\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LScTOSIVRE95"
      },
      "source": [
        "# Verify Sections and manually delete extraneous CHAPTER or SECTION Headers\n",
        "\n",
        "corpus_sect_ct = len(corpus_sects_filtered_ls)\n",
        "corpus_sects_clean_ls = []\n",
        "\n",
        "if corpus_sect_ct > 1:\n",
        "\n",
        "  # Remove the extraneous Section by Hand if necessary\n",
        "  corpus_sects_filtered_ls = [x for x in corpus_sects_filtered_ls if not x.isupper()]\n",
        "\n",
        "  # Clean the text\n",
        "  corpus_sects_clean_ls = [clean_text(x) for x in corpus_sects_filtered_ls]\n",
        "\n",
        "else:\n",
        "\n",
        "  print(f'WARNING: Corpus contains no SECTION structure')\n",
        "\n",
        "  if len(corpus_chaps_filtered_ls) > 1:\n",
        "    print('         Copying CHAPTER structure to SECTION\\n\\n')\n",
        "    # If Chapters exists, copy Chapter structure to Section structure\n",
        "    corpus_sects_filtered_ls = corpus_chaps_filtered_ls\n",
        "    corpus_sects_clean_ls = corpus_chaps_clean_ls\n",
        "    sect_chapno_ls = list(range(len(corpus_sects_filtered_ls)))\n",
        "\n",
        "  else:\n",
        "    # No Chapter nor Section structure, just plain text in Corpus without any headings\n",
        "    print('         No CHAPTER nor SECTION structure in this Corpus\\n\\n')\n",
        "    sect_chapno_ls = [1]\n",
        "\n",
        "\n",
        "if len(corpus_sects_filtered_ls) > 1:\n",
        "\n",
        "  # Verify\n",
        "  print(f'First Section of {len(corpus_sects_filtered_ls)}:\\n\\n  Beginning: {corpus_sects_filtered_ls[0][:50]}\\n\\n  Ending: {corpus_sects_filtered_ls[0][-50:]}\\n\\n')\n",
        "\n",
        "  print('----------')  \n",
        "\n",
        "  print(f'{corpus_sect_ct} Chapters found in this Corpus:\\n\\n')\n",
        "\n",
        "  print(f'First Section of {len(corpus_sects_filtered_ls)}:\\n\\n  Beginning: {corpus_sects_filtered_ls[0][:50]}\\n\\n  Ending: {corpus_sects_filtered_ls[0][-50:]}\\n\\n')\n",
        "\n",
        "  print(f'Second Section of {len(corpus_sects_filtered_ls)}:\\n\\n  Beginning: {corpus_sects_filtered_ls[1][:50]}\\n\\n  Ending: {corpus_sects_filtered_ls[1][-50:]}\\n\\n')\n",
        "\n",
        "  print(f'Second Last Section of {len(corpus_sects_filtered_ls)}:\\n\\n  Beginning: {corpus_sects_filtered_ls[-2][:50]}\\n\\n  Ending: {corpus_sects_filtered_ls[-2][-50:]}\\n\\n')\n",
        "\n",
        "  print(f'Last Section of {len(corpus_sects_filtered_ls)}:\\n\\n  Beginning: {corpus_sects_filtered_ls[-1][:50]}\\n\\n  Ending: {corpus_sects_filtered_ls[-1][-50:]}\\n\\n')\n",
        "\n",
        "  print('----------')\n",
        "\n",
        "else:\n",
        "\n",
        "  print('\\n\\nCorpus has no CHAPTER nor SECTION headers:')\n",
        "  print('  handle as one block to text above Paragraph/Sentence structural level')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJgZpAJtxYJO"
      },
      "source": [
        "# Test\n",
        "\n",
        "test_ls = [x for x in corpus_chaps_filtered_ls if 'I have no' in x]\n",
        "len(test_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovxAu0w1cRou"
      },
      "source": [
        "# TODO: Temp fix\n",
        "\n",
        "corpus_chaps_clean_ls = [clean_text(x) for x in corpus_chaps_filtered_ls]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohieoJ_ehb2e"
      },
      "source": [
        "# Verify that Chapter DataFrame inputs are all same length\n",
        "\n",
        "print(f'chap_no: {list(range(len(corpus_chaps_filtered_ls)))}')\n",
        "print(f'chap_raw: {len(corpus_chaps_filtered_ls)}')\n",
        "print(f'chap_clean: {len(corpus_chaps_clean_ls)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dvljymc6cDee"
      },
      "source": [
        "# corpus_chaps_filtered_ls[4][:50]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Coq6ZS6aMkvd"
      },
      "source": [
        "# Create Chapter DataFrame\n",
        "\n",
        "chap_no_ls = list(range(len(corpus_chaps_filtered_ls)))\n",
        "corpus_chaps_df = pd.DataFrame({'chap_no':chap_no_ls, 'chap_raw':corpus_chaps_filtered_ls, 'chap_clean':corpus_chaps_clean_ls})\n",
        "corpus_chaps_df['chap_raw'] = corpus_chaps_df['chap_raw'].astype('string')\n",
        "corpus_chaps_df['chap_clean'] = corpus_chaps_df['chap_clean'].astype('string')\n",
        "# corpus_chaps_df.head(1)\n",
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdKAEsWt-y_w"
      },
      "source": [
        "# Calculate length statistics for Chapters\n",
        "\n",
        "corpus_chaps_df['char_len'] = corpus_chaps_df['chap_raw'].apply(lambda x : len(x))\n",
        "corpus_chaps_df['token_len'] = corpus_chaps_df['chap_raw'].apply(lambda x : len(x.split()))\n",
        "# corpus_chaps_df.head()\n",
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTDdHkUa45rB"
      },
      "source": [
        "# Correct if lengths don't match due to Section != Chapter structures\n",
        "\n",
        "if corpus_chaps_df.shape[0] < corpus_sects_df.shape[0]:\n",
        "  sect_chapno_ls = [0]*corpus_sects_df.shape[0]\n",
        "\n",
        "len(sect_chapno_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKmMapiBuzKN"
      },
      "source": [
        "corpus_raw_str[:500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYG8knXZtpHm"
      },
      "source": [
        "# TODO: Temp fix\n",
        "\n",
        "\"\"\"\n",
        "corpus_tokens_ls = corpus_raw_str.split()\n",
        "sect_chapno_ls = []\n",
        "chap_ptr = 0\n",
        "sect_ptr = 0\n",
        "len(corpus_tokens_ls)\n",
        "for i, atoken in enumerate(corpus_tokens_ls):\n",
        "  if atoken == 'CHAPTER':\n",
        "    chap_ptr += 1\n",
        "  if atoken == 'SECTION':\n",
        "    sect_ptr += 1\n",
        "    sect_chapno_ls.append(chap_ptr)\n",
        "\n",
        "print(f'Section ChapNo Length: {len(sect_chapno_ls)}\\n    {sect_chapno_ls}')\n",
        "\n",
        "# If OK\n",
        "\n",
        "# sect_chapno_ls = sect_chapno_ls\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK7mAwMVirjE"
      },
      "source": [
        "len(sect_chapno_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJRG7cXI5T10"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "len(sect_chapno_ls)\n",
        "print('\\n')\n",
        "len(sect_no_ls)\n",
        "print('\\n')\n",
        "len(corpus_sects_filtered_ls)\n",
        "print('\\n')\n",
        "\n",
        "# TODO: Fix earlier\n",
        "corpus_sects_clean_ls = [clean_text(x) for x in corpus_sects_filtered_ls]\n",
        "\n",
        "len(corpus_sects_clean_ls)\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvUvQ1WMjEqd"
      },
      "source": [
        "# TODO: To fix\n",
        "\n",
        "sect_no_ls = sect_no_ls = chap_no_ls\n",
        "\n",
        "sect_chapno_ls = list(range(len(sect_no_ls)))\n",
        "\n",
        "# corpus_sects_clean_ls = [clean_text(x) for x in corpus_sects_filtered_ls]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBCM9oqUTmU3"
      },
      "source": [
        "# corpus_sects_clean_ls = [clean_text(x) for x in corpus_sects_filtered_ls]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNYDPkO7izxE"
      },
      "source": [
        "# Verify that Section DataFrame inputs are all same length\n",
        "\n",
        "print(f'sect_no: {len(sect_no_ls)}')\n",
        "print(f'sect_chapno_ls: {len(sect_chapno_ls)}')\n",
        "print(f'sect_raw: {len(corpus_sects_filtered_ls)}')\n",
        "print(f'sect_clean: {len(corpus_sects_clean_ls)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiBMyYDD88z5"
      },
      "source": [
        "# Create Section DataFrame\n",
        "\n",
        "sect_no_ls = list(range(len(corpus_sects_filtered_ls)))\n",
        "corpus_sects_df = pd.DataFrame({'sect_no':sect_no_ls, 'chap_no':sect_chapno_ls, 'sect_raw':corpus_sects_filtered_ls, 'sect_clean':corpus_sects_clean_ls})\n",
        "corpus_sects_df['sect_raw'] = corpus_sects_df['sect_raw'].astype('string')\n",
        "corpus_sects_df['sect_clean'] = corpus_sects_df['sect_clean'].astype('string')\n",
        "# corpus_sects_df.head(1)\n",
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnBFWwX62RZ7"
      },
      "source": [
        "len(sect_no_ls)\n",
        "print('\\n')\n",
        "len(sect_chapno_ls)\n",
        "print('\\n')\n",
        "len(corpus_sects_filtered_ls)\n",
        "print('\\n')\n",
        "len(corpus_sects_clean_ls)\n",
        "print('\\n')\n",
        "\n",
        "# TODO: Make more robust solution\n",
        "sect_chapno_len = len(sect_no_ls)\n",
        "print(f'sect_chapno_ls: {sect_chapno_len}')\n",
        "if len(sect_chapno_ls) == 0:\n",
        "  sect_chapno_ls = [0]*len(sect_no_ls)\n",
        "\n",
        "print('\\n')\n",
        "len(sect_no_ls)\n",
        "print('\\n')\n",
        "len(sect_chapno_ls)\n",
        "print('\\n')\n",
        "len(corpus_sects_filtered_ls)\n",
        "print('\\n')\n",
        "len(corpus_sects_clean_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9jpNBIGmyBT"
      },
      "source": [
        "# Calculate length statistics for Chapters\n",
        "\n",
        "corpus_sects_df['char_len'] = corpus_sects_df['sect_raw'].apply(lambda x : len(x))\n",
        "corpus_sects_df['token_len'] = corpus_sects_df['sect_raw'].apply(lambda x : len(x.split()))\n",
        "# corpus_sects_df.head()\n",
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpNdgPL_4rbQ"
      },
      "source": [
        "corpus_sects_df.iloc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFj2CQPD6l01"
      },
      "source": [
        "#### **Create Paragraph and Sentence DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td-w3TyEmSn1"
      },
      "source": [
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui_fYtR4G34A"
      },
      "source": [
        "# The spacy/nlp/pipe need to be recreated each time a large Corpus is parsed below\n",
        "\n",
        "# import pysbd\n",
        "# import spacy\n",
        "# from pysbd.utils import PySBDFactory\n",
        "\n",
        "\"\"\"\n",
        "if CORPUS_LANGUAGE == 'english':\n",
        "  nlp = spacy.blank('en')\n",
        "elif CORPUS_LANGUAGE == 'french':\n",
        "  nlp = spacy.blank('fr')\n",
        "else:\n",
        "  print(f'ERROR: CORPUS_LANGUAGE must be [english|french] but was set to: {CORPUS_LANGUAGE}')\n",
        "\n",
        "# explicitly adding component to pipeline\n",
        "# (recommended - makes it more readable to tell what's going on)\n",
        "nlp.add_pipe(PySBDFactory(nlp))\n",
        "\"\"\";\n",
        "\n",
        "# Test\n",
        "\n",
        "test_en_str = \"My name is Jonas E. Smith. Please turn to p. 55.\"\n",
        "\n",
        "test_fr_str = \"Le pépiement matinal des oiseaux semblait insipide à Françoise. Chaque parole des «bonnes» la faisait sursauter; incommodée par tous leurs pas, elle s'interrogeait sur eux; 'est que nous avions déménagé. Certes les domestiques ne remuaient pas moins, dans le «sixième» de notre ancienne demeure; mais elle les connaissait; elle avait fait de leurs allées et venues des choses amicales. Maintenant elle portait au silence même une attention douloureuse.\"\n",
        "\n",
        "# doc = nlp(test_fr_str)\n",
        "# print(list(doc.sents))\n",
        "# [My name is Jonas E. Smith., Please turn to p. 55.]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P34vN8P-9TiV"
      },
      "source": [
        "corpus_sects_df.iloc[0]['sect_raw'].split('\\n')[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weu1ZRsC6XCP"
      },
      "source": [
        "corpus_sectno = -1\n",
        "\n",
        "corpus_paragno = -1\n",
        "corpus_parags_ls = []\n",
        "\n",
        "corpus_sentno = -1\n",
        "corpus_sents_ls = []\n",
        "\n",
        "sects_filtered_ls = list(corpus_sects_df.sect_raw)\n",
        "\n",
        "# For every Section in the Corpus\n",
        "for asectno, asect_raw in enumerate(sects_filtered_ls):\n",
        "  # print(f'Section #{asectno}')\n",
        "  corpus_sectno += 1\n",
        "\n",
        "  # Split into a list of Paragraphs\n",
        "  sect_parags_filtered_ls, sect_clean_str = sect2parags(asect_raw)\n",
        "  # For every Paragraph in Section \n",
        "  for aparagno, aparag_raw in enumerate(sect_parags_filtered_ls):\n",
        "    print(f'  Paragraph #{aparagno}')\n",
        "    print(f'Split Section #{asectno} in {len(sect_parags_filtered_ls)} Paragraphs')\n",
        "    corpus_paragno += 1\n",
        "\n",
        "    # Split into list of Sentences\n",
        "    print(f'\\nPassing Paragraph:\\n\\n    {aparag_raw} to parag2sents')\n",
        "    parag_sents_filtered_ls, parag_clean_str = parag2sents(aparag_raw)\n",
        "    print(f'Split Paragraph into {len(parag_sents_filtered_ls)} Sentences')\n",
        "    aparag_clean = clean_text(aparag_raw)\n",
        "    if any_alphachar(aparag_clean):\n",
        "      # Only add Paragraphs that have at least one alpha char after clean_text() (e.g. skip Paragraph = '$1.00!!! ---' )\n",
        "      corpus_parags_ls.append((corpus_paragno, corpus_sectno, aparag_raw, aparag_clean))\n",
        "\n",
        "    # For every Sentence in Paragraph\n",
        "    for asentno, asent_raw in enumerate(parag_sents_filtered_ls):\n",
        "      print(f'Section #{asectno}, Paragraph #{aparagno}, Section Sentence #{asentno} Corpus Sentence #{corpus_sentno}')\n",
        "      corpus_sentno += 1\n",
        "      asent_clean = clean_text(asent_raw)\n",
        "      if any_alphachar(asent_clean):\n",
        "        # Only add Sentences that have at least one alpha char after clean_text() (e.g. skip Sentence = '$1.00!!! ---' )\n",
        "        corpus_sents_ls.append((corpus_sentno, corpus_paragno, corpus_sectno, asent_raw, asent_clean))\n",
        "\n",
        "    # if asectno > 2:\n",
        "    #   break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5eu0IKxORTS"
      },
      "source": [
        "# Test (The Great Gatsby) ensure iloc[2844] raw_sent '$2.11' removed\n",
        "\n",
        "# corpus_sents_df.shape\n",
        "# corpus_sents_df.iloc[2843]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKFvr35VvfFC"
      },
      "source": [
        "# Verfiy Section counts\n",
        "\n",
        "for i, asect in enumerate(sects_filtered_ls):\n",
        "  print(f'Length of Section #{i}: {len(asect)}\\n')\n",
        "\n",
        "\"\"\"\n",
        "Before FRENCH modifications:\n",
        "\n",
        "Length of Section #0: 409601\n",
        "\n",
        "Length of Section #1: 455968\n",
        "\n",
        "Length of Section #2: 485479\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc5-8GDOd8rF"
      },
      "source": [
        "# Verify the first 500 chars of first few Sections\n",
        "\n",
        "char_ct = 500\n",
        "\n",
        "for i, asect in enumerate(sects_filtered_ls):\n",
        "  print(f'Start of Section #{i} ------------------------------\\n\\n    {asect[:char_ct]}\\n')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhXKvuQPevmM"
      },
      "source": [
        "# Verify first raw Section text\n",
        "\n",
        "sects_filtered_ls[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4721-er6W96"
      },
      "source": [
        "# Verify Sentence and Paragraph Counts\n",
        "\n",
        "sent_ct = len(corpus_sents_ls)\n",
        "print(f'{sent_ct} Sentences were found in the Corpus')\n",
        "\n",
        "parag_ct = len(corpus_parags_ls)\n",
        "print(f'{parag_ct} Paragraphs were found in the Corpus')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0gltS-r0QPv"
      },
      "source": [
        "print(corpus_parags_ls[0][:50])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm9fDtVJziE3"
      },
      "source": [
        "# Create Paragraph DataFrame\n",
        "\"\"\"\n",
        "parag_no_ls = list(range(len(corpus_parags_ls)))\n",
        "corpus_parags_df = pd.DataFrame({'sect_no':sect_no_ls, 'chap_no':sect_chapno_ls, 'sect_raw':corpus_sects_raw_ls, 'sect_clean':corpus_sects_clean_ls})\n",
        "corpus_parags_df['sect_raw'] = corpus_parags_df['sect_raw'].astype('string')\n",
        "corpus_parags_df['sect_clean'] = corpus_parags_df['sect_clean'].astype('string')\n",
        "corpus_parags_df.info()\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ7Xdmyt0Asb"
      },
      "source": [
        "# Create Paragraph DataFrame\n",
        "\n",
        "corpus_parags_df = pd.DataFrame(corpus_parags_ls,columns=['parag_no','sect_no','parag_raw','parag_clean'])\n",
        "corpus_parags_df['parag_raw'] = corpus_parags_df['parag_raw'].astype('string')\n",
        "corpus_parags_df['parag_clean'] = corpus_parags_df['parag_clean'].astype('string')\n",
        "corpus_parags_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arm9ZlvSl-42"
      },
      "source": [
        "# Calculate length statistics for Paragraphs\n",
        "\n",
        "corpus_parags_df['char_len'] = corpus_parags_df['parag_raw'].apply(lambda x : len(x))\n",
        "corpus_parags_df['token_len'] = corpus_parags_df['parag_raw'].apply(lambda x : len(x.split()))\n",
        "corpus_parags_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqN4aFeT3RMq"
      },
      "source": [
        "# Verify Paragraph DataFrame start and end\n",
        "\n",
        "corpus_parags_df.head(5)\n",
        "corpus_parags_df.tail(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T27_raCzWk6"
      },
      "source": [
        "# Create Sentences DataFrame\n",
        "\n",
        "corpus_sents_df = pd.DataFrame(corpus_sents_ls,columns=['sent_no', 'parag_no','sect_no','sent_raw','sent_clean'])\n",
        "corpus_sents_df['sent_raw'] = corpus_sents_df['sent_raw'].astype('string')\n",
        "corpus_sents_df['sent_clean'] = corpus_sents_df['sent_clean'].astype('string')\n",
        "corpus_sents_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glceM5TylaA8"
      },
      "source": [
        "# Compute length statistics for Sentences\n",
        "\n",
        "corpus_sents_df['char_len'] = corpus_sents_df['sent_raw'].apply(lambda x : len(x))\n",
        "corpus_sents_df['token_len'] = corpus_sents_df['sent_raw'].apply(lambda x : len(x.split()))\n",
        "corpus_sents_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4WWrd1J2uz_"
      },
      "source": [
        "# Verify Sentence DataFrame start and end\n",
        "\n",
        "corpus_sents_df.head(20)\n",
        "corpus_sents_df.tail(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSzNKPacx9Nd"
      },
      "source": [
        "# Test\n",
        "\n",
        "search_str = 'I have no'\n",
        "corpus_sents_df[corpus_sents_df['sent_raw'].str.find(search_str) != -1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgJKnHHk4f3F"
      },
      "source": [
        "#### **For each Section, insert [start|mid|end] Sentence numbers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tnwy-rFW4swr"
      },
      "source": [
        "# Calculate the start, mid and end Sentence No for each Section\n",
        "\n",
        "sect_sent_no_start_ls = np.array(corpus_sents_df.groupby('sect_no')['sent_no'].min())\n",
        "sect_sent_no_end_ls = np.array(corpus_sents_df.groupby('sect_no')['sent_no'].max())\n",
        "\n",
        "def my_mid(anum, bnum):\n",
        "  mid_no = (anum - bnum)//2 + bnum\n",
        "\n",
        "  return mid_no\n",
        "\n",
        "print('\\nSection start sentence no: -----')\n",
        "print(sect_sent_no_start_ls)\n",
        "\n",
        "sect_sent_no_mid_ls = list(map(my_mid, sect_sent_no_end_ls, sect_sent_no_start_ls))\n",
        "print('\\nSection mid-sentence no: -----')\n",
        "print(sect_sent_no_mid_ls)\n",
        "\n",
        "print('\\nSection end sentence no: -----')\n",
        "print(sect_sent_no_end_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MNNcN_d48xa"
      },
      "source": [
        "# Insert 3 new columns on start,mid and end Sentence No for each Section\n",
        "\n",
        "corpus_sects_df.insert(2, 'sent_no_start', sect_sent_no_start_ls)\n",
        "corpus_sects_df.insert(3, 'sent_no_mid', sect_sent_no_mid_ls)\n",
        "corpus_sects_df.insert(4, 'sent_no_end', sect_sent_no_end_ls)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuxMQpOY2uwF"
      },
      "source": [
        "# Verfiy Section \n",
        "\n",
        "corpus_sects_df.filter(like='_no')\n",
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z48WKV1W6KdA"
      },
      "source": [
        "#### **For Each Chapter, Insert [start|mid|end] Sentence numbers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77oGMj4v6pZZ"
      },
      "source": [
        "corpus_chaps_filtered_ls[0][:50]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGNlqV5G7Tk-"
      },
      "source": [
        "corpus_chaps_clean_ls[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70ntj-6X8PbU"
      },
      "source": [
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWFbBuEGQ4fH"
      },
      "source": [
        "search_str = 'goose'\n",
        "\n",
        "corpus_sents_df[corpus_sents_df['sent_clean'].str.contains(search_str)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWvddQwkCjKY"
      },
      "source": [
        "# corpus_sents_df.iloc[1056]['sent_clean']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DylkEa8cCwG"
      },
      "source": [
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vrZVqCRVOwF"
      },
      "source": [
        "achap_sentstart_clean_ls = []\n",
        "\n",
        "for indx, achap_tup in corpus_chaps_df.iterrows():\n",
        "  achap_no, achap_raw, achap_clean, achap_charlen, achap_tokenlen = achap_tup\n",
        "  achap_sentstart_clean_ls.append(achap_clean[:100])\n",
        "\n",
        "print(achap_sentstart_clean_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2HcU3WLaHpV"
      },
      "source": [
        "!pip install fuzzywuzzy[speedup]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU_11lWzaI-I"
      },
      "source": [
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbxpUygQaL3g"
      },
      "source": [
        " fuzz.ratio(\"this is a test\", \"this is a test!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6B0n3hdbLyp"
      },
      "source": [
        "corpus_sects_df.info()\n",
        "\n",
        "type(corpus_sects_df['sect_clean'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCarKELJ-S2x"
      },
      "source": [
        "# Optional\n",
        "\n",
        "# corpus_chaps_df.drop(columns=['sect_no'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDKC_kucCYih"
      },
      "source": [
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ytgSzv5DCjM"
      },
      "source": [
        "corpus_parags_df.iloc[:5]['parag_clean'][:50]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oXrE-d0C3Ik"
      },
      "source": [
        "corpus_sects_df.iloc[:5]['sect_clean'][:50]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaoY4ACmDdEN"
      },
      "source": [
        "corpus_sents_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qn8CySv9byQ"
      },
      "source": [
        "corpus_chaps_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSqva3DLwu4H"
      },
      "source": [
        "# Clean Chapters DataFrame\n",
        "\n",
        "corpus_chaps_df['chap_clean'] = corpus_chaps_df['chap_clean'].apply(lambda x: re.sub(r'SECTION [IVXL]{1,10}[.]','',x))\n",
        "corpus_chaps_df['chap_clean'] = corpus_chaps_df['chap_clean'].apply(lambda x: clean_text(x).strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDOUcy8fyGBM"
      },
      "source": [
        "corpus_chaps_df.iloc[0]['chap_clean'][:500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtGurlnd6-Qt"
      },
      "source": [
        "# Calculate the start, mid and end Sentence No for each Section\n",
        "\n",
        "min_charlen = 80  # How many characters to match at the start of start/end Sentences\n",
        "\n",
        "# If there is no Chapter structure\n",
        "if corpus_chaps_df.shape[0] == 1:\n",
        "  \n",
        "  chaps_sentend = corpus_sents_df.shape[0] - 1\n",
        "  chaps_sentmid = chaps_sentend//2\n",
        "\n",
        "  chaps_sentstart_ls = [0]\n",
        "  chaps_sentmid_ls = [chaps_sentmid]\n",
        "  chaps_sentend_ls = [chaps_sentend]\n",
        "\n",
        "else:\n",
        "\n",
        "  # First, find which Sections align with each Chapter and save Section's sent_no_start as the same for Chapter\n",
        "  chaps_sentstart_ls = []\n",
        "  sects_sentstart_ls = list(corpus_sects_df['sect_clean'].apply(lambda x: x[:min_charlen].strip()))\n",
        "  for achap_indx, achap_tup in corpus_chaps_df.iterrows():\n",
        "    # TODO: Insert deal with 5 or 6 returned items in tuple depending on Corpus Chapter/Section structure\n",
        "    # 6 args returned\n",
        "    # achap_no, achap_sentno_start, achap_raw, achap_clean, achap_charlen, achap_tokenlen = achap_tup\n",
        "    # 5 args returned\n",
        "    achap_no, achap_raw, achap_clean, achap_charlen, achap_tokenlen = achap_tup\n",
        "    achap_sentstart_str = achap_clean[:min_charlen].strip()\n",
        "    achap_sentstart_str = ' '.join(achap_sentstart_str.split())\n",
        "\n",
        "    sent_startno_found = False\n",
        "    # Loop over all the Sections to see if the starting text matches the Chapter starting text\n",
        "    for asect_indx, asect_sentstart_str in enumerate(sects_sentstart_ls):\n",
        "      asect_sentstart_str = ' '.join(asect_sentstart_str.split())\n",
        "      achap_sentstart_len = len(achap_sentstart_str)\n",
        "      asect_sentstart_len = len(asect_sentstart_str)\n",
        "      if (achap_sentstart_len > asect_sentstart_len):\n",
        "        len_diff = achap_sentstart_len - asect_sentstart_len\n",
        "        achap_sentstart_str = achap_sentstart_str[:-len_diff]\n",
        "      elif (achap_sentstart_len < asect_sentstart_len):\n",
        "        len_diff = asect_sentstart_len - achap_sentstart_len\n",
        "        asect_sentstart_str = asect_sentstart_str[:-len_diff]\n",
        "      else:\n",
        "        # Both Chapter and Section starting Sentence strings are equal length\n",
        "        pass\n",
        "\n",
        "      print(f'Fuzzy Compare:\\n\\n    Chapter Start: {achap_sentstart_str}\\n    Section Start: {asect_sentstart_str}')\n",
        "      if fuzz.ratio(achap_sentstart_str, asect_sentstart_str) > 97:\n",
        "        sent_startno_ls = list(corpus_sects_df[corpus_sects_df['sect_no'] == asect_indx]['sent_no_start'])\n",
        "        # print(f'MATCH!!! type(sent_startno): {sent_startno_ls[0]}')\n",
        "        chaps_sentstart_ls.append(sent_startno_ls[0])\n",
        "        sent_startno_found = True\n",
        "        break\n",
        "    # If no match found, enter ERROR code -1 in the Sentence start no for the current Chapter\n",
        "    if sent_startno_found == False:\n",
        "      chaps_sentstart_ls.append((achap_indx, -1))\n",
        "\n",
        "  print(f'\\n\\nchaps_sentstart_ls: {chaps_sentstart_ls}')\n",
        "\n",
        "\n",
        "\n",
        "  # Second, get the end Sentence for Each Chapter by rotating Sentence Start No left and pushing on the last Sentence No\n",
        "  chaps_sentend_ls = []\n",
        "  chaps_sentend_ls = [x-1 for x in chaps_sentstart_ls]\n",
        "  corpus_sentlast = corpus_sents_df.shape[0] - 1\n",
        "\n",
        "  chaps_sentend_ls.pop(0)\n",
        "  chaps_sentend_ls.append(corpus_sentlast)\n",
        "\n",
        "  print(f'\\n\\nchaps_sentend_ls: {chaps_sentend_ls}')\n",
        "\n",
        "\n",
        "  # Third, calculate the Sentence No in the middle of each Chapter\n",
        "\n",
        "  chaps_sentmid_ls = [(((chaps_sentend_ls[i] - chaps_sentstart_ls[i])//2)+chaps_sentstart_ls[i]) for i in range(len(chaps_sentend_ls))]\n",
        "\n",
        "  print(f'\\n\\nchaps_sentmid_ls: {chaps_sentmid_ls}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpOzOahxhgvU"
      },
      "source": [
        "# Verify boundry cases\n",
        "\n",
        "corpus_sents_df.iloc[268]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN_GXkBekH0P"
      },
      "source": [
        "# corpus_chaps_df.drop(columns=['sent_no_start','sent_no_mid','sent_no_end'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrfK9MVAEuYp"
      },
      "source": [
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZTduIsl6KdB"
      },
      "source": [
        "# Insert 3 new columns on start,mid and end Sentence No for each Chapter\n",
        "\n",
        "corpus_chaps_df.insert(1, 'sent_no_start', chaps_sentstart_ls)\n",
        "corpus_chaps_df.insert(2, 'sent_no_mid', chaps_sentmid_ls)\n",
        "corpus_chaps_df.insert(3, 'sent_no_end', chaps_sentend_ls)\n",
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTW3Gxmf6KdC"
      },
      "source": [
        "# Verfiy Chapter \n",
        "\n",
        "corpus_chaps_df.filter(like='_no')\n",
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDSyIfqDQCMI"
      },
      "source": [
        "# Verify\n",
        "\n",
        "print(f'Corpus Sentence DataFrame shape: {corpus_sents_df.shape}')\n",
        "print(f'Corpus Paragraph DataFrame shape: {corpus_parags_df.shape}')\n",
        "print(f'Corpus Section DataFrame shape: {corpus_sects_df.shape}')\n",
        "print(f'Corpus Chapter DataFrame shape: {corpus_chaps_df.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjfAWFJ1xl8d"
      },
      "source": [
        "corpus_sects_df.iloc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEtOOm2UQd1o"
      },
      "source": [
        "#### **Save Corpus DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39_ehy97zB1Z"
      },
      "source": [
        "# Test\n",
        "\n",
        "search_str = 'I have no'\n",
        "corpus_sents_df[corpus_sents_df['sent_raw'].str.find(search_str) != -1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hf92HlV9--1"
      },
      "source": [
        "%whos DataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGkvSy4HQdCe"
      },
      "source": [
        "# Save Corpus DataFrames\n",
        "\n",
        "save_dataframes(df_ls=['baseline'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDEqASdRUfVF"
      },
      "source": [
        "corpus_sents_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK27hN0KkvBI"
      },
      "source": [
        "### **END HERE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVCkjat0vffd"
      },
      "source": [
        "#### **Get All (non-null) Raw Lines**\n",
        "\n",
        "* NOTE: Corpus textfile needs to be Preprocessed before running this\n",
        "- Remove all Curve Parenthesis that span multiple sentences or paragraphs\n",
        "- Remove all Square Parenthesis\n",
        "- Filter out non-printing characters if they exist (or use proper encoding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgqqpwagWPS7"
      },
      "source": [
        "len(corpus_lines_ls)\n",
        "print('\\n')\n",
        "print(corpus_lines_ls[11])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBl_hrhPZo29"
      },
      "source": [
        "min(corpus_lines_ls, key=lambda word: len(word))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lthUz3kpZ8_K"
      },
      "source": [
        "corpus_lines_ls.sort(key=lambda s: len(s))\n",
        "corpus_lines_ls[:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an7SzlAuvXA0"
      },
      "source": [
        "# NOTE: ~3-15 minutes (one pass with PySBD)\n",
        "#             minutes (two passes with PySBD+NLTK)\n",
        "\n",
        "# Time consuming so only set pysbd_only=True (second NLTK sentence tokenizer pass) \n",
        "#   if necessary (e.g. Samuel Butler's 1900 trans. of Homer's Odyssey)\n",
        "#                 PySBD: 1075 lines, PySBD+NLTK: 3905 lines, NLTK: 3109 lines\n",
        "#                        Why? a 3 Sentence Paragraph enclosed in double quotes is counted as one Sentence by PySBD\n",
        "#           w/spec char strip: PySBD+NLTK: 3926\n",
        "#           w/o digits/footnotes: PySBD+NLTK: 3925\n",
        "\n",
        "corpus_lines_ls, lines_raw_str = corpus2lines(corpus_filename, pysbd_only=False)\n",
        "\n",
        "# Verify\n",
        "print(f'\\n\\nRead raw corpus lines: character count: {len(lines_raw_str)}')\n",
        "print(f'                        raw line count:  {len(corpus_lines_ls)}\\n\\n')\n",
        "\n",
        "line_ct = 10\n",
        "print(f'First {line_ct} raw lines: --------------------\\n')\n",
        "for i,aline in enumerate(corpus_lines_ls[:line_ct]):\n",
        "  print(f'Line #{i}:\\n    {aline}')\n",
        "print(f'\\n\\nLast {line_ct} raw lines: -------------------\\n')\n",
        "for i,aline in enumerate(corpus_lines_ls[-line_ct:]):\n",
        "  print(f'Line #{i}: {aline}')\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "BEFORE stripping out headings len: 610949 (605835 w/2nd pass)\n",
        "Corpus Paragraph Raw Count: 1075\n",
        "   Parag count before processing sents: 1075\n",
        "About to return corpus_sents_raw_ls with len = 2469\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b6ORN6A08Dv"
      },
      "source": [
        "#### **Create Sentence DataFrame: [corpus_sents_df]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BeGt1ot0_dK"
      },
      "source": [
        "# Filter out all the structural/metatag and blank/punctuation only lines\n",
        "#    and save all semantically meaningful Sentences in corpus_sents_ls\n",
        "\n",
        "corpus_sents_ls = []\n",
        "\n",
        "for i, aline in enumerate(corpus_lines_ls):\n",
        "\n",
        "    # print(f'Examing line #{i}: {aline}')\n",
        "\n",
        "    aline_clean = aline.strip()\n",
        "    # Skip/delete whitespace only sentences\n",
        "    if len(aline_clean) == 0:\n",
        "      continue\n",
        "    \n",
        "    # Skip/delete any sentences starting with CHAPTER RegEx Pattern\n",
        "    if aline_clean.startswith('CHAPTER '):\n",
        "      continue\n",
        "    \n",
        "    # Skip/delete any sentences starting with SECTION RegEx Pattern\n",
        "    if aline_clean.startswith('SECTION '):\n",
        "      continue\n",
        "\n",
        "    # Skip/delete any sentences starting with SECTION RegEx Pattern\n",
        "    if aline_clean.startswith('BOOK '):\n",
        "      continue\n",
        "\n",
        "    # Skip/delete any sentence no alpha/numeric charcters (e.g. only punctuation)\n",
        "    if (re.match('^[^a-zA-Z]+$', aline_clean)):\n",
        "      print(f'No alnum line #{i}: {aline}')\n",
        "      continue\n",
        "\n",
        "    # If passed through all previous filters, save as genuine Sentence\n",
        "    corpus_sents_ls.append(aline_clean)\n",
        "\n",
        "# Test\n",
        "print(f'Raw Lines length: {len(corpus_lines_ls)}')\n",
        "print(f' Clean Sentences: {len(corpus_sents_ls)}')\n",
        "\n",
        "line_ct = 10\n",
        "print(f'First {line_ct} clean Sentences : --------------------\\n')\n",
        "for i,aline in enumerate(corpus_sents_ls[:line_ct]):\n",
        "  print(f'Line #{i}:\\n    {aline}')\n",
        "print(f'\\n\\nLast {line_ct} clean Sentences: -------------------\\n')\n",
        "for i,aline in enumerate(corpus_sents_ls[-line_ct:]):\n",
        "  print(f'Line #{i}: {aline}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8ERYqQW7U9q"
      },
      "source": [
        "# Create Sentence DataFrame\n",
        "\n",
        "sent_no_ls = list(range(len(corpus_sents_ls)))\n",
        "\n",
        "corpus_sents_df = pd.DataFrame({'sent_no': sent_no_ls, 'sent_raw': corpus_sents_ls})\n",
        "corpus_sents_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70VO_w4Oql1a"
      },
      "source": [
        "# Compute Sentence text statistics\n",
        "\n",
        "corpus_sents_df['sent_clean'] = corpus_sents_df['sent_raw'].apply(lambda x: clean_text(x))\n",
        "corpus_sents_df['token_len'] = corpus_sents_df['sent_clean'].apply(lambda x: len(x.split()))\n",
        "corpus_sents_df['char_len'] = corpus_sents_df['sent_raw'].apply(lambda x: len(x))\n",
        "corpus_sents_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFC8GTnw6HrG"
      },
      "source": [
        "#### **Create Paragraph DataFrame: [corpus_parags_df]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGog8ZW16bbr"
      },
      "source": [
        "# Read Corpus into a single string then split into raw Paragraphs\n",
        "\n",
        "corpus_parags_ls, corpus_parags_raw_ls, corpus_raw_str = corpus2parags(CORPUS_FILENAME)\n",
        "print(f'Found #{len(corpus_parags_ls)} paragraphs\\n')\n",
        "\n",
        "print('\\nThe first 5 Paragraphs of the Corpus (first 10 chars):')\n",
        "print('-----------------------------------\\n')\n",
        "corpus_parags_ls[:5][:10]\n",
        "print('\\n')\n",
        "print('\\n\\nThe last 5 Paragraphs of the Corpus (first 10 chars):')\n",
        "print('-----------------------------------\\n')\n",
        "corpus_parags_ls[-5:][:10]\n",
        "print('\\n')\n",
        "\n",
        "n_shortest = 10\n",
        "print(f'The {n_shortest} shortest Paragraphs in the Corpus are:')\n",
        "print('--------------------------------------------')\n",
        "temp_parags_ls = sorted(corpus_parags_ls, key=lambda x: (len(x), x))\n",
        "for i, asent in enumerate(temp_parags_ls[:n_shortest]):\n",
        "  print(f'Shortest Paragraph #{i}: {asent}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZdfH-rTXwwT"
      },
      "source": [
        "# Verify Paragraphs found and Sentence-Paragraph matches\n",
        "\n",
        "# TODO: Upgrade if warranted (requires updating x2parags functions)\n",
        "\"\"\"\n",
        "print(f'{len(corpus_parags_ls)} Paragraphs found in Corpus')\n",
        "print(f'{len(sentences_section_ls)} Sentences found in a Section')\n",
        "\n",
        "sentences_nosection_ct = len(sentences_nosection_ls)\n",
        "\n",
        "if (sentences_nosection_ct > 0):\n",
        "  print(f'\\n    WARNING: The following {sentences_nosection_ct} Sentences were NOT FOUND in any Section')\n",
        "  print(f'             If these are important/numerous, go back and edit/correct source Corpus text file and rerun this notebook\\n')\n",
        "\n",
        "  for i, asent in enumerate(sentences_nosection_ls):\n",
        "    print(f'    #{i}: {asent}\\n')\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAwfcbYJnwtq"
      },
      "source": [
        "# Verify Paragraph count and sample\n",
        "\n",
        "len(corpus_parags_ls)\n",
        "print('\\n')\n",
        "\n",
        "parag_no_ls = range(len(corpus_parags_ls))\n",
        "len(corpus_parags_ls)\n",
        "print('\\n')\n",
        "\n",
        "corpus_parags_ls[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnJQvKkyHfVc"
      },
      "source": [
        "# Create DataFrame from list of Paragraphs extracted from Corpus\n",
        "\n",
        "corpus_parags_df = pd.DataFrame({'parag_no':parag_no_ls, 'parag_raw':corpus_parags_raw_ls, 'parag_clean':[clean_text(x) for x in corpus_parags_ls]})\n",
        "corpus_parags_df['parag_raw'] = corpus_parags_df['parag_raw'].astype('string')\n",
        "corpus_parags_df.head(2)\n",
        "corpus_parags_df.tail(2)\n",
        "corpus_parags_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOvIFAsgdgK2"
      },
      "source": [
        "corpus_parags_df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrQ4YmkK6HrH"
      },
      "source": [
        "# For each Paragraph, compute the start, mid and end Sentence Number\n",
        "\n",
        "# NOTE: ~5 minutes runtime\n",
        "\n",
        "# NOTE: May fail on any paragraph/sentence with dirty text and require\n",
        "#       multiple iterations of fix/run cycles\n",
        "\n",
        "# Used raw paragraph data to update Master Corpus DataFrame with Paragraph Info\n",
        "\n",
        "# Filter out all the structural/metatag and blank/punctuation only lines\n",
        "#    and save all semantically meaningful Sentences in corpus_sents_ls\n",
        "\n",
        "corpus_sents2parag_ls = []\n",
        "corpus_sents2parag_reject_ls = []\n",
        "parag_sents_tup_ls = []\n",
        "sent_no_current = 0\n",
        "\n",
        "parag_no_current = 0\n",
        "sent_no_current = 0\n",
        "\n",
        "flag_previous_miss = False\n",
        "\n",
        "corpus_parag_ct = len(corpus_parags_ls)\n",
        "\n",
        "def get_sent2paragno(asent_no, asent_raw_str):\n",
        "  '''\n",
        "  Given a sent_no and sent_raw_str\n",
        "  Search and return the corresponding parag_no that contains the sent_raw_str\n",
        "      (return -1 if not found)\n",
        "  '''\n",
        "\n",
        "  global parag_no_current\n",
        "  global flag_previous_miss\n",
        "  # NOTE: Dependencies on local vars outside this def and global vars corpus_parags_ls\n",
        "  # global parag_no_current\n",
        "\n",
        "  # Loop over every paragraph until we find matching sentence (or fail)\n",
        "  while parag_no_current < corpus_parag_ct:\n",
        "\n",
        "    print(f'Sentence #{asent_no}, Text: {asent_raw_str}')\n",
        "    print(f'    Starting search at Paragraph #{parag_no_current}')\n",
        "    print(f'    Paragraph Text:\\n    {corpus_parags_ls[parag_no_current]}')\n",
        "    parag_str = corpus_parags_ls[parag_no_current]\n",
        "\n",
        "    # Search for Sentence string in current Paragraph string\n",
        "    # if re.search(asent_raw_str, re.escape(parag_str)):\n",
        "    # problems with embedded parenthesis\n",
        "    # noparen_table = str.maketrans({'(':' ', ')':' ', '[':' ', ']':' ', '?':' ', '\"':' ', \"'\":\" \"})\n",
        "    # asent_noparens_str = asent_raw_str.translate(noparen_table)\n",
        "    # parag_noparens_str = parag_str.translate(noparen_table)\n",
        "    asent_noparens_str = re.sub('[^0-9a-zA-Z]+', ' ', asent_raw_str)\n",
        "    parag_noparens_str = re.sub('[^0-9a-zA-Z]+', ' ', parag_str)\n",
        "\n",
        "    if re.search(asent_noparens_str, parag_noparens_str):\n",
        "      print(f'    Found it!')\n",
        "      flag_previous_miss = False\n",
        "      return parag_no_current\n",
        "    else:\n",
        "      if flag_previous_miss == True:\n",
        "        # Sentence not found in 2 consecutive Paragraphs, skip this Sentence\n",
        "        print(f'    Miss: Skip this Sentence and go set current paragraph back 1')\n",
        "        parag_no_current -= 1\n",
        "        flag_previous_miss = False\n",
        "        return -1\n",
        "      else:\n",
        "        # Sentence not found in current Paragraph, so try next one\n",
        "        print(f'     Miss: Sentence not found in current Paragraph, try next one')\n",
        "        parag_no_current += 1\n",
        "        flag_previous_miss = True\n",
        "\n",
        "\n",
        "  # At this point we searched both the current and next Paragraphs for Sentence \n",
        "  #     without success so return error code\n",
        "  return -1 \n",
        "\n",
        "# Step through every Sentence and find the Paragraph Number it lies within\n",
        "# corpus_sents_df['parag_no'] = corpus_sents_df.apply(lambda x: get_sent2paragno(x.sent_no, x.sent_raw), axis=1)\n",
        "parag_no_last_match = 0\n",
        "for idx, row in corpus_sents_df.iterrows():\n",
        "  parag_no_current = parag_no_last_match\n",
        "  asent_no = row['sent_no']\n",
        "  asent_str = row['sent_raw']\n",
        "  print(f'idx #{idx}, sent_no: {asent_no}\\n    {asent_str}')\n",
        "  \n",
        "  asent_parag_no = get_sent2paragno(asent_no, asent_str)\n",
        "  print(f'back from searching for Sentence in all Paragraphs with result: {asent_parag_no}')\n",
        "  if asent_parag_no < 0:\n",
        "    # print(f'FAIL: Did not find current Sentence so skip to next Sentence\\n\\n')\n",
        "    corpus_sents2parag_reject_ls.append((asent_no, corpus_sents_ls[asent_no]))\n",
        "    parag_no_current = parag_no_last_match\n",
        "  else:\n",
        "    # print(f'SUCCESS: Sentence #{asent_no} found in Paragraph #{asent_parag_no}\\n\\n')\n",
        "    corpus_sents2parag_ls.append((asent_no, asent_parag_no))\n",
        "    parag_no_last_match = parag_no_current\n",
        "\n",
        "  # if idx > 20:\n",
        "  #   break\n",
        "\n",
        "# Test\n",
        "\"\"\"\n",
        "print(f'Raw Lines length: {len(corpus_lines_ls)}')\n",
        "print(f' Clean Sentences: {len(corpus_sents_ls)}')\n",
        "\n",
        "line_ct = 10\n",
        "print(f'First {line_ct} clean Sentences : --------------------\\n')\n",
        "for i,aline in enumerate(corpus_sents_ls[:line_ct]):\n",
        "  print(f'Line #{i}:\\n    {aline}')\n",
        "print(f'\\n\\nLast {line_ct} clean Sentences: -------------------\\n')\n",
        "for i,aline in enumerate(corpus_sents_ls[-line_ct:]):\n",
        "  print(f'Line #{i}: {aline}')\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJxi6BUWqj-l"
      },
      "source": [
        "# Any Sentences not found in Corpus Paragraphs?\n",
        "#  If not empty list, manually check and edit corpus if many/significant Sentences rejected\n",
        "\n",
        "sentences_noparag_ct = len(corpus_sents2parag_reject_ls)\n",
        "\n",
        "if sentences_noparag_ct > 0:\n",
        "  print(f'\\n    WARNING: The following {sentences_noparag_ct} Sentences were NOT FOUND in any Paragraph')\n",
        "  print(f'             If these are important/numerous, go back and edit/correct source Corpus text file and rerun this notebook\\n')\n",
        "\n",
        "  for i, asent in enumerate(corpus_sents2parag_reject_ls):\n",
        "    print(f'    #{i}: {asent}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9FrWNj80PkD"
      },
      "source": [
        "corpus_sents_df.iloc[200]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UAnLu0k1PAr"
      },
      "source": [
        "corpus_sents_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGqcTKBtF4QU"
      },
      "source": [
        "# Create a list of the Sentence Nos associated with each Paragraph in the Corpus\n",
        "\n",
        "sent_parag_no_ls = [sentnoparagno_tp[1] for sentnoparagno_tp in corpus_sents2parag_ls]\n",
        "\n",
        "corpus_sent_ct = corpus_sents_df.shape[0]\n",
        "parags_sent_ct = len(sent_parag_no_ls)\n",
        "if (corpus_sent_ct == parags_sent_ct):\n",
        "  print(f'GOOD, all {corpus_sent_ct} Sentences were matched in one of the {corpus_parags_df.shape[0]} Paragraphs\\n')\n",
        "else:\n",
        "  print(f'WARNING: only {parags_sent_ct} Sentences were matched in one of the {corpus_parags_df.shape[0]} Paragraphs')\n",
        "  print(f'         {corpus_sent_ct - parags_sent_ct} Sentences were not matched\\n')\n",
        "\n",
        "print(f'First 10 Sentences belong to these Paragraph:\\n    {sent_parag_no_ls[:10]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7-1oBkJKeJH"
      },
      "source": [
        "# Verfiy the data about to be used to update the master corpus_all_df DataFrame with Paragraph No data\n",
        "\n",
        "corpus_sents2parag_ls[3233:3237]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2vZk07BkeNw"
      },
      "source": [
        "# corpus_all_df.drop(columns=['parag_no'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29tMZKR4KERa"
      },
      "source": [
        "# Update the master corpus_all_df DataFrame with Paragraph No for each Sentence\n",
        "\n",
        "# WARNING: Only execute once (insert Column/Series into DataFrame)\n",
        "\n",
        "parag_no_ser = pd.Series(parag_no_ls)\n",
        "corpus_sents_df.insert(loc=1, column='parag_no', value=sent_parag_no_ls)\n",
        "\n",
        "corpus_sents_df.head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsOgtjM71eKE"
      },
      "source": [
        "corpus_sents_df.iloc[300:320]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK5kKZbVl3jR"
      },
      "source": [
        "# corpus_parags_df.drop(columns=['sent_no_start', 'sent_no_mid','sent_no_end'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmLLzsNtECDt"
      },
      "source": [
        "corpus_parags_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVkStzTrlxll"
      },
      "source": [
        "# Verify the Paragraph only DataFrame\n",
        "\n",
        "corpus_parags_df.head(2)\n",
        "corpus_parags_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkHIEWqEKz66"
      },
      "source": [
        "# Calculate the start, mid and end Sentence No for each Paragraph\n",
        "\n",
        "parag_sent_no_start_ls = np.array(corpus_sents_df.groupby('parag_no')['sent_no'].min())\n",
        "parag_sent_no_end_ls = np.array(corpus_sents_df.groupby('parag_no')['sent_no'].max())\n",
        "\n",
        "def my_mid(anum, bnum):\n",
        "  mid_no = (anum - bnum)//2 + bnum\n",
        "\n",
        "  return mid_no\n",
        "\n",
        "print('\\nParagraph Start Sentence no: -----')\n",
        "print(parag_sent_no_start_ls)\n",
        "\n",
        "parag_sent_no_mid_ls = list(map(my_mid, parag_sent_no_end_ls, parag_sent_no_start_ls))\n",
        "print('\\nParagraph Mid-Sentence no: -----')\n",
        "print(parag_sent_no_mid_ls)\n",
        "\n",
        "print('\\nParagraph End Sentence no: -----')\n",
        "print(parag_sent_no_end_ls)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbSi16c1Kz6_"
      },
      "source": [
        "# If necessary, delete prior columns to update DataFrame with new data\n",
        "\n",
        "# corpus_parags_df.drop(columns=['parag_no_start'], inplace=True)\n",
        "# corpus_parags_df.drop(columns=['parag_no_mid'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkdeR-S_Kz7B"
      },
      "source": [
        "# Insert 3 new columns on start,mid and end Sentence No for each Paragraph\n",
        "\n",
        "corpus_parags_df.insert(1, 'sent_no_start', parag_sent_no_start_ls)\n",
        "corpus_parags_df.insert(2, 'sent_no_mid', parag_sent_no_mid_ls)\n",
        "corpus_parags_df.insert(3, 'sent_no_end', parag_sent_no_end_ls)\n",
        "\n",
        "corpus_parags_df.head()\n",
        "                       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9uIWYnCLSr7"
      },
      "source": [
        "# Create a clean text version of each Paragraph\n",
        "\n",
        "# corpus_parags_df = pd.DataFrame({'parag_no':parag_no_ls, 'parag_raw':corpus_parags_ls})\n",
        "corpus_parags_df['parag_clean'] = corpus_parags_df['parag_raw'].apply(lambda x: clean_text(x))\n",
        "corpus_parags_df['parag_clean'] = corpus_parags_df['parag_clean'].astype('string')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gza5pqW3LSsF"
      },
      "source": [
        "# Compute Paragraph text Statistics\n",
        "\n",
        "corpus_parags_df['token_len'] = corpus_parags_df['parag_clean'].apply(lambda x: len(x.split()))\n",
        "corpus_parags_df['char_len'] = corpus_parags_df['parag_raw'].apply(lambda x: len(x))\n",
        "corpus_parags_df.head(2)\n",
        "corpus_parags_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOjESpbc6Izc"
      },
      "source": [
        "#### **Create Section DataFrame: [corpus_sects_df]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vITL5uo1ABR"
      },
      "source": [
        "# If Corpus has Sections, read Corpus and split into raw Sections\n",
        "#   else just copy Chapter data as pseudo Sections\n",
        "\n",
        "corpus_sects_ls = []    # List of all Section Numbers\n",
        "sent_sectno_ls = []     # Section Number for EVERY Matching Sentence in Corpus found in a Section\n",
        "sent_no_sectno_ls = []  # Sentence Number for for ANY Unmatched Sentence in Corpus NOT found in any Section\n",
        "\n",
        "\n",
        "if SECTION_HEADINGS == 'None':\n",
        "  # Just copy Chapter info\n",
        "  corpus_sects_ls = [x for x in corpus_chaps_ls]\n",
        "  print(f'No Sections in {CORPUS_FULL},\\n    so using Chapters as pseudo-Sections.')\n",
        "  sent_sectno_ls = sent_chap_no_ls # Every Sentence in Corpus belongs to the same SectionNo as CorpusNo\n",
        "\n",
        "else:\n",
        "\n",
        "  # Read corpus into a single string then split into raw Section\n",
        "\n",
        "  corpus_sects_ls, sent_sectno_ls, sent_no_sectno_ls = corpus2sects(CORPUS_FILENAME)\n",
        "  print(f'Found #{len(sent_sectno_ls)} Section\\n')\n",
        "\n",
        "  print('\\nThe first 5 Section of the Corpus (first 10 chars):')\n",
        "  print('-----------------------------------\\n')\n",
        "  sent_sectno_ls[:5][:10]\n",
        "  print('\\n')\n",
        "  print('\\n\\nThe last 5 Section of the Corpus (first 10 chars):')\n",
        "  print('-----------------------------------\\n')\n",
        "  sent_sectno_ls[-5:][:10]\n",
        "  print('\\n')\n",
        "\n",
        "  n_shortest = 10\n",
        "  print(f'The {n_shortest} shortest Section in the Corpus are:')\n",
        "  print('--------------------------------------------')\n",
        "  temp_sects_ls = sorted(sent_sectno_ls, key=lambda x: (len(x), x))\n",
        "  for i, asent in enumerate(temp_sects_ls[:n_shortest]):\n",
        "    print(f'Shortest Section #{i}: {asent}')\n",
        "\n",
        "\n",
        "  # Calculate Section Informationif SECTION_HEADINGS != 'None':\n",
        "  # encoding = 'windows-1252', 'utf-8', 'cp1252', 'iso-8859-1'\n",
        "  # with open(corpus_filename, \"r\", encoding='cp1252') as infp:\n",
        "  # with open(corpus_filename, \"r\", encoding='cp1252') as infp:\n",
        "  # with open(corpus_filename, \"r\", encoding='cp1252') as infp:\n",
        "\n",
        "  \"\"\"\n",
        "  with open(corpus_filename, \"r\", encoding='utf-8') as infp:\n",
        "    corpus_raw_str = infp.read()\n",
        "\n",
        "  len(corpus_raw_str)\n",
        "\n",
        "  # Extract and process Sections from Corpus\n",
        "  corpus_sects_ls, corpus_str_raw = corpus2sects(corpus_filename)\n",
        "\n",
        "  print('\\n\\nAFTER ----------')\n",
        "  print(f'len(corpus_raw_str): {len(corpus_raw_str)}')\n",
        "  print(\"\\n\\n-----\")\n",
        "  print(f'len(corpus_sects_ls): {len(corpus_sects_ls)}\\n\\n')\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  print(\"\\n\\n-----\")\n",
        "  print(f'corpus_sects_ls[0]:\\n\\n    {corpus_sects_ls[0]}')\n",
        "  print(\"\\n\\n-----\")\n",
        "  print(f'corpus_sects_ls[1]:\\n\\n    {corpus_sects_ls[1]}')\n",
        "  print(\"\\n\\n-----\")\n",
        "  print(f'corpus_sects_ls[2]:\\n\\n    {corpus_sects_ls[2]}')\n",
        "  print(\"\\n\\n-----\")\n",
        "  print(f'corpus_sects_ls[-2]:\\n\\n    {corpus_sects_ls[-2]}')\n",
        "  print(\"\\n\\n-----\")\n",
        "  print(f'corpus_sects_ls[-1]:\\n\\n    {corpus_sects_ls[-1]}')\n",
        "  \"\"\";\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1MJfVfpKOU-"
      },
      "source": [
        "# Create a list of the Sentence Nos associated with each Section in the Corpus\n",
        "\n",
        "# sent_chap_no_ls = [sentnochapno_tp[1] for sentnochapno_tp in corpus_sents2chap_ls]\n",
        "\n",
        "corpus_sent_ct = corpus_sents_df.shape[0]\n",
        "sect_sent_ct = len(sent_sectno_ls)\n",
        "if (corpus_sent_ct == sect_sent_ct):\n",
        "  print(f'GOOD, all {corpus_sent_ct} Sentences were matched in one of the {corpus_sects_df.shape[0]} Sections\\n')\n",
        "else:\n",
        "  print(f'WARNING: only {sect_sent_ct} Sentences were matched in one of the {corpus_sects_df.shape[0]} Sections')\n",
        "  print(f'         {corpus_sent_ct - sect_sent_ct} Sentences were not matched\\n')\n",
        "\n",
        "\n",
        "# print(f'There are {corpus_sents_df.shape[0]} Sentences in the Corpus')\n",
        "# print(f'{len(sent_chap_no_ls)} Sentences have been associated with {corpus_chaps_df.shape[0]} Sections\\n')\n",
        "\n",
        "print(f'First 10 Sentences belong to these Sections:\\n    {sent_sectno_ls[:10]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqKwpPs9JC0R"
      },
      "source": [
        "# Verify Sections found and Sentence-Section matches\n",
        "\n",
        "print(f'{len(corpus_sects_ls)} Sections found in Corpus')\n",
        "print(f'{len(sent_sectno_ls)} Sentences found in a Section')\n",
        "\n",
        "sentences_nosection_ct = len(sent_no_sectno_ls)\n",
        "\n",
        "if (sentences_nosection_ct > 0):\n",
        "  print(f'\\n    WARNING: The following {sentences_nosection_ct} Sentences were NOT FOUND in any Section')\n",
        "  print(f'             If these are important/numerous, go back and edit/correct source Corpus text file and rerun this notebook\\n')\n",
        "\n",
        "  for i, asent in enumerate(sentences_nosection_ls):\n",
        "    print(f'    #{i}: {asent}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JFQTmEgK66I"
      },
      "source": [
        "# Create DataFrame from list of Sections extracted from Corpus\n",
        "\n",
        "sect_no_ls = list(range(len(corpus_sects_ls)))\n",
        "corpus_sects_df = pd.DataFrame({'sect_no':sect_no_ls, 'sect_raw':corpus_sects_ls})\n",
        "corpus_sects_df['sect_raw'] = corpus_sects_df['sect_raw'].astype('string')\n",
        "corpus_sects_df.head(1)\n",
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjN6omWrifWm"
      },
      "source": [
        "# Create a list of the Sentence Nos associated with each Section in the Corpus\n",
        "\n",
        "# sentno_sectno_ls = [sentno2sectno_tp[0] for sentno2sectno_tp in sentences_section_ls]\n",
        "# sentstr_sectno_ls = [sentno2sectno_tp[1] for sentno2sectno_tp in sentences_section_ls]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KM-JEKECfSa"
      },
      "source": [
        "# corpus_sents_df.drop(columns=['sect_no'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpAlcbpQru0t"
      },
      "source": [
        "# Add Section No for each Sentence in Master DataFrame corpus_all_df\n",
        "# ONLY RUN THIS CODE CELL ONCE\n",
        "\n",
        "# Test if already exists, if not execute\n",
        "corpus_sents_df.insert(3, 'sect_no', sent_sectno_ls)  # This can only be run once\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "353_Nn7pM1FX"
      },
      "source": [
        "# Verify\n",
        "\n",
        "corpus_sents_df.head(2)\n",
        "corpus_sents_df.tail(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpE0UiORYZy6"
      },
      "source": [
        "# Verfiy correct Section Nos using the Sentence No boundaries found in previous code cell\n",
        "#   Search for iloc index ranges containing 1 or more Section boundaries to check correctness\n",
        "\n",
        "corpus_sents_df.iloc[300:500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVNIhlQpNZiV"
      },
      "source": [
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yG53MVwkNHB"
      },
      "source": [
        "# Calculate the start, mid and end Sentence No for each Section\n",
        "\n",
        "sect_sent_no_start_ls = np.array(corpus_sents_df.groupby('sect_no')['sent_no'].min())\n",
        "sect_sent_no_end_ls = np.array(corpus_sents_df.groupby('sect_no')['sent_no'].max())\n",
        "\n",
        "def my_mid(anum, bnum):\n",
        "  mid_no = (anum - bnum)//2 + bnum\n",
        "\n",
        "  return mid_no\n",
        "\n",
        "print('\\nSection start sentence no: -----')\n",
        "print(sect_sent_no_start_ls)\n",
        "\n",
        "sect_sent_no_mid_ls = list(map(my_mid, sect_sent_no_end_ls, sect_sent_no_start_ls))\n",
        "print('\\nSection mid-sentence no: -----')\n",
        "print(sect_sent_no_mid_ls)\n",
        "\n",
        "print('\\nSection end sentence no: -----')\n",
        "print(sect_sent_no_end_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUofWkm0kNHC"
      },
      "source": [
        "# If necessary, delete prior columns to update DataFrame with new data\n",
        "\n",
        "# corpus_chaps_df.drop(columns=['parag_no_start'], inplace=True)\n",
        "# corpus_chaps_df.drop(columns=['parag_no_mid'], inplace=True)\n",
        "# corpus_chaps_df.drop(columns=['parag_no_end'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HxCqi2XkNHC"
      },
      "source": [
        "# Verify DataFrame before update\n",
        "\n",
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhfgZuiPkNHD"
      },
      "source": [
        "# Insert 3 new columns on start,mid and end Sentence No for each Section\n",
        "\n",
        "corpus_sects_df.insert(1, 'sent_no_start', sect_sent_no_start_ls)\n",
        "corpus_sects_df.insert(2, 'sent_no_mid', sect_sent_no_mid_ls)\n",
        "corpus_sects_df.insert(3, 'sent_no_end', sect_sent_no_end_ls)\n",
        "\n",
        "corpus_sects_df.loc[:, corpus_sects_df.columns != 'sect_raw']\n",
        "# corpus_sects_df.loc[:, ['sect_no', 'sect_no_start', 'sect_no_mid', 'sect_no_end']]\n",
        "corpus_sects_df.info()\n",
        "\n",
        "                       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iObHkdhmkNHF"
      },
      "source": [
        "# Create a clean text version of each Paragraph\n",
        "\n",
        "corpus_sects_df['sect_clean'] = corpus_sects_df['sect_raw'].apply(lambda x: clean_text(x))\n",
        "corpus_sects_df['sect_clean'] = corpus_sects_df['sect_clean'].astype('string')\n",
        "\n",
        "# corpus_sects_df.loc[:, corpus_sects_df.columns != 'sect_raw']\n",
        "corpus_sects_df.filter(like='_no')\n",
        "# corpus_sects_df.loc[:, ['sect_no', 'sect_no_start', 'sect_no_mid', 'sect_no_end']]\n",
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFDwD6M-kNHH"
      },
      "source": [
        "# Compute Paragraph text Statistics\n",
        "\n",
        "corpus_sects_df['token_len'] = corpus_sects_df['sect_clean'].apply(lambda x: len(x.split()))\n",
        "corpus_sects_df['char_len'] = corpus_sects_df['sect_raw'].apply(lambda x: len(x))\n",
        "corpus_sects_df.loc[:, list(set(corpus_sects_df.columns) - set(['sect_raw', 'sect_clean']))]\n",
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SdZ4e3ALYdD"
      },
      "source": [
        "### **Add Descriptive Statistics and Clean Raw Text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWu8_C6PQ4iE"
      },
      "source": [
        "corpus_sents_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7au9Zy2kR0NK"
      },
      "source": [
        "# TODO: Verfiy and eal with any NaN entries\n",
        "#   all Sentences with NaN or '' Raw Text\n",
        "\"\"\"\n",
        "\n",
        "# Sentences\n",
        "# Let's take a look at the updated text\n",
        "corpus_sents_df['sent_clean'] = corpus_sents_df['sent_raw'].apply(lambda x: text_clean(x))\n",
        "# Ensure to drop all Sentences with NaN or '' Raw Textcorpus_sents_df.replace(\"\", np.nan, regex=True, inplace=True)\n",
        "corpus_sents_df.dropna(how='any', axis=0, subset=['sent_raw'], inplace=True)\n",
        "corpus_sents_df.dropna(how='any', axis=0, subset=['sent_clean'], inplace=True)\n",
        "\n",
        "print('\\nCompare Raw and Cleaned Sentences:')\n",
        "print('--------------------------------------')\n",
        "corpus_sents_df.head(2)\n",
        "\n",
        "\n",
        "# Paragraphs\n",
        "# Let's take a look at the updated text\n",
        "corpus_parags_df['parag_clean'] = corpus_parags_df['parag_raw'].apply(lambda x: text_clean(x))\n",
        "# Ensure to drop all Sentences with NaN or '' Raw Text\n",
        "corpus_parags_df.replace(\"\", np.nan, regex=True, inplace=True)\n",
        "corpus_parags_df.dropna(how='any', axis=0, subset=['parag_raw'], inplace=True)\n",
        "\n",
        "print('\\nCompare Raw and Cleaned Paragraphs:')\n",
        "print('--------------------------------------')\n",
        "corpus_parags_df.head(2)\n",
        "\n",
        "\n",
        "# Sections\n",
        "# Let's take a look at the updated text\n",
        "corpus_sects_df['sect_clean'] = corpus_sects_df['sect_raw'].apply(lambda x: text_clean(x))\n",
        "# Ensure to drop all Sentences with NaN or '' Raw Text\n",
        "corpus_sects_df.replace(\"\", np.nan, regex=True, inplace=True)\n",
        "corpus_sects_df.dropna(how='any', axis=0, subset=['sect_raw'], inplace=True)\n",
        "\n",
        "print('\\nCompare Raw and Cleaned Sections:')\n",
        "print('--------------------------------------')\n",
        "# corpus_sects_df.head(2)\n",
        "\n",
        "\n",
        "# Chapters\n",
        "# Let's take a look at the updated text\n",
        "corpus_chaps_df['chap_clean'] = corpus_chaps_df['chap_raw'].apply(lambda x: text_clean(x))\n",
        "# Ensure to drop all Chapters with NaN or '' Raw Text\n",
        "corpus_chaps_df.replace(\"\", np.nan, regex=True, inplace=True)\n",
        "corpus_chaps_df.dropna(how='any', axis=0, subset=['chap_raw'], inplace=True)\n",
        "\n",
        "print('\\nCompare Raw and Cleaned Chapters:')\n",
        "print('--------------------------------------')\n",
        "# corpus_sects_df.head(2)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf99apfwKPAO"
      },
      "source": [
        "# Verify shapes of all 4 Baseline 4 Models\n",
        "\n",
        "print(f'corpus_sents_df.shape: {corpus_sents_df.shape}')\n",
        "print(f'corpus_parags_df.shape: {corpus_parags_df.shape}')\n",
        "print(f'corpus_sects_df.shape: {corpus_sects_df.shape}')\n",
        "print(f'corpus_chaps_df.shape: {corpus_chaps_df.shape}')\n",
        "\n",
        "\"\"\"\n",
        "SButler Odyssey\n",
        "\n",
        "corpus_sents_df.shape: (2445, 8)\n",
        "corpus_parags_df.shape: (1051, 8)\n",
        "corpus_sects_df.shape: (24, 8)\n",
        "corpus_chaps_df.shape: (24, 8)\n",
        "\"\"\";\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHscLkclSYqN"
      },
      "source": [
        "##**Save Preprocess Corpus DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEzo8eltSvWS"
      },
      "source": [
        "# Save Corpus DataFrames\n",
        "\n",
        "save_dataframes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL8R_ANtfYG6"
      },
      "source": [
        "# (Optional) EDA Raw Text Features: Interactive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1njcRD-jgGJh"
      },
      "source": [
        "**(Optional) Can Skip Ahead to: 'EDA of Raw Text and Extracted Features'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ti9jQK7grxO"
      },
      "source": [
        "# Review Cleaned Up Sentences\n",
        "\n",
        "corpus_sents_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TN5ksy55kXy"
      },
      "source": [
        "# Summary Statistics\n",
        "\n",
        "corpus_sents_df.describe()\n",
        "corpus_sents_df['token_len'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxvxkbUGzkfy"
      },
      "source": [
        "# Create histogram of Paragraph lengths\n",
        "\n",
        "sns.histplot(data=corpus_sents_df['char_len'], kde=True).set_title(f'{CORPUS_FULL} \\n Histogram of Paragraph Lengths');\n",
        "\n",
        "if (PLOT_OUTPUT == 'All'):\n",
        "  # Save graph to file.\n",
        "  plot_filename = 'hist_paraglen.png'\n",
        "  plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "  plt.savefig(plotpathfilename_str, format='png', dpi=300)\n",
        "  print(f'Plot saved: {plot_filename}');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqUtGz8UjY2b"
      },
      "source": [
        "# Plot histogram of Sentence lengths\n",
        "\n",
        "sns.histplot(data=corpus_sents_df['token_len'], kde=True).set_title(f'{CORPUS_FULL} \\n Histogram of Sentence Lengths')\n",
        "\n",
        "if (PLOT_OUTPUT == 'All'):\n",
        "  # Save graph to file.\n",
        "  plot_filename = 'hist_sentlen.png'\n",
        "  plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "  plt.savefig(plotpathfilename_str, format='png', dpi=300)\n",
        "  print(f'Plot saved: {plot_filename}');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OoBrucYR9Xc"
      },
      "source": [
        "# SELECT CORPUS TYPE\n",
        "# TODO: Customized Preprocessing (e.g. Tweets) by Corpus Type\n",
        "\n",
        "# Novel, Tweets, Chat Transcript\n",
        "\n",
        "# Processing Options\n",
        "\n",
        "# Apply first level cleaning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2tIua7tTSRz"
      },
      "source": [
        "# (Optional) Manually Create Sentiment Arc Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU11XOZIPalR"
      },
      "source": [
        "***Can skip to Section [Load Sentiment Polarities...] or [Calculate VADER...]***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cke3OowdWk6I"
      },
      "source": [
        "**Interactively Enter Cruxes and Edge Cases**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv7Foe3oTMmz"
      },
      "source": [
        "# Setup data structures for endpoints of Sentiment Time Series\n",
        "\n",
        "#   [-1.0 to +1.0] = [v.neg, neg, neutral, pos, v.pos]\n",
        "\n",
        "corpus_man_crux_ols = []  # working datastructure to dynamically build ordered list of manually selected Crux Points\n",
        "corpus_man_cruxes_odt = OrderedDict() # Once all manual Crux points selected, this will be working data structure\n",
        "\n",
        "corpus_sents_len = corpus_sents_df.shape[0] - 1\n",
        "\n",
        "corpus_parags_len = corpus_sents_df.parag_no.max() # make sure no omissions/repeats/skips\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-_ylgiAc6Aw"
      },
      "source": [
        "# <INPUT> Set the Begining and Ending Sentiment Values (Manual Versions)\n",
        "\n",
        "# Start of Corpus Sentiment Analysis Time Series\n",
        "Corpus_Starting_Sentiment = -0.1 #@param {type:\"slider\", min:-1, max:1, step:0.1}\n",
        "# corpus_sa_begin = Corpus_Starting_Sentiment\n",
        "\n",
        "# End of Corpus Sentiment Analysis Time Series\n",
        "Corpus_Ending_Sentiment = -1 #@param {type:\"slider\", min:-1, max:1, step:0.1}\n",
        "# corpus_sa_end = Corpus_Ending_Sentiment\n",
        "\n",
        "corpus_man_crux_ols = [tuple((0, Corpus_Starting_Sentiment)), tuple((corpus_sents_len, Corpus_Ending_Sentiment))]\n",
        "# corpus_man_cruxes_dt[0.] = corpus_sa_begin\n",
        "# corpus_man_cruxes_dt[float(corpus_sents_len)] = corpus_sa_end\n",
        "\n",
        "print(f'Manual Cruxes with Start/End: {corpus_man_crux_ols}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmcLrzyUw93d"
      },
      "source": [
        "**Seach for Key Words that suggest Min/Max Sentiment Crux**\n",
        "* Specific to the Novel: Introduction of Pivotal Character, Scene, Factual Reveal, McGuffin, etc...\n",
        "* General to Events/Themes: Death, Birth, Fight, Accident, Money, Sex, etc... "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UESgwwIAY28T"
      },
      "source": [
        "# <INPUT> Search Corpus for Line No of Peaks/Valleys\n",
        "# TODO: Better Vis\n",
        "Search_String = \"Death\" #@param {type:\"string\"}\n",
        "if (Search_String == \"\"):\n",
        "  search_str = \"accident\"\n",
        "else:\n",
        "  search_str = Search_String.lower()\n",
        "\n",
        "# search the list of cleaned paragraphs\n",
        "# results_ls = [x for x in search_match_ls if re.search(subs, x)]\n",
        "\n",
        "# creating and passsing series to new column\n",
        "match_sents_ser = corpus_sents_df[\"sent_clean\"].str.find(search_str)\n",
        "\n",
        "# print(f'Found #{len(match_index>0)} Matches')\n",
        "match_sents_df = corpus_sents_df.loc[match_sents_ser > 0]\n",
        "print(f'Found #{match_sents_df.shape[0]} Matching Sentences')\n",
        "print('------------------------------------')\n",
        "# print(f'  {match_sents_df}')\n",
        "match_sents_df[['sent_no', 'parag_no', 'sent_raw', 'token_len']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oVYBfz6-EVo"
      },
      "source": [
        "**Get Context for Matched Sentence by Retrieving Surrounding Paragraph**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AvYQqT5TsdV"
      },
      "source": [
        "# Extract Surrounding Paragraphs for context on matching Sentences\n",
        "\n",
        "def get_parag4sentno(asent_no):\n",
        "  '''\n",
        "  Return the original raw paragraph containing a \n",
        "  given sentence number.\n",
        "  '''\n",
        "  # parag_df = pd.DataFrame()\n",
        "  # print(f'Passed in sent_no: {asent_no}')\n",
        "  aparag_no = int(corpus_sents_df.loc[corpus_sents_df['sent_no'] == asent_no]['parag_no'])\n",
        "  # print(f'  This sent_no {asent_no} is in parag_no: {aparag_no}')\n",
        "  aparag_str = corpus_sents_df.loc[corpus_sents_df['parag_no'] == aparag_no]['sent_raw'].str.cat() # ['sent_clean']\n",
        "  # sentno_parag_df = corpus_sents_df[corpus_sents_df['sent_no']==asent_no]\n",
        "  # print(f'Sent #{asent_no} is in the paragraph: ')\n",
        "  # print(aparag)\n",
        "  # print(f'returning aparag_no: [{aparag_no}]: {aparag}')\n",
        "  return aparag_no, aparag_str\n",
        "\n",
        "'''\n",
        "# Testing\n",
        "asent_no = 7\n",
        "print(f'Searching for paragraph containing Sentence #{asent_no}')\n",
        "\n",
        "aparag_no, aparag_str = get_parag4sentno(asent_no)\n",
        "print(f'\\n  Found in Paragraph #{aparag_no} \\n\\n{aparag_str}')\n",
        "''';"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnHz08NyDroK"
      },
      "source": [
        "# Extract Surrounding Paragraphs for context on matching Sentences\n",
        "\n",
        "def get_parag_str(aparag_no):\n",
        "  '''\n",
        "  Return the original raw paragraph containing a \n",
        "  given sentence number.\n",
        "  '''\n",
        "  # parag_df = pd.DataFrame()\n",
        "  # print(f'Passed in sent_no: {asent_no}')\n",
        "  # aparag_no = int(corpus_sents_df.loc[corpus_sents_df['sent_no'] == asent_no]['parag_no'])\n",
        "  # print(f'  This sent_no {asent_no} is in parag_no: {aparag_no}')\n",
        "  aparag_str = corpus_sents_df.loc[corpus_sents_df['parag_no'] == aparag_no]['sent_raw'].str.cat() # ['sent_clean']\n",
        "  # sentno_parag_df = corpus_sents_df[corpus_sents_df['sent_no']==asent_no]\n",
        "  # print(f'Sent #{asent_no} is in the paragraph: ')\n",
        "  # print(aparag)\n",
        "  # print(f'returning aparag_no: [{aparag_no}]: {aparag}')\n",
        "  return aparag_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByKLYZDsK123"
      },
      "source": [
        "# Summarize current status of manually selected Crux Points\n",
        "# TODO:\n",
        "\n",
        "def crux_sum_short():\n",
        "  print(f'\\nOrdered list of all manually selected Crux Points')\n",
        "  print('---------------------------------------')\n",
        "  for i, acrux_tp in enumerate(corpus_man_crux_ols):\n",
        "    asent_no, asent_pol = acrux_tp\n",
        "    asent_str = corpus_sents_df[corpus_sents_df.sent_no==asent_no].sent_raw.str.cat()\n",
        "    # print(f'Type: {type(asent_str)}')\n",
        "    print(f'Sent No {asent_no:4d}: Polarity: {asent_pol}\\nText: {asent_str}\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz0FLzt2UeSe"
      },
      "source": [
        "# Summarize current manually selected Crux Points\n",
        "\n",
        "def crux_summary():\n",
        "  print(f'\\nOrdered list of all manually selected Crux Points')\n",
        "  print('---------------------------------------\\n\\n')\n",
        "  for i, acrux_tp in enumerate(corpus_man_crux_ols):\n",
        "    asent_no, asent_pol = acrux_tp\n",
        "    asent_str = corpus_sents_df[corpus_sents_df.sent_no==asent_no].sent_raw.str.cat()\n",
        "    # print(f'Type: {type(asent_str)}')\n",
        "    print(f'Sent No {asent_no:4d}: Polarity: {asent_pol}')\n",
        "    print('------------------------------')\n",
        "    print(f'Text: {asent_str}\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiUmseNw3CkN"
      },
      "source": [
        "# View the Paragraph containing your Matching Sentence:\n",
        "\n",
        "def get_nparags_context(crux_sent_no, parag_ct):\n",
        "\n",
        "  parag_win = int(parag_ct)\n",
        "  parag_crux_str = ''\n",
        "\n",
        "  parag_crux_no = 0\n",
        "\n",
        "  if (crux_sent_no < 0) | (crux_sent_no > corpus_sents_len):\n",
        "    print(f'ERROR: Pick a Sentence No between 0-{corpus_sents_len-1}')\n",
        "  else:\n",
        "    # get_sent_no = crux_sent_no\n",
        "    # print(f'Retrieving Sentence No: {get_sent_no}')\n",
        "    # print('----------')\n",
        "\n",
        "    parag_crux_no, aparag_str = get_parag4sentno(crux_sent_no)\n",
        "    if parag_win == 1:\n",
        "      print(f'Match #{i}: Sentence No. {asent_no} found in Paragraph No. {parag_crux_no}')\n",
        "      print('----------------------------')\n",
        "      print(f'Sentence:\\n')\n",
        "      # print(f'     {corpus_sents_df[corpus_sents_df.sent_no == crux_sent_no]}\\n\\n')\n",
        "      corpus_sents_df[corpus_sents_df.sent_no == crux_sent_no]\n",
        "      print('----------------------------')\n",
        "      print(f'Paragraph Context:\\n')\n",
        "      print(f'     {aparag_str}\\n\\n')\n",
        "    else:\n",
        "      parag_half_win = int((parag_win-1)/2)\n",
        "      parag_start = parag_crux_no - parag_half_win\n",
        "      parag_end = parag_crux_no + parag_half_win\n",
        "      print(f'Retrieving {parag_ct} Contextual Paragraphs Nos {parag_start} to {parag_end}')\n",
        "      print(f'  for Crux Point centered on Sentence No {crux_sent_no}')\n",
        "      for i in range(parag_start, parag_end + 1, 1):\n",
        "        if i == parag_crux_no:\n",
        "          print(f'\\n   ---------------------------------------------------------')\n",
        "          print(f'** Crux Point Paragraph #{i} with Sentence No. {crux_sent_no} **')\n",
        "          print(f'   ---------------------------------------------------------')\n",
        "          parag_crux_str = get_parag_str(i)\n",
        "          print(parag_crux_str)\n",
        "        else:\n",
        "          print(f'\\n   ----------------------')\n",
        "          print(f'   Regular Paragraph #{i}')\n",
        "          print(f'   ----------------------')\n",
        "          print(get_parag_str(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjoXC8Fg3lBP"
      },
      "source": [
        "# Insert new crux point into ordered list: corpus_man_crux_ls\n",
        "\n",
        "# NOTE: For very long lists, use Python simple bisect library (at cost of additional dependency)\n",
        "\n",
        "\n",
        "def insert_ord_tp_list(crux_ord_ols, crux_tp):\n",
        "  '''\n",
        "  Insert new crux tuple: crux_tp = (sent_no, sentiment_polarity)\n",
        "  into ordered list of tuples while maintaining sent_no order\n",
        "  '''\n",
        "  sent_no, senti_pol = crux_tp\n",
        "\n",
        "  # Searching for the position\n",
        "  for i in range(len(crux_ord_ols)):\n",
        "    if crux_ord_ols[i][0] == sent_no:\n",
        "      # Attempting to insert duplicate\n",
        "      return crux_ord_ols\n",
        "    elif crux_ord_ols[i][0] < sent_no:\n",
        "      insert_idx = i\n",
        "    else:\n",
        "      break\n",
        "      \n",
        "  # Inserting n in the list\n",
        "  list = crux_ord_ols[:i] + [crux_tp] + crux_ord_ols[i:]\n",
        "  return list\n",
        "\n",
        "'''\n",
        "# Test\n",
        "crux_test_ls = [(1,0), (5,1), (10,-1)]\n",
        "crux_test_tp = (3,10)\n",
        "  \n",
        "print(insert_ord_tp_list(crux_test_ls, crux_test_tp))\n",
        "''';"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PPOLJDZ1wHc"
      },
      "source": [
        "**Start of Human in the Loop Manual Crux Point Identification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1MLexX57Guc"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "print('Enter a Sentence number based upon your search above to see the ')\n",
        "print('  surrounding Paragraph context.')\n",
        "print('----------------------------------------')\n",
        "print(f'(Enter an integer between 0 and {corpus_sents_len-1})\\n\\n')\n",
        "\n",
        "print('\\n')\n",
        "print('Enter an ODD NUMBER for the Number of surrounding Paragraphs ')\n",
        "print('  around the Sentence No to give Context.')\n",
        "print('----------------------------------------')\n",
        "print(f'(Enter an integer: 3, 5, 7\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exxWtaUPC30l"
      },
      "source": [
        "# Input your Context Retrieval Parameters\n",
        "\n",
        "Sentence_No =  2692#@param {type:\"integer\"}\n",
        "No_Paragraphs_Context = \"3\" #@param [\"1\", \"3\", \"5\"]\n",
        "\n",
        "get_nparags_context(Sentence_No, No_Paragraphs_Context)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30fBikIrrgMe"
      },
      "source": [
        "**Add Crux to Manually Generated Sentiment Arc**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgljeT6ypNbo"
      },
      "source": [
        "# Instructions to add current sentence as a Crux Point\n",
        "\n",
        "crux_summary()\n",
        "\n",
        "print('--------------------------------------------------------')\n",
        "print(f'INSTRUCTIONS To current Sentence No: {Sentence_No} as a Crux Point')\n",
        "print('--------------------------------------------------------')\n",
        "\n",
        "print(\"\\nCheck this box if you want to add the Sentence/Paragraph above \")\n",
        "print(\"  as a new Min/Max Crux Point with your approximation \")\n",
        "print(\"  for a Sentiment Polarity value between -1.0 to +1.0\\n\\n\")\n",
        "\n",
        "print(f\"Crux Sentence No: {Sentence_No} in Paragraph No: {parag_crux_no}\\n\")\n",
        "print(parag_crux_str)\n",
        "\n",
        "print(\"\\n\\nLeave Add_Sentence_Crux 'unchecked' to not add\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia1IXChRmyr3"
      },
      "source": [
        "# <INPUT> Option to add this Sentence/Paragraph as a Min/Max Crux Point\n",
        "\n",
        "Sentiment_Polarity = -0.4 #@param {type:\"slider\", min:-1, max:1, step:0.1}\n",
        "Add_Sentence_Crux = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# Add Crux if selected and give current summary status\n",
        "\n",
        "if Add_Sentence_Crux == True:\n",
        "  crux_new_tp = tuple((Sentence_No, Sentiment_Polarity))\n",
        "  corpus_man_crux_ols = insert_ord_tp_list(corpus_man_crux_ols, crux_new_tp)\n",
        "  if (corpus_man_crux_ols):\n",
        "    print(f'Successfully inserted new Crux = {crux_new_tp}')\n",
        "    print(f'Added Crux at Sentence No={Sentence_No} with Polarity={Sentiment_Polarity}')\n",
        "    # corpus_man_cruxes_dt[Sentence_No] = Sentiment_Polarity\n",
        "  else:\n",
        "    print(f'ERROR: Could not insert new Crux = {crux_new_tp}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lps67T-lUTi2"
      },
      "source": [
        "# Summary of current Crux Points after addition\n",
        "\n",
        "print('\\n------------------------------------------------------------')\n",
        "print(f'After addition of new Crux Point (Sentence No {Sentence_No})')\n",
        "print('------------------------------------------------------------\\n')\n",
        "\n",
        "crux_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjZT9_0CrzFk"
      },
      "source": [
        "**Delete Manually Selected Crux Points**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTX30nokNPBp"
      },
      "source": [
        "len(corpus_man_crux_ols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxS-J_hPOfkI"
      },
      "source": [
        "crux_tp = (1, 2)\n",
        "a, b = crux_tp\n",
        "print(f'a is {a} and b is {b}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi7Cu1iErvzc"
      },
      "source": [
        "# Insert new crux point into ordered list: corpus_man_crux_ls\n",
        "\n",
        "# FIX: 20210616 and move to utility functions\n",
        "\n",
        "# NOTE: For very long lists, use Python simple bisect library (at cost of additional dependency)\n",
        "\n",
        "\n",
        "def del_ord_tp_list(acorpus_man_crux_ols, crux_tp):\n",
        "  '''\n",
        "  Insert new crux tuple: crux_tp = (sent_no, sentiment_polarity)\n",
        "  into ordered list of tuples while maintaining sent_no order\n",
        "  '''\n",
        "  crux_ct = len(acorpus_man_crux_ols)\n",
        "  sent_no = crux_tp[0]\n",
        "  print(f'Deleting sent_no: {sent_no} over crux_ls len={len(acorpus_man_crux_ols)}')\n",
        "\n",
        "  # Searching for the positionk\n",
        "  del_idx = -1\n",
        "  for i in range(len(acorpus_man_crux_ols)):\n",
        "    acrux_sent_no = acorpus_man_crux_ols[i][0]\n",
        "    print(f'Crux #{i} is sent_no={acrux_sent_no}')\n",
        "    if acrux_sent_no == sent_no:\n",
        "      print(f'Matching index at {i}')\n",
        "      del_idx = i\n",
        "      \n",
        "  # Delete n in the list\n",
        "  print(f'Deletion index = {del_idx}')\n",
        "  if del_idx == 0:\n",
        "    # Delete the first Crux\n",
        "    list = acorpus_man_crux_ols[1:]\n",
        "    return list\n",
        "  elif del_idx == crux_ct -1:\n",
        "    # Delete the last Crux\n",
        "    list = acorpus_man_crux_ols[:-1]\n",
        "    return list    \n",
        "  elif (del_idx > 0) & (del_idx < crux_ct):\n",
        "    # Delete an interior Crux\n",
        "    before_idx = i - 1\n",
        "    after_idx = i\n",
        "    list = acorpus_man_crux_ols[:before_idx] + acorpus_man_crux_ols[after_idx:]\n",
        "    print(f'Returning list: {list}')\n",
        "    return list\n",
        "  else:\n",
        "    print('No matching Crux tuple found')\n",
        "    return acorpus_man_crux_ols\n",
        "  \n",
        "\n",
        "# Test\n",
        "crux_test_ls = [(1,0), (5,1), (10,-1)]\n",
        "crux_test_tp = (5,5)\n",
        "  \n",
        "print(del_ord_tp_list(crux_test_ls, crux_test_tp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI5hZqmSLg5R"
      },
      "source": [
        "# Instructions to Delete a Crux Point\n",
        "\n",
        "crux_summary()\n",
        "\n",
        "print('--------------------------------------------------------')\n",
        "print('INSTRUCTIONS To Delete a Crux Point')\n",
        "print('--------------------------------------------------------')\n",
        "\n",
        "print(\"\\nEnter the Sentence No of a Crux you want to delete.\\n\")\n",
        "print(f'     Current Crux Points by Sentence No: {corpus_man_crux_ols}\\n\\n')\n",
        "print(\" Skip this if you want to keep all manually selected Crux Points.\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzowFY-I8U1_"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "print(\"\\nEnter the Sentence No of a Crux you want to delete.\\n\")\n",
        "print(f'     Current Crux Points by Sentence No: {corpus_man_crux_ols}\\n\\n')\n",
        "print(\" Skip this if you want to keep all manually selected Crux Points.\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ShFCfOsrvsv"
      },
      "source": [
        "Delete_Sent_No =  777#@param {type:\"integer\"}\n",
        "# Select a Crux to Delete\n",
        "# TODO: Drop down list\n",
        "\n",
        "# corpus_man_crux_ols\n",
        "corpus_man_crux_temp_ols = []\n",
        "\n",
        "crux_sent_set = set([x[0] for x in corpus_man_crux_ols])\n",
        "if not(Delete_Sent_No in crux_sent_set):\n",
        "  print(f'ERROR: {Delete_Sent_No} is not a Crux Point Sentence No')\n",
        "else:\n",
        "  # Keep the same tuple format for uniformity and future features\n",
        "  crux_del_tp = tuple((Delete_Sent_No, 'dummy_sentence'))\n",
        "  print(f'Selected {(crux_del_tp)} to delete')\n",
        "  # corpus_man_crux_temp_ols = \n",
        "  print(f'WTF: {del_ord_tp_list(corpus_man_crux_ols, crux_del_tp)}')\n",
        "  corpus_man_crux_old = del_ord_tp_list(corpus_man_crux_ols, crux_del_tp)\n",
        "  print(f\"corpus_man_crux_ols: {corpus_man_crux_ols}\")\n",
        "  # get_sent_no = Sentence_No\n",
        "  # print(f'Retrieving Sentence No: {get_sent_no}')\n",
        "  # print('----------')\n",
        "  print(f'Updated Crux Points by Sentence No: {corpus_man_crux_ols}\\n\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJdNu-oYrwHv"
      },
      "source": [
        "**Review Summary of all Manually Selected Crux Points**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmpggAWuvMb1"
      },
      "source": [
        "# Generate Report Summary of All Manually Selected Cruxes\n",
        "\n",
        "f = io.StringIO()\n",
        "with contextlib.redirect_stdout(f):\n",
        "    crux_summary()\n",
        "crux_summary = f.getvalue()\n",
        "\n",
        "# Print Manual Crux Report Summary to Screen\n",
        "\n",
        "# print(crux_summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ULFfHbxwDfu"
      },
      "source": [
        "# Save Manual Crux Summary Report\n",
        "\n",
        "plot_filename = 'man_cruxes.txt'\n",
        "plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "\n",
        "with open(plotpathfilename_str, 'a+') as outfp:\n",
        "  outfp.write(crux_summary)\n",
        "\n",
        "# Verify \n",
        "\n",
        "!ls -alt $plotpathfilename_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG_hGPgjxY7X"
      },
      "source": [
        "# Verify Report Content\n",
        "\n",
        "!cat man_cruxes_fscottfitzgerald_thegreatgatsby_20210616214050.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zPYRKCex8-U"
      },
      "source": [
        "**Clean and Organize Manual Crux Points into new Data Structures**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YICJNt3AXI2d"
      },
      "source": [
        "print(corpus_sents_df[corpus_sents_df['sent_no']==5]['sent_raw'].squeeze())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2bLtpweWQt4"
      },
      "source": [
        "# Convert and assemble all the Crux values in lists to save in a new Crux DataFrame\n",
        "\n",
        "\n",
        "pol_val_ls = [x[1] for x in corpus_man_crux_ols]\n",
        "sent_no_ls = [x[0] for x in corpus_man_crux_ols]\n",
        "parag_no_ls = [(get_parag4sentno(x))[0] for x in sent_no_ls]\n",
        "parag_str_ls = [get_parag_str(x) for x in parag_no_ls]\n",
        "sent_no_ls = [x[0] for x in corpus_man_crux_ols]\n",
        "sent_raw_ls = [corpus_sents_df[corpus_sents_df['sent_no']==x]['sent_raw'].squeeze() for x in sent_no_ls]\n",
        "sent_raw_ls\n",
        "sent_clean_ls = [corpus_sents_df[corpus_sents_df['sent_no']==x]['sent_clean'].squeeze() for x in sent_no_ls]\n",
        "sent_clean_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFEYg7Gfbj9i"
      },
      "source": [
        "# Create a Dict of Crux Points to Tuples (Polarity, Raw Sentence)\n",
        "\n",
        "# First Create the Tuples for each Sentence No (Sentiment Polarity, Raw Text)\n",
        "def merge(list1, list2):\n",
        "    merged_list = tuple(zip(list1, list2)) \n",
        "    return merged_list\n",
        "      \n",
        "crux_tp_ls = merge(pol_val_ls, sent_raw_ls)\n",
        "\n",
        "# Second, Create the Dictionary C\n",
        "corpus_man_cruxes_dt = {sent_no_ls[i]: crux_tp_ls[i] for i in range(len(crux_tp_ls))}\n",
        "\n",
        "# Verify\n",
        "corpus_man_cruxes_dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtIHecpMdbXa"
      },
      "source": [
        "corpus_sents_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8qmpFRaTfu2"
      },
      "source": [
        "**Plot Interpolated Manual Sentiment Arc**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8ASg7uUZWf3"
      },
      "source": [
        "corpus_man_sa_df = pd.DataFrame({'sent_no':xn, 'sentiment':yn, 'sent_raw':corpus_sents_df.sent_raw.values})\n",
        "corpus_man_sa_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36VfGi4a47Yl"
      },
      "source": [
        "# Hermite Interpolation with SciPy\n",
        "\n",
        "pol_val_ls = [x[1] for x in corpus_man_crux_ols]\n",
        "sent_no_ls = [x[0] for x in corpus_man_crux_ols]\n",
        "parag_no_ls = [(get_parag4sentno(x))[0] for x in sent_no_ls]\n",
        "parag_str_ls = [get_parag_str(x) for x in parag_no_ls]\n",
        "sent_no_ls = [x[0] for x in corpus_man_crux_ols]\n",
        "sent_raw_ls = [corpus_sents_df[corpus_sents_df['sent_no']==x]['sent_raw'].squeeze() for x in sent_no_ls]\n",
        "sent_raw_ls\n",
        "sent_clean_ls = [corpus_sents_df[corpus_sents_df['sent_no']==x]['sent_clean'].squeeze() for x in sent_no_ls]\n",
        "sent_clean_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElJKawWfZWbv"
      },
      "source": [
        "sent_no_ls\n",
        "pol_val_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xufA403s3lbF"
      },
      "source": [
        "corpus_man_crux_np = np.asarray(corpus_man_crux_ols)\n",
        "corpus_man_crux_np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdgKbjpi63a9"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMkgU-JhwudG"
      },
      "source": [
        "x2 = np.array(sent_no_ls)\n",
        "y2 = np.array(pol_val_ls)\n",
        "\n",
        "xn = np.linspace(0, corpus_sents_len, corpus_sents_len)\n",
        "yn = interpolate.pchip_interpolate(x2, y2, xn)\n",
        "\n",
        "crux_man_df = pd.DataFrame(\n",
        "    {'sent_no': sent_no_ls,\n",
        "     'pol_val': pol_val_ls\n",
        "     }\n",
        ")\n",
        "\n",
        "# plt.plot(x2, y2, 'ok', label='True values')\n",
        "# plt.plot(xn, yn, label='Hermite Interpolation')\n",
        "\n",
        "# plt.plot(xn, yn4, label='Spline order 4')\n",
        "# plt.plot(xn, yn5, label='Spline order 5')\n",
        "# plt.plot(xn, yn6, label='Spline order 6')\n",
        "# plt.plot(xn, yn7, label='Spline order 7')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# sns.histplot(data=corpus_sents_df['char_len'], kde=True).set_title(f'{CORPUS_FULL} \\n Histogram of Paragraph Lengths')\n",
        "sns.histplot(data=crux_man_df, x='sent_no', y='pol_val', kde=True).set_title(f'{CORPUS_FULL} \\n Manual Cruxes with Hermite Smoothing')\n",
        "\n",
        "\n",
        "# Save graph to file.\n",
        "plot_filename = 'man_crux_plot.png'\n",
        "plotpathfilename_str = gen_pathfiletime(plot_filename)\n",
        "plt.savefig(plotpathfilename_str, format='png', dpi=300)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WW-VkS2s_ogy"
      },
      "source": [
        "**Gaussian Process Regression**\n",
        "\n",
        "* https://blog.dominodatalab.com/fitting-gaussian-process-models-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLFFYDfYpPjn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0BukxX9ZKYA"
      },
      "source": [
        "# (Optional) Load Sentiment Polarities: Interactive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhPJ9e-V9NMu"
      },
      "source": [
        "***If you upload a file of Sentiment Values you don't have to Calculate them in the following sections***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpx7viqf9AAJ"
      },
      "source": [
        "!ls -altr *.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw8_mUHI9sdr"
      },
      "source": [
        "# Test\n",
        "\n",
        "files.download('sentiments_raw_all_virginiawoolf_tothelighthouse_20210618161224.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90axHClm9cGZ"
      },
      "source": [
        "# Upload your precomputed Sentiment Values\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02NH5nnto2AC"
      },
      "source": [
        "%whos DataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL9JCyCI-Sic"
      },
      "source": [
        "# Verify the file was uploaded correctly\n",
        "\n",
        "newest_csvfile = get_recentfile().split('/')[-1]\n",
        "print(f'The most recently updated *.csv file is: {newest_csvfile}')\n",
        "\n",
        "!head -n 10 $newest_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTfBj8qdi_vZ"
      },
      "source": [
        "%whos DataFrame\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgjz-E-mYgzI"
      },
      "source": [
        "# Upload file into DataFrame\n",
        "\n",
        "corpus_test_df = pd.read_csv(newest_csvfile)\n",
        "corpus_test_df['sent_clean'] = corpus_test_df['sent_clean'].astype('string')\n",
        "corpus_test_df['sent_raw'] = corpus_test_df['sent_raw'].astype('string')\n",
        "corpus_test_df.head()\n",
        "corpus_test_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6ajyb8Jpmzw"
      },
      "source": [
        "***Skip to Section <Calculate Median of All...> if SA Loaded***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGA6sQy6RPDC"
      },
      "source": [
        "corpus_lexicons_stats_dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7CfH00OFkQV"
      },
      "source": [
        "# **Either (a) Load Precomputed Sentiment Series or (b) Calculate Sentiment Values**\n",
        "\n",
        "Sentiment Models\n",
        "\n",
        "* VADER [-1.0 to 1.0] zero peak\n",
        "* TextBlob [-1.0 to 1.0] zero peak\n",
        "* Stanza outliers [-1.0 to 199.0] pos, outliers(+peak)\n",
        "* AFINN [-14 (-8 to 8) 20] discrete\n",
        "* SentimentR 11,710 [-5.4 to 8.8] norm\n",
        "* Syuzhet [-5.4 to 8.8] norm\n",
        "* Bing [-100.0 (-20.0 to 20.0) 100] discrete, outliers\n",
        "* Pattern [-1.0 to 1.0] norm\n",
        "* SentiWord [-3.8 to 4.4] norm\n",
        "* SenticNet [-3.8 to 10] norm\n",
        "* NRC [-100.0 (-5.0 to 5.0) 100] zero, outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ueo8fTSqqaak"
      },
      "source": [
        "## **(a) Load Previously Computed Sentiment Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEq8eWslgu28"
      },
      "source": [
        "!ls -altr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RH8TY-LgCVf"
      },
      "source": [
        "### **Baseline 12 Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlxgCSBH2aLD"
      },
      "source": [
        "%whos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qeB3tRH2eq1"
      },
      "source": [
        "corpus_root_filename = CORPUS_FILENAME.split('.')[:-1][0]\n",
        "corpus_root_filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVX1gXQajWNG"
      },
      "source": [
        "# Read previous Computed 12 Model Baseline sentiment data saved from previous run of this notebook\n",
        "\n",
        "\n",
        "corpus_sents_df = pd.read_csv(f'corpus_sents_baseline_{corpus_root_filename}.csv')\n",
        "corpus_parags_df = pd.read_csv(f'corpus_parags_baseline_{corpus_root_filename}.csv')\n",
        "corpus_sects_df = pd.read_csv(f'corpus_sects_baseline_{corpus_root_filename}.csv')\n",
        "corpus_chaps_df = pd.read_csv(f'corpus_chaps_baseline_{corpus_root_filename}.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZC4--5TojdI"
      },
      "source": [
        "print(f'Corpus Sentences shape: {corpus_sents_df.shape}')\n",
        "print(f'Corpus Paragraphs shape: {corpus_parags_df.shape}')\n",
        "print(f'Corpus Sections shape: {corpus_sects_df.shape}')\n",
        "print(f'Corpus Chapters shape: {corpus_chaps_df.shape}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfl-NIhZeNzT"
      },
      "source": [
        "# Clean Sentences DataFrame\n",
        "\n",
        "if 'Unnamed: 0' in corpus_sents_df.columns:\n",
        "  corpus_sents_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "  \n",
        "corpus_sents_df.head(2)\n",
        "corpus_sents_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WnLPxjefkhE"
      },
      "source": [
        "# Clean Paragraphs DataFrame\n",
        "\n",
        "if 'Unnamed: 0' in corpus_parags_df.columns:\n",
        "  corpus_parags_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "  \n",
        "corpus_parags_df.head(2)\n",
        "corpus_parags_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMNQI76jfkdu"
      },
      "source": [
        "# Clean Section DataFrame\n",
        "\n",
        "if 'Unnamed: 0' in corpus_sects_df.columns:\n",
        "  corpus_sects_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "  \n",
        "corpus_sects_df.head(2)\n",
        "corpus_sects_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFfc4HTPfy5c"
      },
      "source": [
        "# Clean Chapter DataFrame\n",
        "\n",
        "if 'Unnamed: 0' in corpus_chaps_df.columns:\n",
        "  corpus_chaps_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "  \n",
        "corpus_chaps_df.head(2)\n",
        "corpus_chaps_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWDYFJFHxXum"
      },
      "source": [
        "# Derive Normalized/Standaradized Time Series\n",
        "\n",
        "# Once applied modification function\n",
        "\"\"\"\n",
        "test_df = process_timeseries(ts_df=corpus_sents_df, col_models_ls=models_baseline_ls, col_mod='lnorm')\n",
        "corpus_sents_df = pd.concat([corpus_sents_df, test_df], axis=1)\n",
        "corpus_sents_df = corpus_sents_df.loc[:,~corpus_sents_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sents_df, col_models_ls=models_baseline_ls, col_mod='std-minmax')\n",
        "corpus_sents_df = pd.concat([corpus_sents_df, test_df], axis=1)\n",
        "corpus_sents_df = corpus_sents_df.loc[:,~corpus_sents_df.columns.duplicated()]\n",
        "\"\"\"\n",
        "test_df = process_timeseries(ts_df=corpus_sents_df, col_models_ls=models_baseline_ls, col_mod='std-stdscaler')\n",
        "corpus_sents_df = pd.concat([corpus_sents_df, test_df], axis=1)\n",
        "corpus_sents_df = corpus_sents_df.loc[:,~corpus_sents_df.columns.duplicated()]\n",
        "\"\"\"\n",
        "test_df = process_timeseries(ts_df=corpus_sents_df, col_models_ls=models_baseline_ls, col_mod='std-medianiqr')\n",
        "corpus_sents_df = pd.concat([corpus_sents_df, test_df], axis=1)\n",
        "corpus_sents_df = corpus_sents_df.loc[:,~corpus_sents_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sents_df, col_models_ls=models_baseline_ls, col_mod='roll10')\n",
        "corpus_sents_df = pd.concat([corpus_sents_df, test_df], axis=1)\n",
        "corpus_sents_df = corpus_sents_df.loc[:,~corpus_sents_df.columns.duplicated()]\n",
        "\"\"\";\n",
        "\n",
        "# Twice applied modification function (ends with roll)\n",
        "lnorm_ls = [f'{x}_lnorm' for x in models_baseline_ls]\n",
        "stdminmax_ls = [f'{x}_minmax' for x in models_baseline_ls]\n",
        "stdstdscaler_ls = [f'{x}_stdscaler' for x in models_baseline_ls]\n",
        "stdmedianiqr_ls = [f'{x}_medianiqr' for x in models_baseline_ls]\n",
        "\"\"\"\n",
        "test_df = process_timeseries(ts_df=corpus_sents_df, col_models_ls=lnorm_ls, col_mod='std-minmax')\n",
        "corpus_sents_df = pd.concat([corpus_sents_df, test_df], axis=1)\n",
        "corpus_sents_df = corpus_sents_df.loc[:,~corpus_sents_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sents_df, col_models_ls=lnorm_ls, col_mod='std-stdscaler')\n",
        "corpus_sents_df = pd.concat([corpus_sents_df, test_df], axis=1)\n",
        "corpus_sents_df = corpus_sents_df.loc[:,~corpus_sents_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sents_df, col_models_ls=lnorm_ls, col_mod='std-medianiqr')\n",
        "corpus_sents_df = pd.concat([corpus_sents_df, test_df], axis=1)\n",
        "corpus_sents_df = corpus_sents_df.loc[:,~corpus_sents_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sents_df, col_models_ls=lnorm_ls, col_mod='roll10')\n",
        "corpus_sents_df = pd.concat([corpus_sents_df, test_df], axis=1)\n",
        "corpus_sents_df = corpus_sents_df.loc[:,~corpus_sents_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sents_df, col_models_ls=stdminmax_ls, col_mod='roll10')\n",
        "corpus_sents_df = pd.concat([corpus_sents_df, test_df], axis=1)\n",
        "corpus_sents_df = corpus_sents_df.loc[:,~corpus_sents_df.columns.duplicated()]\n",
        "\"\"\"\n",
        "test_df = process_timeseries(ts_df=corpus_sents_df, col_models_ls=stdstdscaler_ls, col_mod='roll10')\n",
        "corpus_sents_df = pd.concat([corpus_sents_df, test_df], axis=1)\n",
        "corpus_sents_df = corpus_sents_df.loc[:,~corpus_sents_df.columns.duplicated()]\n",
        "\"\"\"\n",
        "test_df = process_timeseries(ts_df=corpus_sents_df, col_models_ls=stdmedianiqr_ls, col_mod='roll10')\n",
        "corpus_sents_df = pd.concat([corpus_sents_df, test_df], axis=1)\n",
        "corpus_sents_df = corpus_sents_df.loc[:,~corpus_sents_df.columns.duplicated()]\n",
        "\n",
        "\n",
        "# Thrice applied modification function (starts with lnorm and ends with roll)\n",
        "lnorm_stdminmax_ls = [f'{x}_lnorm_minmax' for x in models_senmodels_baseline_lstimentr_ls]\n",
        "lnorm_stdstdscaler_ls = [f'{x}_lnorm_stdscaler' for x in models_baseline_ls]\n",
        "lnorm_stdmedianiqr_ls = [f'{x}_lnorm_medianiqr' for x in models_baseline_ls]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sents_df, col_models_ls=lnorm_stdminmax_ls, col_mod='roll10')\n",
        "corpus_sents_df = pd.concat([corpus_sents_df, test_df], axis=1)\n",
        "corpus_sents_df = corpus_sents_df.loc[:,~corpus_sents_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sents_df, col_models_ls=lnorm_stdstdscaler_ls, col_mod='roll10')\n",
        "corpus_sents_df = pd.concat([corpus_sents_df, test_df], axis=1)\n",
        "corpus_sents_df = corpus_sents_df.loc[:,~corpus_sents_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sents_df, col_models_ls=lnorm_stdmedianiqr_ls, col_mod='roll10')\n",
        "corpus_sents_df = pd.concat([corpus_sents_df, test_df], axis=1)\n",
        "corpus_sents_df = corpus_sents_df.loc[:,~corpus_sents_df.columns.duplicated()]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "corpus_sents_df.head(2)\n",
        "corpus_sents_df.info()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdYoS50pgJtz"
      },
      "source": [
        "### **SentimentR 7 Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT1kNw36DhgV"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFy2LZzBC_XC"
      },
      "source": [
        "!ls -altr *csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcIDhlU-cEye"
      },
      "source": [
        "%whos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9z1PX8J4Sn1"
      },
      "source": [
        "corpus_root_filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBk7sJltaE43"
      },
      "source": [
        "# SentimentR 7 Models: Read Computed sentiment data saved from previous run of this notebook\n",
        "\n",
        "corpus_root_filename = CORPUS_FILENAME.split('.')[:-1][0]\n",
        "\n",
        "sentimentr_7models_filename = f\"sum_sentiments_sentimentR_7models_sentimenttimeraw_{corpus_root_filename}.csv\"\n",
        "corpus_sentimentr_df = pd.read_csv(sentimentr_7models_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5RkpbLrgWNQ"
      },
      "source": [
        "# Clean DataFrame\n",
        "\n",
        "if 'Unnamed: 0' in corpus_sentimentr_df.columns:\n",
        "  # corpus_sentimentr_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "  corpus_sentimentr_df.rename(columns={'Unnamed: 0':'sent_no'}, inplace=True)\n",
        "\n",
        "corpus_sentimentr_df.head(2)\n",
        "corpus_sentimentr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXotYX02g-Zf"
      },
      "source": [
        "# Derive Normalized/Standaradized Time Series\n",
        "\n",
        "# Once applied modification function\n",
        "test_df = process_timeseries(ts_df=corpus_sentimentr_df, col_models_ls=models_sentimentr_ls, col_mod='lnorm')\n",
        "corpus_sentimentr_df = pd.concat([corpus_sentimentr_df, test_df], axis=1)\n",
        "corpus_sentimentr_df = corpus_sentimentr_df.loc[:,~corpus_sentimentr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sentimentr_df, col_models_ls=models_sentimentr_ls, col_mod='std-minmax')\n",
        "corpus_sentimentr_df = pd.concat([corpus_sentimentr_df, test_df], axis=1)\n",
        "corpus_sentimentr_df = corpus_sentimentr_df.loc[:,~corpus_sentimentr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sentimentr_df, col_models_ls=models_sentimentr_ls, col_mod='std-stdscaler')\n",
        "corpus_sentimentr_df = pd.concat([corpus_sentimentr_df, test_df], axis=1)\n",
        "corpus_sentimentr_df = corpus_sentimentr_df.loc[:,~corpus_sentimentr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sentimentr_df, col_models_ls=models_sentimentr_ls, col_mod='std-medianiqr')\n",
        "corpus_sentimentr_df = pd.concat([corpus_sentimentr_df, test_df], axis=1)\n",
        "corpus_sentimentr_df = corpus_sentimentr_df.loc[:,~corpus_sentimentr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sentimentr_df, col_models_ls=models_sentimentr_ls, col_mod='roll10')\n",
        "corpus_sentimentr_df = pd.concat([corpus_sentimentr_df, test_df], axis=1)\n",
        "corpus_sentimentr_df = corpus_sentimentr_df.loc[:,~corpus_sentimentr_df.columns.duplicated()]\n",
        "\n",
        "# Twice applied modification function (ends with roll)\n",
        "lnorm_ls = [f'{x}_lnorm' for x in models_sentimentr_ls]\n",
        "stdminmax_ls = [f'{x}_minmax' for x in models_sentimentr_ls]\n",
        "stdstdscaler_ls = [f'{x}_stdscaler' for x in models_sentimentr_ls]\n",
        "stdmedianiqr_ls = [f'{x}_medianiqr' for x in models_sentimentr_ls]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sentimentr_df, col_models_ls=lnorm_ls, col_mod='std-minmax')\n",
        "corpus_sentimentr_df = pd.concat([corpus_sentimentr_df, test_df], axis=1)\n",
        "corpus_sentimentr_df = corpus_sentimentr_df.loc[:,~corpus_sentimentr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sentimentr_df, col_models_ls=lnorm_ls, col_mod='std-stdscaler')\n",
        "corpus_sentimentr_df = pd.concat([corpus_sentimentr_df, test_df], axis=1)\n",
        "corpus_sentimentr_df = corpus_sentimentr_df.loc[:,~corpus_sentimentr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sentimentr_df, col_models_ls=lnorm_ls, col_mod='std-medianiqr')\n",
        "corpus_sentimentr_df = pd.concat([corpus_sentimentr_df, test_df], axis=1)\n",
        "corpus_sentimentr_df = corpus_sentimentr_df.loc[:,~corpus_sentimentr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sentimentr_df, col_models_ls=lnorm_ls, col_mod='roll10')\n",
        "corpus_sentimentr_df = pd.concat([corpus_sentimentr_df, test_df], axis=1)\n",
        "corpus_sentimentr_df = corpus_sentimentr_df.loc[:,~corpus_sentimentr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sentimentr_df, col_models_ls=stdminmax_ls, col_mod='roll10')\n",
        "corpus_sentimentr_df = pd.concat([corpus_sentimentr_df, test_df], axis=1)\n",
        "corpus_sentimentr_df = corpus_sentimentr_df.loc[:,~corpus_sentimentr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sentimentr_df, col_models_ls=stdstdscaler_ls, col_mod='roll10')\n",
        "corpus_sentimentr_df = pd.concat([corpus_sentimentr_df, test_df], axis=1)\n",
        "corpus_sentimentr_df = corpus_sentimentr_df.loc[:,~corpus_sentimentr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sentimentr_df, col_models_ls=stdmedianiqr_ls, col_mod='roll10')\n",
        "corpus_sentimentr_df = pd.concat([corpus_sentimentr_df, test_df], axis=1)\n",
        "corpus_sentimentr_df = corpus_sentimentr_df.loc[:,~corpus_sentimentr_df.columns.duplicated()]\n",
        "\n",
        "# Thrice applied modification function (starts with lnorm and ends with roll)\n",
        "lnorm_stdminmax_ls = [f'{x}_lnorm_minmax' for x in models_sentimentr_ls]\n",
        "lnorm_stdstdscaler_ls = [f'{x}_lnorm_stdscaler' for x in models_sentimentr_ls]\n",
        "lnorm_stdmedianiqr_ls = [f'{x}_lnorm_medianiqr' for x in models_sentimentr_ls]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sentimentr_df, col_models_ls=lnorm_stdminmax_ls, col_mod='roll10')\n",
        "corpus_sentimentr_df = pd.concat([corpus_sentimentr_df, test_df], axis=1)\n",
        "corpus_sentimentr_df = corpus_sentimentr_df.loc[:,~corpus_sentimentr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sentimentr_df, col_models_ls=lnorm_stdstdscaler_ls, col_mod='roll10')\n",
        "corpus_sentimentr_df = pd.concat([corpus_sentimentr_df, test_df], axis=1)\n",
        "corpus_sentimentr_df = corpus_sentimentr_df.loc[:,~corpus_sentimentr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_sentimentr_df, col_models_ls=lnorm_stdmedianiqr_ls, col_mod='roll10')\n",
        "corpus_sentimentr_df = pd.concat([corpus_sentimentr_df, test_df], axis=1)\n",
        "corpus_sentimentr_df = corpus_sentimentr_df.loc[:,~corpus_sentimentr_df.columns.duplicated()]\n",
        "\n",
        "corpus_sentimentr_df.head(2)\n",
        "corpus_sentimentr_df.info()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDIq7gP7Ow94"
      },
      "source": [
        "corpus_sentimentr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVqjH8G_O9An"
      },
      "source": [
        "# Derive Rolling Means Time Series\n",
        "\n",
        "temp_ls = [f'{x}_roll10' for x in models_sentimentr_ls]\n",
        "# corpus_sentimentr_df[models_sentimentr_ls].plot()\n",
        "corpus_sentimentr_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} Baseline 12 Models\\nSMA 10%')\n",
        "\n",
        "temp_ls = [f'{x}_minmax_roll10' for x in models_sentimentr_ls]\n",
        "# corpus_sentimentr_df[models_sentimentr_ls].plot()\n",
        "corpus_sentimentr_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} Baseline 12 Models\\nMinMax SMA 10%')\n",
        "\n",
        "temp_ls = [f'{x}_stdscaler_roll10' for x in models_sentimentr_ls]\n",
        "# corpus_sentimentr_df[models_sentimentr_ls].plot()\n",
        "corpus_sentimentr_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} Baseline 12 Models\\nStdScaler SMA 10%')\n",
        "\n",
        "temp_ls = [f'{x}_lnorm_stdscaler_roll10' for x in models_sentimentr_ls]\n",
        "# corpus_sentimentr_df[models_sentimentr_ls].plot()\n",
        "corpus_sentimentr_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} Baseline 12 Models\\nlnorm StdScaler SMA 10%')\n",
        "\n",
        "temp_ls = [f'{x}_medianiqr_roll10' for x in models_sentimentr_ls]\n",
        "# corpus_sentimentr_df[models_sentimentr_ls].plot()\n",
        "corpus_sentimentr_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} Baseline 12 Models\\nMedianIQR SMA 10%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krB0DGVMgNbW"
      },
      "source": [
        "### **SyuzhetR 4 Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI_U-nwPG_ur"
      },
      "source": [
        "!ls -altr *.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9GOO2EseGTV"
      },
      "source": [
        "# SyuzhetR 4 Models: Read Computed sentiment data saved from previous run of this notebook\n",
        "\n",
        "# corpus_syuzhetr_df = pd.read_csv('sum_sentiments_syuzhetR_4models_vwoolf_tothelighthouse.csv')\n",
        "\n",
        "corpus_root_filename = CORPUS_FILENAME.split('.')[:-1][0]\n",
        "\n",
        "syuzhetr_7models_filename = f\"sum_sentiments_syuzhetR_4models_sentimenttimeraw_{corpus_root_filename}.csv\"\n",
        "corpus_syuzhetr_df = pd.read_csv(syuzhetr_7models_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EAxGBWwgdPz"
      },
      "source": [
        "# Clean Chapter DataFrame\n",
        "\n",
        "if 'Unnamed: 0' in corpus_syuzhetr_df.columns:\n",
        "  corpus_syuzhetr_df.rename(columns={'Unnamed: 0':'sent_no'}, inplace=True)\n",
        "  \n",
        "corpus_syuzhetr_df.head(2)\n",
        "corpus_syuzhetr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bPKx_55M_iM"
      },
      "source": [
        "# Derive Normalized/Standardized Time Series\n",
        "\n",
        "# Once applied modification function\n",
        "test_df = process_timeseries(ts_df=corpus_syuzhetr_df, col_models_ls=models_syuzhetr_ls, col_mod='lnorm')\n",
        "corpus_syuzhetr_df = pd.concat([corpus_syuzhetr_df, test_df], axis=1)\n",
        "corpus_syuzhetr_df = corpus_syuzhetr_df.loc[:,~corpus_syuzhetr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_syuzhetr_df, col_models_ls=models_syuzhetr_ls, col_mod='std-minmax')\n",
        "corpus_syuzhetr_df = pd.concat([corpus_syuzhetr_df, test_df], axis=1)\n",
        "corpus_syuzhetr_df = corpus_syuzhetr_df.loc[:,~corpus_syuzhetr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_syuzhetr_df, col_models_ls=models_syuzhetr_ls, col_mod='std-stdscaler')\n",
        "corpus_syuzhetr_df = pd.concat([corpus_syuzhetr_df, test_df], axis=1)\n",
        "corpus_syuzhetr_df = corpus_syuzhetr_df.loc[:,~corpus_syuzhetr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_syuzhetr_df, col_models_ls=models_syuzhetr_ls, col_mod='std-medianiqr')\n",
        "corpus_syuzhetr_df = pd.concat([corpus_syuzhetr_df, test_df], axis=1)\n",
        "corpus_syuzhetr_df = corpus_syuzhetr_df.loc[:,~corpus_syuzhetr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_syuzhetr_df, col_models_ls=models_syuzhetr_ls, col_mod='roll10')\n",
        "corpus_syuzhetr_df = pd.concat([corpus_syuzhetr_df, test_df], axis=1)\n",
        "corpus_syuzhetr_df = corpus_syuzhetr_df.loc[:,~corpus_syuzhetr_df.columns.duplicated()]\n",
        "\n",
        "# Twice applied modification function (ends with roll)\n",
        "lnorm_ls = [f'{x}_lnorm' for x in models_syuzhetr_ls]\n",
        "stdminmax_ls = [f'{x}_minmax' for x in models_syuzhetr_ls]\n",
        "stdstdscaler_ls = [f'{x}_stdscaler' for x in models_syuzhetr_ls]\n",
        "stdmedianiqr_ls = [f'{x}_medianiqr' for x in models_syuzhetr_ls]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_syuzhetr_df, col_models_ls=lnorm_ls, col_mod='std-minmax')\n",
        "corpus_syuzhetr_df = pd.concat([corpus_syuzhetr_df, test_df], axis=1)\n",
        "corpus_syuzhetr_df = corpus_syuzhetr_df.loc[:,~corpus_syuzhetr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_syuzhetr_df, col_models_ls=lnorm_ls, col_mod='std-stdscaler')\n",
        "corpus_syuzhetr_df = pd.concat([corpus_syuzhetr_df, test_df], axis=1)\n",
        "corpus_syuzhetr_df = corpus_syuzhetr_df.loc[:,~corpus_syuzhetr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_syuzhetr_df, col_models_ls=lnorm_ls, col_mod='std-medianiqr')\n",
        "corpus_syuzhetr_df = pd.concat([corpus_syuzhetr_df, test_df], axis=1)\n",
        "corpus_syuzhetr_df = corpus_syuzhetr_df.loc[:,~corpus_syuzhetr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_syuzhetr_df, col_models_ls=lnorm_ls, col_mod='roll10')\n",
        "corpus_syuzhetr_df = pd.concat([corpus_syuzhetr_df, test_df], axis=1)\n",
        "corpus_syuzhetr_df = corpus_syuzhetr_df.loc[:,~corpus_syuzhetr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_syuzhetr_df, col_models_ls=stdminmax_ls, col_mod='roll10')\n",
        "corpus_syuzhetr_df = pd.concat([corpus_syuzhetr_df, test_df], axis=1)\n",
        "corpus_syuzhetr_df = corpus_syuzhetr_df.loc[:,~corpus_syuzhetr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_syuzhetr_df, col_models_ls=stdstdscaler_ls, col_mod='roll10')\n",
        "corpus_syuzhetr_df = pd.concat([corpus_syuzhetr_df, test_df], axis=1)\n",
        "corpus_syuzhetr_df = corpus_syuzhetr_df.loc[:,~corpus_syuzhetr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_syuzhetr_df, col_models_ls=stdmedianiqr_ls, col_mod='roll10')\n",
        "corpus_syuzhetr_df = pd.concat([corpus_syuzhetr_df, test_df], axis=1)\n",
        "corpus_syuzhetr_df = corpus_syuzhetr_df.loc[:,~corpus_syuzhetr_df.columns.duplicated()]\n",
        "\n",
        "# Thrice applied modification function (starts with lnorm and ends with roll)\n",
        "lnorm_stdminmax_ls = [f'{x}_lnorm_minmax' for x in models_syuzhetr_ls]\n",
        "lnorm_stdstdscaler_ls = [f'{x}_lnorm_stdscaler' for x in models_syuzhetr_ls]\n",
        "lnorm_stdmedianiqr_ls = [f'{x}_lnorm_medianiqr' for x in models_syuzhetr_ls]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_syuzhetr_df, col_models_ls=lnorm_stdminmax_ls, col_mod='roll10')\n",
        "corpus_syuzhetr_df = pd.concat([corpus_syuzhetr_df, test_df], axis=1)\n",
        "corpus_syuzhetr_df = corpus_syuzhetr_df.loc[:,~corpus_syuzhetr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_syuzhetr_df, col_models_ls=lnorm_stdstdscaler_ls, col_mod='roll10')\n",
        "corpus_syuzhetr_df = pd.concat([corpus_syuzhetr_df, test_df], axis=1)\n",
        "corpus_syuzhetr_df = corpus_syuzhetr_df.loc[:,~corpus_syuzhetr_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_syuzhetr_df, col_models_ls=lnorm_stdmedianiqr_ls, col_mod='roll10')\n",
        "corpus_syuzhetr_df = pd.concat([corpus_syuzhetr_df, test_df], axis=1)\n",
        "corpus_syuzhetr_df = corpus_syuzhetr_df.loc[:,~corpus_syuzhetr_df.columns.duplicated()]\n",
        "\n",
        "corpus_syuzhetr_df.head(2)\n",
        "corpus_syuzhetr_df.info()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVcqz_baLcMe"
      },
      "source": [
        "corpus_syuzhetr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpP3mwFLaFQi"
      },
      "source": [
        "# Derive Rolling Means Time Series\n",
        "\n",
        "temp_ls = [f'{x}_roll10' for x in models_syuzhetr_ls]\n",
        "# corpus_syuzhetr_df[models_syuzhetr_ls].plot()\n",
        "corpus_syuzhetr_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} SyuzhetR 4 Models\\nSMA 10%')\n",
        "\n",
        "temp_ls = [f'{x}_minmax_roll10' for x in models_syuzhetr_ls]\n",
        "# corpus_syuzhetr_df[models_syuzhetr_ls].plot()\n",
        "corpus_syuzhetr_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} SyuzhetR 4 Models\\nMinMax SMA 10%')\n",
        "\n",
        "temp_ls = [f'{x}_stdscaler_roll10' for x in models_syuzhetr_ls]\n",
        "# corpus_syuzhetr_df[models_syuzhetr_ls].plot()\n",
        "corpus_syuzhetr_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} SyuzhetR 4 Models\\nStdScaler SMA 10%')\n",
        "\n",
        "temp_ls = [f'{x}_lnorm_stdscaler_roll10' for x in models_syuzhetr_ls]\n",
        "# corpus_syuzhetr_df[models_syuzhetr_ls].plot()\n",
        "corpus_syuzhetr_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} SyuzhetR 4 Models\\nlnorm StdScaler SMA 10%')\n",
        "\n",
        "temp_ls = [f'{x}_medianiqr_roll10' for x in models_syuzhetr_ls]\n",
        "# corpus_syuzhetr_df[models_syuzhetr_ls].plot()\n",
        "corpus_syuzhetr_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} SyuzhetR 4 Models\\nMedianIQR SMA 10%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPuuUo3aZMWD"
      },
      "source": [
        "test_df = corpus_syuzhetr_df.filter(['sent_no', 'sent_raw'], axis=1)\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXdacd0FXWTq"
      },
      "source": [
        "corpus_syuzhetr_df.info()\n",
        "corpus_syuzhetr_df = corpus_syuzhetr_df.loc[:,~corpus_syuzhetr_df.columns.duplicated()]\n",
        "corpus_syuzhetr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "933q5T5HasEW"
      },
      "source": [
        "plt.clf()\n",
        "corpus_syuzhetr_df[['syuzhet_roll10', 'bing_roll10', 'syuzhet_lnorm_roll10','bing_lnorm_roll10']].plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is7GsGTCgQik"
      },
      "source": [
        "### **Transformer 8 Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoBNrmdEIxYs"
      },
      "source": [
        "!ls -altr *.csv\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuGaejHXeGP2"
      },
      "source": [
        "# Transformer 8 Models: Read Computed sentiment data saved from previous run of this notebook\n",
        "\n",
        "# corpus_transformer_df = pd.read_csv('sum_sentiments_sents_trans_mproust_theguermantesway-french.csv')\n",
        "\n",
        "corpus_root_filename = CORPUS_FILENAME.split('.')[:-1][0]\n",
        "\n",
        "corpus_transformer_df = pd.read_csv(f\"sum_sentiments_sents_trans_{corpus_root_filename}.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm2Lsk4zgoce"
      },
      "source": [
        "# Clean Chapter DataFrame\n",
        "\n",
        "if 'Unnamed: 0' in corpus_transformer_df.columns:\n",
        "  corpus_transformer_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "  \n",
        "corpus_transformer_df.head(2)\n",
        "corpus_transformer_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPJyxE-1JMcZ"
      },
      "source": [
        "# Derive Normalized/Standardized Time Series\n",
        "\n",
        "# Once applied modification function\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=models_transformer_ls, col_mod='lnorm')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=models_transformer_ls, col_mod='std-minmax')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=models_transformer_ls, col_mod='std-stdscaler')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=models_transformer_ls, col_mod='std-medianiqr')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=models_transformer_ls, col_mod='roll10')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "\n",
        "# Twice applied modification function (ends with roll)\n",
        "lnorm_ls = [f'{x}_lnorm' for x in models_transformer_ls]\n",
        "stdminmax_ls = [f'{x}_minmax' for x in models_transformer_ls]\n",
        "stdstdscaler_ls = [f'{x}_stdscaler' for x in models_transformer_ls]\n",
        "stdmedianiqr_ls = [f'{x}_medianiqr' for x in models_transformer_ls]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=lnorm_ls, col_mod='std-minmax')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=lnorm_ls, col_mod='std-stdscaler')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=lnorm_ls, col_mod='std-medianiqr')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=lnorm_ls, col_mod='roll10')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=stdminmax_ls, col_mod='roll10')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=stdstdscaler_ls, col_mod='roll10')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=stdmedianiqr_ls, col_mod='roll10')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "\n",
        "# Thrice applied modification function (starts with lnorm and ends with roll)\n",
        "lnorm_stdminmax_ls = [f'{x}_lnorm_minmax' for x in models_transformer_ls]\n",
        "lnorm_stdstdscaler_ls = [f'{x}_lnorm_stdscaler' for x in models_transformer_ls]\n",
        "lnorm_stdmedianiqr_ls = [f'{x}_lnorm_medianiqr' for x in models_transformer_ls]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=lnorm_stdminmax_ls, col_mod='roll10')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=lnorm_stdstdscaler_ls, col_mod='roll10')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=lnorm_stdmedianiqr_ls, col_mod='roll10')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "\n",
        "corpus_transformer_df.head(2)\n",
        "corpus_transformer_df.info()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHoF3nhvZejR"
      },
      "source": [
        "print(*corpus_transformer_df.columns, sep='\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ks0Xq3KXpFB"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "# Test reversing order of operations: first smooth (elim outliers) then Standardize\n",
        "\n",
        "# Create the plain roll10 series\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=models_transformer_ls, col_mod='roll10')\n",
        "print(f'test_df/roll10 shape: {test_df.shape}')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "\n",
        "temp_ls = [f'{x}_roll10' for x in models_transformer_ls]\n",
        "print(f'ROLL_LS: {temp_ls}')\n",
        "\n",
        "# Create the roll10_stdscaler series\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=temp_ls, col_mod='std-stdscaler')\n",
        "print(f'test_df/std-stdscaler shape: {test_df.shape}')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "\n",
        "temp_ls = [f'{x}_roll10_stdscaler' for x in models_transformer_ls]\n",
        "print(f'ROLL_STDSCALER_LS: {temp_ls}')\n",
        "\n",
        "# Plot \n",
        "# corpus_transformer_df[models_transformer_ls].plot()\n",
        "corpus_transformer_df['robertaxml8lang_roll10'].plot()\n",
        "\n",
        "# corpus_transformer_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} Transformer 8 Models\\n[SAM 10% then StdScaler]')\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NygCjCgGuFAb"
      },
      "source": [
        "# CORPUS_FULL = 'The Guermantes Way - English, Marcel Proust'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YsA6DGcS_3e"
      },
      "source": [
        "# Derive Rolling Means Time Series\n",
        "\n",
        "temp_ls = [f'{x}_roll10' for x in models_transformer_ls]\n",
        "# corpus_transformer_df[models_transformer_ls].plot()\n",
        "corpus_transformer_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} Transformer 8 Models\\n[SMA 10%]')\n",
        "\n",
        "temp_ls = [f'{x}_minmax_roll10' for x in models_transformer_ls]\n",
        "# corpus_transformer_df[models_transformer_ls].plot()\n",
        "corpus_transformer_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} Transformer 8 Models\\n[MinMax -> SMA 10%]')\n",
        "\n",
        "temp_ls = [f'{x}_stdscaler_roll10' for x in models_transformer_ls]\n",
        "# corpus_transformer_df[models_transformer_ls].plot()\n",
        "corpus_transformer_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} Transformer 8 Models\\n[StdScaler -> SMA 10%]')\n",
        "\n",
        "temp_ls = [f'{x}_lnorm_stdscaler_roll10' for x in models_transformer_ls]\n",
        "# corpus_transformer_df[models_transformer_ls].plot()\n",
        "corpus_transformer_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} Transformer 8 Models\\n[lnorm -> StdScaler -> SMA 10%]')\n",
        "\n",
        "temp_ls = [f'{x}_medianiqr_roll10' for x in models_transformer_ls]\n",
        "# corpus_transformer_df[models_transformer_ls].plot()\n",
        "corpus_transformer_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} Transformer 8 Models\\n[MedianIQR -> SMA 10%]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz5ruOK6Cvmd"
      },
      "source": [
        "### **Supervised ML 8 Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVqfI7DOCvmf"
      },
      "source": [
        "!ls -altr *.csv\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFNzjvmKCvmh"
      },
      "source": [
        "# Supervised ML Models: Read Computed sentiment data saved from previous run of this notebook\n",
        "\n",
        "# corpus_transformer_df = pd.read_csv('sum_sentiments_sents_trans_mproust_theguermantesway-french.csv')\n",
        "\n",
        "corpus_supervised_df = pd.read_csv('ml_sents_df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_GuNTJ2DH2K"
      },
      "source": [
        "corpus_supervised_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8kZKaP5o5WF"
      },
      "source": [
        "corpus_supervised_df['sent_raw'] = corpus_sents_df['sent_raw']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6JP9ty6Cvmi"
      },
      "source": [
        "# Clean Chapter DataFrame\n",
        "\n",
        "if 'Unnamed: 0' in corpus_supervised_df.columns:\n",
        "  corpus_supervised_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "  \n",
        "corpus_supervised_df.head(2)\n",
        "corpus_supervised_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAda1ePMpFEf"
      },
      "source": [
        "models_mlsu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYDSgtuqCvmj"
      },
      "source": [
        "# Derive Normalized/Standardized Time Series\n",
        "\n",
        "# Once applied modification function\n",
        "test_df = process_timeseries(ts_df=corpus_supervised_df, col_models_ls=models_supervised_ls, col_mod='lnorm')\n",
        "corpus_supervised_df = pd.concat([corpus_supervised_df, test_df], axis=1)\n",
        "corpus_supervised_df = corpus_supervised_df.loc[:,~corpus_supervised_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_supervised_df, col_models_ls=models_supervised_ls, col_mod='std-minmax')\n",
        "corpus_supervised_df = pd.concat([corpus_supervised_df, test_df], axis=1)\n",
        "corpus_supervised_df = corpus_supervised_df.loc[:,~corpus_supervised_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_supervised_df, col_models_ls=models_supervised_ls, col_mod='std-stdscaler')\n",
        "corpus_supervised_df = pd.concat([corpus_supervised_df, test_df], axis=1)\n",
        "corpus_supervised_df = corpus_supervised_df.loc[:,~corpus_supervised_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_supervised_df, col_models_ls=models_supervised_ls, col_mod='std-medianiqr')\n",
        "corpus_supervised_df = pd.concat([corpus_supervised_df, test_df], axis=1)\n",
        "corpus_supervised_df = corpus_supervised_df.loc[:,~corpus_supervised_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_supervised_df, col_models_ls=models_supervised_ls, col_mod='roll10')\n",
        "corpus_supervised_df = pd.concat([corpus_supervised_df, test_df], axis=1)\n",
        "corpus_supervised_df = corpus_supervised_df.loc[:,~corpus_supervised_df.columns.duplicated()]\n",
        "\n",
        "# Twice applied modification function (ends with roll)\n",
        "lnorm_ls = [f'{x}_lnorm' for x in models_supervised_ls]\n",
        "stdminmax_ls = [f'{x}_minmax' for x in models_supervised_ls]\n",
        "stdstdscaler_ls = [f'{x}_stdscaler' for x in models_supervised_ls]\n",
        "stdmedianiqr_ls = [f'{x}_medianiqr' for x in models_supervised_ls]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_supervised_df, col_models_ls=lnorm_ls, col_mod='std-minmax')\n",
        "corpus_supervised_df = pd.concat([corpus_supervised_df, test_df], axis=1)\n",
        "corpus_supervised_df = corpus_supervised_df.loc[:,~corpus_supervised_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_supervised_df, col_models_ls=lnorm_ls, col_mod='std-stdscaler')\n",
        "corpus_supervised_df = pd.concat([corpus_supervised_df, test_df], axis=1)\n",
        "corpus_supervised_df = corpus_supervised_df.loc[:,~corpus_supervised_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_supervised_df, col_models_ls=lnorm_ls, col_mod='std-medianiqr')\n",
        "corpus_supervised_df = pd.concat([corpus_supervised_df, test_df], axis=1)\n",
        "corpus_supervised_df = corpus_supervised_df.loc[:,~corpus_supervised_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_supervised_df, col_models_ls=lnorm_ls, col_mod='roll10')\n",
        "corpus_supervised_df = pd.concat([corpus_supervised_df, test_df], axis=1)\n",
        "corpus_supervised_df = corpus_supervised_df.loc[:,~corpus_supervised_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_supervised_df, col_models_ls=stdminmax_ls, col_mod='roll10')\n",
        "corpus_supervised_df = pd.concat([corpus_supervised_df, test_df], axis=1)\n",
        "corpus_supervised_df = corpus_supervised_df.loc[:,~corpus_supervised_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_supervised_df, col_models_ls=stdstdscaler_ls, col_mod='roll10')\n",
        "corpus_supervised_df = pd.concat([corpus_supervised_df, test_df], axis=1)\n",
        "corpus_supervised_df = corpus_supervised_df.loc[:,~corpus_supervised_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_supervised_df, col_models_ls=stdmedianiqr_ls, col_mod='roll10')\n",
        "corpus_supervised_df = pd.concat([corpus_supervised_df, test_df], axis=1)\n",
        "corpus_supervised_df = corpus_supervised_df.loc[:,~corpus_supervised_df.columns.duplicated()]\n",
        "\n",
        "# Thrice applied modification function (starts with lnorm and ends with roll)\n",
        "lnorm_stdminmax_ls = [f'{x}_lnorm_minmax' for x in models_supervised_ls]\n",
        "lnorm_stdstdscaler_ls = [f'{x}_lnorm_stdscaler' for x in models_supervised_ls]\n",
        "lnorm_stdmedianiqr_ls = [f'{x}_lnorm_medianiqr' for x in models_supervised_ls]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_supervised_df, col_models_ls=lnorm_stdminmax_ls, col_mod='roll10')\n",
        "corpus_supervised_df = pd.concat([corpus_supervised_df, test_df], axis=1)\n",
        "corpus_supervised_df = corpus_supervised_df.loc[:,~corpus_supervised_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_supervised_df, col_models_ls=lnorm_stdstdscaler_ls, col_mod='roll10')\n",
        "corpus_supervised_df = pd.concat([corpus_supervised_df, test_df], axis=1)\n",
        "corpus_supervised_df = corpus_supervised_df.loc[:,~corpus_supervised_df.columns.duplicated()]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_supervised_df, col_models_ls=lnorm_stdmedianiqr_ls, col_mod='roll10')\n",
        "corpus_supervised_df = pd.concat([corpus_supervised_df, test_df], axis=1)\n",
        "corpus_supervised_df = corpus_supervised_df.loc[:,~corpus_supervised_df.columns.duplicated()]\n",
        "\n",
        "corpus_supervised_df.head(2)\n",
        "corpus_supervised_df.info()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTS6H0wECvmm"
      },
      "source": [
        "print(*corpus_supervised_df.columns, sep='\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLmhh3hsCvmn"
      },
      "source": [
        "# roberta15lg_roll10_stdscaler\n",
        "# robertaxml8lang_roll10_stdscaler\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeAMMdtyCvmp"
      },
      "source": [
        "roll_ls = [10]\n",
        "\n",
        "test_df = process_timeseries(ts_df=corpus_supervised_df, col_models_ls=roll_ls, col_mod='medianiqr')\n",
        "test_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64yy5q0TCvmq"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "# Test reversing order of operations: first smooth (elim outliers) then Standardize\n",
        "\n",
        "# Create the plain roll10 series\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=models_transformer_ls, col_mod='roll10')\n",
        "print(f'test_df/roll10 shape: {test_df.shape}')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "\n",
        "temp_ls = [f'{x}_roll10' for x in models_transformer_ls]\n",
        "print(f'ROLL_LS: {temp_ls}')\n",
        "\n",
        "# Create the roll10_stdscaler series\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=temp_ls, col_mod='std-stdscaler')\n",
        "print(f'test_df/std-stdscaler shape: {test_df.shape}')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "\n",
        "temp_ls = [f'{x}_roll10_stdscaler' for x in models_transformer_ls]\n",
        "print(f'ROLL_STDSCALER_LS: {temp_ls}')\n",
        "\n",
        "# Plot \n",
        "# corpus_transformer_df[models_transformer_ls].plot()\n",
        "corpus_transformer_df['robertaxml8lang_roll10'].plot()\n",
        "\n",
        "# corpus_transformer_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} Transformer 8 Models\\n[SAM 10% then StdScaler]')\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UclmI8obCvmq"
      },
      "source": [
        "# CORPUS_FULL = 'The Guermantes Way - English, Marcel Proust'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzdX5N2jCvmr"
      },
      "source": [
        "# Derive Rolling Means Time Series\n",
        "\n",
        "temp_ls = [f'{x}_roll10' for x in models_supervised_ls]\n",
        "# corpus_supervised_df[models_supervised_ls].plot()\n",
        "corpus_supervised_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} Transformer 8 Models\\n[SMA 10%]')\n",
        "\n",
        "temp_ls = [f'{x}_minmax_roll10' for x in models_supervised_ls]\n",
        "# corpus_supervised_df[models_supervised_ls].plot()\n",
        "corpus_supervised_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} Transformer 8 Models\\n[MinMax -> SMA 10%]')\n",
        "\n",
        "temp_ls = [f'{x}_stdscaler_roll10' for x in models_supervised_ls]\n",
        "# corpus_supervised_df[models_supervised_ls].plot()\n",
        "corpus_supervised_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} Transformer 8 Models\\n[StdScaler -> SMA 10%]')\n",
        "\n",
        "temp_ls = [f'{x}_lnorm_stdscaler_roll10' for x in models_supervised_ls]\n",
        "# corpus_supervised_df[models_supervised_ls].plot()\n",
        "corpus_supervised_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} Transformer 8 Models\\n[lnorm -> StdScaler -> SMA 10%]')\n",
        "\n",
        "temp_ls = [f'{x}_medianiqr_roll10' for x in models_supervised_ls]\n",
        "# corpus_supervised_df[models_supervised_ls].plot()\n",
        "corpus_supervised_df[temp_ls].plot()\n",
        "plt.title(f'{CORPUS_FULL} Transformer 8 Models\\n[MedianIQR -> SMA 10%]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FiDm09nbAdF"
      },
      "source": [
        "### **Save Corpus DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSAWxF_7WKBS"
      },
      "source": [
        "!ls -altr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTif8-2IWRVc"
      },
      "source": [
        "corpus_root_filename = CORPUS_FILENAME.split('.')[:-1][0]\n",
        "\n",
        "corpus_sents_all_df = pd.read_csv(f'sum_sentiments_all31_sents_{corpus_root_filename}.csv')\n",
        "corpus_sents_all_df.head()\n",
        "corpus_sents_all_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZg_ve-7bAdH"
      },
      "source": [
        "# Save Corpus DataFrames\n",
        "\n",
        "save_dataframes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfyebD6HhQIU"
      },
      "source": [
        "# TODO: If missing, generate derived values for each model, lnorm/not, stdscaler/medianiqr, roll10/not"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d-AM_WvbqFu"
      },
      "source": [
        "\n",
        "# Verfiy there are no NaN or Empty strings that passed the cleaning process\n",
        "\n",
        "# Only execute if previously datafile/corpus_sents_df\n",
        "\n",
        "\n",
        "# corpus_sents_df[corpus_sents_df['sent_clean'].isnull()]\n",
        "\n",
        "# corpus_sents_df[corpus_sents_df['sent_clean'].apply(lambda x: len(str(x)) <= 0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAAQ0SwfZynO"
      },
      "source": [
        "# Verify that hyphenated words are correctly handled (e.g. 'summer-mroning' -> 'summer morning')\n",
        "\n",
        "# corpus_sents_df[corpus_sents_df['sent_clean'].str.contains('summer', na=False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsEbvCoCX7HY"
      },
      "source": [
        "## **(b) Compute Baseline Sentiments (Auto)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmyydBrCYctI"
      },
      "source": [
        "### **4 Stastical Machine Learning Classifiers (Optional: Auto)**\n",
        "\n",
        "* Linear Regression\n",
        "* Logistic Regression\n",
        "* Random Forest Classifier\n",
        "* Linear SVC\n",
        "* MultinomialNB\n",
        "\n",
        "Tutorials\n",
        "\n",
        "* https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794 (Tutorial) \n",
        "* https://github.com/mdipietro09/DataScience_ArtificialIntelligence_Utils/blob/master/natural_language_processing/example_text_classification.ipynb (github)\n",
        "* https://wellsr.com/python/python-sentiment-analysis-with-sklearn/\n",
        "* https://colab.research.google.com/drive/186bOdu08nv4xHe6VeBgt_aIk9_fziqsX#scrollTo=hpDp3V0Lg-sw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZB6O8_BFaA-"
      },
      "source": [
        "#### **Setup**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ym-yOrRbq5N"
      },
      "source": [
        "# Vectorizing text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "# Validation: https://www.kaggle.com/pocooo/types-of-cross-validation-all-you-need\n",
        "\n",
        "# Simple Cross Fold Validation\n",
        "from sklearn.model_selection import KFold\n",
        "# model=DecisionTreeClassifier()\n",
        "kfold_validation=KFold(10)\n",
        "\n",
        "# import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# results=cross_val_score(model,X,y,cv=kfold_validation)\n",
        "# print(results)\n",
        "# print(np.mean(results))\n",
        "\n",
        "# Stratified CV \n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "skfold=StratifiedKFold(n_splits=5)\n",
        "# model=DecisionTreeClassifier()\n",
        "# scores=cross_val_score(model,X,y,cv=skfold)\n",
        "# print(np.mean(scores))\n",
        "\n",
        "# LOO CV\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "# model=DecisionTreeClassifier()\n",
        "leave_validation=LeaveOneOut()\n",
        "# results=cross_val_score(model,X,y,cv=leave_validation)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcLbN-4SFiQM"
      },
      "source": [
        "from xgboost import XGBClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS-7DdAstqfg"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMVXlIEQqett"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuzrvLoAqfDV"
      },
      "source": [
        "nlp = spacy.blank('en')\n",
        "\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "# explicitly adding component to pipeline\n",
        "# (recommended - makes it more readable to tell what's going on)\n",
        "# nlp.add_pipe(PySBDFactory(nlp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXGMVY3dLlgE"
      },
      "source": [
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aisw4yS2EnL9"
      },
      "source": [
        "# END"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdO8oGyOMrQk"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "text_clf_SGDClassifier = Pipeline([('vect', CountVectorizer(ngram_range=(2,4), stop_words='english',lowercase=True)),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', SGDClassifier()),\n",
        "])\n",
        "text_clf_SGDClassifier.fit(X, y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai2efaWnOWHv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH62PhR6OWDI"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "# import plotly.offline as ply\n",
        "# plotly.offline.init_notebook_mode()\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHd2hh9SMrMB"
      },
      "source": [
        "classifier_names = ['Naive Bayes', \n",
        "                    'Decision Tree', \n",
        "                    'Random Forest', \n",
        "                    'Nearest Neighbors', \n",
        "                    'Neural Network']\n",
        "\n",
        "classifiers = [GaussianNB(),\n",
        "               DecisionTreeClassifier(max_depth=10),\n",
        "               RandomForestClassifier(max_depth=10),\n",
        "               KNeighborsClassifier(5),\n",
        "               MLPClassifier()]\n",
        "\n",
        "plot_data=[]\n",
        "\n",
        "clf_data=zip(classifier_names, classifiers)\n",
        "\n",
        "for clf_name, clf in clf_data:\n",
        "    print('Running '+clf_name)\n",
        "    kf=StratifiedKFold(n_splits=10, shuffle=True)\n",
        "    scores=cross_val_score(clf, X, y, cv=kf)\n",
        "    print(scores)\n",
        "    plot_data.append(\n",
        "        go.Scatter(\n",
        "            x=[i+1 for i in range(10)],\n",
        "            y=scores,\n",
        "            mode='lines',\n",
        "            name=clf_name\n",
        "        )\n",
        "    )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RQAiwjNRGUb"
      },
      "source": [
        "plot_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLkfeBvTQZYh"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY4o2FgRQbOu"
      },
      "source": [
        "layout = go.Layout(\n",
        "    xaxis=dict(\n",
        "        title='Fold no.'\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        range=[np.min([i['y'] for i in plot_data]), 1],\n",
        "        title='Accuracy'\n",
        "    )\n",
        ")\n",
        "fig=go.Figure(data=plot_data, layout=layout)\n",
        "ply.iplot(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAQ3P3lnOQpX"
      },
      "source": [
        "layout = go.Layout(\n",
        "    xaxis=dict(\n",
        "        title='Fold no.'\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        range=[np.min([i['y'] for i in plot_data]), 1],\n",
        "        title='Accuracy'\n",
        "    )\n",
        ")\n",
        "fig=go.scatter(data=plot_data, layout=layout)\n",
        "fig.show()\n",
        "# ply.iplot(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWlJS6T8PXOP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4o4HDc3SL8F"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use('ggplot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dslGduteUACr"
      },
      "source": [
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
        "    NuSVC(probability=True),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GradientBoostingClassifier(),\n",
        "    GaussianNB(),\n",
        "    LinearDiscriminantAnalysis(),\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "    # MultinomialNB(),\n",
        "    MLPClassifier()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spqkf9VUSL29"
      },
      "source": [
        "seed = 50\n",
        "dataset = datasets.load_wine()\n",
        "# X = dataset.data; y = dataset.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
        "kfold = model_selection.KFold(n_splits=10, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k08_iXqkSLxk"
      },
      "source": [
        "models = []\n",
        "models.append(('LR', LogisticRegression()))\n",
        "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC2tlurpTOP4"
      },
      "source": [
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy'\n",
        "for name, model in models:\n",
        "      kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
        "      cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "      results.append(cv_results)\n",
        "      names.append(name)\n",
        "      msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "      print(msg)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "LR: 0.862886 (0.005822)\n",
        "LDA: 0.859657 (0.006562)\n",
        "KNN: 0.728571 (0.008688)\n",
        "CART: 0.710829 (0.007842)\n",
        "NB: 0.817286 (0.007659)\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbRGacBAnDyT"
      },
      "source": [
        "models2 = []\n",
        "\n",
        "models2.append(('SVM', SVC()))\n",
        "models2.append(('MultiNB', MultinomialNB()))\n",
        "models2.append(('RFC', RandomForestClassifier()))\n",
        "models2.append(('MultiLP', MLPClassifier()))\n",
        "\n",
        "models2.append(('NuSVC', NuSVC(probability=True)))\n",
        "models2.append(('AdaBC', AdaBoostClassifier()))\n",
        "models2.append(('GradBC', GradientBoostingClassifier()))\n",
        "models2.append(('LinDA', LinearDiscriminantAnalysis()))\n",
        "models2.append(('QuadDA', QuadraticDiscriminantAnalysis()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpKeO3CcnFcj"
      },
      "source": [
        "results2 = []\n",
        "names2 = []\n",
        "scoring = 'accuracy'\n",
        "for name, model in models2:\n",
        "      kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
        "      cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "      results2.append(cv_results)\n",
        "      names2.append(name)\n",
        "      msg = \"%s: %f (%f)\" % (name2, cv_results.mean(), cv_results.std())\n",
        "      print(msg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGom-DXdTROf"
      },
      "source": [
        "fig = plt.figure(figsize=(10,10))\n",
        "fig.suptitle('How to compare sklearn classification algorithms')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kJ6HRtBSLsX"
      },
      "source": [
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy'\n",
        "for name, model in models:\n",
        "      kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
        "      cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "      results.append(cv_results)\n",
        "      names.append(name)\n",
        "      msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "      print(msg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWcwr4sRSLnK"
      },
      "source": [
        "fig = plt.figure(figsize=(10,10))\n",
        "fig.suptitle('How to compare sklearn classification algorithms')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVJkMiprSLhG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5o9P-qLSLb2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlvJf9cuSLXO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW_cTC3KPigo"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZz-jk5hPXJI"
      },
      "source": [
        "sss = StratifiedShuffleSplit(labels, 10, test_size=0.2, random_state=23)\n",
        "\n",
        "for train_index, test_index in sss:\n",
        "    X_train, X_test = train.values[train_index], train.values[test_index]\n",
        "    y_train, y_test = labels[train_index], labels[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OVgc73dQAHn"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WFleRcSOeb_"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
        "    NuSVC(probability=True),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GradientBoostingClassifier(),\n",
        "    GaussianNB(),\n",
        "    LinearDiscriminantAnalysis(),\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "    # MultinomialNB(),\n",
        "    MLPClassifier()]\n",
        "\n",
        "# Logging for Visual Comparison\n",
        "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
        "log = pd.DataFrame(columns=log_cols)\n",
        "\n",
        "for clf in classifiers:\n",
        "    clf.fit(X_train, y_train)\n",
        "    name = clf.__class__.__name__\n",
        "    \n",
        "    print(\"=\"*30)\n",
        "    print(name)\n",
        "    \n",
        "    print('****Results****')\n",
        "    train_predictions = clf.predict(X_test)\n",
        "    acc = accuracy_score(y_test, train_predictions)\n",
        "    print(\"Accuracy: {:.4%}\".format(acc))\n",
        "    \n",
        "    train_predictions = clf.predict_proba(X_test)\n",
        "    ll = log_loss(y_test, train_predictions)\n",
        "    print(\"Log Loss: {}\".format(ll))\n",
        "    \n",
        "    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n",
        "    log = log.append(log_entry)\n",
        "    \n",
        "print(\"=\"*30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4QHEHqgOeW-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCgNcZExqfDc"
      },
      "source": [
        "# WARNING: This will execute without error even if SpaCy model not loaded (silent error)\n",
        "#          Must choose between En/Fr and consider PySBD sentence segementation as part of nlp pipeline\n",
        "\n",
        "def lemmatize(text):\n",
        "    \"\"\"Perform lemmatization and stopword removal in the clean text\n",
        "       Returns a list of lemmas\n",
        "    \"\"\"\n",
        "    text = ''.join([c for c in text if c.isascii()])\n",
        "    doc = nlp(text)\n",
        "    lemma_list = [str(tok.lemma_).lower() for tok in doc\n",
        "                  if tok.is_alpha and tok.text.lower() not in stopwords_en]\n",
        "    return lemma_list\n",
        "\n",
        "# Test\n",
        "print(lemmatize('I was running late and decided to to stop drinking.'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQqNyV16OQk2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUUDZ8H6qfDf"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Method #1: Lemmatize with Pandas apply()\n",
        "\n",
        "# Note: on C.Dickens' Great Expectations\n",
        "\n",
        "# imdb50k_df['text_lemma1'] = imdb50k_df['text_clean'].apply(lemmatize)\n",
        "# imdb50k_df.head(3)\n",
        "\n",
        "\n",
        "# Save checkpoint\n",
        "\n",
        "# imdb50k_df.to_csv(f'mlimdb50k_lemma3_sents_df.csv')\n",
        "# imdb50k_df.to_csv(f'ml{supervised_db}_sents_df.csv')\n",
        "\n",
        "# files.download('mlimdb50k_lemma3_sents_df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGISHWdKqfDn"
      },
      "source": [
        "# Method #2: Lemmatize with spacy nlp.pipe\n",
        "\n",
        "def lemmatize_pipe(doc):\n",
        "    lemma_list = [str(tok.lemma_).lower() for tok in doc\n",
        "                  if tok.is_alpha and tok.text.lower() not in stopwords_en] \n",
        "    return lemma_list\n",
        "\n",
        "def preprocess_pipe(texts):\n",
        "    preproc_pipe = []\n",
        "    for doc in nlp.pipe(texts, batch_size=20):\n",
        "        preproc_pipe.append(lemmatize_pipe(doc))\n",
        "    return preproc_pipe\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwnFq1V-qfDp"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Method #2: Lemmatize with spacy nlp.pipe\n",
        "# Note: 22min\n",
        "\n",
        "# imdb50k_df['text_lemma2'] = preprocess_pipe(imdb50k_df['text_clean'])\n",
        "# imdb50k_df.head(3)\n",
        "\n",
        "# imdb50k_df.rename(columns={'text_lemma3':'text_lemma'}, inplace=True)\n",
        "# imdb50k_df.drop(columns=['text_lemma2'], inplace=True)\n",
        "\n",
        "# Save checkpoint\n",
        "\n",
        "# imdb50k_df.to_csv(f'mlimdb50k_lemma2_sents_df.csv')\n",
        "# imdb50k_df.to_csv(f'ml{supervised_db}_sents_df.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WkbBU9YqfDs"
      },
      "source": [
        "!pip install joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNVjmuGbqfDt"
      },
      "source": [
        "# Method #3: Lemmatize with joblib parallelization\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "def chunker(iterable, total_length, chunksize):\n",
        "    return (iterable[pos: pos + chunksize] for pos in range(0, total_length, chunksize))\n",
        "\n",
        "def flatten(list_of_lists):\n",
        "    \"Flatten a list of lists to a combined list\"\n",
        "    return [item for sublist in list_of_lists for item in sublist]\n",
        "\n",
        "def process_chunk(texts):\n",
        "    preproc_pipe = []\n",
        "    for doc in nlp.pipe(texts, batch_size=20):\n",
        "        preproc_pipe.append(lemmatize_pipe(doc))\n",
        "    return preproc_pipe\n",
        "\n",
        "def preprocess_parallel(texts, chunksize=100):\n",
        "    executor = Parallel(n_jobs=2, backend='multiprocessing', prefer=\"processes\")\n",
        "    do = delayed(process_chunk)\n",
        "    tasks = (do(chunk) for chunk in chunker(texts, len(imdb50k_df), chunksize=chunksize))\n",
        "    result = executor(tasks)\n",
        "    return flatten(result)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOWTIHg_qfDu"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Method #3: Lemmatize with joblib parallelization\n",
        "# NOTE: 17m13s \n",
        "\n",
        "# imdb50k_df['text_lemma3'] = preprocess_parallel(imdb50k_df['text_clean'], chunksize=1000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WEb4RV0guDX"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "if ML_Models_Arc == True:\n",
        "  model_base = 'vader'\n",
        "  model_name = 'vader_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'\n",
        "\n",
        "if VADER_Arc == True:\n",
        "  # Sentiment evaluation function\n",
        "  sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "  # Test\n",
        "  sid.polarity_scores('hello world'\n",
        "\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJT8Z7p1bE-N"
      },
      "source": [
        "#### **Preparing Labeled Sentiment Dataset**\n",
        "\n",
        "* SST-2/SST-5\n",
        "* IMDB\n",
        "* Yelp\n",
        "* Sentiment140"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE1mTRBenRYh"
      },
      "source": [
        "# Upload kaggle credentials *.json file\n",
        "\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiwD6YVXnRUf"
      },
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Vxm1Pc4GdKg"
      },
      "source": [
        "!mkdir /root/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8C5ikUVngGS"
      },
      "source": [
        "!cp kaggle.json /root/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snpmtQv2GHzz"
      },
      "source": [
        "!ls /root/.kaggle/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoAbKdAPmagz"
      },
      "source": [
        "**IMDB 50k (Movie)**\n",
        "\n",
        "* https://huggingface.co/datasets/imdb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6DzdXynmXzZ"
      },
      "source": [
        "# !wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWjGurjNxGz_"
      },
      "source": [
        "supervised_db = 'imdb50k'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqKUuGKOHOXD"
      },
      "source": [
        "!ls -altr *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKUUzsTrHJw1"
      },
      "source": [
        "# Option A: Load in imdb_df\n",
        "\n",
        "imdb50k_df = pd.read_csv(\"sa_train_lemma_imdb50k.csv\")\n",
        "imdb50k_df.head(1)\n",
        "imdb50k_df.info()\n",
        "\n",
        "\"\"\"\n",
        "imdb50k_df[\"polarity\"] = imdb50k_df[\"sentiment\"].map({\"negative\": 0, \"positive\": 1})\n",
        "imdb50k_df[\"text_raw\"] = imdb50k_df[\"review\"].astype('string')\n",
        "imdb50k_df.drop(columns=['sentiment', 'review'], inplace=True)\n",
        "\n",
        "supervised_db = 'imdb50k'\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA1Rq6Y2qhwV"
      },
      "source": [
        "# Option B: Create IMDB_df\n",
        "\n",
        "!kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKQg7q3ary2i"
      },
      "source": [
        "!ls *zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNoXUTsxryxC"
      },
      "source": [
        "!unzip imdb-dataset-of-50k-movie-reviews.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S-ZShOmsCEx"
      },
      "source": [
        "imdb50k_df = pd.read_csv(\"IMDB Dataset.csv\")\n",
        "imdb50k_df[\"polarity\"] = imdb50k_df[\"sentiment\"].map({\"negative\": 0, \"positive\": 1})\n",
        "imdb50k_df[\"text_raw\"] = imdb50k_df[\"review\"].astype('string')\n",
        "imdb50k_df.drop(columns=['sentiment', 'review'], inplace=True)\n",
        "\n",
        "supervised_db = 'imdb50k'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBFpI0KusB_h"
      },
      "source": [
        "imdb50k_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "874pXJ8jxDH9"
      },
      "source": [
        "# Remove non-alphanumeric chacters\n",
        "# imdb50k_df['text_lower'] = imdb50k_df['text_raw']\n",
        "\n",
        "pattern = re.compile(r\"[A-Za-z0-9\\-]{3,50}\")\n",
        "imdb50k_df['text_clean'] = imdb50k_df['text_raw'].str.lower().str.strip().str.findall(pattern).str.join(' ')\n",
        "imdb50k_df.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0hlgbsUzvbg"
      },
      "source": [
        "stopwords_custom"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk1M_iJgdgCG"
      },
      "source": [
        "nlp = spacy.blank('en')\n",
        "\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "# explicitly adding component to pipeline\n",
        "# (recommended - makes it more readable to tell what's going on)\n",
        "# nlp.add_pipe(PySBDFactory(nlp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTTwI1MsxC4V"
      },
      "source": [
        "# WARNING: This will execute without error even if SpaCy model not loaded (silent error)\n",
        "#          Must choose between En/Fr and consider PySBD sentence segementation as part of nlp pipeline\n",
        "\n",
        "def lemmatize(text):\n",
        "    \"\"\"Perform lemmatization and stopword removal in the clean text\n",
        "       Returns a list of lemmas\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "    lemma_list = [str(tok.lemma_).lower() for tok in doc\n",
        "                  if tok.is_alpha and tok.text.lower() not in stopwords_en]\n",
        "    return lemma_list\n",
        "\n",
        "# Test\n",
        "print(lemmatize('I was running late and decided to to stop drinking.'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eKCtw6mzCRv"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Method #1: Lemmatize with Pandas apply()\n",
        "\n",
        "# Note: on C.Dickens' Great Expectations\n",
        "\n",
        "imdb50k_df['text_lemma'] = imdb50k_df['text_clean'].apply(lemmatize)\n",
        "imdb50k_df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb1PTFdB377O"
      },
      "source": [
        "# Save checkpoint\n",
        "\n",
        "imdb50k_df.to_csv(f'mlimdb50k_lemma_sents_df.csv')\n",
        "# imdb50k_df.to_csv(f'ml{supervised_db}_sents_df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEWc92Z7CnE3"
      },
      "source": [
        "!ls -altr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0wRacWECqgY"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K83u01NC8Ft"
      },
      "source": [
        "files.download('mlimdb50k_lemma_sents_df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkc5w9b6DCJJ"
      },
      "source": [
        "files.download('ml_sents_df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JefUrhgQDMiQ"
      },
      "source": [
        "!rm mlimdb50k_lemma2_sents_df.csv\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA5zr9xr0Pmf"
      },
      "source": [
        "# Method #2: Lemmatize with spacy nlp.pipe\n",
        "\n",
        "def lemmatize_pipe(doc):\n",
        "    lemma_list = [str(tok.lemma_).lower() for tok in doc\n",
        "                  if tok.is_alpha and tok.text.lower() not in stopwords_en] \n",
        "    return lemma_list\n",
        "\n",
        "def preprocess_pipe(texts):\n",
        "    preproc_pipe = []\n",
        "    for doc in nlp.pipe(texts, batch_size=20):\n",
        "        preproc_pipe.append(lemmatize_pipe(doc))\n",
        "    return preproc_pipe\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYZF5fDt0Pdj"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Method #2: Lemmatize with spacy nlp.pipe\n",
        "# Note: 22min\n",
        "\n",
        "imdb50k_df['text_lemma2'] = preprocess_pipe(imdb50k_df['text_clean'])\n",
        "imdb50k_df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IvyLp_DEA4q"
      },
      "source": [
        "imdb50k_df.rename(columns={'text_lemma3':'text_lemma'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veKXUZgDD8Ae"
      },
      "source": [
        "imdb50k_df.drop(columns=['text_lemma2'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwiRAVYJD3bM"
      },
      "source": [
        "imdb50k_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVgGKfjIEVC3"
      },
      "source": [
        "imdb50k_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZgnzBM431XH"
      },
      "source": [
        "# Save checkpoint\n",
        "\n",
        "imdb50k_df.to_csv(f'mlimdb50k_lemma2_sents_df.csv')\n",
        "# imdb50k_df.to_csv(f'ml{supervised_db}_sents_df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t3Nkmo01Gyy"
      },
      "source": [
        "!pip install joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEQ2iZOS0vOo"
      },
      "source": [
        "# Method #3: Lemmatize with joblib parallelization\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "def chunker(iterable, total_length, chunksize):\n",
        "    return (iterable[pos: pos + chunksize] for pos in range(0, total_length, chunksize))\n",
        "\n",
        "def flatten(list_of_lists):\n",
        "    \"Flatten a list of lists to a combined list\"\n",
        "    return [item for sublist in list_of_lists for item in sublist]\n",
        "\n",
        "def process_chunk(texts):\n",
        "    preproc_pipe = []\n",
        "    for doc in nlp.pipe(texts, batch_size=20):\n",
        "        preproc_pipe.append(lemmatize_pipe(doc))\n",
        "    return preproc_pipe\n",
        "\n",
        "def preprocess_parallel(texts, chunksize=100):\n",
        "    executor = Parallel(n_jobs=2, backend='multiprocessing', prefer=\"processes\")\n",
        "    do = delayed(process_chunk)\n",
        "    tasks = (do(chunk) for chunk in chunker(texts, len(imdb50k_df), chunksize=chunksize))\n",
        "    result = executor(tasks)\n",
        "    return flatten(result)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnQ55as-0vEs"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Method #3: Lemmatize with joblib parallelization\n",
        "# NOTE: 17m13s \n",
        "\n",
        "imdb50k_df['text_lemma'] = preprocess_parallel(imdb50k_df['text_clean'], chunksize=1000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2w6i8dv0u_c"
      },
      "source": [
        "# Save checkpoint\n",
        "\n",
        "imdb50k_df.to_csv(f'sa_train_lemma_imdb50k.csv')\n",
        "# imdb50k_df.to_csv(f'ml{supervised_db}_sents_df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcqEhl0UCOaX"
      },
      "source": [
        "imdb50k_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaZQ8pTtFIvI"
      },
      "source": [
        "print(imdb50k_df.iloc[0]['text_lemma'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFuZBs9KFb4E"
      },
      "source": [
        "def list2str(str_ls):\n",
        "  '''\n",
        "  Given a list of string\n",
        "  Return a all strings concatenated, separated by ' '\n",
        "  '''\n",
        "  joined_str = ' '.join(str_ls)\n",
        "\n",
        "  return joined_str\n",
        "\n",
        "imdb50k_df['text_lemma'] = imdb50k_df['text_lemma'].apply(list2str)\n",
        "# imdb50k_df.drop(columns=['text_lemma'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IynLUxIJMUIJ"
      },
      "source": [
        "imdb50k_df.drop(columns=['text_lemma3'],inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlC9MdSNfBVb"
      },
      "source": [
        "imdb50k_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y2Qrq1bGf7O"
      },
      "source": [
        "# imdb50k_df.rename(columns={'text_lemma':'text_clean'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifyd8x6OtFo1"
      },
      "source": [
        "# def clean_stemlemma_text(text, stem_fl =False, lemma_fl=True, punct_fl=True, stopword_ls=stopwords_en):\n",
        "# TODO: pandas DataFrame.Series.apply(curried function)\n",
        "\n",
        "# NOTE: SST2: >25m\n",
        "# sst2_sents_df['text_lemma'] = sst2_sents_df['text_raw'].apply(clean_stemlemma_text)\n",
        "\n",
        "# imdb50k_df['text_lower'] = imdb50k_df['text_raw'].str.strip().str.lower()\n",
        "# imdb50k_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDzfd0okE_Yr"
      },
      "source": [
        "# Vectorize IMDB Training dataset with TF-IDF\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stopwords_en = stopwords.words('english') # + stopwords.words('french')\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,3), stop_words=stopwords_en, max_features=1000)\n",
        "vectors = vectorizer.fit_transform(imdb50k_df.text_clean)\n",
        "words_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
        "words_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzqocELYE_Yt"
      },
      "source": [
        "# Separate text from labels\n",
        "\n",
        "X = words_df\n",
        "y = imdb50k_df.polarity\n",
        "X.shape\n",
        "print('\\n')\n",
        "y.shape\n",
        "type(y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVg2Vh1QmYJf"
      },
      "source": [
        "**SST-5 (Text)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4l9EPgVmqzU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSa0vYLfmg3i"
      },
      "source": [
        "**SST-2 (Text)**\n",
        "\n",
        "* https://prrao87.github.io/blog/spacy/nlp/performance/2020/05/02/spacy-multiprocess.html (Accelerate with SpaCy pipelines/joblib)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPoZ3onS8u-1"
      },
      "source": [
        "**Retrieve via PyTorch TorchText**\n",
        "\n",
        "* https://github.com/shayneobrien/sentiment-classification/blob/master/notebooks/02-naive-bayes-unigram.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXJyGQ-9Eq7Q"
      },
      "source": [
        "supervised_db = 'sst2'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FheAchd8uxd"
      },
      "source": [
        "import torchtext\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from torchtext.vocab import Vectors\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZdWe3yQ9EHn"
      },
      "source": [
        "text = torchtext.data.Field(include_lengths = False)\n",
        "label = torchtext.data.Field(sequential=False)\n",
        "train, val, test = torchtext.datasets.SST.splits(text, label, filter_pred=lambda ex: ex.label != 'neutral')\n",
        "text.build_vocab(train)\n",
        "label.build_vocab(train)\n",
        "train_iter, val_iter, test_iter = torchtext.data.BucketIterator.splits((train, val, test), batch_size=10, device=-1, repeat = False)\n",
        "url = 'https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.simple.vec'\n",
        "text.vocab.load_vectors(vectors=Vectors('wiki.simple.vec', url=url))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UhDXd2N9ECt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZrHoKfh2vUC"
      },
      "source": [
        "**Retrieve from Kaggle Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGow41Oz2qpv"
      },
      "source": [
        "!kaggle datasets download -d atulanandjha/stanford-sentiment-treebank-v2-sst2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLs5cDNH2qlM"
      },
      "source": [
        "!unzip stanford-sentiment-treebank-v2-sst2.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhLqfmQh-xLj"
      },
      "source": [
        "!cat SST2-Data/SST2-Data/stanfordSentimentTreebank/stanfordSentimentTreebank/README.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcPO1OjQ2qgx"
      },
      "source": [
        "!ls SST2-Data/SST2-Data/stanfordSentimentTreebank/stanfordSentimentTreebank/SST2-Data/SST2-Data/stanfordSentimentTreebank/stanfordSentimentTreebank/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nluKanu2qcU"
      },
      "source": [
        "!head -n 5 ./SST2-Data/SST2-Data/stanfordSentimentTreebank/stanfordSentimentTreebank/datasetSentences.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEqbDjgN2qXq"
      },
      "source": [
        "!head -n 5 ./SST2-Data/SST2-Data/stanfordSentimentTreebank/stanfordSentimentTreebank/sentiment_labels.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbomRqan2qTD"
      },
      "source": [
        "sst2_sents_filename = './SST2-Data/SST2-Data/stanfordSentimentTreebank/stanfordSentimentTreebank/dictionary.txt'\n",
        "sst2_sents_df = pd.read_csv(sst2_sents_filename, sep='|', header=None) \n",
        "sst2_sents_df.columns = ['text_raw','phrase_id']\n",
        "sst2_sents_df['text_raw'] = sst2_sents_df['text_raw'].astype('string')\n",
        "sst2_sents_df.head(20)\n",
        "sst2_sents_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP69q79JdZSb"
      },
      "source": [
        "# def clean_stemlemma_text(text, stem_fl =False, lemma_fl=True, punct_fl=True, stopword_ls=stopwords_en):\n",
        "# TODO: pandas DataFrame.Series.apply(curried function)\n",
        "\n",
        "# NOTE: SST2: >25m\n",
        "# sst2_sents_df['text_lemma'] = sst2_sents_df['text_raw'].apply(clean_stemlemma_text)\n",
        "\n",
        "sst2_sents_df['text_lower'] = sst2_sents_df['text_raw'].str.strip().str.lower()\n",
        "sst2_sents_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtswvhMeaEyV"
      },
      "source": [
        "# sst2_sents_df['text_clean'] = sst2_sents_df['text_raw'].apply(clean_stemlemma_text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxEgiVXGeS_z"
      },
      "source": [
        "# sst2_sents_df['text_lower'] = sst2_sents_df['text_raw'].apply(lambda x: lower(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ8dmvpR2qNz"
      },
      "source": [
        "sst2_labels_filename = './SST2-Data/SST2-Data/stanfordSentimentTreebank/stanfordSentimentTreebank/sentiment_labels.txt'\n",
        "sst2_labels_df = pd.read_csv(sst2_labels_filename, sep='|') \n",
        "sst2_labels_df.columns = ['phrase_id','polarity_fl']\n",
        "sst2_labels_df.head(20)\n",
        "sst2_labels_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sZztnmG_xEF"
      },
      "source": [
        "sst2_df = pd.concat([sst2_sents_df.set_index('phrase_id'),sst2_labels_df.set_index('phrase_id')], axis=1, join='inner')\n",
        "sst2_df.head()\n",
        "sst2_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsOcAE-6Cbid"
      },
      "source": [
        "def polarity_float2int(val_fl):\n",
        "  '''\n",
        "  Given a float between 0.0 and 1.0\n",
        "  Return an integer between 0-5 mapped to every 0.2 interval\n",
        "  '''\n",
        "  val_int = 0\n",
        "  if (val_fl < 0.2):\n",
        "    val_int = 0\n",
        "  elif (0.2 <= val_fl < 0.4):\n",
        "    val_int = 1\n",
        "  elif (0.4 <= val_fl < 0.6):\n",
        "    val_int = 2\n",
        "  elif (0.6 <= val_fl < 0.8):\n",
        "    val_int = 3\n",
        "  elif (0.8 <= val_fl <= 1.0):\n",
        "    val_int = 4\n",
        "  else:\n",
        "    print(f'ERROR: polarity value must be [0.0-1.0] but was set to: {val_fl}')\n",
        "    val_int = -99\n",
        "\n",
        "  return val_int\n",
        "\n",
        "# Test\n",
        "polarity_float2int(0.55)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTyFUTZyDWbD"
      },
      "source": [
        "sst2_df['polarity'] = sst2_df['polarity_fl'].apply(lambda x: polarity_float2int(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuBCKBbAEDeB"
      },
      "source": [
        "sst2_df.head(10)\n",
        "sst2_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQa4nAmb6H6X"
      },
      "source": [
        "sst2_df.shape\n",
        "sst2_df[sst2_df.polarity.isna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y_bnL4Dglpk"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "from sklearn.feature_extraction import text\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "stopwords_custom = text.ENGLISH_STOP_WORDS.union([\"bazinga\"])\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,1), stop_words=my_stop_words)\n",
        "\n",
        "X = vectorizer.fit_transform([\"this is an apple.\",\"this is a book.\"])\n",
        "\n",
        "idf_values = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
        "\n",
        "# printing the tfidf vectors\n",
        "print(X)\n",
        "\n",
        "# printing the vocabulary\n",
        "print(vectorizer.vocabulary_)\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw8AN5wghXVT"
      },
      "source": [
        "from sklearn.feature_extraction import text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETCHx_Z5hXI4"
      },
      "source": [
        "stopwords_custom = text.ENGLISH_STOP_WORDS.union([\"bazinga\"])\n",
        "len(stopwords_custom)\n",
        "print('\\n')\n",
        "type(stopwords_custom)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uXkt1Ha5-3d"
      },
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(1,1), stop_words=stopwords_custom, max_features=1000)\n",
        "vectors = vectorizer.fit_transform(sst2_df.text_lower)\n",
        "words_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
        "words_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DML2PyO5-3e"
      },
      "source": [
        "X = words_df\n",
        "y = sst2_df.polarity\n",
        "X.shape\n",
        "print('\\n')\n",
        "y.shape\n",
        "type(y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGzl5dKk2rST"
      },
      "source": [
        "**Retrieve from Huggingface Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSbf4OyPzkgl"
      },
      "source": [
        "# install datasets\n",
        "!pip install datasets\n",
        "\n",
        "# Make sure that we have a recent version of pyarrow in the session before we continue - otherwise reboot Colab to activate it\n",
        "import pyarrow\n",
        "if int(pyarrow.__version__.split('.')[1]) < 16 and int(pyarrow.__version__.split('.')[0]) == 0:\n",
        "    import os\n",
        "    os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH_3O8oEzmB5"
      },
      "source": [
        "# Let's import the library. We typically only need at most four methods:\n",
        "from datasets import list_datasets, list_metrics, load_dataset, load_metric\n",
        "\n",
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKhOr-XAzl7K"
      },
      "source": [
        "# Currently available datasets and metrics\n",
        "datasets = list_datasets()\n",
        "metrics = list_metrics()\n",
        "\n",
        "print(f\"🤩 Currently {len(datasets)} datasets are available on the hub:\")\n",
        "pprint(datasets, compact=True)\n",
        "print(f\"🤩 Currently {len(metrics)} metrics are available on the hub:\")\n",
        "pprint(metrics, compact=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WEl8TzImj-P"
      },
      "source": [
        "# You can access various attributes of the datasets before downloading them\n",
        "sst_dataset = list_datasets(with_details=True)[datasets.index('sst')]\n",
        "\n",
        "pprint(sst_dataset.__dict__)  # It's a simple python dataclass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqTkQELdmqgs"
      },
      "source": [
        "# Downloading and loading a dataset\n",
        "dataset = load_dataset('sst', split='validation[:10%]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjIO3bR_0XBG"
      },
      "source": [
        "# Informations on the dataset (description, citation, size, splits, format...)\n",
        "# are provided in `dataset.info` (a simple python dataclass) and also as direct attributes in the dataset object\n",
        "pprint(dataset.info.__dict__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfG9DIZe0W8r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBchwJCdG-4z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzGBqKZmG-rt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGa8FGa9E-7W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA_dToBAE-2B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG2_kq-cE-m8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZP_L_4CuTw-"
      },
      "source": [
        "# Create a version of text that is lemmatized and has both stopwords and punctuation removed \n",
        "# clean_stemlemma_text(text, stem_fl =False, lemma_fl=True, punct_fl=True, stopword_ls=stopwords_en):\n",
        "\n",
        "# TODO: Accelerate with joblib: https://prrao87.github.io/blog/spacy/nlp/performance/2020/05/02/spacy-multiprocess.html\n",
        "\n",
        "# NOTE: Xm \n",
        "\n",
        "imdb50k_df['text_lemma'] = imdb50k_df['text_raw'].apply(lambda x : clean_stemlemma_text(x))\n",
        "imdb50k_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04M3cGefwKyl"
      },
      "source": [
        "# reload spacy with minimal components for speed\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'ner'])\n",
        "nlp.add_pipe(nlp.create_pipe('sentencizer'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iomWpSsVwVOF"
      },
      "source": [
        "# use stopword SETS O(1) < LISTS O(n) for performance\n",
        "\n",
        "stopword_custom_set = set(stopword_custom_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20yaHuU5w11S"
      },
      "source": [
        "def cleaner(df):\n",
        "    \"Extract relevant text from DataFrame using a regex\"\n",
        "    # Regex pattern for only alphanumeric, hyphenated text with 3 or more chars\n",
        "    pattern = re.compile(r\"[A-Za-z0-9\\-]{3,50}\")\n",
        "    df['clean'] = df['content'].str.findall(pattern).str.join(' ')\n",
        "    if limit > 0:\n",
        "        return df.iloc[:limit, :].copy()\n",
        "    else:\n",
        "        return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URbYB3pYw1wD"
      },
      "source": [
        "df_preproc = cleaner(df)\n",
        "df_preproc.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SikvRyYLw1r3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OmOg71lwKtI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj-lYZ3GwKjF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXrmI1r3sOiT"
      },
      "source": [
        "imdb50k_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFSEutU5th5k"
      },
      "source": [
        "stopwords_custom = text.ENGLISH_STOP_WORDS.union([\"bazinga\"])\n",
        "len(stopwords_custom)\n",
        "print('\\n')\n",
        "type(stopwords_custom)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZW3feRLth5l"
      },
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(1,1), stop_words=stopwords_custom, max_features=1000)\n",
        "vectors = vectorizer.fit_transform(imdb50k_df.text_lower)\n",
        "words_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
        "words_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMu2M9OntyGk"
      },
      "source": [
        "imdb50k_df.shape\n",
        "print('\\n')\n",
        "imdb50k_df.polarity.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0_3XDOxtyGm"
      },
      "source": [
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "vectors = vectorizer.fit_transform(imdb50k_df.text)\n",
        "words_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
        "words_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYHtomVHtyGn"
      },
      "source": [
        "X = words_df\n",
        "y = imdb50k_df.polarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzuarHPWtxzC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kpd0U4BNtxu7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlj9bxfOtxoy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hBT6n_jmcr2"
      },
      "source": [
        "**Yelp (Restaurant)**\n",
        "\n",
        "* https://www.kaggle.com/suzanaiacob/sentiment-analysis-of-the-yelp-reviews-data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXRwivGimXsV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQMPluV-mXlD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meNQhTTkeIiB"
      },
      "source": [
        "**Sentiment140 (Tweets)**\n",
        "\n",
        "* http://help.sentiment140.com/for-students/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxns2Ni1Yb4Q"
      },
      "source": [
        "# Make data directory if it doesn't exist\n",
        "!mkdir -p data\n",
        "!wget -nc https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/investigating-sentiment-analysis/data/sentiment140-subset.csv.zip -P data\n",
        "!unzip -n -d data data/sentiment140-subset.csv.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_-UTBc6bSIy"
      },
      "source": [
        "sentiment140_df = pd.read_csv(\"data/sentiment140-subset.csv\", nrows=30000)\n",
        "sentiment140_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01BWNOW7bcz0"
      },
      "source": [
        "sentiment140_df.shape\n",
        "print('\\n')\n",
        "sentiment140_df.polarity.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Pyudw8Ybquc"
      },
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(1,3), stop_words=stopwords_en, max_features=1000)\n",
        "vectors = vectorizer.fit_transform(sentiment140_df.text)\n",
        "\n",
        "vectors_np = vectors.toarray()\n",
        "\n",
        "words_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
        "words_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-C97ACebr3A"
      },
      "source": [
        "X = words_df\n",
        "y = sentiment140_df.polarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNqksop2eygX"
      },
      "source": [
        "#### **Training**\n",
        "\n",
        "Tuning Hyperparameters: Grid and Random Search\n",
        "\n",
        "* https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
        "\n",
        "Acceleration:\n",
        "\n",
        "* https://rapids.ai/start.html \n",
        "* https://colab.research.google.com/drive/1rY7Ln6rEE1pOlfSHCYOVaqt8OvDO35J0#forceEdit=true&offline=true&sandboxMode=true (Rapids)\n",
        "* https://github.com/lebedov/scikit-cuda \n",
        "* https://github.com/skorch-dev/skorch (Scikit wrap of PyTorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S6_aU98Ckmy"
      },
      "source": [
        "**AutoML: MS flaml**\n",
        "\n",
        "* https://github.com/microsoft/FLAML/blob/main/notebook/flaml_automl.ipynb\n",
        "* https://www.youtube.com/watch?v=bJfDJhe-O-c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPS7SHVJJ0Bs"
      },
      "source": [
        "# !pip install flaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MSHAEn2qzMt"
      },
      "source": [
        "!pip install flaml[notebook]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QiH_9pUrRaK"
      },
      "source": [
        "!mkdir test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmQz-X7B96Dr"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7bnmcENq2Wj"
      },
      "source": [
        "# Split into Training and Testing Dataset\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJiEPNRSEg2g"
      },
      "source": [
        "from flaml import AutoML\n",
        "from sklearn.datasets import load_iris\n",
        "# Initialize an AutoML instance\n",
        "automl = AutoML()\n",
        "# Specify automl goal and constraint\n",
        "automl_settings = {\n",
        "    \"time_budget\": 10,  # in seconds\n",
        "    \"metric\": 'accuracy',\n",
        "    \"task\": 'classification',\n",
        "    \"log_file_name\": \"test/iris.log\",\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr3K_zFhq2bD"
      },
      "source": [
        "\n",
        "X_train, y_train = load_iris(return_X_y=True)\n",
        "# Train with labeled input data\n",
        "automl.fit(X_train=X_train, y_train=y_train,\n",
        "           **automl_settings)\n",
        "# Predict\n",
        "print(automl.predict_proba(X_train))\n",
        "# Export the best model\n",
        "print(automl.model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8pqoDcO5m2b"
      },
      "source": [
        "y_train.hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt4uDl-fsWlC"
      },
      "source": [
        "settings = {\n",
        "    \"time_budget\": 1000,  # total running time in seconds\n",
        "    \"metric\": 'accuracy',  # primary metrics can be chosen from: ['accuracy','roc_auc','f1','log_loss','mae','mse','r2']\n",
        "    \"task\": 'classification',  # task type    \n",
        "    \"log_file_name\": 'airlines_experiment.log',  # flaml log file\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okke1rN1wvbM"
      },
      "source": [
        "'''The main flaml automl API'''\n",
        "automl.fit(X_train=X_train, y_train=y_train, **settings)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "[flaml.automl: 08-18 05:53:11] {1461} INFO - selected model: LGBMClassifier(colsample_bytree=0.7733707792852584,\n",
        "               learning_rate=0.11190988982157068, max_bin=128,\n",
        "               min_child_samples=62, n_estimators=701, num_leaves=12,\n",
        "               objective='binary', reg_alpha=0.001291764523034099,\n",
        "               reg_lambda=0.5058442385321611, verbose=-1)\n",
        "[flaml.automl: 08-18 05:53:11] {1184} INFO - fit succeeded\n",
        "[flaml.automl: 08-18 05:53:11] {1185} INFO - Time taken to find the best model: 567.884330034256\n",
        "\n",
        "\n",
        "[flaml.automl: 08-18 05:31:22] {1411} INFO -  at 291.7s,\tbest extra_tree's error=0.2469,\tbest lgbm's error=0.1504\n",
        "[flaml.automl: 08-18 05:31:27] {1438} INFO - retrain extra_tree for 5.0s\n",
        "[flaml.automl: 08-18 05:31:27] {1253} INFO - iteration 46, current learner lrl1\n",
        "No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'.\n",
        "[flaml.automl: 08-18 05:31:41] {1411} INFO -  at 310.7s,\tbest lrl1's error=0.1454,\tbest lrl1's error=0.1454\n",
        "[flaml.automl: 08-18 05:31:41] {1461} INFO - selected model: LogisticRegression(n_jobs=-1, penalty='l1', solver='saga')\n",
        "[flaml.automl: 08-18 05:31:41] {1184} INFO - fit succeeded\n",
        "[flaml.automl: 08-18 05:31:41] {1185} INFO - Time taken to find the best model: 310.6792550086975\n",
        "[flaml.automl: 08-18 05:31:41] {1191} WARNING - Time taken to find the best model is 104% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaOrLHPMsWZW"
      },
      "source": [
        "''' retrieve best config and best learner'''\n",
        "print('Best ML leaner:', automl.best_estimator)\n",
        "print('Best hyperparmeter config:', automl.best_config)\n",
        "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
        "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "retrieve best config and best learner\n",
        "\n",
        "Best ML leaner: lgbm\n",
        "Best hyperparmeter config: {'n_estimators': 701, 'num_leaves': 12, 'min_child_samples': 62, 'learning_rate': 0.11190988982157068, 'subsample': 1.0, 'log_max_bin': 8, 'colsample_bytree': 0.7733707792852584, 'reg_alpha': 0.001291764523034099, 'reg_lambda': 0.5058442385321611}\n",
        "Best accuracy on validation data: 0.8516\n",
        "Training duration of best run: 14.68 s\n",
        "\n",
        "Best ML leaner: lrl1\n",
        "Best hyperparmeter config: {'C': 1.0}\n",
        "Best accuracy on validation data: 0.8546\n",
        "Training duration of best run: 13.9 s\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3akuUrlou1qO"
      },
      "source": [
        "automl.model.estimator\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "LogisticRegression(n_jobs=-1, penalty='l1', solver='saga')\n",
        "\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9k2tIm9sWT_"
      },
      "source": [
        "''' compute predictions of testing dataset ''' \n",
        "y_pred = automl.predict(X_test)\n",
        "print('Predicted labels', y_pred)\n",
        "print('True labels', y_test)\n",
        "y_pred_proba = automl.predict_proba(X_test)[:,1]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7nWCA3cwFro"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "mcc_y_test_predict = matthews_corrcoef(y_test, y_pred)\n",
        "mcc_y_test_predict\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "0.7274299237200138\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "582R-hBp7M3Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHXqdHVF-QD-"
      },
      "source": [
        "**AutoML: Auto-Sklearn**\n",
        "\n",
        "* https://www.youtube.com/watch?v=CF-GZ9tK_Ik\n",
        "* https://github.com/GauravSahani1417/Kaggle-Datasets/blob/master/Heart_failure_prediction_using_Auto_Sklearn_%F0%9F%A9%BA.ipynb "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mR64ZI27Mud"
      },
      "source": [
        "!pip install auto-sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAp6SYZO7hZw"
      },
      "source": [
        "!pip install scipy>=1.7.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVnzpkq77nxZ"
      },
      "source": [
        "import scipy\n",
        "print(scipy.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WXzXnPs7MnL"
      },
      "source": [
        "from autosklearn.classification import AutoSklearnClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mMzgBVt7Wuj"
      },
      "source": [
        "clf = AutoSklearnClassifier(time_left_for_this_task=1000, \n",
        "                              per_run_time_limit=9, \n",
        "                              ensemble_size=1, \n",
        "                              initial_configurations_via_metalearning=0)\n",
        "# Init training\n",
        "clf.fit(X_train, y_train)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fodvu7kc7WpJ"
      },
      "source": [
        "clf.score(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gsuzebjd7Wji"
      },
      "source": [
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhxWnZ3L7WdB"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zysNiGqP-tif"
      },
      "source": [
        "conf_matrix = confusion_matrix(y_pred, y_test)\n",
        "sns.heatmap(conf_matrix, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lscmJ8ID-tca"
      },
      "source": [
        "#Performance Measures\n",
        "tn = conf_matrix[0,0]\n",
        "fp = conf_matrix[0,1]\n",
        "tp = conf_matrix[1,1]\n",
        "fn = conf_matrix[1,0]\n",
        "\n",
        "total = tn + fp + tp + fn\n",
        "real_positive = tp + fn\n",
        "real_negative = tn + fp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdadaB_7-3iD"
      },
      "source": [
        "accuracy  = (tp + tn) / total # Accuracy Rate\n",
        "precision = tp / (tp + fp) # Positive Predictive Value\n",
        "recall    = tp / (tp + fn) # True Positive Rate\n",
        "f1score  = 2 * precision * recall / (precision + recall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tDDtHX6-3dh"
      },
      "source": [
        "print(f'Accuracy    : {accuracy}')\n",
        "print(f'Precision   : {precision}')\n",
        "print(f'Recall      : {recall}')\n",
        "print(f'F1 score    : {f1score}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1ZEyU-sLVhk"
      },
      "source": [
        "**AutoML: HyperOpt-Sklearn**\n",
        "\n",
        "* https://github.com/hyperopt/hyperopt-sklearn\n",
        "* https://github.com/hyperopt/hyperopt-sklearn/blob/master/notebooks/Demo-Iris.ipynb \n",
        "\n",
        "svc\n",
        "svc_linear\n",
        "svc_rbf\n",
        "svc_poly\n",
        "svc_sigmoid\n",
        "liblinear_svc\n",
        "\n",
        "knn\n",
        "\n",
        "ada_boost\n",
        "gradient_boosting\n",
        "\n",
        "random_forest\n",
        "extra_trees\n",
        "decision_tree\n",
        "\n",
        "sgd\n",
        "\n",
        "xgboost_classification\n",
        "\n",
        "multinomial_nb\n",
        "gaussian_nb\n",
        "\n",
        "passive_aggressive\n",
        "\n",
        "linear_discriminant_analysis\n",
        "quadratic_discriminant_analysis\n",
        "\n",
        "one_vs_rest\n",
        "one_vs_one\n",
        "output_code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVs_kVZF--zj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfDks6td-_Kv"
      },
      "source": [
        "**Supervised ML Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAqHgshvg-tB"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Create and train a logistic regression\n",
        "# SST2: 1800s/1000it, 20s/10it (default, max_iter=1000)\n",
        "# IMDB50k: 1000it, 1.14s\n",
        "\n",
        "logreg = LogisticRegression(C=1e9, solver='lbfgs', max_iter=10)\n",
        "logreg.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4dnGSxAAGfe"
      },
      "source": [
        "%%time\n",
        "\n",
        "# NOTE: 964s\n",
        "\n",
        "# example of grid searching key hyperparametres for logistic regression\n",
        "# https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
        "\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# define dataset\n",
        "# X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\n",
        "\n",
        "# define models and parameters\n",
        "model = LogisticRegression()\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalty = ['l2']\n",
        "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "\n",
        "# define grid search\n",
        "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X, y)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "0.858347 (0.004245) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
        "0.858367 (0.004238) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
        "0.858360 (0.004251) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
        "0.835080 (0.004164) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
        "0.835093 (0.004186) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
        "0.835287 (0.004264) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
        "CPU times: user 27.2 s, sys: 9.56 s, total: 36.8 s\n",
        "Wall time: 16min 4s\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-5yEd1Zg-tB"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Create and train a random forest classifier\n",
        "# SST2: 27m-1500s/50n_est  36s/5n_est (default n_estimators=50)\n",
        "# IMDB50k: 46s (n_est=50)\n",
        "\n",
        "# https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74 (Hyperparm search)\n",
        "# https://github.com/WillKoehrsen/Machine-Learning-Projects/tree/master/random_forest_explained (github/Jupyter)\n",
        "\n",
        "dforest = RandomForestClassifier(n_estimators=50)\n",
        "dforest.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7PAaPzLAxDN"
      },
      "source": [
        "%%time\n",
        "\n",
        "# NOTE: 9381s\n",
        "\n",
        "# example of grid searching key hyperparameters for RandomForestClassifier\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# define dataset\n",
        "# X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\n",
        "\n",
        "# define models and parameters\n",
        "model = RandomForestClassifier()\n",
        "n_estimators = [10, 100, 1000]\n",
        "max_features = ['sqrt', 'log2']\n",
        "\n",
        "# define grid search\n",
        "grid = dict(n_estimators=n_estimators,max_features=max_features)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X, y)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Best: 0.852973 using {'max_features': 'log2', 'n_estimators': 1000}\n",
        "0.785433 (0.005143) with: {'max_features': 'sqrt', 'n_estimators': 10}\n",
        "0.834120 (0.005947) with: {'max_features': 'sqrt', 'n_estimators': 100}\n",
        "0.839340 (0.005137) with: {'max_features': 'sqrt', 'n_estimators': 1000}\n",
        "0.762820 (0.005924) with: {'max_features': 'log2', 'n_estimators': 10}\n",
        "0.842607 (0.005467) with: {'max_features': 'log2', 'n_estimators': 100}\n",
        "0.852973 (0.004983) with: {'max_features': 'log2', 'n_estimators': 1000}\n",
        "CPU times: user 4min 50s, sys: 11.5 s, total: 5min 2s\n",
        "Wall time: 2h 36min 21s\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve3gAwnPBVNu"
      },
      "source": [
        "# Simple Bagged Decision Tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qHg_b15BsBC"
      },
      "source": [
        "%%time\n",
        "\n",
        "# NOTE: >5hrs\n",
        "\n",
        "# example of grid searching key hyperparameters for BaggingClassifier\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "# define dataset\n",
        "# X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\n",
        "\n",
        "# define models and parameters\n",
        "model = BaggingClassifier()\n",
        "n_estimators = [10, 100, 1000]\n",
        "\n",
        "# define grid search\n",
        "grid = dict(n_estimators=n_estimators)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X, y)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4afRwJCBQxZ"
      },
      "source": [
        "# Simple kNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03j_BjeXBF0G"
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# example of grid searching key hyperparametres for KNeighborsClassifier\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# define dataset\n",
        "#X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\n",
        "\n",
        "# define models and parameters\n",
        "model = KNeighborsClassifier()\n",
        "n_neighbors = range(1, 21, 2)\n",
        "weights = ['uniform', 'distance']\n",
        "metric = ['euclidean', 'manhattan', 'minkowski']\n",
        "\n",
        "# define grid search\n",
        "grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X, y)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAErlAgVBaNf"
      },
      "source": [
        "# Simple Ridge Classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko4RsndnA3aQ"
      },
      "source": [
        "%%time\n",
        "\n",
        "# example of grid searching key hyperparametres for ridge classifier\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "\n",
        "# define dataset\n",
        "# X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\n",
        "\n",
        "# define models and parameters\n",
        "model = RidgeClassifier()\n",
        "alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "\n",
        "# define grid search\n",
        "grid = dict(alpha=alpha)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X, y)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBue6PpPg-tC"
      },
      "source": [
        "%%time\n",
        "# Create and train a linear support vector classifier (LinearSVC)\n",
        "# SST2: 20s \n",
        "# IMDB50k: 1.7s\n",
        "\n",
        "svc = LinearSVC()\n",
        "svc.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fwgE5eJBfnS"
      },
      "source": [
        "%%time\n",
        "\n",
        "# example of grid searching key hyperparametres for SVC\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# define dataset\n",
        "# X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\n",
        "\n",
        "# define model and parameters\n",
        "model = SVC()\n",
        "kernel = ['poly', 'rbf', 'sigmoid']\n",
        "C = [50, 10, 1.0, 0.1, 0.01]\n",
        "gamma = ['scale']\n",
        "\n",
        "# define grid search\n",
        "grid = dict(kernel=kernel,C=C,gamma=gamma)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X, y)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptD0DvanCGJs"
      },
      "source": [
        "# Simple Stochastic Gradient Boosting   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL1uhFpUCGBX"
      },
      "source": [
        "%%time\n",
        "\n",
        "# example of grid searching key hyperparameters for GradientBoostingClassifier\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# define dataset\n",
        "# X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\n",
        "\n",
        "# define models and parameters\n",
        "model = GradientBoostingClassifier()\n",
        "n_estimators = [10, 100, 1000]\n",
        "learning_rate = [0.001, 0.01, 0.1]\n",
        "subsample = [0.5, 0.7, 1.0]\n",
        "max_depth = [3, 7, 9]\n",
        "\n",
        "# define grid search\n",
        "grid = dict(learning_rate=learning_rate, n_estimators=n_estimators, subsample=subsample, max_depth=max_depth)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X, y)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k55atR6-JNFo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQb2_OgGg-tD"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Create and train a multinomial naive bayes classifier (MultinomialNB)\n",
        "# SST2: 1.3s \n",
        "# IMDB50k: 0.24s\n",
        "\n",
        "multinb = MultinomialNB()\n",
        "multinb.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlXy8nPhJ-nC"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "https://stats.stackexchange.com/questions/299842/why-grid-search-is-not-performed-for-naive-bayes-classifier/299843\n",
        "\n",
        "Just a thought, I've used NB almost exclusively for NLP tasks. Consider sentiment analysis, the distribution over the word \"fast\" might be {pos:0.8, neg:0.2}. this design is often called \"unigram\" (just one word), however, n-grams (2 or more) will improve accuracy. In general, perplexity is used to evaluate if added model complexity is worth the effort. All that to say, grid search might be useful, if you were trying to optimize the number of n-grams (though this would no longer be \"Naive Bayes\" but rather a conceptual extension.) But outside of NLP, there might be no use for this idea. – jbuddy_13 Jan 2 at 16:41 \n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0Mh-bxNJGED"
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f3ibspoLKnb"
      },
      "source": [
        "# Split into Training and Testing Dataset\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "# name = df.toxic.name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj4kbvQgLKhk"
      },
      "source": [
        "# K-fold cross variations\n",
        "\n",
        "# https://towardsdatascience.com/building-a-sentiment-classifier-using-scikit-learn-54c8e7c5d2f0 (2020) *\n",
        "# https://www.kaggle.com/pocooo/types-of-cross-validation-all-you-need (3mo)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJqe-pftgh4x"
      },
      "source": [
        "# Hyper parameter grid search using Stratified k-fold search for better l2 penality\n",
        "\n",
        "# https://www.kaggle.com/babbler/cross-validation-considerations (3 yr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyE1gBtGjiXt"
      },
      "source": [
        "# Model Comparisons\n",
        "\n",
        "# https://stackabuse.com/overview-of-classification-methods-in-python-with-scikit-learn/ *\n",
        "# https://nulpointerexception.com/2017/12/31/a-tutorial-to-find-best-scikit-classifiers-for-sentiment-analysis/ *\n",
        "# https://www.dezyre.com/recipes/compare-sklearn-classification-algorithms-in-python *\n",
        "# https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html \n",
        "# https://www.kaggle.com/meetnaren/comparing-different-sklearn-classifiers (4yr) *\n",
        "# https://www.kaggle.com/jeffd23/10-classifier-showdown-in-scikit-learn (5yr) *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vmd5IxGLityA"
      },
      "source": [
        "# SA with XGBoost + Pipelines\n",
        "\n",
        "* https://ai.plainenglish.io/sentiment-classification-using-xgboost-7abdaf4771f9\n",
        "* https://github.com/jaotheboss/Drug-Sentiment-Analysis/blob/master/main.py\n",
        "* https://www.kaggle.com/sudhirnl7/simple-naive-bayes-xgboost (4yrs)\n",
        "* https://www.kaggle.com/diveki/classification-with-nlp-xgboost-and-pipelines (3yrs)\n",
        "* https://blessing3ke.medium.com/twitter-sentiment-analysis-with-xgboost-f0016e94d317 (1yr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5M43Z9RLKbs"
      },
      "source": [
        "# ROC/AUC compare classifiers\n",
        "\n",
        "# https://github.com/dformoso/sklearn-classification *\n",
        "# https://colab.research.google.com/github/astg606/py_materials/blob/master/machine_learning/ml_models_scikit-learn.ipynb *\n",
        "# https://colab.research.google.com/github/goswami-rahul/machine-learning/blob/master/UnderstandingMetrics.ipynb *\n",
        "# https://stats.stackexchange.com/questions/133225/how-to-validate-sentiment-classification-and-compare-different-algorithms (6yr)\n",
        "# https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
        "# https://www.kaggle.com/nirajvermafcb/comparing-various-ml-models-roc-curve-comparison (4yr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DX2BNSush-e7"
      },
      "source": [
        "# Ensemble Methods\n",
        "\n",
        "* https://scikit-learn.org/stable/modules/ensemble.html?highlight=xgboost\n",
        "* https://journalofbigdata.springeropen.com/articles/10.1186/s40537-018-0152-5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRCqXwipFAxp"
      },
      "source": [
        "#### **Create Supervised Learning DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGe-lstBMyzP"
      },
      "source": [
        "# Setup new DataFrame to hold all Sklearn supervised statistical machine learning models\n",
        "\n",
        "corpus_mlsup_df = pd.DataFrame(corpus_sents_df['sent_clean'])\n",
        "corpus_mlsup_df['sent_clean'] = corpus_mlsup_df['sent_clean'].astype('string')\n",
        "\n",
        "# Remove non-alphanumeric chacters\n",
        "# corpus_mlsup_df['text_lower'] = corpus_mlsup_df['text_raw']\n",
        "\n",
        "pattern = re.compile(r\"[A-Za-z0-9\\-]{3,50}\")\n",
        "corpus_mlsup_df['sent_lemma'] = corpus_mlsup_df['sent_clean'].str.lower().str.strip().str.findall(pattern).str.join(' ')\n",
        "# corpus_mlsup_df.head()\n",
        "\n",
        "# Method #3: Lemmatize with joblib parallelization\n",
        "# NOTE: 17m13s \n",
        "\n",
        "# lemmas_ls = preprocess_parallel(corpus_mlsup_df['sent_lemma'], chunksize=1000)\n",
        "# print(f'type: {type(lemmas_ls[0])}')\n",
        "# corpus_mlsup_df['sent_lemma'] = ' '.join(lemmas_ls)\n",
        "\n",
        "corpus_mlsup_df['sent_lemma'] = preprocess_parallel(corpus_mlsup_df['sent_lemma'], chunksize=1000)\n",
        "corpus_mlsup_df['sent_lemma'] = corpus_mlsup_df['sent_lemma'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "corpus_mlsup_df.info()\n",
        "corpus_mlsup_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryyJwk5IiAew"
      },
      "source": [
        "# Vectorize our Lemmatized Corpus Sentences\n",
        "\n",
        "# transform, not fit_transform, because we already learned all our words\n",
        "sents_vectors = vectorizer.transform(corpus_mlsup_df.sent_lemma)\n",
        "sents_words_df = pd.DataFrame(sents_vectors.toarray(), columns=vectorizer.get_feature_names())\n",
        "sents_words_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEifwA2zYjLw"
      },
      "source": [
        "print(vectorizer.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQVo6UDRopJV"
      },
      "source": [
        "print(corpus_mlsup_df.iloc[0]['sent_lemma'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbvcZo4oiCa7"
      },
      "source": [
        "### **Time Series Clustering**\n",
        "\n",
        "Code:\n",
        "\n",
        "* https://towardsdatascience.com/how-to-apply-hierarchical-clustering-to-time-series-a5fe2a7d8447 (DTW) *\n",
        "* https://cran.r-project.org/web/packages/dtwclust/vignettes/dtwclust.pdf \n",
        "* https://www.sktime.org/en/latest/examples/mrseql.html Classification Mr-SEQL\n",
        "\n",
        "Guidance:\n",
        "\n",
        "* https://stats.stackexchange.com/questions/63546/comparing-hierarchical-clustering-dendrograms-obtained-by-different-distances \n",
        "\n",
        "Ranks:\n",
        "* https://paperswithcode.com/task/time-series-clustering\n",
        "\n",
        "Papers:\n",
        "* https://reader.elsevier.com/reader/sd/pii/S2666827020300013?token=2286F6993FF63B6B3096B72F09503A950095DD5F1C1BB11146BDC0EAAA8E4D942BAD3A216FDBE65978BAE3B5C9F2363F&originRegion=us-east-1&originCreation=20210817184824"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1O0Qmhyh_UO"
      },
      "source": [
        "# Time Series Clustering\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQkSxI7ziaKG"
      },
      "source": [
        "### **Time Series Transformations**\n",
        "\n",
        "Tutorial:\n",
        "* https://opendatascience.com/transforming-skewed-data-for-machine-learning/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfB7xgTIh-Y-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SgVNEKok1QZ"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Create and train a linear regression\n",
        "# SST2: 1800s/1000it, 20s/10it (default, max_iter=1000)\n",
        "# IMDB50k: 1000it, 1.14s\n",
        "\n",
        "# First get a performance metrics\n",
        "# Test/Train Holdout Validation\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "\n",
        "\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X_train, y_train)\n",
        "result = linreg.score(X_test, y_test)\n",
        "print(f'Evaluation (Test/Train holdout): {result}')\n",
        "\n",
        "# K-Fold Validation\n",
        "results=cross_val_score(linreg,X,y,cv=kfold_validation)\n",
        "print(f'Evaluation (K-Fold): {results}')\n",
        "print(np.mean(results))\n",
        "\n",
        "# Stratified Validation\n",
        "skfold=StratifiedKFold(n_splits=5)\n",
        "scores=cross_val_score(linreg,X,y,cv=skfold)\n",
        "print(f'Evaluation (Stratified CV): {np.mean(scores)}')\n",
        "\n",
        "\n",
        "# Run confusion matrix on transformed text and cross-validation predictions\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        " \n",
        "sentiment_predict = cross_val_predict(linreg, X, y, cv=5)\n",
        "confusion_mat = confusion_matrix(sentiment, sentiment_predict)\n",
        "\n",
        "\n",
        "# Second, train on entire corpus\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X, y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkPwGOxnEaYp"
      },
      "source": [
        "# Stratified Validation\n",
        "skfold=StratifiedKFold(n_splits=5)\n",
        "scores=cross_val_score(linreg,X,y,cv=skfold)\n",
        "print(f'Evaluation (Stratified CV): {np.mean(scores)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUiOFpVfJCOE"
      },
      "source": [
        "sentiment_predict = cross_val_predict(linreg, X, y, cv=5)\n",
        "confusion_mat = confusion_matrix(y, sentiment_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE_Y86qlJnmq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyQhiXpnJniK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCA1SVvmJnd8"
      },
      "source": [
        "# Code source: Gaël Varoquaux\n",
        "#              Andreas Müller\n",
        "# Modified for documentation by Jaques Grobler\n",
        "# License: BSD 3 clause\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd0pmghYJrOj"
      },
      "source": [
        "h = .02  # step size in the mesh\n",
        "\n",
        "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
        "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
        "         \"Naive Bayes\", \"QDA\"]\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"linear\", C=0.025),\n",
        "    SVC(gamma=2, C=1),\n",
        "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
        "    DecisionTreeClassifier(max_depth=5),\n",
        "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    MLPClassifier(alpha=1, max_iter=1000),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis()]\n",
        "\n",
        "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
        "                           random_state=1, n_clusters_per_class=1)\n",
        "rng = np.random.RandomState(2)\n",
        "X += 2 * rng.uniform(size=X.shape)\n",
        "linearly_separable = (X, y)\n",
        "\n",
        "datasets = [make_moons(noise=0.3, random_state=0),\n",
        "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
        "            linearly_separable\n",
        "            ]\n",
        "\n",
        "figure = plt.figure(figsize=(27, 9))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bWHOskTJly-"
      },
      "source": [
        "i = 1\n",
        "# iterate over datasets\n",
        "for ds_cnt, ds in enumerate(datasets):\n",
        "    # preprocess dataset, split into training and test part\n",
        "    X, y = ds\n",
        "    X = StandardScaler().fit_transform(X)\n",
        "    X_train, X_test, y_train, y_test = \\\n",
        "        train_test_split(X, y, test_size=.4, random_state=42)\n",
        "\n",
        "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "\n",
        "    # just plot the dataset first\n",
        "    cm = plt.cm.RdBu\n",
        "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
        "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
        "    if ds_cnt == 0:\n",
        "        ax.set_title(\"Input data\")\n",
        "    # Plot the training points\n",
        "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
        "               edgecolors='k')\n",
        "    # Plot the testing points\n",
        "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n",
        "               edgecolors='k')\n",
        "    ax.set_xlim(xx.min(), xx.max())\n",
        "    ax.set_ylim(yy.min(), yy.max())\n",
        "    ax.set_xticks(())\n",
        "    ax.set_yticks(())\n",
        "    i += 1\n",
        "\n",
        "    # iterate over classifiers\n",
        "    for name, clf in zip(names, classifiers):\n",
        "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
        "        clf.fit(X_train, y_train)\n",
        "        score = clf.score(X_test, y_test)\n",
        "\n",
        "        # Plot the decision boundary. For that, we will assign a color to each\n",
        "        # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "        if hasattr(clf, \"decision_function\"):\n",
        "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
        "        else:\n",
        "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
        "\n",
        "        # Put the result into a color plot\n",
        "        Z = Z.reshape(xx.shape)\n",
        "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
        "\n",
        "        # Plot the training points\n",
        "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
        "                   edgecolors='k')\n",
        "        # Plot the testing points\n",
        "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
        "                   edgecolors='k', alpha=0.6)\n",
        "\n",
        "        ax.set_xlim(xx.min(), xx.max())\n",
        "        ax.set_ylim(yy.min(), yy.max())\n",
        "        ax.set_xticks(())\n",
        "        ax.set_yticks(())\n",
        "        if ds_cnt == 0:\n",
        "            ax.set_title(name)\n",
        "        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
        "                size=15, horizontalalignment='right')\n",
        "        i += 1\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXznxtcdJlto"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOaUK2gFJlpF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Euum6F_Encd"
      },
      "source": [
        "classifier1 = svm.SVC(kernel='linear', probability=True)\n",
        "probas_1 = classifier1.fit(X_train, y_train).predict_proba(X_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAkEZMU4evQS"
      },
      "source": [
        "#### **Inference**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMhr3YGCAqcQ"
      },
      "source": [
        "# from sklearn.cross_validation import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test  = train_test_split(\n",
        "        X, \n",
        "        y,\n",
        "        train_size=0.80, \n",
        "        random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej-5lG7Ksh0G"
      },
      "source": [
        "# Set the name of the supervised sentiment classifier training dataset\n",
        "\n",
        "# supervised_db = 'imdb50k'\n",
        "# supervised_db = 'sst2'\n",
        "supervised_db = 'sentiment140'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "draT3Xe9hRLl"
      },
      "source": [
        "# corpus_mlsup_df = pd.DataFrame(corpus_sents_df['sent_clean'])\n",
        "# corpus_mlsup_df['sent_clean'] = corpus_mlsup_df['sent_clean'].astype('string')\n",
        "corpus_mlsup_df.info()\n",
        "corpus_mlsup_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCYVklLkig2H"
      },
      "source": [
        "sents_words_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QB7t_NbilUe"
      },
      "source": [
        "# Predict using all our models. \n",
        "\n",
        "# Linear Regression predictions + probabilities\n",
        "corpus_mlsup_df[f'linreg_{supervised_db}'] = linreg.predict(sents_words_df)\n",
        "\n",
        "# Logistic Regression predictions + probabilities\n",
        "corpus_mlsup_df[f'logreg_{supervised_db}'] = logreg.predict(sents_words_df)\n",
        "corpus_mlsup_df[f'logreg_proba_{supervised_db}'] = logreg.predict_proba(sents_words_df)[:,1]\n",
        "\n",
        "# Random forest predictions + probabilities\n",
        "corpus_mlsup_df[f'dforest_{supervised_db}'] = dforest.predict(sents_words_df)\n",
        "corpus_mlsup_df[f'dforest_proba_{supervised_db}'] = dforest.predict_proba(sents_words_df)[:,1]\n",
        "\n",
        "# SVC predictions\n",
        "corpus_mlsup_df[f'svc_{supervised_db}'] = svc.predict(sents_words_df)\n",
        "\n",
        "# Bayes predictions + probabilities\n",
        "corpus_mlsup_df[f'multinb_{supervised_db}'] = multinb.predict(sents_words_df)\n",
        "corpus_mlsup_df[f'multinb_proba_{supervised_db}'] = multinb.predict_proba(sents_words_df)[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdZcUzSvj0si"
      },
      "source": [
        "corpus_mlsup_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qifISzHlrWdC"
      },
      "source": [
        "# Save checkpoint\n",
        "\n",
        "# corpus_mlsup_df.to_csv('ml_sents_df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XUfmL6p7SsY"
      },
      "source": [
        "#### **Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6XnjgZIrvqB"
      },
      "source": [
        "# supervised_db = 'imdb50k'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMhsXr5Mj46e"
      },
      "source": [
        "# Smooth Time Series\n",
        "\n",
        "win_s1per = int(corpus_sents_df.shape[0] * 1/100)\n",
        "\n",
        "corpus_mlsup_df[f'linreg_{supervised_db}_roll10'] = corpus_mlsup_df[f'linreg_{supervised_db}'].rolling(10*win_s1per, center=True).mean()\n",
        "corpus_mlsup_df[f'logreg_proba_{supervised_db}_roll10'] = corpus_mlsup_df[f'logreg_proba_{supervised_db}'].rolling(10*win_s1per, center=True).mean()\n",
        "corpus_mlsup_df[f'dforest_proba_{supervised_db}_roll10'] = corpus_mlsup_df[f'dforest_proba_{supervised_db}'].rolling(10*win_s1per, center=True).mean()\n",
        "corpus_mlsup_df[f'multinb_proba_{supervised_db}_roll10'] = corpus_mlsup_df[f'multinb_proba_{supervised_db}'].rolling(10*win_s1per, center=True).mean()\n",
        "corpus_mlsup_df[f'svc_{supervised_db}_roll10'] = corpus_mlsup_df[f'svc_{supervised_db}'].rolling(10*win_s1per, center=True).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INJJDXFztcME"
      },
      "source": [
        "corpus_mlsup_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGNSo5mpvGcI"
      },
      "source": [
        "# Standardize Time Series\n",
        "\n",
        "corpus_mlsup_df[f'linreg_{supervised_db}_roll10_stdscaler'] = mean_std_scaler.fit_transform(np.array(corpus_mlsup_df[f'linreg_{supervised_db}_roll10']).reshape(-1, 1))\n",
        "\n",
        "corpus_mlsup_df[f'logreg_proba_{supervised_db}_roll10_stdscaler'] = mean_std_scaler.fit_transform(np.array(corpus_mlsup_df[f'logreg_proba_{supervised_db}_roll10']).reshape(-1, 1))\n",
        "\n",
        "corpus_mlsup_df[f'dforest_proba_{supervised_db}_roll10_stdscaler'] = mean_std_scaler.fit_transform(np.array(corpus_mlsup_df[f'dforest_proba_{supervised_db}_roll10']).reshape(-1, 1))\n",
        "\n",
        "corpus_mlsup_df[f'multinb_proba_{supervised_db}_roll10_stdscaler'] = mean_std_scaler.fit_transform(np.array(corpus_mlsup_df[f'multinb_proba_{supervised_db}_roll10']).reshape(-1, 1))\n",
        "\n",
        "corpus_mlsup_df[f'svc_{supervised_db}_roll10_stdscaler'] = mean_std_scaler.fit_transform(np.array(corpus_mlsup_df[f'svc_{supervised_db}_roll10']).reshape(-1, 1))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oyz_dvkm_X6T"
      },
      "source": [
        "supervised_db = 'sentiment140'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHiTTCLH9qbX"
      },
      "source": [
        "corpus_mlsup_df[f'linreg_{supervised_db}_roll10_stdscaler'].plot(label='Linear Regression')\n",
        "corpus_mlsup_df[f'logreg_proba_{supervised_db}_roll10_stdscaler'].plot(label='Logistic Regression')\n",
        "corpus_mlsup_df[f'dforest_proba_{supervised_db}_roll10_stdscaler'].plot(label='Random Forest')\n",
        "corpus_mlsup_df[f'multinb_proba_{supervised_db}_roll10_stdscaler'].plot(label='Naive Bayes')\n",
        "corpus_mlsup_df[f'svc_{supervised_db}_roll10_stdscaler'].plot(label='SVC')\n",
        "plt.title(f'{CORPUS_FULL}\\n Sentence Sentiment Statistical ML with SMA 10% + StdScaler (TrainingDB: {supervised_db})')\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyR6jNKl-Y7B"
      },
      "source": [
        "corpus_mlsup_df[f'linreg_{supervised_db}_roll10_stdscaler'].plot(label='Linear Regression')\n",
        "corpus_mlsup_df[f'logreg_proba_{supervised_db}_roll10_stdscaler'].plot(label='Logistic Regression')\n",
        "corpus_mlsup_df[f'dforest_proba_{supervised_db}_roll10_stdscaler'].plot(label='Random Forest')\n",
        "corpus_mlsup_df[f'multinb_proba_{supervised_db}_roll10_stdscaler'].plot(label='Naive Bayes')\n",
        "corpus_mlsup_df[f'svc_{supervised_db}_roll10_stdscaler'].plot(label='SVC')\n",
        "plt.title(f'{CORPUS_FULL}\\n Sentence Sentiment Statistical ML with SMA 10% + StdScaler (TrainingDB: {supervised_db})')\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_jx0uTC2FHO"
      },
      "source": [
        "corpus_mlsup_df[f'linreg_{supervised_db}_roll10_stdscaler'].plot(label='Linear Regression')\n",
        "corpus_mlsup_df[f'logreg_proba_{supervised_db}_roll10_stdscaler'].plot(label='Logistic Regression')\n",
        "corpus_mlsup_df[f'dforest_proba_{supervised_db}_roll10_stdscaler'].plot(label='Random Forest')\n",
        "corpus_mlsup_df[f'multinb_proba_{supervised_db}_roll10_stdscaler'].plot(label='Naive Bayes')\n",
        "corpus_mlsup_df[f'svc_{supervised_db}_roll10_stdscaler'].plot(label='SVC')\n",
        "plt.title(f'{CORPUS_FULL}\\n Sentence Sentiment Statistical ML with SMA 10% + StdScaler (TrainingDB: {supervised_db})')\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueAfVXa1d0rn"
      },
      "source": [
        "%%time\n",
        "\n",
        "print(\"Training logistic regression\")\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training random forest\")\n",
        "forest.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training SVC\")\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training Naive Bayes\")\n",
        "bayes.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smj2QgkLd0oL"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49iy8tQNg-tP"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = logreg.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T20MMTzBg-tQ"
      },
      "source": [
        "# Random Forest\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = forest.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3P6nAMCg-tS"
      },
      "source": [
        "# SVC\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = svc.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGpFNtIgg-tT"
      },
      "source": [
        "# Nultinomial Naive Bayes\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = bayes.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsrKrn77g-tU"
      },
      "source": [
        "**Percentage-based confusion matrices**\n",
        "\n",
        "Those are kind of irritating in that they're just numbers. Let's try percentages instead"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-_N9nsyg-tU"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = logreg.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PANO3BE3g-tV"
      },
      "source": [
        "# Random Forest\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = forest.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxsX_xxjg-tW"
      },
      "source": [
        "# SVC\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = svc.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJyA3W7dg-tW"
      },
      "source": [
        "# Multinomial Naive Bayes\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = bayes.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCfbdBGlhhS-"
      },
      "source": [
        "#### **Save Corpus DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "524E0SgJiVQq"
      },
      "source": [
        "supervised_db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UE2xijYiWtg"
      },
      "source": [
        "corpus_mlsup_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6J5xizNhdXt"
      },
      "source": [
        "save_dataframes(df_ls=['mlsupervised'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZK1gA47xzkS"
      },
      "source": [
        "### **Select Sentiment Models (Manual)**\n",
        "\n",
        "NOTE:\n",
        "\n",
        "* Stanza (Stanford OpenNLP) can take upto 50 minutes to run\n",
        "\n",
        "* Listed in increasing order of (approx) run time\n",
        "\n",
        "* MPQA/SentiStrength not yet implemented (placeholders only for now)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0pStg1gJTZA"
      },
      "source": [
        "SentimentR_Arc = True #@param {type:\"boolean\"}\n",
        "Syuzhet_Arc = True #@param {type:\"boolean\"}\n",
        "Bing_Arc = True #@param {type:\"boolean\"}\n",
        "SenticNet_Arc = True #@param {type:\"boolean\"}\n",
        "SentiWord_Arc = True #@param {type:\"boolean\"}\n",
        "NRC_Arc = True #@param {type:\"boolean\"}\n",
        "AFINN_Arc = True #@param {type:\"boolean\"}\n",
        "VADER_Arc = True #@param {type:\"boolean\"}\n",
        "TextBlob_Arc = True #@param {type:\"boolean\"}\n",
        "Flair_Arc = True #@param {type:\"boolean\"}\n",
        "Pattern_Arc = True #@param {type:\"boolean\"}\n",
        "Stanza_Arc = True #@param {type:\"boolean\"}\n",
        "# MPQA_Arc = False #@param {type:\"boolean\"}\n",
        "# SentiStrength_Arc = False #@param {type:\"boolean\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0IACAN5JTZC"
      },
      "source": [
        "# Create and Verify custom list of Models to include\n",
        "\n",
        "MODELS_CUSTOM_LS = []\n",
        "\n",
        "if VADER_Arc:\n",
        "  MODELS_CUSTOM_LS.append('vader')\n",
        "if TextBlob_Arc:\n",
        "  MODELS_CUSTOM_LS.append('textblob')\n",
        "if Flair_Arc:\n",
        "  MODELS_CUSTOM_LS.append('flair')\n",
        "if Stanza_Arc:\n",
        "  MODELS_CUSTOM_LS.append('stanza')\n",
        "if SentimentR_Arc:\n",
        "  MODELS_CUSTOM_LS.append('sentimentr')\n",
        "if Syuzhet_Arc:\n",
        "  MODELS_CUSTOM_LS.append('syuzhet')\n",
        "if AFINN_Arc:\n",
        "  MODELS_CUSTOM_LS.append('afinn')\n",
        "if Bing_Arc:\n",
        "  MODELS_CUSTOM_LS.append('bing')\n",
        "if Pattern_Arc:\n",
        "  MODELS_CUSTOM_LS.append('pattern')\n",
        "if SentiWord_Arc:\n",
        "  MODELS_CUSTOM_LS.append('sentiword')\n",
        "if SenticNet_Arc:\n",
        "  MODELS_CUSTOM_LS.append('senticnet')\n",
        "if NRC_Arc:\n",
        "  MODELS_CUSTOM_LS.append('nrc')\n",
        "\n",
        "print(f'Here are the Models we are using to ensemble and save:\\n\\n   {MODELS_CUSTOM_LS}')\n",
        "\n",
        "\"\"\"\n",
        "models_incl_ls = []\n",
        "for amodel in MODELS_CUSTOM_LS:\n",
        "  models_incl_ls.append(amodel[:2])\n",
        "models_incl_str = ''.join(models_incl_ls)\n",
        "\n",
        "print(f'Here is a custom name abbr: {models_incl_str}')\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw0JPNe6T2ap"
      },
      "source": [
        "# Calculate (win_(x)1per) 1% of Corpus length for smallest (odd-valued) rolling window\n",
        "\n",
        "# Sentences\n",
        "corpus_sents_len = corpus_sents_df.shape[0]\n",
        "\n",
        "win_raw_s1per = int(corpus_sents_len * 0.01)\n",
        "# print(f'1% Rolling Window: {win_raw_s1per}')\n",
        "\n",
        "if win_raw_s1per % 2:\n",
        "  win_s1per = win_raw_s1per\n",
        "else:\n",
        "  win_s1per = win_raw_s1per + 1\n",
        "\n",
        "# Paragraphs\n",
        "# corpus_parags_df = corpus_all_df\n",
        "corpus_parags_len = len(corpus_sents_df['parag_no'].unique())\n",
        "\n",
        "win_raw_p1per = int(corpus_parags_len * 0.01)\n",
        "# print(f'1% Rolling Window: {win_raw_1per}')\n",
        "\n",
        "if win_raw_p1per % 2:\n",
        "  win_p1per = win_raw_p1per\n",
        "else:\n",
        "  win_p1per = win_raw_p1per + 1\n",
        "\n",
        "\n",
        "# Sections\n",
        "\n",
        "# NO NEED FOR SLIDING WINDOW ON SECTIONS\n",
        "\n",
        "\n",
        "print(f'Sentence 1 Percent window: {win_s1per}')\n",
        "print(f'Paragraph 1 Percent window: {win_p1per}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGjfPK9u21HH"
      },
      "source": [
        "# Verify Sentiment Lexicon hash files are accessable\n",
        "\n",
        "lexicons_path = f'/gdrive/MyDrive/{LEXICONS_SUBDIR[1:]}/hash*.csv'\n",
        "!pwd\n",
        "!ls $lexicons_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tAxuAxU7ueg"
      },
      "source": [
        "### **Calculate SentimentR (Jockers-Rinker) Sentiment Polarities (Optional: Auto)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foQeDPQpvyB3"
      },
      "source": [
        "if SentimentR_Arc == True:\n",
        "  model_base = 'sentimentr'\n",
        "\n",
        "  \"\"\"\n",
        "  model_name = 'sentimentr_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'\n",
        "  \"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEnJj5rIMcSj"
      },
      "source": [
        "# Verify Lexicon subdirectory and datafiles\n",
        "!ls /gdrive/MyDrive/$LEXICONS_SUBDIR\n",
        "\n",
        "print('\\nTop of Dictionary datafile ----------')\n",
        "!head -n 5  /gdrive/MyDrive/$LEXICONS_SUBDIR/hash_sentiment_sentimentr.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq7dImOJozm5"
      },
      "source": [
        "# Read Lexicon into DataFrame \n",
        "\n",
        "if SentimentR_Arc == True:\n",
        "\n",
        "  lexicon_sentimentr_df = get_lexicon(f'/gdrive/MyDrive/{LEXICONS_SUBDIR}/hash_sentiment_sentimentr.csv')\n",
        "  lexicon_sentimentr_df['x'] = lexicon_sentimentr_df['x'].astype('string')\n",
        "\n",
        "  # Clean/Reorg DataFrame\n",
        "  lexicon_sentimentr_df.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
        "  lexicon_sentimentr_df.rename(columns={'x':'word', 'y':'polarity'}, inplace=True)\n",
        "\n",
        "  # Verify\n",
        "  if (PLOT_OUTPUT == 'All'):\n",
        "    lexicon_sentimentr_df.head()\n",
        "    lexicon_sentimentr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25_Zjja0o_Hx"
      },
      "source": [
        "# Convert DataFrame to Dict[word] = polarity\n",
        "\n",
        "if SentimentR_Arc == True:\n",
        "\n",
        "  id = lexicon_sentimentr_df.word.values\n",
        "  values = lexicon_sentimentr_df.polarity.values\n",
        "\n",
        "  lexicon_sentimentr_dt = dict(zip(id, values))\n",
        "  # lexicon_sentimentr_dt\n",
        "\n",
        "  # Test\n",
        "  sent_test='I hate Mondays.'\n",
        "  print(text2sentiment(sent_test, lexicon_sentimentr_dt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQYYP2hiO53j"
      },
      "source": [
        "# Verify\n",
        "\n",
        "# corpus_sents_df['sent_clean'].isna().any()\n",
        "# corpus_chaps_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVSImJ3ETSYt"
      },
      "source": [
        "corpus_parags_df.columns\n",
        "print('\\n')\n",
        "corpus_sects_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxe15XjNwByS"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Sentiment evaluation function\n",
        "def sentiment_sentimentr(text_str):\n",
        "  '''\n",
        "  Given a text string\n",
        "  Return corresponding sentiment value based on sentimentr lexicon\n",
        "  '''\n",
        "  \n",
        "  sentiment_val = text2sentiment(str(text_str), lexicon_sentimentr_dt)\n",
        "\n",
        "  return sentiment_val \n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if SentimentR_Arc == True:\n",
        "  model_base = 'sentimentr'\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=sentiment_sentimentr, sentiment_type='lexicon')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVX6rg5KwBvF"
      },
      "source": [
        "corpus_sents_df.head(2)\n",
        "corpus_sents_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Pkrp6TwY7OI"
      },
      "source": [
        "# Verify there are no empty Sentences\n",
        "\n",
        "corpus_sents_df[corpus_sents_df['token_len'] == 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYeO-NotzY0-"
      },
      "source": [
        "# TODO: Put above at the start of processing each new Corpus\n",
        "\n",
        "corpus_lexicons_stats_dt = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbGz2Yi5wByY"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if SentimentR_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4aDdJcrzlE1"
      },
      "source": [
        "corpus_sents_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOSiIyhbN2-8"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if SentimentR_Arc == True:\n",
        "  # corpus_sents_df['sentimentr'].plot(alpha=0.3)\n",
        "  corpus_sents_df['sentimentr_stdscaler'].plot(alpha=0.1)\n",
        "  corpus_sents_df['sentimentr_medianiqr'].plot(alpha=0.3)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8POYGujomVt"
      },
      "source": [
        "corpus_sents_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lvswx9yovMV"
      },
      "source": [
        "corpus_parags_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZjqwTvU76AR"
      },
      "source": [
        "### **Calculate Syuzhet (Jockers) Sentiment Polarities (Optional: Auto)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjOXGQX54lbX"
      },
      "source": [
        "# Define Model names\n",
        "\n",
        "if Syuzhet_Arc == True:\n",
        "  model_base = 'syuzhet'\n",
        "  model_name = 'syuzhet_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB5fBNQ-QNwk"
      },
      "source": [
        "# Verify Lexicon subdirectory and datafiles\n",
        "!ls /gdrive/MyDrive/$LEXICONS_SUBDIR\n",
        "\n",
        "print('\\nTop of Dictionary datafile ----------')\n",
        "!head -n 5  /gdrive/MyDrive/$LEXICONS_SUBDIR/hash_sentiment_syuzhet.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkhaGcuy4lbg"
      },
      "source": [
        "# Read Lexicon into DataFrame \n",
        "\n",
        "if Syuzhet_Arc == True:\n",
        "\n",
        "  lexicon_syuzhet_df = get_lexicon(f'/gdrive/MyDrive/{LEXICONS_SUBDIR}/hash_sentiment_syuzhet.csv')\n",
        "  lexicon_syuzhet_df['word'] = lexicon_syuzhet_df['word'].astype('string')\n",
        "\n",
        "  # Clean/Reorg DataFrame\n",
        "  lexicon_syuzhet_df.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
        "  lexicon_syuzhet_df.rename(columns={'x':'word', 'y':'polarity'}, inplace=True)\n",
        "\n",
        "  # Verify\n",
        "  if (PLOT_OUTPUT == 'All'):\n",
        "    lexicon_syuzhet_df.head()\n",
        "    lexicon_syuzhet_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9IuINuR4lbi"
      },
      "source": [
        "# Convert DataFrame to Dict[word] = polarity\n",
        "\n",
        "if Syuzhet_Arc == True:\n",
        "\n",
        "  id = lexicon_syuzhet_df.word.values\n",
        "  values = lexicon_syuzhet_df.value.values\n",
        "\n",
        "  lexicon_syuzhet_dt = dict(zip(id, values))\n",
        "  # lexicon_sentimentr_dt\n",
        "\n",
        "  # Test\n",
        "  sent_test='I hate Mondays.'\n",
        "  print(text2sentiment(sent_test, lexicon_syuzhet_dt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO-txaFL4lbo"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Sentiment evaluation function\n",
        "def sentiment_syuzhet(text_str):\n",
        "  '''\n",
        "  Given a text string\n",
        "  Return corresponding sentiment value based on sentimentr lexicon\n",
        "  '''\n",
        "  \n",
        "  sentiment_val = text2sentiment(str(text_str), lexicon_syuzhet_dt)\n",
        "\n",
        "  return sentiment_val \n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "\n",
        "if Syuzhet_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=sentiment_syuzhet, sentiment_type='lexicon')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfsLZSo04lbp"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if Syuzhet_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9VFBSXD0vJo"
      },
      "source": [
        "corpus_sents_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-BwrbyXR5Hd"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if Syuzhet_Arc == True:\n",
        "  # corpus_sents_df['syuzhet'].plot(alpha=0.3)\n",
        "  corpus_sents_df['syuzhet_stdscaler'].plot(alpha=0.3)\n",
        "  corpus_sents_df['syuzhet_medianiqr'].plot(alpha=0.1)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA3dWsnF78mi"
      },
      "source": [
        "### **Calculate Bing (HuLiu) Sentiment Polarities (Optional: Auto)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wvq1prK7n1k"
      },
      "source": [
        "if Bing_Arc == True:\n",
        "  model_base = 'bing'\n",
        "  model_name = 'bing_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDfB2f0olded"
      },
      "source": [
        "# Verify Lexicon subdirectory and datafiles\n",
        "!ls /gdrive/MyDrive/$LEXICONS_SUBDIR\n",
        "\n",
        "print('\\nTop of Dictionary datafile ----------')\n",
        "!head -n 5  /gdrive/MyDrive/$LEXICONS_SUBDIR/hash_sentiment_bing.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZELGxS8y9PiS"
      },
      "source": [
        "# Read Lexicon into DataFrame \n",
        "\n",
        "if Bing_Arc == True:\n",
        "  \n",
        "  lexicon_bing_df = get_lexicon(f'/gdrive/MyDrive/{LEXICONS_SUBDIR}/hash_sentiment_bing.csv')\n",
        "  lexicon_bing_df['x'] = lexicon_bing_df['x'].astype('string')\n",
        "\n",
        "  # Clean/Reorg DataFrame\n",
        "  lexicon_bing_df.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
        "  lexicon_bing_df.rename(columns={'x':'word', 'y':'polarity'}, inplace=True)\n",
        "\n",
        "  # Verify\n",
        "  if (PLOT_OUTPUT == 'All'):\n",
        "    lexicon_bing_df.head()\n",
        "    lexicon_bing_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJQTaeue9VjI"
      },
      "source": [
        "# Convert DataFrame to Dict[word] = polarity\n",
        "\n",
        "if Bing_Arc == True:\n",
        "\n",
        "  id = lexicon_bing_df.word.values\n",
        "  values = lexicon_bing_df.polarity.values\n",
        "\n",
        "  lexicon_bing_dt = dict(zip(id, values))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_Ffzu1m7n10"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Sentiment evaluation function\n",
        "def sentiment_bing(text_str):\n",
        "  '''\n",
        "  Given a text string\n",
        "  Return corresponding sentiment value based on sentimentr lexicon\n",
        "  '''\n",
        "  \n",
        "  sentiment_val = text2sentiment(str(text_str), lexicon_bing_dt)\n",
        "\n",
        "  return sentiment_val \n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if Bing_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=sentiment_bing, sentiment_type='lexicon')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWITnL2a9rrx"
      },
      "source": [
        "# Calculate Bing Sentiment [0,1,2]\n",
        "\n",
        "def bing_discrete2continous_sentiment(text):\n",
        "  '''\n",
        "  Given a plain text string, give it to\n",
        "    Stanford Stanza (OpenNLP) to calculate sentiment for each word on a 3 point scale 0-2\n",
        "  Return a sentiment value for the entire sentence (sum of word sentiments/log(len of sentence)) \n",
        "    that approximates a normal distribution for all values\n",
        "    In order to get more fine grained measure of overall Sentence sentiment\n",
        "    Sentiment values will be Normalized/Standardized so absolute precision is not required\n",
        "  '''\n",
        "  text_sentiment_total = 0.\n",
        "  text_ls = text.split()\n",
        "  text_len = len(text_ls)\n",
        "  for aword in text_ls:\n",
        "    text_sentiment_total += lex_discrete2continous_sentiment(str(aword), lexicon_bing_dt)\n",
        "  text_sentiment_norm = text_sentiment_total/(np.log(text_len)+1)\n",
        "\n",
        "  return text_sentiment_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xpzm3hi7n1x"
      },
      "source": [
        "# Test\n",
        "\n",
        "if Bing_Arc == True:\n",
        "  sent_test='I hate Mondays.'\n",
        "  print(bing_discrete2continous_sentiment(sent_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UFEItnO-i7h"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if Bing_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=bing_discrete2continous_sentiment, sentiment_type='function')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4thQWz3-i7k"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if Bing_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKlKnqmWmBEP"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if Bing_Arc == True:\n",
        "  # corpus_sents_df['bing'].plot(alpha=0.3)\n",
        "  corpus_sents_df['bing_stdscaler'].plot(alpha=0.3)\n",
        "  corpus_sents_df['bing_medianiqr'].plot(alpha=0.1)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkNZVk128jV9"
      },
      "source": [
        "### **Calculate SentiWord Sentiment Polarities (Optional: Auto)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnL4ORNp8MgB"
      },
      "source": [
        "if SentiWord_Arc == True:\n",
        "  model_base = 'sentiword'\n",
        "  model_name = 'sentiword_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ootf8xdbnHPx"
      },
      "source": [
        "# Verify Lexicon subdirectory and datafiles\n",
        "!ls /gdrive/MyDrive/$LEXICONS_SUBDIR\n",
        "\n",
        "print('\\nTop of Dictionary datafile ----------')\n",
        "!head -n 5  /gdrive/MyDrive/$LEXICONS_SUBDIR/hash_sentiment_sentiword.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpVmt0fK8xi_"
      },
      "source": [
        "# Read Lexicon into DataFrame \n",
        "\n",
        "if SentiWord_Arc == True:\n",
        "\n",
        "  lexicon_sentiword_df = get_lexicon(f'/gdrive/MyDrive/{LEXICONS_SUBDIR}/hash_sentiment_sentiword.csv')\n",
        "  lexicon_sentiword_df['x'] = lexicon_sentiword_df['x'].astype('string')\n",
        "\n",
        "  # Clean/Reorg DataFrame\n",
        "  lexicon_sentiword_df.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
        "  lexicon_sentiword_df.rename(columns={'x':'word', 'y':'polarity'}, inplace=True)\n",
        "\n",
        "  # Verify\n",
        "  if (PLOT_OUTPUT == 'All'):\n",
        "    lexicon_sentiword_df.head()\n",
        "    lexicon_sentiword_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwtK2M9h879M"
      },
      "source": [
        "# Convert DataFrame to Dict[word] = polarity\n",
        "\n",
        "if SentiWord_Arc == True:\n",
        "\n",
        "  id = lexicon_sentiword_df.word.values\n",
        "  values = lexicon_sentiword_df.polarity.values\n",
        "\n",
        "  lexicon_sentiword_dt = dict(zip(id, values))\n",
        "  # lexicon_sentiword_dt\n",
        "\n",
        "  # Test\n",
        "  sent_test='I hate Mondays.'\n",
        "  print(text2sentiment(sent_test, lexicon_sentiword_dt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I-QwB478MgP"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Sentiment evaluation function\n",
        "def sentiment_sentiword(text_str):\n",
        "  '''\n",
        "  Given a text string\n",
        "  Return corresponding sentiment value based on sentimentr lexicon\n",
        "  '''\n",
        "  \n",
        "  sentiment_val = text2sentiment(str(text_str), lexicon_sentiword_dt)\n",
        "\n",
        "  return sentiment_val \n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if SentiWord_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=sentiment_sentiword, sentiment_type='lexicon')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbEF88568MgS"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if SentiWord_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9GfZ5RQnn4G"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if SentiWord_Arc == True:\n",
        "  # corpus_sents_df['sentiword'].plot(alpha=0.3)\n",
        "  corpus_sents_df['sentiword_stdscaler'].plot(alpha=0.3)\n",
        "  corpus_sents_df['sentiword_medianiqr'].plot(alpha=0.1)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUcANLM_8mtT"
      },
      "source": [
        "### **Calculate SenticNet Sentiment Polarities (Optional: Auto)**\n",
        "\n",
        "* https://sentic.net/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OqhSberA1hZ"
      },
      "source": [
        "if SenticNet_Arc == True:\n",
        "  model_base = 'senticnet'\n",
        "  model_name = 'senticnet_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsnCzsfFnx7B"
      },
      "source": [
        "# Verify Lexicon subdirectory and datafiles\n",
        "!ls /gdrive/MyDrive/$LEXICONS_SUBDIR\n",
        "\n",
        "print('\\nTop of Dictionary datafile ----------')\n",
        "!head -n 5  /gdrive/MyDrive/$LEXICONS_SUBDIR/hash_sentiment_senticnet.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmMfvQvYBBoM"
      },
      "source": [
        "# Read Lexicon into DataFrame \n",
        "\n",
        "if SenticNet_Arc == True:\n",
        "\n",
        "  lexicon_senticnet_df = get_lexicon(f'/gdrive/MyDrive/{LEXICONS_SUBDIR}/hash_sentiment_senticnet.csv')\n",
        "  lexicon_senticnet_df['x'] = lexicon_senticnet_df['x'].astype('string')\n",
        "\n",
        "  # Clean/Reorg DataFrame\n",
        "  lexicon_senticnet_df.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
        "  lexicon_senticnet_df.rename(columns={'x':'word', 'y':'polarity'}, inplace=True)\n",
        "\n",
        "  # Verify\n",
        "  if (PLOT_OUTPUT == 'All'):\n",
        "    lexicon_senticnet_df.head()\n",
        "    lexicon_senticnet_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2oS71STBIUS"
      },
      "source": [
        "# Convert DataFrame to Dict[word] = polarity\n",
        "\n",
        "if SenticNet_Arc == True:\n",
        "\n",
        "  id = lexicon_senticnet_df.word.values\n",
        "  values = lexicon_senticnet_df.polarity.values\n",
        "\n",
        "  lexicon_senticnet_dt =dict(zip(id, values))\n",
        "  # lexicon_jockersrinker_dt\n",
        "\n",
        "  # Test\n",
        "  sent_test='I hate Mondays.'\n",
        "  text2sentiment(sent_test, lexicon_senticnet_dt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHQwXBl5BlRM"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Sentiment evaluation function\n",
        "def sentiment_senticnet(text_str):\n",
        "  '''\n",
        "  Given a text string\n",
        "  Return corresponding sentiment value based on senticnet lexicon\n",
        "  '''\n",
        "  \n",
        "  sentiment_val = text2sentiment(str(text_str), lexicon_senticnet_dt)\n",
        "\n",
        "  return sentiment_val \n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if SenticNet_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=sentiment_senticnet, sentiment_type='lexicon')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raHUj3a4A1hs"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if SenticNet_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9lSo0Kmn_T4"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if SenticNet_Arc == True:\n",
        "  # corpus_sents_df['senticnet'].plot(alpha=0.3)\n",
        "  corpus_sents_df['senticnet_stdscaler'].plot(alpha=0.3)\n",
        "  corpus_sents_df['senticnet_medianiqr'].plot(alpha=0.1)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn4KQYpH3glK"
      },
      "source": [
        "### **Calculate NRC Sentiment Polarities (Optional: Auto)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USx6LRmoCFV8"
      },
      "source": [
        "if NRC_Arc == True:\n",
        "  model_base = 'nrc'\n",
        "  model_name = 'nrc_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EdOTv3KoFEV"
      },
      "source": [
        "# Verify Lexicon subdirectory and datafiles\n",
        "!ls /gdrive/MyDrive/$LEXICONS_SUBDIR\n",
        "\n",
        "print('\\nTop of Dictionary datafile ----------')\n",
        "!head -n 5  /gdrive/MyDrive/$LEXICONS_SUBDIR/hash_sentiment_nrc.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFEszSc13glL"
      },
      "source": [
        "# Read Lexicon into DataFrame \n",
        "\n",
        "if NRC_Arc == True:\n",
        "\n",
        "  lexicon_nrc_df = get_lexicon(f'/gdrive/MyDrive/{LEXICONS_SUBDIR}/hash_sentiment_nrc.csv')\n",
        "  lexicon_nrc_df['x'] = lexicon_nrc_df['x'].astype('string')\n",
        "\n",
        "  # Clean/Reorg DataFrame\n",
        "  lexicon_nrc_df.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
        "  lexicon_nrc_df.rename(columns={'x':'word', 'y':'polarity'}, inplace=True)\n",
        "\n",
        "  # Verify\n",
        "  if (PLOT_OUTPUT == 'All'):\n",
        "    lexicon_nrc_df.head()\n",
        "    lexicon_nrc_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nAkx4Mv3glL"
      },
      "source": [
        "# Convert DataFrame to Dict[word] = polarity\n",
        "\n",
        "if NRC_Arc == True:\n",
        "\n",
        "  id = lexicon_nrc_df.word.values\n",
        "  values = lexicon_nrc_df.polarity.values\n",
        "\n",
        "  lexicon_nrc_dt =dict(zip(id, values))\n",
        "  # lexicon_jockersrinker_dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv1nVSATb7z4"
      },
      "source": [
        "# Calculate NRC Sentiment [0,1,2]\n",
        "\n",
        "def nrc_discrete2continous_sentiment(text):\n",
        "  '''\n",
        "  Given a plain text string, give it to\n",
        "    Stanford Stanza (OpenNLP) to calculate sentiment for each word on a 3 point scale 0-2\n",
        "  Return a sentiment value for the entire sentence (sum of word sentiments/log(len of sentence)) \n",
        "    that approximates a normal distribution for all values\n",
        "    In order to get more fine grained measure of overall Sentence sentiment\n",
        "    Sentiment values will be Normalized/Standardized so absolute precision is not required\n",
        "  '''\n",
        "  text_sentiment_total = 0.\n",
        "  text_ls = text.split()\n",
        "  text_len = len(text_ls)\n",
        "  for aword in text_ls:\n",
        "    text_sentiment_total += lex_discrete2continous_sentiment(str(aword), lexicon_nrc_dt)\n",
        "  text_sentiment_norm = text_sentiment_total/(np.log(text_len)+10)\n",
        "\n",
        "  return text_sentiment_norm\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss3Xixo_CX2q"
      },
      "source": [
        "# Test\n",
        "\n",
        "if NRC_Arc == True:\n",
        "  sent_test='I hate Mondays.'\n",
        "  print(nrc_discrete2continous_sentiment(sent_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhqnljMSCX2w"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if NRC_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=nrc_discrete2continous_sentiment, sentiment_type='function')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2q97Dm-CX2z"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if NRC_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBK7LQx4oXI-"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if NRC_Arc == True:\n",
        "  # corpus_sents_df['nrc'].plot(alpha=0.3)\n",
        "  corpus_sents_df['nrc_stdscaler'].plot(alpha=0.1)\n",
        "  corpus_sents_df['nrc_medianiqr'].plot(alpha=0.3)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRTjCPLb8cbB"
      },
      "source": [
        "### **Calculate Afinn Sentiment Polarities (Optional: Auto)**\n",
        "\n",
        "* https://github.com/fnielsen/afinn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcnxqnyzDCde"
      },
      "source": [
        "if AFINN_Arc == True:\n",
        "  model_base = 'afinn'\n",
        "  model_name = 'afinn_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDG2KxvNBdj6"
      },
      "source": [
        "if AFINN_Arc == True:\n",
        "  !pip install afinn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evnkXWL58CcX"
      },
      "source": [
        "# Install and configure for English\n",
        "\n",
        "if AFINN_Arc == True:\n",
        "  from afinn import Afinn\n",
        "  afinn = Afinn(language='en')\n",
        "\n",
        "  # Test\n",
        "\n",
        "  # afinn.score('I had the worst day.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKbeW_cMXhmI"
      },
      "source": [
        "# Calculate AFINN Sentiment [0,1,2]\n",
        "\n",
        "def afinn_discrete2continous_sentiment(text):\n",
        "  '''\n",
        "  Given a plain text string, give it to\n",
        "    Stanford Stanza (OpenNLP) to calculate sentiment for each word on a 3 point scale 0-2\n",
        "  Return a sentiment value for the entire sentence (sum of word sentiments/log(len of sentence)) \n",
        "    that approximates a normal distribution for all values\n",
        "    In order to get more fine grained measure of overall Sentence sentiment\n",
        "    Sentiment values will be Normalized/Standardized so absolute precision is not required\n",
        "  '''\n",
        "  text_sentiment_total = 0.\n",
        "  text_ls = text.split()\n",
        "  text_len = len(text_ls)\n",
        "  for aword in text_ls:\n",
        "    text_sentiment_total += afinn.score(aword)\n",
        "  text_sentiment_norm = text_sentiment_total/(np.log(text_len)+0.1)\n",
        "\n",
        "  return float(text_sentiment_norm)  # return float vs np.float64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRCd4VpwDO0Q"
      },
      "source": [
        "# Test\n",
        "\n",
        "if AFINN_Arc == True:\n",
        "  sent_test='I hate Mondays.'\n",
        "  print(afinn_discrete2continous_sentiment(sent_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrP_wxB3DO0S"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if AFINN_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=afinn_discrete2continous_sentiment, sentiment_type='function')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgZaMPYKDO0T"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if AFINN_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clUzylGOog5h"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if AFINN_Arc == True:\n",
        "  # corpus_sents_df['afinn'].plot(alpha=0.3)\n",
        "  corpus_sents_df['afinn_stdscaler'].plot(alpha=0.3)\n",
        "  corpus_sents_df['afinn_medianiqr'].plot(alpha=0.1)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAEiglIPDfFI"
      },
      "source": [
        "### **Calculate VADER Sentiment Polarities (Optional: Auto)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgkvefzpDgx-"
      },
      "source": [
        "if VADER_Arc == True:\n",
        "  model_base = 'vader'\n",
        "  model_name = 'vader_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wodGtjXhDmZN"
      },
      "source": [
        "if VADER_Arc == True:\n",
        "  # Sentiment evaluation function\n",
        "  sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "  # Test\n",
        "  sid.polarity_scores('hello world')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS8e25MkDmZP"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "if VADER_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=sid.polarity_scores, sentiment_type='compound')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2Azyv2lDmZP"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if VADER_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq8KNwpjom4X"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if VADER_Arc == True:\n",
        "  # corpus_sents_df['vader'].plot(alpha=0.3)\n",
        "  corpus_sents_df['vader_stdscaler'].plot(alpha=0.1)\n",
        "  corpus_sents_df['vader_medianiqr'].plot(alpha=0.3)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCN4c-G48e7-"
      },
      "source": [
        "### **Calculate TextBlob Sentiment Polarities (Optional: Auto)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MfVWZ34Vg8U"
      },
      "source": [
        "if TextBlob_Arc == True:\n",
        "  model_base = 'textblob'\n",
        "  model_name = 'textblob_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "118Blghk7fjp"
      },
      "source": [
        "if TextBlob_Arc == True:\n",
        "  from textblob import TextBlob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhJsYxPoVhY4"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "def textblob_sentiment(text_str):\n",
        "  '''\n",
        "  Given a text string\n",
        "  Return a sentiment value between -1.0 to +1.0 using TextBlob\n",
        "  '''\n",
        "  return TextBlob(text_str).sentiment.polarity\n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if TextBlob_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=textblob_sentiment, sentiment_type='function')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlHRf2aFVhY7"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if TextBlob_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_name, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_name, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_name, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_name, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMWewkTgord1"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if TextBlob_Arc == True:\n",
        "  # corpus_sents_df['textblob'].plot(alpha=0.3)\n",
        "  corpus_sents_df['textblob_stdscaler'].plot(alpha=0.3)\n",
        "  corpus_sents_df['textblob_medianiqr'].plot(alpha=0.1)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2blGfVlKb_s"
      },
      "source": [
        "### **Calculate Pattern Sentiment Polarities (Optional: Auto)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU60-nqpCsl7"
      },
      "source": [
        "if Pattern_Arc == True:\n",
        "  model_base = 'pattern'\n",
        "  model_name = 'pattern_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KxnLfHoL3Fy"
      },
      "source": [
        "if Pattern_Arc == True:\n",
        "  !pip install pattern"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtwmIrSOKZRm"
      },
      "source": [
        "if Pattern_Arc == True:\n",
        "  from pattern.en import sentiment as pattern_sa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vwtm_jBKZM2"
      },
      "source": [
        "# Test\n",
        "\n",
        "if Pattern_Arc == True:\n",
        "  sent_test='I hate Mondays.'\n",
        "  pattern_sa(sent_test)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXq-jDPxasVY"
      },
      "source": [
        "# Calculate Pattern Sentiment [0,1,2]\n",
        "\n",
        "def pattern_discrete2continous_sentiment(text):\n",
        "  '''\n",
        "  Given a plain text string, give it to\n",
        "    Stanford Stanza (OpenNLP) to calculate sentiment for each word on a 3 point scale 0-2\n",
        "  Return a sentiment value for the entire sentence (sum of word sentiments/log(len of sentence)) \n",
        "    that approximates a normal distribution for all values\n",
        "    In order to get more fine grained measure of overall Sentence sentiment\n",
        "    Sentiment values will be Normalized/Standardized so absolute precision is not required\n",
        "  '''\n",
        "  text_sentiment_total = 0.\n",
        "  text_ls = text.split()\n",
        "  text_len = len(text_ls)\n",
        "  for aword in text_ls:\n",
        "    text_sentiment_total += pattern_sa(str(aword))[0]\n",
        "  text_sentiment_norm = text_sentiment_total/(np.log(text_len)+0.01)\n",
        "\n",
        "  return text_sentiment_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-sXRBNWC08o"
      },
      "source": [
        "# Test\n",
        "\n",
        "if Pattern_Arc == True:\n",
        "  sent_test='I hate Mondays.'\n",
        "  print(pattern_discrete2continous_sentiment(sent_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db0hezLKC08p"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if Pattern_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=pattern_discrete2continous_sentiment, sentiment_type='function')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGHixqpOC08q"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if Pattern_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clydVLby2KhG"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if Pattern_Arc == True:\n",
        "  # corpus_sents_df['pattern'].plot(alpha=0.3)\n",
        "  corpus_sents_df['pattern_stdscaler'].plot(alpha=0.3)\n",
        "  corpus_sents_df['pattern_medianiqr'].plot(alpha=0.1)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-X3xNWkoyLS"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if Pattern_Arc == True:\n",
        "  corpus_sents_df['pattern'].rolling(10*win_s1per, center=True).mean().plot();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQwX3APKnhjP"
      },
      "source": [
        "corpus_sents_df['pattern'].plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM1OmuaiVQIH"
      },
      "source": [
        "# Check Pattern Series for Outliers\n",
        "\n",
        "if Pattern_Arc == True:\n",
        "  print('Furthest Positive Outlier in Pattern Time Series:')\n",
        "  corpus_sents_df[corpus_sents_df['pattern'] == corpus_sents_df['pattern'].max()][['sent_no', 'pattern', 'sent_raw']]\n",
        "\n",
        "  pattern_max_sentno = int(corpus_sents_df[corpus_sents_df['pattern'] == corpus_sents_df['pattern'].max()][['sent_no']].max())\n",
        "  print(f'Max Outlier for Pattern Sentiment Model is at Sentence #{pattern_max_sentno}')\n",
        "\n",
        "  print('Furthest Negative Outlier in Pattern Time Series:')\n",
        "  corpus_sents_df[corpus_sents_df['pattern'] == corpus_sents_df['pattern'].min()][['sent_no', 'pattern', 'sent_raw']]\n",
        "\n",
        "  pattern_min_sentno = int(corpus_sents_df[corpus_sents_df['pattern'] == corpus_sents_df['pattern'].min()][['sent_no']].min())\n",
        "  print(f'Max Outlier for Pattern Sentiment Model is at Sentence #{pattern_min_sentno}')\n",
        "\n",
        "  print('\\n')\n",
        "  print('Median Absolute Deviation (MAD) for Pattern Time Series:')\n",
        "  robust.mad(corpus_sents_df['pattern'])\n",
        "\n",
        "  temp_df = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny19347PZ85l"
      },
      "source": [
        "# Verify what is happening in the neighborhood of the Maximum Sentiment Outlier for Pattern\n",
        "\n",
        "if Pattern_Arc == True:\n",
        "  outlier_halfwin = 10\n",
        "  outlier_winstart = pattern_max_sentno - outlier_halfwin\n",
        "  outlier_winend = pattern_max_sentno + outlier_halfwin\n",
        "\n",
        "  corpus_sents_df.iloc[outlier_winstart:outlier_winend]['pattern'].plot();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRDctGTdUfKk"
      },
      "source": [
        "# Pattern library has a bug wherein a/several Sentences have far outlying Sentiments\n",
        "#   we need to clip these to within n * MAD\n",
        "\n",
        "if Pattern_Arc == True:\n",
        "  MAD_Clip_Boundary = 5.2 #@param {type:\"slider\", min:1.0, max:10, step:0.1}\n",
        "\n",
        "  # find the limits of 2.5 Median Absolute Deviation of Pattern Time Series\n",
        "\n",
        "  clip_25mad = MAD_Clip_Boundary * robust.mad(corpus_sents_df['pattern'])\n",
        "  print(f'Clip Pattern Series at 2.5 x Median Absolute Deviation (MAD) = {clip_25mad}')\n",
        "\n",
        "  # Create a Temporary DataFrame to test/find best MAD Clipping multiplier for Pattern\n",
        "  temp_df['pattern'] = pd.Series(corpus_sents_df['pattern'].clip(upper=clip_25mad))\n",
        "  temp_df['pattern'].clip(lower=-clip_25mad, inplace=True)\n",
        "\n",
        "  # Verify \n",
        "  temp_df['pattern'].plot();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co3jaquyZom7"
      },
      "source": [
        "# Once a good Clip_MAD_multiplier if found, update Pattern Time Series with it\n",
        "\n",
        "if Pattern_Arc == True:\n",
        "  corpus_sents_df['pattern'] = temp_df['pattern']\n",
        "  corpus_sents_df['pattern'].plot();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsaziON_Z263"
      },
      "source": [
        "### **Calculate Stanza/OpenNLP Sentiment Polarities (Optional: Auto)**\n",
        "\n",
        "* https://github.com/piyushpathak03/NLP-using-STANZA/blob/main/Stanza.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZgGfcCuFnmI"
      },
      "source": [
        "if Stanza_Arc == True:\n",
        "  model_base = 'stanza'\n",
        "  model_name = 'stanza_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoZUi2AwZ_7L"
      },
      "source": [
        "if Stanza_Arc == True:\n",
        "  !pip install stanza"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5txTb6aIZ2tN"
      },
      "source": [
        "%time\n",
        "\n",
        "import stanza\n",
        "\n",
        "if Stanza_Arc == True:\n",
        "  stanza.download('en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NORYbxsxZ2qg"
      },
      "source": [
        "if Stanza_Arc == True:\n",
        "  nlp = stanza.Pipeline('en', processors='tokenize,sentiment')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtOtBfYwZ2na"
      },
      "source": [
        "# Test stanza directly\n",
        "\n",
        "# doc = nlp('Ram is a bad boy')\n",
        "# for i, sentence in enumerate(doc.sentences):\n",
        "#     print(i, sentence.sentiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKnox67kayod"
      },
      "source": [
        "# Calculate Stanza Sentiment [0,1,2]\n",
        "\n",
        "def stanza_discrete2continous_sentiment(text):\n",
        "  '''\n",
        "  Given a plain text string, give it to\n",
        "    Stanford Stanza (OpenNLP) to calculate sentiment for each word on a 3 point scale 0-2\n",
        "  Return a sentiment value for the entire sentence (sum of word sentiments/log(len of sentence)) \n",
        "    that approximates a normal distribution for all values\n",
        "    In order to get more fine grained measure of overall Sentence sentiment\n",
        "    Sentiment values will be Normalized/Standardized so absolute precision is not required\n",
        "  '''\n",
        "  text_sentiment_tot = 0.\n",
        "  text_ls = text.split()\n",
        "  text_len = len(text_ls)\n",
        "  for aword in text_ls:\n",
        "    adoc = nlp(aword)\n",
        "    for i, sentence in enumerate(adoc.sentences):\n",
        "      text_sentiment_tot += float(sentence.sentiment)\n",
        "  text_sentiment_norm = text_sentiment_tot/(np.log(text_len)+0.1)\n",
        "\n",
        "  return text_sentiment_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNngkBBAF26C"
      },
      "source": [
        "# Test\n",
        "\n",
        "if Stanza_Arc == True:\n",
        "  sent_test='I hate Mondays.'\n",
        "  print(stanza_discrete2continous_sentiment(sent_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrY2mrhVF26D"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# NOTE: requires about 30-50mins (20210708 at 0730) Colab Pro: GPU+RAM \n",
        "#                      2hrs30mins (20210802 at 1330) Colab Pro: CPU only\n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if Stanza_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=stanza_discrete2continous_sentiment, sentiment_type='function')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSiYC73nF26D"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if Stanza_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5tUYZA1DExu"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if Stanza_Arc == True:\n",
        "  # corpus_sents_df['stanza'].plot(alpha=0.3)\n",
        "  corpus_sents_df['stanza_stdscaler'].plot(alpha=0.3)\n",
        "  corpus_sents_df['stanza_medianiqr'].plot(alpha=0.1)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIGQgWvyOtg6"
      },
      "source": [
        "### **Calculate Flair Sentiment Polarities (Optional: Auto)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWbcaaDDO1J1"
      },
      "source": [
        "if Flair_Arc == True:\n",
        "  model_base = 'flair'\n",
        "  model_name = 'flair_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooLdktLHO1J3"
      },
      "source": [
        "if Flair_Arc == True:\n",
        "  !pip install flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77-3mVyRPJbb"
      },
      "source": [
        "if Flair_Arc == True:\n",
        "  from flair.models import TextClassifier\n",
        "  from flair.data import Sentence\n",
        "\n",
        "  classifier = TextClassifier.load('en-sentiment')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJOopGZhO1J5"
      },
      "source": [
        "# Test\n",
        "\n",
        "if Flair_Arc == True:\n",
        "  sentence = Sentence('The food was great!')\n",
        "  classifier.predict(sentence)\n",
        "\n",
        "  # print sentence with predicted labels\n",
        "  print('Sentence above is: ', sentence.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7fZT10HQDqd"
      },
      "source": [
        "def get_flairsentiment(text_str):\n",
        "  # TODO: For efficiency, combine sentences in batches as arrays (if possible)\n",
        "  '''\n",
        "  Given a text string\n",
        "  Return a floating point -1.0 to 1.0 value for Sentiment\n",
        "  '''\n",
        "\n",
        "  text_tokenized_obj = Sentence(text_str)\n",
        "  classifier.predict(text_tokenized_obj)\n",
        "\n",
        "  # print(f'Processing text_str: {text_str}')\n",
        "  sentiment_str = str(text_tokenized_obj.labels[0])\n",
        "\n",
        "  sentiment_ls = sentiment_str.split(' ')\n",
        "  \n",
        "  sentiment_sign = sentiment_ls[0]\n",
        "\n",
        "  if sentiment_sign.lower() == 'positive':\n",
        "    sign_multiplier = 1.0\n",
        "  else:\n",
        "    sign_multiplier = -1.0\n",
        "\n",
        "  sentiment_abs = float(sentiment_ls[1][1:-1])\n",
        "\n",
        "  sentiment_fl = sign_multiplier * sentiment_abs \n",
        "\n",
        "  return sentiment_fl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbgQVQlNSdcE"
      },
      "source": [
        "# Test\n",
        "\n",
        "if Flair_Arc == True:\n",
        "  get_flairsentiment('it is.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX0PDn5AO1J9"
      },
      "source": [
        "# Calculate all the Sentence, Paragraph, Section and Chapter Sentiment Scores and Standardized variants\n",
        "\n",
        "# Calculate all Sentiment values and variants\n",
        "if Flair_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=get_flairsentiment, sentiment_type='function')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v5Q2ota94_r"
      },
      "source": [
        "corpus_sents_df[corpus_sents_df['sent_clean'].str.find('smokeing') != -1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfJEaIw1-QLs"
      },
      "source": [
        "corpus_sents_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vlK-dyHO1J-"
      },
      "source": [
        "# Get/Set Sentiment Statistics\n",
        "\n",
        "if Flair_Arc == True:\n",
        "  get_lexstats(corpus_sents_df, model_base, text_unit='sentence')\n",
        "  get_lexstats(corpus_parags_df, model_base, text_unit='paragraph')\n",
        "  get_lexstats(corpus_sects_df, model_base, text_unit='section')\n",
        "  get_lexstats(corpus_chaps_df, model_base, text_unit='chapter')\n",
        "\n",
        "  # Validate\n",
        "  corpus_lexicons_stats_dt\n",
        "\n",
        "  # corpus_lexicons_stats_dt['vader']['sents']['sentiment_max']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VycWC2gDO1J_"
      },
      "source": [
        "# Verify \n",
        "\n",
        "if Flair_Arc == True:\n",
        "  corpus_sents_df['flair'].plot(alpha=0.3)\n",
        "  corpus_sents_df['flair_stdscaler'].plot(alpha=0.3)\n",
        "  corpus_sents_df['flair_medianiqr'].plot(alpha=0.1)\n",
        "  plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaISmTWT-pev"
      },
      "source": [
        "### **Calculate FRENCH FEEL Lexicon Sentiment Polarities (Optional: Auto)**\n",
        "\n",
        "* https://github.com/kujjwal02/French_Tragedies_Dataset/blob/master/French%20Tragedies.ipynb\n",
        "* https://github.com/shalinijaiswalsj09/French-Language-Processing-/blob/master/feelNLP.py (201802271s) FEEL Lexical analysis\n",
        "*https://github.com/nishchaychawla/Sentiment_Analysis_of_french_text (20180226 3s) Sentiment analysis of ftragedy dataset using tidytext and French Expanded Emotion Lexicon\n",
        "* https://github.com/kujjwal02/French_Tragedies_Dataset (20180502 5s) Lexical SA of French Tragedies from Kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMCz0gt7-a6f"
      },
      "source": [
        "lexicon_feel_df = pd.read_csv('https://raw.githubusercontent.com/kujjwal02/French_Tragedies_Dataset/master/FEEL.csv',delimiter=';', index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urA-XaQH-nnz"
      },
      "source": [
        "lexicon_feel_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW_MJVzawiR3"
      },
      "source": [
        "lexicon_feel_df[lexicon_feel_df.word == 'bien']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE7MPz6Swh3y"
      },
      "source": [
        "lexicon_feel_df = lexicon_feel_df.drop(2831)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1Go8lTAxTyg"
      },
      "source": [
        "lexicon_feel_df.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC4PWccVxbSF"
      },
      "source": [
        "lexicon_feel_df.set_index('word')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVA_kK3ZxbJx"
      },
      "source": [
        "lexicon_feel_df.set_index('word').loc['moins']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDos_t5kxuA8"
      },
      "source": [
        "lexicon_feel_df.polarity.value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqDUqj5Dxt8G"
      },
      "source": [
        "lexicon_feel_df[lexicon_feel_df.word.str.split().map(lambda lst: len(lst)) > 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8gU6G1g1Jar"
      },
      "source": [
        "lexicon_feel_df['length'] = lexicon_feel_df.word.str.split().map(lambda lst: len(lst))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxH8GuKF0WvE"
      },
      "source": [
        "lexicon_feel_dt = lexicon_feel_df.set_index('word')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBjtuuS34nSY"
      },
      "source": [
        "lexicon_feel_dt.loc['mal']['polarity']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeVXivA5xt4A"
      },
      "source": [
        "def get_frsentiment(fr_sent):\n",
        "  '''\n",
        "  Given a text sentence in French\n",
        "  Return a sentiment 1.0 (positive) or -1.0 (negative)\n",
        "  '''\n",
        "\n",
        "  fr_sent_clean = fr_sent.translate(str.maketrans('', '', string.punctuation))\n",
        "  asent_sentiment = 0.0\n",
        "  pol_fl = 0.0\n",
        "  token_ls = fr_sent_clean.split()\n",
        "  for i, atoken in enumerate(token_ls):\n",
        "    try:\n",
        "      atoken_sentiment = lexicon_feel_dt.loc[atoken.lower()]['polarity']\n",
        "      print(f'atoken_sentiment: {atoken_sentiment}')\n",
        "      if atoken_sentiment.lower().strip() == 'positive':\n",
        "        pol_fl = 1.0\n",
        "      elif atoken_sentiment.lower().strip() == 'negative':\n",
        "        pol_fl = -1.0\n",
        "      else:\n",
        "        print(f'ERROR: atoken_sentiment = {atoken_sentiment}')\n",
        "\n",
        "      asent_sentiment += pol_fl\n",
        "    except KeyError:\n",
        "      pass\n",
        "\n",
        "  return asent_sentiment\n",
        "\n",
        "# Test\n",
        "\n",
        "test_fr_sent1 = u\"C'est une voiture mal y terribles y horrible.\"\n",
        "test_fr_sent2 = u\"C'est une voiture super y bon y bonne.\"\n",
        "test_fr_sent3 = u\"C'est une voiture.\"\n",
        "\n",
        "print(get_frsentiment(re.escape(test_fr_sent1)))\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  # for window_size in range(6, 0, -1):\n",
        "  for each in window(sent.split(), window_size):\n",
        "      sub_str = ' '.join(each)\n",
        "      try:\n",
        "          sentiment = lexicon_dict.loc[sub_str]\n",
        "          sent.replace(sub_str, '')\n",
        "          yield sentiment\n",
        "#                 if window_size > 1:\n",
        "#                     print(sub_str, ':', proprty['polarity'])\n",
        "      except KeyError:\n",
        "          pass\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Jjdto_Ixt0D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivEy4LGOxtwU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcLU3Gr46LLl"
      },
      "source": [
        "### **Calculate FRENCH VADER Sentiment Polarities (Optional: Auto)**\n",
        "\n",
        "* https://github.com/thomas7lieues/vader_FR\n",
        "* https://github.com/brunneis/vader-multi "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpSWmVK-6CYW"
      },
      "source": [
        "!pip install vaderSentiment-fr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJCxXQZ67yGx"
      },
      "source": [
        "SIA = SentimentIntensityAnalyzer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1tydph07x-s"
      },
      "source": [
        "phrase = \"Une phrase très cool à analyser\"\n",
        "\n",
        "score = SIA.polarity_scores(phrase)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMG_TtQY_TKI"
      },
      "source": [
        "model_base = 'vaderfr'\n",
        "model_name = 'vaderfr_lnorm_medianiqr'\n",
        "\n",
        "col_medianiqr = f'{model_base}_medianiqr'\n",
        "col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'\n",
        "\n",
        "get_sentiments(model_base=model_base, sentiment_fn=SIA.polarity_scores, sentiment_type='compound', text_prep='raw')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiWihAaN7x6N"
      },
      "source": [
        "get_sentiments(model_base=model_base, sentiment_fn=SIA.polarity_scores, sentiment_type='compound', text_prep='raw')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-8wBC4nCiKg"
      },
      "source": [
        "corpus_sents_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVjg7jXcCm5E"
      },
      "source": [
        "\n",
        "corpus_sents_df['vaderfr_stdscaler_roll10'] = corpus_sents_df['vaderfr_stdscaler'].rolling(win_s1per*10, center=True).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDx4aNeDDASj"
      },
      "source": [
        "corpus_sents_df['vaderfr_stdscaler_roll10'].plot()\n",
        "plt.title(f'{CORPUS_FULL}\\nFrench VADER Sentence StdScaler SMA 10%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCY-BlXr6DNH"
      },
      "source": [
        "### **Calculate FRENCH TextBlob Sentiment Polarities (Optional: Auto)**\n",
        "\n",
        "* https://pypi.org/project/textblob-fr/ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0A2pFRHpLzL"
      },
      "source": [
        "!pip install textblob_fr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqtw1BE_6AdW"
      },
      "source": [
        "# import re\n",
        "# import spacy\n",
        "# from spacy.lang.fr.stop_words import STOP_WORDS\n",
        "from textblob import Blobber\n",
        "from textblob_fr import PatternTagger, PatternAnalyzer\n",
        "TextBlobFr = Blobber(pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
        "# from nltk.tokenize import sent_tokenize\n",
        "# from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu1j1jQlt6Wz"
      },
      "source": [
        "TextBlobFrench_Arc = True\n",
        "\n",
        "if TextBlobFrench_Arc == True:\n",
        "  model_base = 'textblobfr'\n",
        "  model_name = 'textblobfr_lnorm_medianiqr'\n",
        "\n",
        "  col_medianiqr = f'{model_base}_medianiqr'\n",
        "  col_meanstd = f'{model_base}_meanstd'\n",
        "\n",
        "  col_lnorm_medianiqr = f'{model_base}_lnorm_medianiqr'\n",
        "  col_lnorm_meanstd = f'{model_base}_lnorm_meanstd'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTIDEsrnqW_C"
      },
      "source": [
        "# Test\n",
        "\n",
        "blob2 = TextBlobFr(u\"C'est une voiture terribles.\")\n",
        "blob2.sentiment\n",
        "blob2 = TextBlobFr(u\"C'est une voiture super y bon.\")\n",
        "blob2.sentiment\n",
        "blob2 = TextBlobFr(u\"C'est une voiture.\")\n",
        "blob2.sentiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqKdowoppQFn"
      },
      "source": [
        "for i in range(5):\n",
        "  test_sent = corpus_sents_df.iloc[i]['sent_raw']\n",
        "  print(f'test_sent: {test_sent}')\n",
        "  test_score = TextBlobFr(test_sent).sentiment[0]\n",
        "  print(test_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxo3cl-SqJpl"
      },
      "source": [
        "def textblobfr_sentiment(text_str):\n",
        "  '''\n",
        "  Given a text string\n",
        "  Return a sentiment value between -1.0 to +1.0 using TextBlob\n",
        "  '''\n",
        "  return TextBlobFr(text_str).sentiment[0]\n",
        "\n",
        "# Test\n",
        "\n",
        "test_sents_ls = [u\"C'est une voiture terribles.\", u\"C'est une voiture super y bon.\", u\"C'est une voiture.\"]\n",
        "\n",
        "for i,asent in enumerate(test_sents_ls):\n",
        "  print(f'Sent #{i} Sentiment: {textblobfr_sentiment(asent)}\\n     Sentence: {asent}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHuIWpF8uwGY"
      },
      "source": [
        "# Calculate all Sentiment values and variants\n",
        "if TextBlobFrench_Arc == True:\n",
        "  get_sentiments(model_base=model_base, sentiment_fn=textblobfr_sentiment, sentiment_type='function')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mSF91nlv8cP"
      },
      "source": [
        "win_s1per = int(1/100 * corpus_sents_df.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvuGwwshvil4"
      },
      "source": [
        "\n",
        "\n",
        "corpus_sents_df['textblobfr_stdscaler_roll10'] = corpus_sents_df['textblobfr_stdscaler'].rolling(10*win_s1per, center=True).mean()\n",
        "corpus_sents_df['textblobfr_stdscaler_roll10'].plot()\n",
        "plt.title(f'{CORPUS_FULL}\\nFrench TextBlob StdScaler SMA 10%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JljMuTggpWya"
      },
      "source": [
        "sentiments = []\n",
        "\n",
        "for i in range(5):\n",
        "  asent = corpus_sents_df.iloc[i]['sent_raw']\n",
        "  sentiment = tb(asent).sentiment[0]\n",
        "  if (sentiment > 0):\n",
        "      sentiments.append('Positif')\n",
        "  elif (sentiment < 0):\n",
        "      sentiments.append('Negatif')\n",
        "  else:\n",
        "      sentiments.append('Neutre') \n",
        "\n",
        "[f'{x}\\n' for x in sentiments]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbo61bCr7PPb"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "def load_data():\n",
        "  # https://github.com/adepril/CustomerSatisfactionAnalysisOfInsuranceCompanies/blob/main/app.py\n",
        "\n",
        "  df = pd.read_csv(\"https://raw.githubusercontent.com/adepril/datasets/main/insurance-reviews-france-Comments.csv\")\n",
        "  df = df.drop(['Unnamed: 0'],axis=1)\n",
        "  df = df.dropna()\n",
        "  df[\"Comment\"]= df[\"Comment\"].str.lower()\n",
        "\n",
        "  # Word Tokenization and deleting punctuation\n",
        "  comments=[]\n",
        "  for comment in df[\"Comment\"].apply(str):\n",
        "      WordTokenizer = []\n",
        "      for word in  re.sub(\"\\W\",\" \",comment ).split():\n",
        "          WordTokenizer.append(word)\n",
        "      comments.append(WordTokenizer)\n",
        "\n",
        "  #Ajoute une nouvelle colonne\n",
        "  df[\"Word_Tokenizer\"]= comments\n",
        "\n",
        "  # Set new Spacy's Stop Word list by deleting negation word \n",
        "  stop_words=set(STOP_WORDS)\n",
        "\n",
        "  deselect_stop_words = ['n\\'','ne','pas','plus','personne','aucun','ni','aucune','rien']\n",
        "  for w in deselect_stop_words:\n",
        "      if w in stop_words:\n",
        "          stop_words.remove(w)\n",
        "      else:\n",
        "          continue\n",
        "\n",
        "  # Add a new column for comments without StopWords\n",
        "  AllfilteredComment=[]\n",
        "  for comment in df[\"Word_Tokenizer\"]:\n",
        "      filteredComment = [w for w in comment if not ((w in stop_words) or (len(w) == 1))]\n",
        "      AllfilteredComment.append(' '.join(filteredComment))\n",
        "      \n",
        "  df[\"CommentAferPreproc\"]=AllfilteredComment\n",
        "\n",
        "  # Sentiment Analysis with TextBlob\n",
        "  sentiments = []\n",
        "  for i in df[\"CommentAferPreproc\"]:\n",
        "      sentiment = tb(i).sentiment[0]\n",
        "      if (sentiment > 0):\n",
        "          sentiments.append('Positif')\n",
        "      elif (sentiment < 0):\n",
        "          sentiments.append('Negatif')\n",
        "      else:\n",
        "          sentiments.append('Neutre')   \n",
        "\n",
        "  # Ajoute une colonne : Sentiment\n",
        "  df[\"sentiment\"]=sentiments\n",
        "\n",
        "  return df\n",
        "\n",
        "df = load_data()\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZpW9HYk7PBC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rozr6h7x6cmO"
      },
      "source": [
        "### **Calculate FRENCH SVM Sentiment Polarities (Optional: Auto)**\n",
        "\n",
        "* https://github.com/amineabdaoui/python-sentiment-classification (20200813) Pretrained SVM Sentiment Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3z39csg6hMx"
      },
      "source": [
        "!git clone https://github.com/amineabdaoui/python-sentiment-classification.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzdeNyxz5Wwe"
      },
      "source": [
        "%cd ./python-sentiment-classification/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB6_irHF65i2"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGQIyG2q65XH"
      },
      "source": [
        "import predictSentiment as ps\n",
        "\n",
        "print(ps.predictFrench('Je suis content, il fait beau c\\'est super ! '))\n",
        "print(ps.predictFrench('Je suis triste, il pleut c\\'est horrible ! '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5rJwLyU7DER"
      },
      "source": [
        "%cd ..\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfMwbhVMwgXw"
      },
      "source": [
        "### **(Optional) Calculate SentimentR and SyuzhetR Sentiments in RStudio**\n",
        "\n",
        "**NOTE** Process in RStudio with the following R Script\n",
        "```\n",
        "# Setup\n",
        "# getwd()\n",
        "# list.files(pattern='*.csv')\n",
        "# setwd('./sentimenttime')\n",
        "\n",
        "###\n",
        "# Begin SyuzhetR Preprocessing\n",
        "library('syuzhet')\n",
        "\n",
        "# import the RAW Sentences.csv, not CLEAN\n",
        "# because SentimentR assigns greater polarity to HATE > hate\n",
        "# TODO: Compare CLEAN vs RAW for SentimentR and VADER for impact of such Heuristics\n",
        "\n",
        "# >>> CUSTOMIZE THIS FOR EACH CORPUS <<<\n",
        "corpus_name = 'ddefoe_robinsoncrusoe' \n",
        "# >>> CUSTOMIZE THIS FOR EACH CORPUS <<<\n",
        "\n",
        "# SentimentTime Preprocessing (e.g. corpus_text_sents_raw_ddefoe_robinsoncrusoe.csv)\n",
        "input_filename_prefix = 'corpus_text_sents_raw_'\n",
        "input_filename_suffix = '.csv'\n",
        "\n",
        "corpus_input_filename = trimws(paste0(input_filename_prefix, corpus_name, input_filename_suffix, sep=' '))\n",
        "\n",
        "###\n",
        "syuzhet_output_prefix = 'sum_sentiments_syuzhetR_4models_sentimenttimeraw_'\n",
        "syuzhet_output_suffix = '.csv'\n",
        "syuzhet_output = trimws(paste0(syuzhet_output_prefix, corpus_name, syuzhet_output_suffix, sep=' '))\n",
        "\n",
        "\n",
        "# Use 4 Models in Syuzhet to parse Corpus and generate 4 Sentiment Time Series\n",
        "\n",
        "# (OPTION A) Read preprocessed Corpus *.csv (Sentence Tokenized and text cleaned by sentimenttime)\n",
        "corpus_str <- read.csv(corpus_input_filename,header=T)$sent_raw\n",
        "\n",
        "# corpus_sents_v <- syuzhet::get_sentences(corpus_str) # SyuzhetR often splits a line with one Sentence into several lines\n",
        "corpus_sents_v <- read.csv(corpus_input_filename, header = TRUE, row.names = 1)\n",
        "\n",
        "# (OPTION B) Read raw textfile using Syuzhet Sentence Tokenizer and text preprocessing\n",
        "# corpus_str <- syuzhet::get_text_as_string(corpus_input)\n",
        "# corpus_sents_v <- syuzhet::get_sentences(corpus_str)\n",
        "\n",
        "# Read in RAW Sentences\n",
        "syuzhet_all_df <- data.frame(sent_raw = corpus_sents_v)\n",
        "\n",
        "# Compute Sentiment values for each Model \n",
        "syuzhet_all_df$syuzhet <- syuzhet::get_sentiment(corpus_sents_v, method='syuzhet')\n",
        "syuzhet_all_df$bing <- syuzhet::get_sentiment(corpus_sents_v, method='bing')\n",
        "syuzhet_all_df$afinn <- syuzhet::get_sentiment(corpus_sents_v, method='afinn')\n",
        "syuzhet_all_df$nrc <- syuzhet::get_sentiment(corpus_sents_v, method='nrc')\n",
        "\n",
        "# Save Syuzhet Results    \n",
        "write.csv(syuzhet_all_df, syuzhet_output)\n",
        "\n",
        "\n",
        "\n",
        "# Begin SentimentR Processing\n",
        "library('sentimentr')\n",
        "\n",
        "# Set Output Sentiments Datafile names\n",
        "sentimentr_output_prefix = 'sum_sentiments_sentimentR_7models_sentimenttimeraw_'\n",
        "sentimentr_output_suffix = '.csv'\n",
        "sentimentr_output = trimws(paste0(sentimentr_output_prefix, corpus_name, sentimentr_output_suffix, sep=' '))\n",
        "\n",
        "# Use vector of RAW sentences already read (originally parsed by SentimentTime.py) \n",
        "# sentimentr_sents_v <- sentimentr::get_sentences(corpus_sents_v)\n",
        "# sentimentr_sents_v <- corpus_sents_v\n",
        "  \n",
        "  \n",
        "# Create data.frame with jockers_rinker sentiments\n",
        "sentimentr_all_df <- data.frame(sent_raw = corpus_sents_v)\n",
        "\n",
        "# sentimentr_sents_v <- read.csv(corpus_input_filename, header = TRUE, row.names = 1)\n",
        "# Create data.frame with jockers_rinker sentiments\n",
        "# sentimentr_all_df <- data.frame(sent_raw = sentimentr_sents_v)\n",
        "\n",
        "# Code from sentimentr.R\n",
        "# \n",
        "# SentimentR function sentiment will not work on native R data types, only\n",
        "#   types of 'get_sentences'/'get_sentences_char' created by passing text\n",
        "#   through the sentence tokenizer textshape::split_sentence\n",
        "# We fool SentimentR by copying and calling it's make_class function in utils.R\n",
        "#   and passing our preprocessed text (sentence tokenization done in Python) to\n",
        "#   ensure that SentimentR has the same number/alignment of Sentences in our Corpus\n",
        "#   as all other Sentiment analysis methods\n",
        "# \n",
        "# get_sentences.character <- function(x, ...) {\n",
        "#   out <- textshape::split_sentence(x, ...)\n",
        "#   make_class(out, \"get_sentences\", \"get_sentences_character\")\n",
        "# }\n",
        "\n",
        "# Code from SentimentR.r (in utils.R)\n",
        "make_class <- function(x, ...) {\n",
        "  class(x) <- unique(c(..., class(x)))    \n",
        "  x\n",
        "}\n",
        "\n",
        "# Add other lexicon sentiments\n",
        "sentimentr_all_df$jockers_rinker <- sentimentr::sentiment(make_class(corpus_sents_v, \"get_sentences\", \"get_sentences_character\"), polarity_dt=lexicon::hash_sentiment_jockers_rinker, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "sentimentr_all_df$jockers <- sentimentr::sentiment(make_class(corpus_sents_v, \"get_sentences\", \"get_sentences_character\"), polarity_dt=lexicon::hash_sentiment_jockers, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "sentimentr_all_df$huliu <- sentimentr::sentiment(make_class(corpus_sents_v, \"get_sentences\", \"get_sentences_character\"), polarity_dt=lexicon::hash_sentiment_huliu, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "sentimentr_all_df$lmcd <- sentimentr::sentiment(make_class(corpus_sents_v, \"get_sentences\", \"get_sentences_character\"), polarity_dt=lexicon::hash_sentiment_loughran_mcdonald, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "sentimentr_all_df$nrc <- sentimentr::sentiment(make_class(corpus_sents_v, \"get_sentences\", \"get_sentences_character\"), polarity_dt=lexicon::hash_sentiment_nrc, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "sentimentr_all_df$senticnet <- sentimentr::sentiment(make_class(corpus_sents_v, \"get_sentences\", \"get_sentences_character\"), polarity_dt=lexicon::hash_sentiment_senticnet, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "sentimentr_all_df$sentiword <- sentimentr::sentiment(make_class(corpus_sents_v, \"get_sentences\", \"get_sentences_character\"), polarity_dt=lexicon::hash_sentiment_sentiword, hyphen=\" \", neutral.nonverb.like=TRUE)$sentiment\n",
        "\n",
        "write.csv(sentimentr_all_df, sentimentr_output)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNCGf1KZEpld"
      },
      "source": [
        "## **Save Checkpoint**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuNJ9x_2lGYl"
      },
      "source": [
        "corpus_sents_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DJvqmOPOcfE"
      },
      "source": [
        "corpus_sents_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjOmN2yobL9d"
      },
      "source": [
        "# Save Corpus DataFrames\n",
        " \n",
        "# save_dataframes(df_ls=['baseline','sentimentr','syuzhetr','transformer','combined','subset','everything']):\n",
        "save_dataframes(df_ls=['baseline'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDhq0IizMdp7"
      },
      "source": [
        "# corpus_sents_df.iloc[2843]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0s6LIujwDD2"
      },
      "source": [
        "# **Explore Sentiment Models and Arcs**\n",
        "\n",
        "Baseline Models\n",
        "\n",
        "* VADER [-1.0 to 1.0] zero peak\n",
        "* TextBlob [-1.0 to 1.0] zero peak\n",
        "* Stanza outliers [-1.0 to 199.0] pos, outliers(+peak)\n",
        "* AFINN [-14 (-8 to 8) 20] discrete\n",
        "* SentimentR 11,710 [-5.4 to 8.8] norm\n",
        "* Syuzhet [-5.4 to 8.8] norm\n",
        "* Bing [-100.0 (-20.0 to 20.0) 100] discrete, outliers\n",
        "* Pattern [-1.0 to 1.0] norm\n",
        "* SentiWord [-3.8 to 4.4] norm\n",
        "* SenticNet [-3.8 to 10] norm\n",
        "* NRC [-100.0 (-5.0 to 5.0) 100] zero, outliers\n",
        "\n",
        "SentimentR Models\n",
        "\n",
        "* Jockers_Rinker\n",
        "* Jockers\n",
        "* HuLiu\n",
        "* NRC\n",
        "* Loughran-McDonald\n",
        "* SenticNet\n",
        "* SentiWord\n",
        "\n",
        "SyuzhetR Models\n",
        "\n",
        "* Syuzhet\n",
        "* Bing\n",
        "* AFINN\n",
        "* NRC\n",
        "\n",
        "Tranformer Models\n",
        "\n",
        "* NLPTown\n",
        "* RoBERTa Large 15 Datasets\n",
        "* BERT Yelp Dataset\n",
        "* BERT Code Switching Hinglish\n",
        "* IMDB 2-way \n",
        "* Huggingface Default (Distilled BERT)\n",
        "* T5 IMDB 50k Dataset\n",
        "* RoBERTa XML 8 Languages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGqpjXvRwS20"
      },
      "source": [
        "## **EDA Baseline Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f91FoxP6w28t"
      },
      "source": [
        "# Create 4 Standardized versions of each Model: stdscaler, medianiqr both lnormed and not\n",
        "\n",
        "print('\\nBefore Standardization ----------')\n",
        "corpus_sents_df.columns\n",
        "\n",
        "standardize_ts_ls(corpus_sents_df, models_baseline_ls)\n",
        "\n",
        "print('\\nAfter Standardization ----------')\n",
        "corpus_sents_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_Rb2CkuLvv9"
      },
      "source": [
        "corpus_sents_df['pattern'].rolling(800, center=True).mean().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4Ddk8J8wynL"
      },
      "source": [
        "corpus_sents_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfqKmcKqDz2y"
      },
      "source": [
        "##### **Interactive LOWESS Smoothed Plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ktO5sRIDzUZ"
      },
      "source": [
        "# Sentence Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "LOWESS_frac = 0.15 #@param {type:\"slider\", min:0.01, max:0.20, step:0.01}\n",
        "\n",
        "SentimentR_Arc = True #@param {type:\"boolean\"}\n",
        "Syuzhet_Arc = True #@param {type:\"boolean\"}\n",
        "Bing_Arc = False #@param {type:\"boolean\"}\n",
        "SenticNet_Arc = True #@param {type:\"boolean\"}\n",
        "SentiWord_Arc = True #@param {type:\"boolean\"}\n",
        "NRC_Arc = True #@param {type:\"boolean\"}\n",
        "AFINN_Arc = False #@param {type:\"boolean\"}\n",
        "VADER_Arc = True #@param {type:\"boolean\"}\n",
        "TextBlob_Arc = True #@param {type:\"boolean\"}\n",
        "Flair_Arc = True #@param {type:\"boolean\"}\n",
        "Pattern_Arc = True #@param {type:\"boolean\"}\n",
        "Stanza_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_All_Arc = True #@param {type:\"boolean\"}\n",
        "# Mean_Subset_Arc = False #@param {type:\"boolean\"}\n",
        "# MPQA_Arc = False #@param {type:\"boolean\"}\n",
        "# SentiStrength_Arc = False #@param {type:\"boolean\"}\n",
        "\n",
        "models_subset_ls = []\n",
        "if SentimentR_Arc == True:\n",
        "  models_subset_ls.append('sentimentr_stdscaler')\n",
        "if Syuzhet_Arc == True:\n",
        "  models_subset_ls.append('syuzhet_stdscaler')\n",
        "if Bing_Arc == True:\n",
        "  models_subset_ls.append('bing_stdscaler')\n",
        "if SenticNet_Arc == True:\n",
        "  models_subset_ls.append('senticnet_stdscaler')\n",
        "if SentiWord_Arc == True:\n",
        "  models_subset_ls.append('sentiword_stdscaler')\n",
        "if NRC_Arc == True:\n",
        "  models_subset_ls.append('nrc_stdscaler')\n",
        "if AFINN_Arc == True:\n",
        "  models_subset_ls.append('afinn_stdscaler')\n",
        "if VADER_Arc == True:\n",
        "  models_subset_ls.append('vader_stdscaler')\n",
        "if TextBlob_Arc == True:\n",
        "  models_subset_ls.append('textblob_stdscaler')\n",
        "if Flair_Arc == True:\n",
        "  models_subset_ls.append('flair_stdscaler')\n",
        "if Pattern_Arc == True:\n",
        "  models_subset_ls.append('pattern_stdscaler')\n",
        "if Stanza_Arc == True:\n",
        "  models_subset_ls.append('stanza_stdscaler')\n",
        "# if Mean_All_Arc == True:\n",
        "#   models_subset_ls.append('mean_all')\n",
        "\n",
        "\"\"\"\n",
        "if len(str(SMA_Window_Percent)) == 1:\n",
        "  roll_str = 'roll0' + str(SMA_Window_Percent)\n",
        "else:\n",
        "  roll_str = 'roll' + str(SMA_Window_Percent%100)\n",
        "\n",
        "print(f'Rolling Window: {roll_str}')\n",
        "\"\"\";\n",
        "\n",
        "# 1192.73 - All\n",
        "\n",
        "temp_df = get_lowess(corpus_sents_df, models_ls=models_subset_ls, text_unit='sentence', afrac=LOWESS_frac);\n",
        "\n",
        "# plot_models(models_subset_ls, models_type='baseline', text_unit='sent_no', win_per=SMA_Window_Percent)\n",
        "temp_df['minmax_diff'] = temp_df.max(axis=1) - temp_df.min(axis=1)\n",
        "print(f\"Sum of minmax_diff: {temp_df['minmax_diff'].sum()}\");\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC6FQTWiSt3Z"
      },
      "source": [
        "##### **Grid Search LOWESS frac**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI_FMNKIcqXs"
      },
      "source": [
        "temp_df['avg_stdscaler'] = corpus_sents_df[models_subset_ls].mean()\n",
        "temp_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkw3hBeMR9h3"
      },
      "source": [
        "Frac_Start = 0.08 #@param {type:\"slider\", min:0.01, max:0.3, step:0.01}\n",
        "Frac_End = 0.2 #@param {type:\"slider\", min:0.01, max:0.2, step:0.01}\n",
        "Frac_Step = 0.02 #@param {type:\"slider\", min:0.01, max:0.05, step:0.01}\n",
        "\n",
        "frac_start_int = int(100*Frac_Start)\n",
        "frac_end_int = int(100*Frac_End) + 1\n",
        "frac_step_int = int(100*Frac_Step)\n",
        "\n",
        "print('GRID SEARCH --------------------\\n')\n",
        "\n",
        "lowess_grid_dt = {}\n",
        "crux_ct_ls = []\n",
        "# temp_df['sent_no'] = pd.Series([x for x in corpus_sents_df['sent_no']])\n",
        "temp_df['avg_stdscaler'] = corpus_sents_df[models_subset_ls].mean()\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "\n",
        "\n",
        "for afrac in range(frac_start_int, frac_end_int, frac_step_int):\n",
        "  print(f'Processing afrac = {afrac}')\n",
        "  # Compute error between subset of models\n",
        "  afrac_fl = afrac/100\n",
        "  temp_df = get_lowess(corpus_sents_df, models_ls=models_subset_ls, text_unit='sentence', afrac=afrac_fl, do_plot=False);\n",
        "  temp_df['minmax_diff'] = temp_df.max(axis=1) - temp_df.min(axis=1)\n",
        "  diff_sum = temp_df['minmax_diff'].sum()\n",
        "  print(f\"  Sum(minmax_diff): {diff_sum}\");\n",
        "  lowess_grid_dt[afrac] = diff_sum\n",
        "  # Compute Crux Points\n",
        "  temp_df['sent_no'] = pd.Series(list(range(temp_df.shape[0])))\n",
        "  crux_ls = get_crux_points(temp_df,\n",
        "                            'median',\n",
        "                            text_type='sentence', \n",
        "                            win_per=5, \n",
        "                            sec_y_labels=False, \n",
        "                            sec_y_height=0, \n",
        "                            subtitle_str=' ', \n",
        "                            do_plot=False,\n",
        "                            save2file=False)\n",
        "  ax.plot(temp_df['sent_no'], temp_df['median'], label=f'frac={afrac}')\n",
        "  # plt.plot(data=temp_df, x='sent_no', y='median', label=f'frac={afrac}')\n",
        "  crux_ct_ls.append(len(crux_ls))\n",
        "  print(f'  {len(crux_ls)} Crux Points')\n",
        "\n",
        "plt.title(f\"{CORPUS_FULL} \\n LOWESS Smoothing Grid Search (frac={Frac_Start} to {Frac_End}\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm1ywpfuQJWA"
      },
      "source": [
        "# Plot Declining Error as a function of LOWESS frac\n",
        "\n",
        "# lowess_grid_dt\n",
        "\n",
        "lists = sorted(lowess_grid_dt.items()) # sorted by key, return a list of tuples\n",
        "\n",
        "x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
        "# plt.plot(x, y, label='Interplot Error')\n",
        "\n",
        "adj_factor = 40\n",
        "crux_ct_adj_ls = [adj_factor * x for x in crux_ct_ls]\n",
        "\n",
        "# create figure and axis objects with subplots()\n",
        "fig,ax = plt.subplots()\n",
        "# make first plot: Error\n",
        "ax.plot(x, y, color=\"red\", label='Coherence Error', marker=\"o\")\n",
        "# set x-axis label\n",
        "ax.set_xlabel(\"LOWESS frac Hyperparemeter\",fontsize=14)\n",
        "# set y-axis label\n",
        "ax.set_ylabel(\"Coherence Error\",color=\"red\",fontsize=14)\n",
        "\n",
        "# twin object for two different y-axis on the sample plot\n",
        "ax2=ax.twinx()\n",
        "\n",
        "# make second plot: Crux Count, with different y-axis using second axis object\n",
        "ax2.plot(x, crux_ct_ls,color=\"blue\",label='Crux Count', marker=\"o\")\n",
        "ax2.set_ylabel(\"Crux Count\",color=\"blue\",fontsize=14)\n",
        "plt.title(f'{CORPUS_FULL} Sentence Sentiment \\n Grid Search for LOWESS [frac] Hyperparemeter')\n",
        "plt.legend(loc='best')\n",
        "plt.show();\n",
        "\"\"\"\n",
        "# save the plot as a file\n",
        "fig.savefig('two_different_y_axis_for_single_python_plot_with_twinx.jpg',\n",
        "            format='jpeg',\n",
        "            dpi=100,\n",
        "            bbox_inches='tight')\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9stl4BAQUn5Q"
      },
      "source": [
        "##### **Autmatic Sentence SMA Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjUvHqm1KTa7"
      },
      "source": [
        "corpus_sents_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uMTLx9Qej22"
      },
      "source": [
        "corpus_sents_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8gYxSS0GRWk"
      },
      "source": [
        "# Create SMA roll=10% for all models_stdscaler as baseline\n",
        "\n",
        "win_s1per = int(corpus_sents_df.shape[0] * 1/100)\n",
        "\n",
        "col_stdscaler_roll_ls = []\n",
        "for amodel in models_baseline_ls:\n",
        "  col_stdscaler = f'{amodel}_stdscaler'\n",
        "  col_stdscaler_roll = f'{amodel}_stdscaler_{roll_str}'\n",
        "  corpus_sents_df[col_stdscaler_roll] = corpus_sents_df[col_stdscaler].rolling(10*win_s1per, center=True).mean()\n",
        "  col_stdscaler_roll_ls.append(col_stdscaler_roll)\n",
        "\n",
        "col_stdscaler_roll_mean = col_stdscaler_roll + '_mean'\n",
        "corpus_sents_df[col_stdscaler_roll_mean] = corpus_sents_df[col_stdscaler_roll_ls].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFLneZYefJ6W"
      },
      "source": [
        "col_stdscaler_roll_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZYRLVQYH6__"
      },
      "source": [
        "corpus_sents_df[col_stdscaler_roll_ls].plot()\n",
        "# corpus_sents_df['sentimentr_stdscaler_roll10'].plot()\n",
        "plt.title(f'{CORPUS_FULL} Sentence Sentiment \\n Baseline 12 Models StdScaler SMA 10%');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJJNNaxR0iJ0"
      },
      "source": [
        "##### **Interactive Sentence SMA Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqmU4QRLOClI"
      },
      "source": [
        "# Sentence Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "SentimentR_Arc = True #@param {type:\"boolean\"}\n",
        "Syuzhet_Arc = True #@param {type:\"boolean\"}\n",
        "Bing_Arc = True #@param {type:\"boolean\"}\n",
        "SenticNet_Arc = True #@param {type:\"boolean\"}\n",
        "SentiWord_Arc = True #@param {type:\"boolean\"}\n",
        "NRC_Arc = True #@param {type:\"boolean\"}\n",
        "AFINN_Arc = True #@param {type:\"boolean\"}\n",
        "VADER_Arc = True #@param {type:\"boolean\"}\n",
        "TextBlob_Arc = True #@param {type:\"boolean\"}\n",
        "Flair_Arc = True #@param {type:\"boolean\"}\n",
        "Pattern_Arc = False #@param {type:\"boolean\"}\n",
        "Stanza_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_All_Arc = True #@param {type:\"boolean\"}\n",
        "# Mean_Subset_Arc = False #@param {type:\"boolean\"}\n",
        "# MPQA_Arc = False #@param {type:\"boolean\"}\n",
        "# SentiStrength_Arc = False #@param {type:\"boolean\"}\n",
        "\n",
        "models_subset_ls = []\n",
        "if SentimentR_Arc == True:\n",
        "  models_subset_ls.append('sentimentr')\n",
        "if Syuzhet_Arc == True:\n",
        "  models_subset_ls.append('syuzhet')\n",
        "if Bing_Arc == True:\n",
        "  models_subset_ls.append('bing')\n",
        "if SenticNet_Arc == True:\n",
        "  models_subset_ls.append('senticnet')\n",
        "if SentiWord_Arc == True:\n",
        "  models_subset_ls.append('sentiword')\n",
        "if NRC_Arc == True:\n",
        "  models_subset_ls.append('nrc')\n",
        "if AFINN_Arc == True:\n",
        "  models_subset_ls.append('afinn')\n",
        "if VADER_Arc == True:\n",
        "  models_subset_ls.append('vader')\n",
        "if TextBlob_Arc == True:\n",
        "  models_subset_ls.append('textblob')\n",
        "if Flair_Arc == True:\n",
        "  models_subset_ls.append('flair')\n",
        "if Pattern_Arc == True:\n",
        "  models_subset_ls.append('pattern')\n",
        "if Stanza_Arc == True:\n",
        "  models_subset_ls.append('stanza')\n",
        "if Mean_All_Arc == True:\n",
        "  models_subset_ls.append('mean_all')\n",
        "\n",
        "if len(str(SMA_Window_Percent)) == 1:\n",
        "  roll_str = 'roll0' + str(SMA_Window_Percent)\n",
        "else:\n",
        "  roll_str = 'roll' + str(SMA_Window_Percent%100)\n",
        "\n",
        "print(f'Rolling Window: {roll_str}')\n",
        "\n",
        "plot_models(models_subset_ls, models_type='baseline', text_unit='sent_no', win_per=SMA_Window_Percent)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bafsX4zKd-wT"
      },
      "source": [
        "##### **(ABOVE) Plotly SMA Sentence, (BELOW) Correlation Heatmap**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxRGGdcgHj2S"
      },
      "source": [
        "# Sentence Heatmap Correlation of StdScaler Roll100 Sentiments\n",
        "# Depends on 'col_stdscaler_rollwin_ls' defined in prior code cell\n",
        "\n",
        "Correlation_Algo = \"spearman\" #@param [\"pearson\", \"spearman\", \"kendall\"]\n",
        "# corr_methods_ls = ['pearson', 'spearman', 'kendall']\n",
        "\n",
        "col_stdscaler_rollwin_ls = []\n",
        "for amodel in models_baseline_ls:\n",
        "  col_amodel_stdscaler_rollwin = f'{amodel}_stdscaler_{roll_str}'\n",
        "  col_stdscaler_rollwin_ls.append(col_amodel_stdscaler_rollwin)\n",
        "print(f'DEFAULT Models:\\n\\n    col_stdscaler_rollwin_ls: {col_stdscaler_rollwin_ls}')\n",
        "\n",
        "# OPTIONAL EDIT: Manually select problematic model to remove from analysis \n",
        "#                (e.g. Pattern can misbehave at times)\n",
        "model_root_bad = 'pattern'\n",
        "# model_root_bad = ''\n",
        "col_stdscaler_rollwin_ls = [x for x in col_stdscaler_rollwin_ls if model_root_bad not in x]\n",
        "\n",
        "print(f'MODIFED Models:\\n\\n    col_stdscaler_rollwin_ls: {col_stdscaler_rollwin_ls}')\n",
        "\n",
        "corr_df = corpus_sents_df[col_stdscaler_rollwin_ls].dropna(axis=0, how='any').corr(method=Correlation_Algo)\n",
        "\n",
        "# Customize the heatmap of the corr_meat correlation matrix and rotate the x-axis labels\n",
        "fig = sns.clustermap(corr_df, # corpus_sents_df[col_stdscaler_rollwin_ls].dropna(axis=0, how='any').corr(method=corr_method),\n",
        "                    row_cluster=True,\n",
        "                    col_cluster=True,\n",
        "                    figsize=(10, 10))\n",
        "\n",
        "\n",
        "plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n",
        "plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
        "plt.title(f'{CORPUS_FULL} Sentence Sentiment for Baseline Model Sentiments\\n {Correlation_Algo.capitalize()} Correlation - StdScale Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxfultUPZr-J"
      },
      "source": [
        "##### **Sentence Sentiment DTW Hierarichal Clustering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1rU88PlFkss"
      },
      "source": [
        "# Dynamic Time Series Clustering\n",
        "\n",
        "# !pip install dtaidistance[all]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44Hys86nFkox"
      },
      "source": [
        "# from dtaidistance import dtw\n",
        "# from dtaidistance import dtw_visualisation as dtwvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMq5XOXTFkjL"
      },
      "source": [
        "\"\"\"\n",
        "s1 = np.array([0., 0, 1, 2, 1, 0, 1, 0, 0, 2, 1, 0, 0])\n",
        "s2 = np.array([0., 1, 2, 3, 1, 0, 0, 0, 2, 1, 0, 0, 0])\n",
        "path = dtw.warping_path(s1, s2)\n",
        "dtwvis.plot_warping(s1, s2, path, filename=\"warp.png\")\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mra_zDRSF0LN"
      },
      "source": [
        "\"\"\"\n",
        "from dtaidistance import dtw\n",
        "import numpy as np\n",
        "\n",
        "series = np.matrix([\n",
        "    [0.0, 0, 1, 2, 1, 0, 1, 0, 0],\n",
        "    [0.0, 1, 2, 0, 0, 0, 0, 0, 0],\n",
        "    [0.0, 0, 1, 2, 1, 0, 0, 0, 0]])\n",
        "ds = dtw.distance_matrix_fast(series)\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wycvgBTtvJYY"
      },
      "source": [
        "##### **Top-n Crux Peaks and Valleys**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8QX8tSKM376"
      },
      "source": [
        "**Search Corpus for Substring**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* In [Search_for_Substring] enter a Substring to search for in the Corpus\n",
        "\n",
        "* Enter a Substring long enough/unique enough so only a reasonable number of Sentences will be returned\n",
        "\n",
        "* Substring can contain spaces/punctuation, for example: 'in the garden'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJYjOu9Ks_pL"
      },
      "source": [
        "# Search Corpus Sentences for Substring\n",
        "\n",
        "Search_for_Substring = \"abuse\" #@param {type:\"string\"}\n",
        "\n",
        "sentno_matching_ls = corpus_sents_df[corpus_sents_df['sent_raw'].str.contains(Search_for_Substring, regex=False)]['sent_no']\n",
        "\n",
        "for i, asentno in enumerate(sentno_matching_ls):\n",
        "  # sentno, sentraw = asent\n",
        "  print(f\"\\n\\nMatch #{i}: Sentence #{asentno}\\n\\n\")\n",
        "  sent_highlight = re.sub(Search_for_Substring, Search_for_Substring.upper(), corpus_sents_df.iloc[asentno]['sent_raw'])\n",
        "  print(f'    {sent_highlight}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap_K_gpH0FTm"
      },
      "source": [
        "**Plot Top-n Crux Peaks/Valleys for selected Model**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Crux_Window_Percent] exclusive zone around Crux Points as a percentage of Corpus length\n",
        "\n",
        "* [Sentiment_Model] Select a Sentiment Analysis model\n",
        "\n",
        "* Select [Anomaly_Detction] to plot raw Sentiment values to detect outlier/anomaly Sentences. Leave unchecked to plot SMA smoothed Sentiment arc and detect Crux points\n",
        "\n",
        "* Select [Save_to_File] to also save plot to external *.png file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHPx5a0xvJYb"
      },
      "source": [
        "Crux_Window_Percent = 5 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "Baseline_SMA_Model = \"SentiWord\" #@param [\"SentimentR\", \"SyuzhetR\", \"Bing\", \"SenticNet\", \"SentiWord\", \"NRC\", \"AFINN\", \"VADER\", \"TextBlob\", \"Flair\", \"Pattern\", \"Stanza\"]\n",
        "Anomaly_Detection = False #@param {type:\"boolean\"}\n",
        "Vertical_Labels = True #@param {type:\"boolean\"}\n",
        "Vertical_Labels_Height = -0.1 #@param {type:\"slider\", min:-50, max:50, step:0.1}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "if Baseline_SMA_Model == 'SentimentR':\n",
        "  model_selected = f'sentimentr'\n",
        "if Baseline_SMA_Model == 'SyuzhetR':\n",
        "  model_selected = f'syuzhet'\n",
        "if Baseline_SMA_Model == 'Bing':\n",
        "  model_selected = f'bing'\n",
        "if Baseline_SMA_Model == 'SenticNet':\n",
        "  model_selected = f'senticnet'\n",
        "if Baseline_SMA_Model == 'SentiWord':\n",
        "  model_selected = f'sentiword'\n",
        "if Baseline_SMA_Model == 'NRC':\n",
        "  model_selected = f'nrc'\n",
        "if Baseline_SMA_Model == 'AFINN':\n",
        "  model_selected = f'afinn'\n",
        "if Baseline_SMA_Model == 'VADER':\n",
        "  model_selected = f'vader'\n",
        "if Baseline_SMA_Model == 'TextBlob':\n",
        "  model_selected = f'textblob'\n",
        "if Baseline_SMA_Model == 'Flair':\n",
        "  model_selected = f'flair'\n",
        "if Baseline_SMA_Model == 'Pattern':\n",
        "  model_selected = f'pattern'\n",
        "if Baseline_SMA_Model == 'Stanza':\n",
        "  model_selected = f'stanza'\n",
        "\n",
        "if Anomaly_Detection == False:\n",
        "  # (a) Use Sentence SMA smoothed Sentiment models to detect Crux Points\n",
        "  model_selected_fullname = f'{model_selected}_stdscaler_{roll_str}'\n",
        "else:\n",
        "  # (b)Use Sentence Raw Sentiment models to detect outliers\n",
        "  model_selected_fullname = f'{model_selected}'\n",
        "\n",
        "\n",
        "# TODO: enable multiple overlay crux points with underlying mean/median arc\n",
        "corpus_models_selected_ls = [model_selected_fullname]\n",
        "\n",
        "# Warning: requires definitions of: x, section_sents_df\n",
        "#          so Baseline models must be run first\n",
        "\n",
        "for amodel in corpus_models_selected_ls:\n",
        "  corpus_cruxes_all_dt[amodel] = get_crux_points(ts_df=corpus_sents_df, \n",
        "                                         col_series=corpus_models_selected_ls, \n",
        "                                         text_type='sentence', \n",
        "                                         win_per=Crux_Window_Percent, \n",
        "                                         sec_y_labels=Vertical_Labels,\n",
        "                                         sec_y_height=Vertical_Labels_Height, \n",
        "                                         subtitle_str= '5% Crux ', \n",
        "                                         do_plot=True, \n",
        "                                         save2file=False);\n",
        "  \n",
        "model_crux_ls = corpus_cruxes_all_dt[amodel]\n",
        "# model_crux_ls;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6PU1zR8vJYf"
      },
      "source": [
        "### **Context around Top-n Crux Peaks/Valleys**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Get_Peak_Cruxes] to retrieve Peaks (if unchecked Valleys are retrieved)\n",
        "\n",
        "* [Get_n_Cruxes] determines how many Top-n Cruxes to retrieve\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUoJz_nyvJYh"
      },
      "source": [
        "# Crux Point Details\n",
        "Get_Peak_Cruxes = False #@param {type:\"boolean\"}\n",
        "Get_n_Cruxes = 20 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "Sort_by_SentenceNo = True #@param {type:\"boolean\"}\n",
        "\n",
        "# Context Details\n",
        "No_Paragraphs_on_Each_Side = 2 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "Highlight_Sentence = True #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "if Sort_by_SentenceNo == True:\n",
        "  sort_on = 'sent_no'\n",
        "else:\n",
        "  sort_on = 'sentiment_val'\n",
        "\n",
        "\n",
        "print(f'Crux Report --------------------\\n')\n",
        "print(f'            Corpus: {CORPUS_FULL}')\n",
        "print(f'            Model: {Baseline_SMA_Model}')\n",
        "print(f'            Crux Win%: {Crux_Window_Percent}')\n",
        "print(f'            SMA Win%: {roll_str}')\n",
        "\n",
        "if Save_to_Report == False:\n",
        "  crux_sortsents_report(model_crux_ls, \n",
        "                        ts_df = corpus_sents_df,\n",
        "                        library_type='baseline', \n",
        "                        top_n=Get_n_Cruxes, \n",
        "                        get_peaks=Get_Peak_Cruxes,\n",
        "                        sort_by = sort_on, # sent_no, or abs(polarity)\n",
        "                        n_sideparags=No_Paragraphs_on_Each_Side,\n",
        "                        sentence_highlight=Highlight_Sentence)\n",
        "else:\n",
        "  # import sys\n",
        "  # with open('filename.txt', 'w') as f:\n",
        "  #   print('This message will be written to a file.', file=f)\n",
        "  # https://www.kite.com/python/answers/how-to-get-stdout-and-stderr-from-a-process-as-a-string-in-python\n",
        "  # process = subprocess.run([\"echo\", \"This goes to stdout\"], capture_output=True)\n",
        "  # stdout_as_str = process.stdout.decode(\"utf-8\")\n",
        "  # print(stdout_as_str)\n",
        "  temp_out = StringIO()\n",
        "  sys.stdout = temp_out\n",
        "  crux_sortsents_report(model_crux_ls, top_n=Get_n_Cruxes, get_peaks=Get_Peak_Cruxes, n_sideparags=No_Paragraphs_on_Each_Side)\n",
        "  print(temp_out)\n",
        "  # attempt to save temp_out to generated filename\n",
        "  sys.stdout = sys.__stdout__\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJlFM5kFJDdA"
      },
      "source": [
        "asent_no = 124\n",
        "corpus_df = corpus_sents_df\n",
        "asent_raw = str(corpus_df[corpus_df['sent_no'] == int(asent_no)]['sent_raw'].values[0])\n",
        "asent_raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-XtE7xovJYj"
      },
      "source": [
        "**Zoom in on Context surrounding a particular Crux Point**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Enter [Crux_Sentence_No] that matches a Crux point/Sentence No you want to explore\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1By1LTGvJYk"
      },
      "source": [
        "# Select details about the Crux Point Context to Retrieve\n",
        "\n",
        "# print(f'Last Sentence No: {corpus_sents_df.shape[0]}')\n",
        "Crux_Sentence_No =  200#@param {type:\"number\"}\n",
        "No_Paragraphs_on_Each_Side = 4 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "Highlight_Crux_Sentence = True #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "corpus_sents_len = corpus_sents_df.shape[0]\n",
        "\n",
        "# if (Crux_Sentence_No >= No_Paragraphs_on_Each_Side) & (Crux_Sentence_No+No_Paragraphs_on_Each_Side <= corpus_parag_len):\n",
        "# get_sentnocontext_report()\n",
        "# try:\n",
        "\n",
        "# get_sentnocontext_report(ts_df = corpus_sents_df, the_sent_no=7, the_n_sideparags=1, the_sent_highlight=True):\n",
        "get_sentnocontext_report(ts_df=corpus_sents_df, the_sent_no=Crux_Sentence_No, the_n_sideparags=No_Paragraphs_on_Each_Side, the_sent_highlight=Highlight_Crux_Sentence)\n",
        "\n",
        "# except:\n",
        "#   print('ERROR')\n",
        "# else:\n",
        "#   print(f'ERROR: The combination of your [Crux_Sentence_No] and [No_Pargraphs_on_Each_Side]\\n       results in a window outside the range of the Corpus Paragraphs.\\n\\n       Try again with different values.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmXIEIpY3jrX"
      },
      "source": [
        "### **Select Interactive Sentence Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTD3VvWj3jrY"
      },
      "source": [
        "# Multiple Sentence Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "SentimentR_Arc = True #@param {type:\"boolean\"}\n",
        "Syuzhet_Arc = False #@param {type:\"boolean\"}\n",
        "Bing_Arc = False #@param {type:\"boolean\"}\n",
        "SenticNet_Arc = False #@param {type:\"boolean\"}\n",
        "SentiWord_Arc = True #@param {type:\"boolean\"}\n",
        "NRC_Arc = False #@param {type:\"boolean\"}\n",
        "AFINN_Arc = False #@param {type:\"boolean\"}\n",
        "VADER_Arc = True #@param {type:\"boolean\"}\n",
        "TextBlob_Arc = True #@param {type:\"boolean\"}\n",
        "Flair_Arc = True #@param {type:\"boolean\"}\n",
        "Pattern_Arc = True #@param {type:\"boolean\"}\n",
        "Stanza_Arc = False #@param {type:\"boolean\"}\n",
        "Mean_All_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_Subset_Arc = False #@param {type:\"boolean\"}\n",
        "# MPQA_Arc = False #@param {type:\"boolean\"}\n",
        "# SentiStrength_Arc = False #@param {type:\"boolean\"}\n",
        "\n",
        "models_subset_ls = []\n",
        "if SentimentR_Arc == True:\n",
        "  models_subset_ls.append('sentimentr')\n",
        "if Syuzhet_Arc == True:\n",
        "  models_subset_ls.append('syuzhet')\n",
        "if Bing_Arc == True:\n",
        "  models_subset_ls.append('bing')\n",
        "if SenticNet_Arc == True:\n",
        "  models_subset_ls.append('senticnet')\n",
        "if SentiWord_Arc == True:\n",
        "  models_subset_ls.append('sentiword')\n",
        "if NRC_Arc == True:\n",
        "  models_subset_ls.append('nrc')\n",
        "if AFINN_Arc == True:\n",
        "  models_subset_ls.append('afinn')\n",
        "if VADER_Arc == True:\n",
        "  models_subset_ls.append('vader')\n",
        "if TextBlob_Arc == True:\n",
        "  models_subset_ls.append('textblob')\n",
        "if Flair_Arc == True:\n",
        "  models_subset_ls.append('flair')\n",
        "if Pattern_Arc == True:\n",
        "  models_subset_ls.append('pattern')\n",
        "if Stanza_Arc == True:\n",
        "  models_subset_ls.append('stanza')\n",
        "if Mean_All_Arc == True:\n",
        "  models_subset_ls.append('mean_all')\n",
        "\n",
        "plot_models(models_subset_ls, models_type='baseline', text_unit='sent_no', win_per=SMA_Window_Percent)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84HximpOla3K"
      },
      "source": [
        "### **END WORKING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuvAAR2x0x1B"
      },
      "source": [
        "##### **Selected Paragraph Interactive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhh0wT5yGaa0"
      },
      "source": [
        "# Paragraph Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "SentimentR_Arc = True #@param {type:\"boolean\"}\n",
        "Syuzhet_Arc = False #@param {type:\"boolean\"}\n",
        "Bing_Arc = False #@param {type:\"boolean\"}\n",
        "SenticNet_Arc = False #@param {type:\"boolean\"}\n",
        "SentiWord_Arc = True #@param {type:\"boolean\"}\n",
        "NRC_Arc = False #@param {type:\"boolean\"}\n",
        "AFINN_Arc = False #@param {type:\"boolean\"}\n",
        "VADER_Arc = True #@param {type:\"boolean\"}\n",
        "TextBlob_Arc = True #@param {type:\"boolean\"}\n",
        "Flair_Arc = True #@param {type:\"boolean\"}\n",
        "Pattern_Arc = True #@param {type:\"boolean\"}\n",
        "Stanza_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_All_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_Subset_Arc = False #@param {type:\"boolean\"}\n",
        "MPQA_Arc = False #@param {type:\"boolean\"}\n",
        "SentiStrength_Arc = False #@param {type:\"boolean\"}\n",
        "\n",
        "models_subset_ls = []\n",
        "if SentimentR_Arc == True:\n",
        "  models_subset_ls.append('sentimentr')\n",
        "if Syuzhet_Arc == True:\n",
        "  models_subset_ls.append('syuzhet')\n",
        "if Bing_Arc == True:\n",
        "  models_subset_ls.append('bing')\n",
        "if SenticNet_Arc == True:\n",
        "  models_subset_ls.append('senticnet')\n",
        "if SentiWord_Arc == True:\n",
        "  models_subset_ls.append('sentiword')\n",
        "if NRC_Arc == True:\n",
        "  models_subset_ls.append('nrc')\n",
        "if AFINN_Arc == True:\n",
        "  models_subset_ls.append('afinn')\n",
        "if VADER_Arc == True:\n",
        "  models_subset_ls.append('vader')\n",
        "if TextBlob_Arc == True:\n",
        "  models_subset_ls.append('textblob')\n",
        "if Flair_Arc == True:\n",
        "  models_subset_ls.append('flair')\n",
        "if Pattern_Arc == True:\n",
        "  models_subset_ls.append('pattern')\n",
        "if Stanza_Arc == True:\n",
        "  models_subset_ls.append('stanza')\n",
        "if Mean_All_Arc == True:\n",
        "  models_subset_ls.append('mean_all')\n",
        "\n",
        "plot_models(models_subset_ls, models_type='baseline', text_unit='parag_no', win_per=SMA_Window_Percent)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYt6fgEsapFj"
      },
      "source": [
        "##### **Selected Section Interactive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "culyTw0tapFk"
      },
      "source": [
        "# Paragraph Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "SentimentR_Arc = False #@param {type:\"boolean\"}\n",
        "Syuzhet_Arc = True #@param {type:\"boolean\"}\n",
        "Bing_Arc = False #@param {type:\"boolean\"}\n",
        "SenticNet_Arc = False #@param {type:\"boolean\"}\n",
        "SentiWord_Arc = False #@param {type:\"boolean\"}\n",
        "NRC_Arc = False #@param {type:\"boolean\"}\n",
        "AFINN_Arc = False #@param {type:\"boolean\"}\n",
        "VADER_Arc = True #@param {type:\"boolean\"}\n",
        "TextBlob_Arc = True #@param {type:\"boolean\"}\n",
        "Flair_Arc = True #@param {type:\"boolean\"}\n",
        "Pattern_Arc = True #@param {type:\"boolean\"}\n",
        "Stanza_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_All_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_Subset_Arc = False #@param {type:\"boolean\"}\n",
        "MPQA_Arc = False #@param {type:\"boolean\"}\n",
        "SentiStrength_Arc = False #@param {type:\"boolean\"}\n",
        "\n",
        "models_subset_ls = []\n",
        "if SentimentR_Arc == True:\n",
        "  models_subset_ls.append('sentimentr')\n",
        "if Syuzhet_Arc == True:\n",
        "  models_subset_ls.append('syuzhet')\n",
        "if Bing_Arc == True:\n",
        "  models_subset_ls.append('bing')\n",
        "if SenticNet_Arc == True:\n",
        "  models_subset_ls.append('senticnet')\n",
        "if SentiWord_Arc == True:\n",
        "  models_subset_ls.append('sentiword')\n",
        "if NRC_Arc == True:\n",
        "  models_subset_ls.append('nrc')\n",
        "if AFINN_Arc == True:\n",
        "  models_subset_ls.append('afinn')\n",
        "if VADER_Arc == True:\n",
        "  models_subset_ls.append('vader')\n",
        "if TextBlob_Arc == True:\n",
        "  models_subset_ls.append('textblob')\n",
        "if Flair_Arc == True:\n",
        "  models_subset_ls.append('flair')\n",
        "if Pattern_Arc == True:\n",
        "  models_subset_ls.append('pattern')\n",
        "if Stanza_Arc == True:\n",
        "  models_subset_ls.append('stanza')\n",
        "if Mean_All_Arc == True:\n",
        "  models_subset_ls.append('mean_all')\n",
        "\n",
        "plot_models(models_subset_ls, models_type='baseline', text_unit='sect_no', win_per=SMA_Window_Percent)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRt69D1Zbem0"
      },
      "source": [
        "##### **Chapter SMA Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjlr8LEybem0"
      },
      "source": [
        "# Paragraph Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "SentimentR_Arc = False #@param {type:\"boolean\"}\n",
        "Syuzhet_Arc = True #@param {type:\"boolean\"}\n",
        "Bing_Arc = False #@param {type:\"boolean\"}\n",
        "SenticNet_Arc = False #@param {type:\"boolean\"}\n",
        "SentiWord_Arc = False #@param {type:\"boolean\"}\n",
        "NRC_Arc = False #@param {type:\"boolean\"}\n",
        "AFINN_Arc = False #@param {type:\"boolean\"}\n",
        "VADER_Arc = True #@param {type:\"boolean\"}\n",
        "TextBlob_Arc = True #@param {type:\"boolean\"}\n",
        "Flair_Arc = True #@param {type:\"boolean\"}\n",
        "Pattern_Arc = True #@param {type:\"boolean\"}\n",
        "Stanza_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_All_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_Subset_Arc = False #@param {type:\"boolean\"}\n",
        "MPQA_Arc = False #@param {type:\"boolean\"}\n",
        "SentiStrength_Arc = False #@param {type:\"boolean\"}\n",
        "\n",
        "models_subset_ls = []\n",
        "if SentimentR_Arc == True:\n",
        "  models_subset_ls.append('sentimentr')\n",
        "if Syuzhet_Arc == True:\n",
        "  models_subset_ls.append('syuzhet')\n",
        "if Bing_Arc == True:\n",
        "  models_subset_ls.append('bing')\n",
        "if SenticNet_Arc == True:\n",
        "  models_subset_ls.append('senticnet')\n",
        "if SentiWord_Arc == True:\n",
        "  models_subset_ls.append('sentiword')\n",
        "if NRC_Arc == True:\n",
        "  models_subset_ls.append('nrc')\n",
        "if AFINN_Arc == True:\n",
        "  models_subset_ls.append('afinn')\n",
        "if VADER_Arc == True:\n",
        "  models_subset_ls.append('vader')\n",
        "if TextBlob_Arc == True:\n",
        "  models_subset_ls.append('textblob')\n",
        "if Flair_Arc == True:\n",
        "  models_subset_ls.append('flair')\n",
        "if Pattern_Arc == True:\n",
        "  models_subset_ls.append('pattern')\n",
        "if Stanza_Arc == True:\n",
        "  models_subset_ls.append('stanza')\n",
        "if Mean_All_Arc == True:\n",
        "  models_subset_ls.append('mean_all')\n",
        "\n",
        "plot_models(models_subset_ls, models_type='baseline', text_unit='chap_no', win_per=SMA_Window_Percent)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TszUw6HFQ6lU"
      },
      "source": [
        "##### **Comparison of Sentence Baseline Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSNxgw5TjU8L"
      },
      "source": [
        "# Compare Sentence Baseline Length-Normed Standardized Sentiment Values\n",
        "\n",
        "\"\"\"\n",
        "model_baselines_ls = ['sentimentr', 'syuzhet', 'bing',\n",
        "                  'sentiword', 'senticnet', 'nrc',\n",
        "                  'afinn', 'vader', 'textblob',\n",
        "                  'flair', 'pattern', 'stanza']\n",
        "\"\"\";\n",
        "\n",
        "\"\"\"\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# col_roll_ls = []\n",
        "model_base_standardized_roll_ls = []\n",
        "for amodel in model_baselines_ls:\n",
        "  # Create the simple model_rollxxx rolling mean\n",
        "  col_roll = f'{amodel}_{roll_str}'\n",
        "  corpus_sents_df['col_roll'] = corpus_sents_df[amodel].rolling(10*win_s1per, center=True).mean()\n",
        "\n",
        "  # Create list of column names for model_lnorm_medianiqr_rollxxx\n",
        "  # col_name = f'{amodel}_lnorm_medianiqr_{roll_str}'  # TODO: drop lnorm_medianiqr earlier and just Standardize here                                                   # NOTE: Simple SciPy StandardScaler works on SMA Series that don't have outliers like Raw Series\n",
        "  col_name = f'{amodel}_{roll_str}'  # TODO: drop lnorm_medianiqr earlier and just Standardize here                                                   # NOTE: Simple SciPy StandardScaler works on SMA Series that don't have outliers like Raw Series\n",
        "  # print(f'col_name: {col_name}')\n",
        "  model_base_standardized_roll_ls.append(col_name)\n",
        "\n",
        "  # for i,amodel in enumerate(model_base_standardized_roll_ls):\n",
        "\n",
        "  col_name_roll_stand = f'{col_roll}_stdscale'\n",
        "  # print(f'col_name_roll_stand: {col_name_roll_stand}')\n",
        "  model_roll_stand_np = np.array(corpus_sents_df[col_roll])\n",
        "  # .apply(lambda x: Scale_SentimentR*x))\n",
        "  \n",
        "  model_roll_stand_np = model_roll_stand_np.reshape((len(model_roll_stand_np), 1))\n",
        "\n",
        "  scaler = scaler.fit(model_roll_stand_np)\n",
        "  print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, np.sqrt(scaler.var_)))\n",
        "  model_roll_stand_xform_np = scaler.transform(model_roll_stand_np)\n",
        "\n",
        "  corpus_sents_df[col_name_roll_stand] = pd.Series(model_roll_stand_xform_np.flatten())\n",
        "\n",
        "  # Plot\n",
        "  corpus_sents_df[col_name_roll_stand].plot(label=amodel) # label=col_name_roll_stand))\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Sentences for Baseline Model Sentiments\\nMean StdScale Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YsG5H1xway0"
      },
      "source": [
        "## **EDA SentimentR Plots**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id_VKOPiR7Mg"
      },
      "source": [
        "#### **(If not already exists) Import SentimentR Sentiment Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTPbrXDM0Gm1"
      },
      "source": [
        "# Verify SentimentR Sentiment Files exported from RStudio\n",
        "!pwd\n",
        "!ls -altr *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wlizkrlv-y1l"
      },
      "source": [
        "!mv sum_sentiments_syuzhetR_4models_sentimenttimeraw_emforster_howardsend.csv sum_sentiments_syuzhetR_4models_emforster_howardsend.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlONG-ZwuuVb"
      },
      "source": [
        "# Get SentimentR Sentiment Datafile (with data on 7 Models)\n",
        "\n",
        "SentimentR_sentiment_datafile = 'sum_sentiments_sentimentR_7models_emforster_howardsend.csv' #@param {type:\"string\"}\n",
        "\n",
        "sum_sentiments_sentimentr_filename = SentimentR_sentiment_datafile\n",
        "\n",
        "!head -n 3 $sum_sentiments_sentimentr_filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7jOvdLrIkSm"
      },
      "source": [
        "corpus_sentimentr_df = pd.read_csv(sum_sentiments_sentimentr_filename)\n",
        "corpus_sentimentr_df.head(2)\n",
        "corpus_sentimentr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_fV4UKUJTdS"
      },
      "source": [
        "# corpus_sents_df = corpus_sents_df.loc[:, ~corpus_sents_df.columns.str.contains('^Unnamed')]\n",
        "\n",
        "corpus_sentimentr_df.rename(columns={'Unnamed: 0':'sent_no'}, inplace=True)\n",
        "corpus_sentimentr_df['sent_raw'] = corpus_sentimentr_df['sent_raw'].astype('string')\n",
        "corpus_sentimentr_df.head(2)\n",
        "corpus_sentimentr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJp4DgcIwa7A"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "# (Optional) Read Sentiment Series generated in RStudio by SentimentR into DataFrame: corpus_sents_sentimentr_df\n",
        "#            SKIP if no SyuzhetR sentiment datafile to read in\n",
        "\n",
        "# MANUALLY: copy and paste the filename above into the quotes below for sum_sentiment_sentimentR_filename\n",
        "\n",
        "corpus_sentimentr_df = pd.read_csv(sum_sentiments_sentimentr_filename, encoding = 'unicode_escape', engine ='python')\n",
        "\n",
        "# Rename columns if necessary\n",
        "corpus_sentimentr_df.rename(columns={'Unnamed: 0':'sent_no'}, inplace=True)\n",
        "corpus_sentimentr_df['sent_raw'] = corpus_sentimentr_df['sent_raw'].astype('string')\n",
        "corpus_sentimentr_df['sent_raw'] = corpus_sentimentr_df['sent_raw'].apply(lambda x : re.sub(f'[^{re.escape(string.printable)}]', '', x))\n",
        "corpus_sentimentr_df['sent_raw'] = corpus_sentimentr_df['sent_raw'].apply(lambda x : filter_nonprintable(x))\n",
        "\n",
        "\n",
        "# create a clean version of Sentence in sent_clean column\n",
        "corpus_sentimentr_df['sent_clean'] = corpus_sentimentr_df['sent_raw'].apply(lambda x : clean_text(x))\n",
        "corpus_sentimentr_df['sent_clean'] = corpus_sentimentr_df['sent_raw'].apply(lambda x : re.sub(f'[^{re.escape(string.printable)}]', '', x))\n",
        "corpus_sentimentr_df['sent_clean'] = corpus_sentimentr_df['sent_raw'].apply(lambda x : filter_nonprintable(x))\n",
        "\n",
        "corpus_sentimentr_df['sent_clean'] = corpus_sentimentr_df['sent_clean'].astype('string')\n",
        "\n",
        "corpus_sentimentr_df.head(2)\n",
        "corpus_sentimentr_df.info()\n",
        "corpus_sentimentr_df.columns\n",
        "\n",
        "corpus_sents_sentimentr_len = corpus_sentimentr_df.shape[0]\n",
        "\n",
        "# BUG FIX: SentimentR can create many additional rows that must be deleted \n",
        "#          to enable it to be merged with other Sentiment Models on the same Corpus\n",
        "#          OR just leave SentimentR unmerged and analyze separately (preferred)\n",
        "#\n",
        "# POSSIBLE SOLUTIONS (from worst/easiest to better)\n",
        "#     \n",
        "#   1) Trim extra n rows from head/tail\n",
        "#   2) Naive Downsampling of Series\n",
        "#   3) Clustering and distribute deletes of near-medians from longest runs, avoiding outliers, start/end\n",
        "#   4) DTW character-preserving Compression\n",
        "# \n",
        "#          Simplification, 1D cluster jockers_rinker column as proxy for full interrow distance features\n",
        "#                          and delete rows near the median from the largest cluster (vs taking into account\n",
        "#                          all features in Euclidian or other distance metric)\n",
        "\n",
        "# import kmeans1d\n",
        "\n",
        "# Approximate k cluster number as 1 cluster for every 500 sentences in Corpus\n",
        "# k = corpus_sentimentr_df.shape[0]//500  \n",
        "# clusters, centroids = kmeans1d.cluster(np.array(corpus_sentimentr_df['jockers_rinker']), k)\n",
        "\n",
        "def del_oneincluster(df, cluster_per=1):\n",
        "  '''\n",
        "  TODO: Skip for now and use kmeans1d instead\n",
        "  Given a DataFrame and a Cluster Percent to calculate a sliding window\n",
        "  Return DataFrame with one row removed within a sliding window cluster with most self-similiar rows\n",
        "  '''\n",
        "\n",
        "  # Compute sliding window for cluster size\n",
        "  win_cluster_len = int(cluster_per/100 * df.shape[0])\n",
        "  win_start = 0\n",
        "  win_stop = df.shape[0] - win_cluster_len\n",
        "\n",
        "  # Get numeric columns\n",
        "  numeric_df = df.select_dtypes(include=numerics)\n",
        "\n",
        "  most_selfsimilar_value = 0\n",
        "  most_selfsimilar_index = 0\n",
        "  for i in range(win_start, win_stop, 1):\n",
        "    selfsim_score = selfsim_metric(numeric_df.iloc[i:win_cluster_len+1])\n",
        "    if selfsim_score > most_selfsimilar_value:\n",
        "      most_selfsimilar_index = i\n",
        "\n",
        "  oneless_df = del_onerow(most_selfsimilar_index)\n",
        "\n",
        "  return oneless_df\n",
        "\n",
        "# BAD SOLUTION, just trim the last n rows of corpus_sentimentr_df to make lengths match for merging\n",
        "# corpus_sentimentr_df = corpus_sentimentr_df.iloc[:-n,:]\n",
        "\n",
        "corpus_sentimentr_len = corpus_sentimentr_df.shape[0]\n",
        "if corpus_sentimentr_len != corpus_sents_df.shape[0]:\n",
        "  print('\\n\\n\\n======================================================================\\n')\n",
        "  print(f'ERROR: sentence sentiment values read into corpus_syuzhetr (len={corpus_sents_sentimentr_len})')\n",
        "  print(f'       is not the same length as corpus_sents_df (len={corpus_sents_df.shape[0]}) ')\n",
        "  print(f'\\nRECOMMENDATION: Use the preprocessed corpus output created by this notebook ')\n",
        "  print(f'                as input to SentimentR in RStudio to generate sentiment series')\n",
        "  print(f'                and then retry importing')\n",
        "  print('\\n======================================================================\\n');\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWlzPu0ygMRD"
      },
      "source": [
        "corpus_sentimentr_df.info('sent_raw')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgtj_-KthMdS"
      },
      "source": [
        "# Insert Sentence Numbers (sent_no)\n",
        "\"\"\"\n",
        "sent_ct = corpus_sentimentr_df.shape[0]\n",
        "sent_no_ls = list(range(sent_ct))\n",
        "corpus_sentimentr_df.insert(0, 'sent_no', sent_no_ls)\n",
        "corpus_sentimentr_df.head(2)\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAiKRKTehzmX"
      },
      "source": [
        "corpus_sentimentr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOg-Z7Z5k1px"
      },
      "source": [
        "corpus_sentimentr_df['jockers'].isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGxoCc5WgUNt"
      },
      "source": [
        "# Rename columns if necessary\n",
        "corpus_sentimentr_df['sent_raw'] = corpus_sentimentr_df['sent_raw'].astype('string')\n",
        "corpus_sentimentr_df['sent_raw'] = corpus_sentimentr_df['sent_raw'].apply(lambda x : re.sub(f'[^{re.escape(string.printable)}]', '', x))\n",
        "corpus_sentimentr_df['sent_raw'] = corpus_sentimentr_df['sent_raw'].apply(lambda x : filter_nonprintable(x))\n",
        "\n",
        "\n",
        "# create a clean version of Sentence in sent_clean column\n",
        "corpus_sentimentr_df['sent_clean'] = corpus_sentimentr_df['sent_raw'].apply(lambda x : clean_text(x))\n",
        "corpus_sentimentr_df['sent_clean'] = corpus_sentimentr_df['sent_clean'].astype('string')\n",
        "\n",
        "corpus_sentimentr_df.head(2)\n",
        "corpus_sentimentr_df.info()\n",
        "corpus_sentimentr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bpDK9m_5Ea6"
      },
      "source": [
        "# Add summary statistics\n",
        "\n",
        "corpus_sentimentr_df['char_len'] = corpus_sentimentr_df['sent_clean'].apply(lambda x: len(x))\n",
        "corpus_sentimentr_df['token_len'] = corpus_sentimentr_df['sent_clean'].apply(lambda x: len(x.split())) \n",
        "\n",
        "# Verify\n",
        "\n",
        "corpus_sentimentr_df.head(2)\n",
        "corpus_sentimentr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnLz5_Gzh-DO"
      },
      "source": [
        "# Create 4 Standardized versions of each Model: stdscaler, medianiqr both lnormed and not\n",
        "\n",
        "print('\\nBefore Standardization ----------')\n",
        "corpus_sentimentr_df.columns\n",
        "\n",
        "standardize_ts_ls(corpus_sentimentr_df, models_sentimentr_ls)\n",
        "\n",
        "print('\\nAfter Standardization ----------')\n",
        "corpus_sentimentr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ0IX-wJ-1fv"
      },
      "source": [
        "# Create SMA roll=10% for all models_stdscaler as baseline\n",
        "\n",
        "win_s1per = int(corpus_sentimentr_df.shape[0] * 1/100)\n",
        "\n",
        "col_stdscaler_roll_ls = []\n",
        "for amodel in models_sentimentr_ls:\n",
        "  col_stdscaler = f'{amodel}_stdscaler'\n",
        "  col_stdscaler_roll = f'{amodel}_stdscaler_{roll_str}'\n",
        "  corpus_sentimentr_df[col_stdscaler_roll] = corpus_sentimentr_df[col_stdscaler].rolling(10*win_s1per, center=True).mean()\n",
        "  col_stdscaler_roll_ls.append(col_stdscaler_roll)\n",
        "\n",
        "col_stdscaler_roll_mean = col_stdscaler_roll + '_mean'\n",
        "corpus_sentimentr_df[col_stdscaler_roll_mean] = corpus_sentimentr_df[col_stdscaler_roll_ls].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpoUy0Dm5Ea8"
      },
      "source": [
        "# Standardize all values with MedianIQR\n",
        "\"\"\"\n",
        "model_sentimentr_ls = ['jockers_rinker', 'jockers', 'huliu', 'lmcd', 'nrc', 'senticnet', 'sentiword']\n",
        "\n",
        "for model_sentimentr in models_sentimentr_ls:\n",
        "\n",
        "  # Normalize the Sentence Sentiment by dividing Sentiment by Sentence Length\n",
        "  sents_len_ls = list(corpus_sentimentr_df['token_len'])\n",
        "  sents_sentiment_ls = list(corpus_sentimentr_df[model_sentimentr])\n",
        "  sents_sentiment_norm_ls = [sents_sentiment_ls[i]/(sents_len_ls[i]+0.01) for i in range(len(sents_len_ls))]\n",
        "\n",
        "  # RobustStandardize Sentence sentiment values\n",
        "  # corpus_sentimentr_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(sents_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  col_medianiqr = f'{model_sentimentr}_medianiqr'\n",
        "  corpus_sentimentr_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(corpus_sentimentr_df[model_sentimentr]).reshape(-1, 1))\n",
        "  col_lnorm_medianiqr = f'{model_sentimentr}_lnorm_medianiqr'\n",
        "  corpus_sentimentr_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(sents_sentiment_norm_ls)).reshape(-1, 1))\n",
        "\"\"\";\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqrVGplu3txO"
      },
      "source": [
        "#### **Interactive Sentence SMA Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFV8VTo1dtf4"
      },
      "source": [
        "# Sentence Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "SentimentR_JockersRinker = True #@param {type:\"boolean\"}\n",
        "SentimentR_Jockers = True #@param {type:\"boolean\"}\n",
        "SentimentR_HuLiu = True #@param {type:\"boolean\"}\n",
        "SentimentR_SenticNet = True #@param {type:\"boolean\"}\n",
        "SentimentR_SentiWord = True #@param {type:\"boolean\"}\n",
        "SentimentR_NRC = True #@param {type:\"boolean\"}\n",
        "SentimentR_LoughranMcDonald = True #@param {type:\"boolean\"}\n",
        "\n",
        "models_subset_ls = []\n",
        "\n",
        "if SentimentR_JockersRinker == True:\n",
        "  models_subset_ls.append('jockers_rinker')\n",
        "if SentimentR_Jockers == True:\n",
        "  models_subset_ls.append('jockers')\n",
        "if SentimentR_HuLiu == True:\n",
        "  models_subset_ls.append('huliu')\n",
        "if SentimentR_SenticNet == True:\n",
        "  models_subset_ls.append('senticnet')\n",
        "if SentimentR_SentiWord == True:\n",
        "  models_subset_ls.append('sentiword')\n",
        "if SentimentR_NRC == True:\n",
        "  models_subset_ls.append('nrc')\n",
        "if SentimentR_LoughranMcDonald == True:\n",
        "  models_subset_ls.append('lmcd')\n",
        "\n",
        "print(f'models_subset_ls:\\n\\n    {models_subset_ls}')\n",
        "plot_models(models_subset_ls, models_type='sentimentr', text_unit='sent_no', win_per=SMA_Window_Percent);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP-Moy3DdrRr"
      },
      "source": [
        "#### **(ABOVE) Plotly SMA Sentence, (BELOW) Correlation Heatmap**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaY7ZYNSm0MM"
      },
      "source": [
        "# Sentence Heatmap Correlation of StdScaler Roll100 Sentiments\n",
        "# Depends on 'col_stdscaler_rollwin_ls' defined in prior code cell\n",
        "\n",
        "Correlation_Algo = \"kendall\" #@param [\"pearson\", \"spearman\", \"kendall\"]\n",
        "# corr_methods_ls = ['pearson', 'spearman', 'kendall']\n",
        "\n",
        "col_stdscaler_rollwin_ls = []\n",
        "for amodel in models_sentimentr_ls:\n",
        "  col_amodel_stdscaler_rollwin = f'{amodel}_stdscaler_{roll_str}'\n",
        "  col_stdscaler_rollwin_ls.append(col_amodel_stdscaler_rollwin)\n",
        "print(f'col_stdscaler_rollwin_ls: {col_stdscaler_rollwin_ls}')\n",
        "\n",
        "corr_df = corpus_sentimentr_df[col_stdscaler_rollwin_ls].dropna(axis=0, how='any').corr(method=Correlation_Algo)\n",
        "corr_df\n",
        "# Customize the heatmap of the corr_meat correlation matrix and rotate the x-axis labels\n",
        "fig = sns.clustermap(corr_df, # corpus_sents_df[col_stdscaler_rollwin_ls].dropna(axis=0, how='any').corr(method=corr_method),\n",
        "                    row_cluster=True,\n",
        "                    col_cluster=True,\n",
        "                    figsize=(10, 10))\n",
        "\n",
        "\n",
        "plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n",
        "plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
        "plt.title(f'{CORPUS_FULL} Sentence Sentiment for SentimentR Model Sentiments\\n {Correlation_Algo.capitalize()} Correlation - StdScale Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yaxyt-MqOxdV"
      },
      "source": [
        "#### **Sentence Sentiment DTW Hierarichal Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S83JA_esuSxc"
      },
      "source": [
        "#### **Top-n Crux Peaks and Valleys**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgETYM8xMGGW"
      },
      "source": [
        "**Search Corpus for Substring**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* In [Search_for_Substring] enter a Substring to search for in the Corpus\n",
        "\n",
        "* Enter a Substring long enough/unique enough so only a reasonable number of Sentences will be returned\n",
        "\n",
        "* Substring can contain spaces/punctuation, for example: 'in the garden'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nyUrE2_L_yr"
      },
      "source": [
        "# Search Corpus Sentences for Substring\n",
        "\n",
        "Search_for_Substring = \"love\" #@param {type:\"string\"}\n",
        "\n",
        "sentno_matching_ls = corpus_sents_df[corpus_sents_df['sent_raw'].str.contains(Search_for_Substring, regex=False)]['sent_no']\n",
        "\n",
        "for i, asentno in enumerate(sentno_matching_ls):\n",
        "  # sentno, sentraw = asent\n",
        "  print(f\"\\n\\nMatch #{i}: Sentence #{asentno}\\n\\n\")\n",
        "  sent_highlight = re.sub(Search_for_Substring, Search_for_Substring.upper(), corpus_sents_df.iloc[asentno]['sent_raw'])\n",
        "  print(f'    {sent_highlight}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7TRTSm34mnl"
      },
      "source": [
        "**Plot Top-n Crux Peaks/Valleys for selected Model**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Crux_Window_Percent] exclusive zone around Crux Points as a percentage of Corpus length\n",
        "\n",
        "* [Sentiment_Model] Select a Sentiment Analysis model\n",
        "\n",
        "* Select [Anomaly_Detction] to plot raw Sentiment values to detect outlier/anomaly Sentences. Leave unchecked to plot SMA smoothed Sentiment arc and detect Crux points\n",
        "\n",
        "* Select [Save_to_File] to also save plot to external *.png file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8SRc-bSKZiO"
      },
      "source": [
        "Crux_Window_Percent = 5 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "SentimentR_SMA_Model = \"SenticNet\" #@param [\"Jockers-Rinker\", \"Jockers\", \"Hu-Liu\", \"SenticNet\", \"SentiWord\", \"NRC\", \"Loughan-McDonald\"]\n",
        "Anomaly_Detection = False #@param {type:\"boolean\"}\n",
        "Vertical_Labels = True #@param {type:\"boolean\"}\n",
        "Vertical_Labels_Height = -0.1 #@param {type:\"slider\", min:-5, max:5, step:0.05}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "if SentimentR_SMA_Model == 'Jockers-Rinker':\n",
        "  model_selected = f'jockers_rinker'\n",
        "if SentimentR_SMA_Model == 'Jockers':\n",
        "  model_selected = f'jockers'\n",
        "if SentimentR_SMA_Model == 'Hu-Liu':\n",
        "  model_selected = f'huliu'\n",
        "if SentimentR_SMA_Model == 'SenticNet':\n",
        "  model_selected = f'senticnet'\n",
        "if SentimentR_SMA_Model == 'SentiWord':\n",
        "  model_selected = f'sentiword'\n",
        "if SentimentR_SMA_Model == 'NRC':\n",
        "  model_selected = f'nrc'\n",
        "if SentimentR_SMA_Model == 'Loughran-McDonald':\n",
        "  model_selected = f'lmcd'\n",
        "\n",
        "if Anomaly_Detection == False:\n",
        "  # (a) Use Sentence SMA smoothed Sentiment models to detect Crux Points\n",
        "  model_selected_fullname = f'{model_selected}_stdscaler_{roll_str}'\n",
        "else:\n",
        "  # (b)Use Sentence Raw Sentiment models to detect outliers\n",
        "  model_selected_fullname = f'{model_selected}'\n",
        "\n",
        "\n",
        "\n",
        "# TODO: enable multiple overlay crux points with underlying mean/median arc\n",
        "corpus_models_selected_ls = [model_selected_fullname]\n",
        "print(f'corpus_models_selected_ls: {corpus_models_selected_ls}')\n",
        "\n",
        "# Warning: requires definitions of: x, section_sents_df\n",
        "#          so Baseline models must be run first\n",
        "\n",
        "\n",
        "for amodel in corpus_models_selected_ls:\n",
        "  corpus_cruxes_all_dt[amodel] = get_crux_points(ts_df=corpus_sentimentr_df, \n",
        "                                         col_series=corpus_models_selected_ls, \n",
        "                                         text_type='sentence', \n",
        "                                         win_per=Crux_Window_Percent, \n",
        "                                         sec_y_labels=Vertical_Labels,\n",
        "                                         sec_y_height=Vertical_Labels_Height, \n",
        "                                         subtitle_str='5% Crux - ', \n",
        "                                         do_plot=True, \n",
        "                                         save2file=False)\n",
        "  \n",
        "model_crux_ls = corpus_cruxes_all_dt[amodel]\n",
        "# model_crux_ls;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_FRnxmUtRIY"
      },
      "source": [
        "### **Context around Top-n Crux Peaks/Valleys**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Get_Peak_Cruxes] to retrieve Peaks (if unchecked Valleys are retrieved)\n",
        "\n",
        "* [Get_n_Cruxes] determines how many Top-n Cruxes to retrieve\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FeWNQLqscUy"
      },
      "source": [
        "corpus_sentimentr_df['sent_raw'].isna().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyeQ7Jpfszhq"
      },
      "source": [
        "# Crux Details\n",
        "Get_Peak_Cruxes = False #@param {type:\"boolean\"}\n",
        "Get_n_Cruxes = 20 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "Sort_by_SentenceNo = True #@param {type:\"boolean\"}\n",
        "\n",
        "# Context Details\n",
        "No_Paragraphs_on_Each_Side = 1 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "Highlight_Sentence = False #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "if Sort_by_SentenceNo == True:\n",
        "  sort_on = 'sent_no'\n",
        "else:\n",
        "  sort_on = 'sentiment_val'\n",
        "  \n",
        "\n",
        "\n",
        "print(f'Crux Report --------------------\\n')\n",
        "print(f'            Corpus: {CORPUS_FULL}')\n",
        "print(f'            Model: {SentimentR_SMA_Model}')\n",
        "print(f'            Crux Win%: {Crux_Window_Percent}')\n",
        "print(f'            SMA Win%: {roll_str}')\n",
        "\n",
        "\n",
        "if Save_to_Report == False:\n",
        "  crux_sortsents_report(model_crux_ls, \n",
        "                        ts_df = corpus_sentimentr_df,\n",
        "                        library_type='sentimentr',\n",
        "                        top_n=Get_n_Cruxes, \n",
        "                        get_peaks=Get_Peak_Cruxes, \n",
        "                        sort_by = sort_on, # sent_no, or abs(polarity)\n",
        "                        n_sideparags=No_Paragraphs_on_Each_Side,\n",
        "                        sentence_highlight=Highlight_Sentence)\n",
        "\n",
        "else:\n",
        "  # https://www.kite.com/python/answers/how-to-get-stdout-and-stderr-from-a-process-as-a-string-in-python\n",
        "  # process = subprocess.run([\"echo\", \"This goes to stdout\"], capture_output=True)\n",
        "  # stdout_as_str = process.stdout.decode(\"utf-8\")\n",
        "  # print(stdout_as_str)\n",
        "  temp_out = StringIO()\n",
        "  sys.stdout = temp_out\n",
        "  crux_sortsents_report(model_crux_ls, top_n=Get_n_Cruxes, get_peaks=Get_Peak_Cruxes, n_sideparags=No_Paragraphs_on_Each_Side)\n",
        "  print(temp_out)\n",
        "  # attempt to save temp_out to generated filename\n",
        "  sys.stdout = sys.__stdout__\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fHyY7YBsbcn"
      },
      "source": [
        "**Zoom in on Context surrounding a particular Crux Point**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Enter [Crux_Sentence_No] that matches a Crux point/Sentence No you want to explore\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYZROB3sgL3q"
      },
      "source": [
        "corpus_sents_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W7iWQErsbco"
      },
      "source": [
        "# Select details about the Crux Point Context to Retrieve\n",
        "\n",
        "# print(f'Last Sentence No: {corpus_sents_df.shape[0]}')\n",
        "Crux_Sentence_No =  1839#@param {type:\"number\"}\n",
        "No_Paragraphs_on_Each_Side = 0 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "Highlight_Crux_Sentence = True #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "corpus_sents_len = corpus_sents_df.shape[0]\n",
        "\n",
        "# if (Crux_Sentence_No >= No_Paragraphs_on_Each_Side) & (Crux_Sentence_No+No_Paragraphs_on_Each_Side <= corpus_parag_len):\n",
        "# get_sentnocontext_report()\n",
        "# try:\n",
        "\n",
        "get_sentnocontext_report(ts_df=corpus_sentimentr_df, \n",
        "                         the_sent_no=Crux_Sentence_No, \n",
        "                         the_n_sideparags=No_Paragraphs_on_Each_Side, \n",
        "                         the_sent_highlight=Highlight_Crux_Sentence)\n",
        "\n",
        "\n",
        "# get_sentnocontext_report(the_sent_no=Crux_Sentence_No, \n",
        "#                          the_n_sideparags=No_Paragraphs_on_Each_Side, \n",
        "#                          the_sent_highlight=Highlight_Crux_Sentence)\n",
        "\n",
        "# except:\n",
        "#   print('ERROR')\n",
        "# else:\n",
        "#   print(f'ERROR: The combination of your [Crux_Sentence_No] and [No_Pargraphs_on_Each_Side]\\n       results in a window outside the range of the Corpus Paragraphs.\\n\\n       Try again with different values.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Lbzxj1zwdC6"
      },
      "source": [
        "## **EDA Syuzhet Plots**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1d2Q3zqSES1"
      },
      "source": [
        "#### **(If not already exists) Import SyuzhetR Sentiment Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npwz74KeliXE"
      },
      "source": [
        "# Verify SentimentR Sentiment Files exported from RStudio\n",
        "!pwd\n",
        "!ls -altr sum_sentiments*syuzhet*.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVZB9Iff0_Nh"
      },
      "source": [
        "# Get SyuzhetR Sentiment Datafile (with data on 4 Models)\n",
        "\n",
        "SyuzhetR_sentiment_datafile = 'sum_sentiments_syuzhetR_4models_emforster_howardsend.csv' #@param {type:\"string\"}\n",
        "\n",
        "sum_sentiments_syuzhetr_filename = SyuzhetR_sentiment_datafile\n",
        "\n",
        "!head -n 3 $sum_sentiments_syuzhetr_filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUdqcl13LV-q"
      },
      "source": [
        "corpus_syuzhetr_df = pd.read_csv(sum_sentiments_syuzhetr_filename)\n",
        "corpus_syuzhetr_df.head(2)\n",
        "corpus_syuzhetr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuZsrB9TLV-5"
      },
      "source": [
        "# corpus_sents_df = corpus_sents_df.loc[:, ~corpus_sents_df.columns.str.contains('^Unnamed')]\n",
        "\n",
        "corpus_syuzhetr_df.rename(columns={'Unnamed: 0':'sent_no'}, inplace=True)\n",
        "corpus_syuzhetr_df['sent_raw'] = corpus_syuzhetr_df['sent_raw'].astype('string')\n",
        "corpus_syuzhetr_df.head(2)\n",
        "corpus_syuzhetr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfJkHlYp4XGZ"
      },
      "source": [
        "# Add summary statistics\n",
        "\n",
        "corpus_syuzhetr_df['char_len'] = corpus_syuzhetr_df['sent_raw'].apply(lambda x: len(x))\n",
        "corpus_syuzhetr_df['token_len'] = corpus_syuzhetr_df['sent_raw'].apply(lambda x: len(x.split())) \n",
        "\n",
        "corpus_syuzhetr_df.head(2)\n",
        "corpus_syuzhetr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ismjoxwCmFvg"
      },
      "source": [
        "# Insert Sentence Numbers (sent_no)\n",
        "\"\"\"\n",
        "sent_ct = corpus_syuzhetr_df.shape[0]\n",
        "sent_no_ls = list(range(sent_ct))\n",
        "corpus_syuzhetr_df.insert(0, 'sent_no', sent_no_ls)\n",
        "corpus_syuzhetr_df.head(2)\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTwYKJWZmFvi"
      },
      "source": [
        "# Rename columns if necessary\n",
        "corpus_syuzhetr_df['sent_raw'] = corpus_syuzhetr_df['sent_raw'].astype('string')\n",
        "corpus_syuzhetr_df['sent_raw'] = corpus_syuzhetr_df['sent_raw'].apply(lambda x : re.sub(f'[^{re.escape(string.printable)}]', '', x))\n",
        "corpus_syuzhetr_df['sent_raw'] = corpus_syuzhetr_df['sent_raw'].apply(lambda x : filter_nonprintable(x))\n",
        "\n",
        "\n",
        "# create a clean version of Sentence in sent_clean column\n",
        "corpus_syuzhetr_df['sent_clean'] = corpus_syuzhetr_df['sent_raw'].apply(lambda x : clean_text(x))\n",
        "corpus_syuzhetr_df['sent_clean'] = corpus_syuzhetr_df['sent_clean'].astype('string')\n",
        "\n",
        "corpus_syuzhetr_df.head(2)\n",
        "corpus_syuzhetr_df.info()\n",
        "corpus_syuzhetr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ElmJTvD1Ntb"
      },
      "source": [
        "corpus_syuzhetr_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlJ6MvuOEV5o"
      },
      "source": [
        "print(*corpus_syuzhetr_df.columns, sep='\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgqSba8FKcMd"
      },
      "source": [
        "# Create 4 Standardized versions of each Model: stdscaler, medianiqr both lnormed and not\n",
        "\n",
        "print('\\nBefore Standardization ----------')\n",
        "corpus_syuzhetr_df.columns\n",
        "\n",
        "standardize_ts_ls(corpus_syuzhetr_df, models_syuzhetr_ls)\n",
        "\n",
        "print('\\nAfter Standardization ----------')\n",
        "corpus_syuzhetr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IDpH20z3lhu"
      },
      "source": [
        "#### **Interactive Sentence SMA Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acNruMABNvte"
      },
      "source": [
        "# Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "# display(corpus_sentimentr_df.head())\n",
        "\n",
        "win_per = SMA_Window_Percent             \n",
        "win_roll = int(win_per/100 * corpus_sentimentr_df.shape[0])\n",
        "\n",
        "# model_syuzhetr_ls = ['syuzhet', 'bing', 'afinn', 'nrc']\n",
        "\n",
        "\n",
        "col_name_roll_ls = []\n",
        "# fig, ax = plt.subplots()\n",
        "for amodel in models_syuzhetr_ls:\n",
        "  # if not(amodel.endswith('roll050')):\n",
        "  if len(str(win_per)) == 1:\n",
        "    roll_str = 'roll0' + str(win_per)\n",
        "  else:\n",
        "    roll_str = 'roll' + str(win_per)\n",
        "  col_name_roll = f'{amodel}_{roll_str}'\n",
        "  col_name_roll_ls.append(col_name_roll)\n",
        "  # else:\n",
        "  #   col_name_roll_ls.append(amodel)\n",
        "  corpus_syuzhetr_df[col_name_roll] = corpus_syuzhetr_df[amodel].rolling(win_roll, center=True).mean()\n",
        "\n",
        "col_mean_roll = 'mean_' + roll_str\n",
        "corpus_syuzhetr_df[col_mean_roll] = corpus_syuzhetr_df[col_name_roll_ls].mean(axis=1)\n",
        "\n",
        "\n",
        "palette = cycle(px.colors.qualitative.Bold)\n",
        "# palette = cycle(px.colors.sequential.PuBu)\n",
        "\n",
        "my_layout = go.Layout(\n",
        "    autosize=False,\n",
        "    width=1600,\n",
        "    height=800,\n",
        "    margin=go.layout.Margin(\n",
        "        l=10,\n",
        "        r=50,\n",
        "        b=100,\n",
        "        t=100,\n",
        "        pad = 1\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "fig = go.Figure(layout=my_layout)\n",
        "\n",
        "# add traces\n",
        "\n",
        "model = 'mean_' + roll_str\n",
        "fig.add_traces(go.Line(x=corpus_syuzhetr_df['sent_no'],\n",
        "                       y = corpus_syuzhetr_df[model],\n",
        "                       line=dict(\n",
        "                            color='#000000',\n",
        "                            width=5\n",
        "                            ),\n",
        "                       text = corpus_syuzhetr_df.index.values,\n",
        "                       name = model,\n",
        "                       hovertemplate = \"Model <b>Mean: \"+str(win_per)+\"%</b><br>Sentence #<b>%{x}</b><br>Polarity <b>%{y}</b>\", \n",
        "                       marker_color=next(palette)))\n",
        "\n",
        "\n",
        "for amodel in models_syuzhetr_ls:\n",
        "  model_roll = f'{amodel}_' + roll_str\n",
        "  fig.add_traces(go.Line(x=corpus_syuzhetr_df['sent_no'],\n",
        "                        y = corpus_syuzhetr_df[model_roll],\n",
        "                        text = corpus_syuzhetr_df['sent_raw'],\n",
        "                        name = model_roll,\n",
        "                        hovertemplate = \"Model <b>\"+model_roll+\"</b><br>Sentence #<b>%{x}</b><br>Polarity <b>%{y:.4f}</b><br>Index: <b><i>%{text}</i></b>\", \n",
        "                        marker_color=next(palette)))\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"SyuzhetR Sentence Sentiment Models <b><i>\" + roll_str.upper() + '</i></b>',\n",
        "    xaxis_title=\"Sentence Number\",\n",
        "    # yaxis_title=\"Sentiment Value\",\n",
        "    hoverlabel=dict(\n",
        "        bgcolor=\"white\",\n",
        "        font_size=16,\n",
        "        font_family=\"Rockwell\"\n",
        "    ),\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=18,\n",
        "        color=\"RebeccaPurple\"\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMIE4UF_PlxL"
      },
      "source": [
        "#### **Comparison of Sentence SyuzhetR Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0iHrpqpmnuE"
      },
      "source": [
        "# Compare Sentence SyuzhetR Standardized Sentiment Values\n",
        "\n",
        "# model_syuzhetr_ls = ['syuzhet', 'bing', 'afinn', 'nrc']\n",
        "\n",
        "model_syuzhetr_standardized_roll_ls = []\n",
        "for amodel in models_syuzhetr_ls:\n",
        "  col_roll_name = f'{amodel}_{roll_str}'  # TODO: drop lnorm_medianiqr earlier and just Standardize here\n",
        "                                                     # NOTE: Simple SciPy StandardScaler works on SMA Series that don't have outliers like Raw Series\n",
        "  # print(f'col_name: {col_name}')\n",
        "  model_syuzhetr_standardized_roll_ls.append(col_roll_name)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i,arollmodel in enumerate(model_syuzhetr_standardized_roll_ls):\n",
        "  print(f'Processing model: {arollmodel}')\n",
        "  col_name_roll_stand = f'{arollmodel}_stdscale'\n",
        "  # print(f'col_name_roll_stand: {col_name_roll_stand}')\n",
        "  model_roll_stand_np = np.array(corpus_syuzhetr_df[arollmodel])\n",
        "  # .apply(lambda x: Scale_SentimentR*x))\n",
        "  \n",
        "  model_roll_stand_np = model_roll_stand_np.reshape((len(model_roll_stand_np), 1))\n",
        "\n",
        "  scaler = scaler.fit(model_roll_stand_np)\n",
        "  print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, np.sqrt(scaler.var_)))\n",
        "  model_roll_stand_xform_np = scaler.transform(model_roll_stand_np)\n",
        "\n",
        "  print(f'  Adding StdScaler Column: {col_name_roll_stand}')\n",
        "  corpus_syuzhetr_df[col_name_roll_stand] = pd.Series(model_roll_stand_xform_np.flatten())\n",
        "\n",
        "  # Plot\n",
        "  corpus_syuzhetr_df[col_name_roll_stand].plot(label=arollmodel) # label=col_name_roll_stand))\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Sentence SyuzhetR Sentiments\\nMean Length-Normed MedianIQR Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aUtGZvXd406"
      },
      "source": [
        "#### **(ABOVE) Plotly SMA Sentence, (BELOW) Correlation Heatmap**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp-9YGD7GRxD"
      },
      "source": [
        "corpus_syuzhetr_df[models_syuzhetr_ls].isna().any().count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onf1ah-vPlAT"
      },
      "source": [
        "# Create a comparison DataFrame of SentimentR Sentence Models\n",
        "# Sentence Heatmap Correlation of StdScaler Roll100 Sentiments\n",
        "# Depends on 'col_stdscaler_rollwin_ls' defined in prior code cell\n",
        "\n",
        "Correlation_Algo = \"pearson\" #@param [\"pearson\", \"spearman\", \"kendall\"]\n",
        "\n",
        "# syuzhetr_corr_models_ls = ['syuzhet', 'bing', 'afinn', 'nrc']\n",
        "\n",
        "corr_df = corpus_syuzhetr_df[models_syuzhetr_ls].corr(method=Correlation_Algo)\n",
        "\n",
        "# Customize the heatmap of the corr_meat correlation matrix and rotate the x-axis labels\n",
        "fig = sns.clustermap(corr_df,\n",
        "                     row_cluster=True,\n",
        "                     col_cluster=True,\n",
        "                     figsize=(10, 10))\n",
        "\n",
        "plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n",
        "plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
        "plt.title(f'{CORPUS_FULL} Sentence Sentiment for SyuzhetR Model Sentiments\\n {Correlation_Algo.capitalize()} Correlation - StdScale Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_C27J8moEZl"
      },
      "source": [
        "#### **Sentence Sentiment DTW Hierarichal Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OemcAFXd6JD5"
      },
      "source": [
        "#### **Top-n Crux Peaks and Valleys**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oGL8mXZNBUw"
      },
      "source": [
        "**Search Corpus for Substring**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* In [Search_for_Substring] enter a Substring to search for in the Corpus\n",
        "\n",
        "* Enter a Substring long enough/unique enough so only a reasonable number of Sentences will be returned\n",
        "\n",
        "* Substring can contain spaces/punctuation, for example: 'in the garden'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMelwTuTNBUx"
      },
      "source": [
        "# Search Corpus Sentences for Substring\n",
        "\n",
        "Search_for_Substring = \"death.\" #@param {type:\"string\"}\n",
        "\n",
        "sentno_matching_ls = corpus_sents_df[corpus_sents_df['sent_raw'].str.contains(Search_for_Substring, regex=False)]['sent_no']\n",
        "\n",
        "for i, asentno in enumerate(sentno_matching_ls):\n",
        "  # sentno, sentraw = asent\n",
        "  print(f\"\\n\\nMatch #{i}: Sentence #{asentno}\\n\\n\")\n",
        "  sent_highlight = re.sub(Search_for_Substring, Search_for_Substring.upper(), corpus_sents_df.iloc[asentno]['sent_raw'])\n",
        "  print(f'    {sent_highlight}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "262TERB06JD8"
      },
      "source": [
        "**Plot Top-n Crux Peaks/Valleys for selected Model**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Crux_Window_Percent] exclusive zone around Crux Points as a percentage of Corpus length\n",
        "\n",
        "* [Sentiment_Model] Select a Sentiment Analysis model\n",
        "\n",
        "* Select [Anomaly_Detction] to plot raw Sentiment values to detect outlier/anomaly Sentences. Leave unchecked to plot SMA smoothed Sentiment arc and detect Crux points\n",
        "\n",
        "* Select [Save_to_File] to also save plot to external *.png file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhmPgogw6JEA"
      },
      "source": [
        "Crux_Window_Percent = 5 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "SyuzhetR_SMA_Model = \"Bing\" #@param [\"Syuzhet\", \"Bing\", \"AFINN\", \"NRC\"]\n",
        "Anomaly_Detection = False #@param {type:\"boolean\"}\n",
        "Vertical_Labels = True #@param {type:\"boolean\"}\n",
        "Vertical_Labels_Height = 0.2 #@param {type:\"slider\", min:-5.0, max:5.0, step:0.05}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "if SyuzhetR_SMA_Model == 'Syuzhet':\n",
        "  model_selected = f'syuzhet'\n",
        "if SyuzhetR_SMA_Model == 'Bing':\n",
        "  model_selected = f'bing'\n",
        "if SyuzhetR_SMA_Model == 'AFINN':\n",
        "  model_selected = f'afinn'\n",
        "if SyuzhetR_SMA_Model == 'NRC':\n",
        "  model_selected = f'nrc'\n",
        "\n",
        "if Anomaly_Detection == False:\n",
        "  # (a) Use Sentence SMA smoothed Sentiment models to detect Crux Points\n",
        "  model_selected_fullname = f'{model_selected}_{roll_str}'\n",
        "  print(f'model_selected_fullname: {model_selected_fullname}')\n",
        "else:\n",
        "  # (b)Use Sentence Raw Sentiment models to detect outliers\n",
        "  model_selected_fullname = f'{model_selected}'\n",
        "\n",
        "\n",
        "# TODO: enable multiple overlay crux points with underlying mean/median arc\n",
        "corpus_models_selected_ls = [model_selected_fullname]\n",
        "print(f'corpus_models_selected_ls: {corpus_models_selected_ls}')\n",
        "\n",
        "# Warning: requires definitions of: x, section_sents_df\n",
        "#          so Baseline models must be run first\n",
        "\n",
        "for amodel in corpus_models_selected_ls:\n",
        "  corpus_cruxes_all_dt[amodel] = get_crux_points(ts_df=corpus_syuzhetr_df, \n",
        "                                         col_series=corpus_models_selected_ls, \n",
        "                                         text_type='sentence', \n",
        "                                         win_per=Crux_Window_Percent, \n",
        "                                         sec_y_labels=Vertical_Labels,\n",
        "                                         sec_y_height=Vertical_Labels_Height, \n",
        "                                         subtitle_str='5% Crux - ', \n",
        "                                         do_plot=True, \n",
        "                                         save2file=False)\n",
        "  \n",
        "model_crux_ls = corpus_cruxes_all_dt[amodel]\n",
        "print(f'model_crux_ls: {model_crux_ls}');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhx-E08q6JEF"
      },
      "source": [
        "### **Context around Top-n Crux Peaks/Valleys**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Get_Peak_Cruxes] to retrieve Peaks (if unchecked Valleys are retrieved)\n",
        "\n",
        "* [Get_n_Cruxes] determines how many Top-n Cruxes to retrieve\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxq3Irr36JEK"
      },
      "source": [
        "# Crux Details\n",
        "Get_Peak_Cruxes = False #@param {type:\"boolean\"}\n",
        "Get_n_Cruxes = 20 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "Sort_by_SentenceNo = True #@param {type:\"boolean\"}\n",
        "\n",
        "# Context Details\n",
        "No_Paragraphs_on_Each_Side = 2 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "Highlight_Sentence = True #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "if Sort_by_SentenceNo == True:\n",
        "  sort_on = 'sent_no'\n",
        "else:\n",
        "  sort_on = 'sentiment_val'\n",
        "\n",
        "print(f'Crux Report --------------------\\n')\n",
        "print(f'            Corpus: {CORPUS_FULL}')\n",
        "print(f'            Model: {SyuzhetR_SMA_Model}')\n",
        "print(f'            Crux Win%: {Crux_Window_Percent}')\n",
        "print(f'            SMA Win%: {roll_str}')\n",
        "\n",
        "\n",
        "if Save_to_Report == False:\n",
        "  crux_sortsents_report(model_crux_ls, \n",
        "                        ts_df = corpus_syuzhetr_df,\n",
        "                        library_type='syuzhetr',\n",
        "                        top_n=Get_n_Cruxes, \n",
        "                        get_peaks=Get_Peak_Cruxes, \n",
        "                        sort_by = sort_on, # sent_no, or abs(polarity)\n",
        "                        n_sideparags=No_Paragraphs_on_Each_Side,\n",
        "                        sentence_highlight=Highlight_Sentence)\n",
        "\n",
        "else:\n",
        "  # https://www.kite.com/python/answers/how-to-get-stdout-and-stderr-from-a-process-as-a-string-in-python\n",
        "  # process = subprocess.run([\"echo\", \"This goes to stdout\"], capture_output=True)\n",
        "  # stdout_as_str = process.stdout.decode(\"utf-8\")\n",
        "  # print(stdout_as_str)\n",
        "  temp_out = StringIO()\n",
        "  sys.stdout = temp_out\n",
        "  crux_sortsents_report(model_crux_ls, top_n=Get_n_Cruxes, get_peaks=Get_Peak_Cruxes, n_sideparags=No_Paragraphs_on_Each_Side)\n",
        "  print(temp_out)\n",
        "  # attempt to save temp_out to generated filename\n",
        "  sys.stdout = sys.__stdout__\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FE5BtcJ6JEN"
      },
      "source": [
        "**Zoom in on Context surrounding a particular Crux Point**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Enter [Crux_Sentence_No] that matches a Crux point/Sentence No you want to explore\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsfMfACJ6JES"
      },
      "source": [
        "# Select details about the Crux Point Context to Retrieve\n",
        "\n",
        "# print(f'Last Sentence No: {corpus_sents_df.shape[0]}')\n",
        "Crux_Sentence_No =  200#@param {type:\"number\"}\n",
        "No_Paragraphs_on_Each_Side = 5 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "Highlight_Crux_Sentence = True #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "corpus_sents_len = corpus_sents_df.shape[0]\n",
        "\n",
        "# if (Crux_Sentence_No >= No_Paragraphs_on_Each_Side) & (Crux_Sentence_No+No_Paragraphs_on_Each_Side <= corpus_parag_len):\n",
        "# get_sentnocontext_report()\n",
        "# try:\n",
        "\n",
        "get_sentnocontext_report(ts_df=corpus_syuzhetr_df, \n",
        "                         the_sent_no=Crux_Sentence_No, \n",
        "                         the_n_sideparags=No_Paragraphs_on_Each_Side, \n",
        "                         the_sent_highlight=Highlight_Crux_Sentence)\n",
        "\n",
        "# except:\n",
        "#   print('ERROR')\n",
        "# else:\n",
        "#   print(f'ERROR: The combination of your [Crux_Sentence_No] and [No_Pargraphs_on_Each_Side]\\n       results in a window outside the range of the Corpus Paragraphs.\\n\\n       Try again with different values.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpHVFidu7whr"
      },
      "source": [
        "#### **Compare Sentence SentimentR vs Syuzhet Sentiment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdtWV6ViKnWH"
      },
      "source": [
        "roll_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzzmTp93CTiE"
      },
      "source": [
        "corpus_syuzhetr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLwVnxNdBx-W"
      },
      "source": [
        "corpus_sentimentr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lb8TqPsEN4A"
      },
      "source": [
        "roll_str = 'roll10'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXY05cztTMl_"
      },
      "source": [
        "# Compare Sentence SentimentR vs SyuzhetR SMA smoothed series\n",
        "\"\"\"\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Standardize SentimentR Mean Rolling\n",
        "sentimentr_mean_roll_np = np.array(corpus_sentimentr_df[f'mean_{roll_str}'])\n",
        "sentimentr_mean_roll_np = sentimentr_mean_roll_np.reshape((len(sentimentr_mean_roll_np), 1))\n",
        "\n",
        "scaler = scaler.fit(sentimentr_mean_roll_np)\n",
        "print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, np.sqrt(scaler.var_)))\n",
        "# standardization the dataset and print the first 5 rows\n",
        "sentimentr_mean_roll_norm_np = scaler.transform(sentimentr_mean_roll_np)\n",
        "\n",
        "# Standardize SyuzhetR Mean Rolling\n",
        "syuzhetr_mean_roll_np = np.array(corpus_syuzhetr_df[f'mean_{roll_str}'])\n",
        "syuzhetr_mean_roll_np = syuzhetr_mean_roll_np.reshape((len(syuzhetr_mean_roll_np), 1))\n",
        "\n",
        "scaler = scaler.fit(syuzhetr_mean_roll_np)\n",
        "print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, np.sqrt(scaler.var_)))\n",
        "# standardization the dataset and print the first 5 rows\n",
        "syuzhetr_mean_roll_norm_np = scaler.transform(syuzhetr_mean_roll_np)\n",
        "\n",
        "\n",
        "# Plot normalized Series\n",
        "plt.plot(sentimentr_mean_roll_norm_np, label=\"SentimentR\")\n",
        "plt.plot(syuzhetr_mean_roll_norm_np, label=\"SyuzhetR\")\n",
        "# plt.plot(transformer_mean_roll_norm_np, label=\"SyuzhetR\")\n",
        "\"\"\";\n",
        "\n",
        "# corpus_syuzhetr_df[f'mean_{roll_str}'].apply(lambda x: Scale_SyuzhetR*x).plot(label='SyuzhetR')\n",
        "col_mean_stdscaler_roll = f'mean_stdscaler_{roll_str}'\n",
        "\n",
        "col_all_sentimentr_stdscaler_roll_ls = []\n",
        "for x in models_sentimentr_ls:\n",
        "  col_name = f'{x}_stdscaler_{roll_str}'\n",
        "  col_all_sentimentr_stdscaler_roll_ls.append(col_name)\n",
        "corpus_sentimentr_df[col_mean_stdscaler_roll] = corpus_sentimentr_df[col_all_sentimentr_stdscaler_roll_ls].mean()\n",
        "\n",
        "col_all_syuzhetr_stdscaler_roll_ls = []\n",
        "for x in models_syuzhetr_ls:\n",
        "  col_name = f'{x}_stdscaler_{roll_str}'\n",
        "  col_all_syuzhetr_stdscaler_roll_ls.append(col_name)\n",
        "corpus_syuzhetr_df[col_mean_stdscaler_roll] = corpus_syuzhetr_df[col_all_syuzhetr_stdscaler_roll_ls].mean()\n",
        "\n",
        "# Plot\n",
        "plt.plot(corpus_sentimentr_df[col_mean_stdscaler_roll], label=f\"SentimentR Mean StdScaler {roll_str}\")\n",
        "plt.plot(corpus_syuzhetr_df[col_mean_stdscaler_roll], label=f\"SyuzhetR Mean StdScaler {roll_str}\")\n",
        "\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Sentence SentimentR vs Syuzhet Sentiments\\nMean Length-Normed MedianIQR Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twq2IuGz7vlR"
      },
      "source": [
        "# Compare Sentence SentimentR vs SyuzhetR SMA smoothed series\n",
        "# TODO: Delete or convert to fine grained/multi-model DTW/correlation\n",
        "\n",
        "# Create a unified DataFrame of Mean Roll_{win_per} from\n",
        "#     SentimentR and SyuzhetR\n",
        "\n",
        "col_mean_roll = f'mean_{roll_str}'\n",
        "\n",
        "compare_sentimentr_syuzhetr_df = pd.concat([\n",
        "    corpus_sentimentr_df[col_mean_roll],\n",
        "    corpus_syuzhetr_df[col_mean_roll]],\n",
        "    axis=1)\n",
        "\n",
        "col_sentimentr_mean_roll = f'sentimentr_{col_mean_roll}'\n",
        "col_syuzhetr_mean_roll = f'syuzhet_{col_mean_roll}'\n",
        "\n",
        "col_mapping = {\n",
        "    compare_sentimentr_syuzhetr_df.columns[0]:'sentimentr_mean_roll', \n",
        "    compare_sentimentr_syuzhetr_df.columns[1]:'syuzhet_mean_roll'\n",
        "}\n",
        "\n",
        "compare_sentimentr_syuzhetr_df.rename(columns=col_mapping,\n",
        "                                      inplace=True)\n",
        "\n",
        "# compare_sentimentr_syuzhetr_df.iloc[1000:1005]\n",
        "\n",
        "\n",
        "# Get correlation matrix of the comparison DataFrame\n",
        "corr_df = compare_sentimentr_syuzhetr_df.corr(method='spearman')\n",
        "\n",
        "# Customize the heatmap of the corr_meat correlation matrix and rotate the x-axis labels\n",
        "fig = sns.clustermap(corr_df,\n",
        "                     row_cluster=True,\n",
        "                     col_cluster=True,\n",
        "                     figsize=(10, 10))\n",
        "\n",
        "plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n",
        "plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yF6RbP2wegA"
      },
      "source": [
        "## **EDA Transformer Plots**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8wOUSyOSIVs"
      },
      "source": [
        "#### **(If not already exists) Import Transformer Sentiment Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5Trl2jZ1Yi8"
      },
      "source": [
        "# Verify SentimentR Sentiment Files exported from RStudio\n",
        "!pwd\n",
        "!ls -altr sum_sentiments*trans*.csv\n",
        "# sum_sentiments_sents_trans_vwoolf_tothelighthouse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnyvNjy91YjF"
      },
      "source": [
        "# Get SyuzhetR Sentiment Datafile (with data on 4 Models)\n",
        "\n",
        "Transformer_sentiment_datafile = 'sum_sentiments_sents_trans_emforster_howardsend.csv' #@param {type:\"string\"}\n",
        "\n",
        "sum_sentiments_transformer_filename = Transformer_sentiment_datafile\n",
        "\n",
        "!head -n 3 $sum_sentiments_transformer_filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcS5aT6RNLg6"
      },
      "source": [
        "corpus_transformer_df = pd.read_csv(sum_sentiments_transformer_filename)\n",
        "corpus_transformer_df.head(2)\n",
        "corpus_transformer_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWIakgmdoZ9g"
      },
      "source": [
        "corpus_transformer_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "corpus_transformer_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYZ7xFFDQrzD"
      },
      "source": [
        "# Add summary statistics\n",
        "\n",
        "corpus_transformer_df['sent_raw'] = corpus_transformer_df['sent_raw'].astype('string')\n",
        "corpus_transformer_df['sent_clean'] = corpus_transformer_df['sent_raw'].apply(lambda x: clean_text(x))\n",
        "corpus_transformer_df['sent_clean'] = corpus_transformer_df['sent_clean'].astype('string')\n",
        "\n",
        "corpus_transformer_df['char_len'] = corpus_transformer_df['sent_raw'].apply(lambda x: len(x))\n",
        "corpus_transformer_df['token_len'] = corpus_transformer_df['sent_clean'].apply(lambda x: len(x.split())) \n",
        "\n",
        "corpus_transformer_df.head(2)\n",
        "corpus_transformer_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgzWVkAYKqS-"
      },
      "source": [
        "# Create 4 Standardized versions of each Model: stdscaler, medianiqr both lnormed and not\n",
        "\n",
        "print('\\nBefore Standardization ----------')\n",
        "corpus_transformer_df.columns\n",
        "\n",
        "standardize_ts_ls(corpus_transformer_df, models_transformer_ls)\n",
        "\n",
        "print('\\nAfter Standardization ----------')\n",
        "corpus_transformer_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rItZhTmgC9Bv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S5kvZ79C91M"
      },
      "source": [
        "# Create 4 Standardized versions of each Model: stdscaler, medianiqr both lnormed and not\n",
        "\n",
        "print('\\nBefore Standardization ----------')\n",
        "corpus_transformer_df.columns\n",
        "\n",
        "standardize_ts_ls(corpus_transformer_df, models_transformer_ls)\n",
        "\n",
        "print('\\nAfter Standardization ----------')\n",
        "corpus_transformer_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdqyG_INC91P"
      },
      "source": [
        "# Create SMA roll=10% for all models_stdscaler as baseline\n",
        "\n",
        "win_s1per = int(corpus_transformer_df.shape[0] * 1/100)\n",
        "\n",
        "col_stdscaler_roll_ls = []\n",
        "for amodel in models_transformer_ls:\n",
        "  col_stdscaler = f'{amodel}_stdscaler'\n",
        "  col_stdscaler_roll = f'{amodel}_stdscaler_{roll_str}'\n",
        "  corpus_transformer_df[col_stdscaler_roll] = corpus_transformer_df[col_stdscaler].rolling(10*win_s1per, center=True).mean()\n",
        "  col_stdscaler_roll_ls.append(col_stdscaler_roll)\n",
        "\n",
        "col_stdscaler_roll_mean = col_stdscaler_roll + '_mean'\n",
        "corpus_transformer_df[col_stdscaler_roll_mean] = corpus_transformer_df[col_stdscaler_roll_ls].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP5laVK8Ee9a"
      },
      "source": [
        "# Create SMA roll=10% for all models_stdscaler as baseline\n",
        "\n",
        "\"\"\"\n",
        "win_s1per = int(corpus_transformer_df.shape[0] * 1/100)\n",
        "\n",
        "col_stdscaler_roll_ls = []\n",
        "for amodel in models_transformer_ls:\n",
        "  col_stdscaler = f'{amodel}_stdscaler'\n",
        "  col_stdscaler_roll = f'{amodel}_stdscaler_{roll_str}'\n",
        "  corpus_transformer_df[col_stdscaler_roll] = corpus_transformer_df[col_stdscaler].rolling(10*win_s1per, center=True).mean()\n",
        "  col_stdscaler_roll_ls.append(col_stdscaler_roll)\n",
        "\n",
        "col_stdscaler_roll_mean = col_stdscaler_roll + '_mean'\n",
        "corpus_transformer_df[col_stdscaler_roll_mean] = corpus_transformer_df[col_stdscaler_roll_ls].mean()\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_iGanTXZSGB"
      },
      "source": [
        "# Standardize all values with MedianIQR\n",
        "\"\"\"\n",
        "# model_transformers_ls = ['nlptown', 'roberta15lg', 'yelp', 'hinglish', 'imdb2way', 'huggingface', 't5imdb50k', 'robertaxml8lang']\n",
        "\n",
        "for model_transformer in models_transformer_ls:\n",
        "\n",
        "  # Normalize the Sentence Sentiment by dividing Sentiment by Sentence Length\n",
        "  sents_len_ls = list(corpus_transformer_df['token_len'])\n",
        "  sents_sentiment_ls = list(corpus_transformer_df[model_transformer])\n",
        "  sents_sentiment_norm_ls = [sents_sentiment_ls[i]/(sents_len_ls[i]+0.01) for i in range(len(sents_len_ls))]\n",
        "\n",
        "  # RobustStandardize Sentence sentiment values\n",
        "  # corpus_transformer_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(sents_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  col_medianiqr = f'{model_transformer}_medianiqr'\n",
        "  corpus_transformer_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(corpus_transformer_df[model_transformer]).reshape(-1, 1))\n",
        "  col_lnorm_medianiqr = f'{model_transformer}_lnorm_medianiqr'\n",
        "  corpus_transformer_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(sents_sentiment_norm_ls)).reshape(-1, 1))\n",
        "\n",
        "  # Verify\n",
        "\n",
        "corpus_transformer_df.head()\n",
        "corpus_transformer_df.info()\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNeuepF33Zyu"
      },
      "source": [
        "#### **Interactive Sentence SMA Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfwwefDOXqq8"
      },
      "source": [
        "RoBERTaLg15_Arc = True #@param {type:\"boolean\"}\n",
        "T5IMDB50k_Arc = True #@param {type:\"boolean\"}\n",
        "Huggingface_Arc = True #@param {type:\"boolean\"}\n",
        "NLPTown_Arc = True #@param {type:\"boolean\"}\n",
        "RoBERTaXML8lang_Arc = True #@param {type:\"boolean\"}\n",
        "IMDB2way_Arc = True #@param {type:\"boolean\"}\n",
        "Hinglish_Arc = True #@param {type:\"boolean\"}\n",
        "Yelp_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_Subset_Arc = True #@param {type:\"boolean\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viS52Ls6vrmo"
      },
      "source": [
        "models_transformer_ls\n",
        "corpus_transformer_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqYU6I5uWeGc"
      },
      "source": [
        "# Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "win_per = SMA_Window_Percent\n",
        "win_roll = int(win_per/100 * corpus_transformer_df.shape[0])\n",
        "\n",
        "if len(str(win_per)) == 1:\n",
        "  roll_str = 'roll0' + str(win_per)\n",
        "else:\n",
        "  roll_str = 'roll' + str(win_per)\n",
        "\n",
        "# display(corpus_transformer_df.head())\n",
        "\n",
        "\"\"\"\n",
        "model_transformers_ls = ['nlptown', 'roberta15lg',\n",
        "                         'yelp', 'hinglish',\n",
        "                         'imdb2way', 'huggingface',\n",
        "                         't5imdb50k', 'robertaxml8lang']\n",
        "\"\"\"\n",
        "\n",
        "# list of (scale, center) adjustments for each model so they can be compared on same graph\n",
        "# Scaling Dictionary for each plot in form of tuple (scale, center) \n",
        "#     so they can be compared on same graph\n",
        "model_transformers_scale_dt = {'nlptown' : (0.5, -1),\n",
        "                               'roberta15lg' : (1,0),\n",
        "                               'yelp' : (1.0, 0.5),\n",
        "                               'hinglish' : (1.0, 0.5),\n",
        "                               'imdb2way' : (1.0, 0.5),\n",
        "                               'huggingface' : (1.0, 0.5),\n",
        "                               't5imdb50k' : (1.0, 0.5),\n",
        "                               'robertxml8lang' : (1.0, 0.5)}\n",
        "col_name_roll_ls = []\n",
        "# fig, ax = plt.subplots()\n",
        "for amodel in models_transformer_ls:\n",
        "  # if not(amodel.endswith('roll050')):\n",
        "  # col_name_roll = f'{amodel}_lnorm_medianiqr_{roll_str}'\n",
        "  col_name_roll = f'{amodel}_{roll_str}'\n",
        "  col_name_roll_ls.append(col_name_roll)\n",
        "  # else:\n",
        "  #   col_name_roll_ls.append(amodel)\n",
        "  # print(f'creating: {col_name_roll}')\n",
        "  corpus_transformer_df[col_name_roll] = corpus_transformer_df[amodel].rolling(win_roll, center=True).mean()\n",
        "\n",
        "  col_name_roll_stdscale = f'{col_name_roll}_stdscale'\n",
        "  corpus_transformer_df[col_name_roll_stdscale] = get_standardscaler(col_name_roll, corpus_transformer_df[col_name_roll])\n",
        "\n",
        "\n",
        "col_mean_roll = 'mean_lnorm_medianiqr_' + roll_str\n",
        "# model_transformers_lnorm_medianiqr_ls = []\n",
        "corpus_transformer_df[col_mean_roll] = corpus_transformer_df[col_name_roll_ls].mean(axis=1)\n",
        "\n",
        "col_mean_lnorm_median_roll = 'mean_lnorm_medianiqr_' + roll_str\n",
        "model_transformers_lnorm_medianiqr_ls = []\n",
        "for acol_name in models_transformer_ls:\n",
        "  # model_transformers_lnorm_medianiqr_ls.append(acol_name+'_lnorm_medianiqr_'+roll_str)\n",
        "  model_transformers_lnorm_medianiqr_ls.append(acol_name+ '_' +roll_str + '_stdscale')\n",
        "corpus_transformer_df[col_mean_lnorm_median_roll] = corpus_transformer_df[model_transformers_lnorm_medianiqr_ls].mean(axis=1)\n",
        "\n",
        "\n",
        "# display(corpus_transformer_df.head())\n",
        "\n",
        "\n",
        "model_transformers_subset_ls = []\n",
        "\n",
        "\n",
        "if NLPTown_Arc == True:\n",
        "  model_transformers_subset_ls.append(f'nlptown_{roll_str}_stdscale')\n",
        "if T5IMDB50k_Arc == True:\n",
        "  model_transformers_subset_ls.append(f't5imdb50k_{roll_str}_stdscale')\n",
        "if Huggingface_Arc == True:\n",
        "  model_transformers_subset_ls.append(f'huggingface_{roll_str}_stdscale')\n",
        "if RoBERTaLg15_Arc == True:\n",
        "  model_transformers_subset_ls.append(f'roberta15lg_{roll_str}_stdscale')\n",
        "if RoBERTaXML8lang_Arc == True:\n",
        "  model_transformers_subset_ls.append(f'robertaxml8lang_{roll_str}_stdscale')\n",
        "  #                                     robertaxml8lang_roll100_stdscale\n",
        "if IMDB2way_Arc == True:\n",
        "  model_transformers_subset_ls.append(f'imdb2way_{roll_str}_stdscale')\n",
        "if Hinglish_Arc == True:\n",
        "  model_transformers_subset_ls.append(f'hinglish_{roll_str}_stdscale')\n",
        "if Yelp_Arc == True:\n",
        "  model_transformers_subset_ls.append(f'yelp_{roll_str}_stdscale')\n",
        "\n",
        "\"\"\"\n",
        "# Manually adjust for custom French Models\n",
        "\n",
        "model_transformers_subset_ls = ['flaubert_roll10_stdscale', \n",
        "                                'nlptown_roll10_stdscale', \n",
        "                                'robertaxml8lang_roll10_stdscale']\n",
        "\"\"\"\n",
        "\n",
        "for i,amodel in enumerate(model_transformers_subset_ls):\n",
        "  print(f'Plot model: {amodel}')\n",
        "  # corpus_transformer_df[amodel].plot()\n",
        "\n",
        "print(f'model_transformers_subset_ls: {model_transformers_subset_ls}')\n",
        "\n",
        "\"\"\"\n",
        "col_mean_subset_roll = f'mean_subset_{roll_str}'\n",
        "corpus_transformer_df[col_mean_subset_roll] = corpus_transformer_df[model_transformers_subset_ls].mean(axis=1)\n",
        "if Mean_Subset_Arc == True:\n",
        "  model_transformers_subset_ls.append(col_mean_subset_roll)\n",
        "\"\"\";\n",
        "\n",
        "palette = cycle(px.colors.qualitative.Bold)\n",
        "# palette = cycle(px.colors.sequential.PuBu)\n",
        "\n",
        "my_layout = go.Layout(\n",
        "    autosize=False,\n",
        "    width=1600,\n",
        "    height=800,\n",
        "    margin=go.layout.Margin(\n",
        "        l=10,\n",
        "        r=50,\n",
        "        b=100,\n",
        "        t=100,\n",
        "        pad = 1\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "fig = go.Figure(layout=my_layout)\n",
        "\n",
        "# add traces\n",
        "# old: y = model_transformers_subset_ls[i][0]*corpus_transformer_df[amodel]+model_baselines_scale_ls[i][1],\n",
        "for amodel in model_transformers_subset_ls:\n",
        "  # print(f'Plot model: {amodel}')\n",
        "  # corpus_transformer_df[amodel].plot()\n",
        "  fig.add_traces(go.Line(x = corpus_transformer_df['sent_no'],\n",
        "                        y = corpus_transformer_df[amodel],\n",
        "                        text = corpus_transformer_df['sent_raw'],\n",
        "                        name = amodel,\n",
        "                        hovertemplate = \"Model: <b>\"+amodel+\"</b><br>Sentence #<b>%{x}</b><br>Polarity <b>%{y}</b><br>Text: <b><i>%{text}</i></b>\", \n",
        "                        marker_color=next(palette)))\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "if Mean_Subset_Arc == True:\n",
        "  mean_subset_col = 'mean_subset_'+roll_str\n",
        "  corpus_transformer_df[mean_subset_col] = corpus_transformer_df[model_transformers_subset_ls].mean(axis=1)\n",
        "  fig.add_traces(go.Line(x=corpus_transformer_df['sent_no'],\n",
        "                        y = 0.1*corpus_transformer_df[mean_subset_col],\n",
        "                        line=dict(\n",
        "                              # color='#000000',\n",
        "                              width=5\n",
        "                              ),\n",
        "                        text = 'NA', # corpus_transformer_df['sent_raw'],\n",
        "                        name = amodel,\n",
        "                        hovertemplate = \"Model <b>%{mean_subset_col}</b><br>Sentence #<b>%{x}</b><br>Polarity <b>%{y}</b>\", \n",
        "                        marker_color=next(palette)))\n",
        "\"\"\";\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Transformer Sentence Sentiment Models <b><i>\" + roll_str.upper() + '</i></b>',\n",
        "    xaxis_title=\"Sentence Number\",\n",
        "    # yaxis_title=\"Sentiment Value\",\n",
        "    hoverlabel=dict(\n",
        "        bgcolor=\"white\",\n",
        "        font_size=16,\n",
        "        font_family=\"Rockwell\"\n",
        "    ),\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=18,\n",
        "        color=\"RebeccaPurple\"\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UWlGJ1IQG9t"
      },
      "source": [
        "#### **Comparison of Sentence Transformer Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiUBs2-go_yi"
      },
      "source": [
        "# Compare Sentence Transformer Standardized Sentiment Values\n",
        "\n",
        "# model_syuzhetr_ls = ['syuzhet', 'bing', 'afinn', 'nrc']\n",
        "\n",
        "model_transformer_standardized_roll_ls = []\n",
        "for amodel in models_transformer_ls:\n",
        "  col_roll_name = f'{amodel}_{roll_str}'  # TODO: drop lnorm_medianiqr earlier and just Standardize here\n",
        "                                                     # NOTE: Simple SciPy StandardScaler works on SMA Series that don't have outliers like Raw Series\n",
        "  # print(f'col_name: {col_name}')\n",
        "  model_transformer_standardized_roll_ls.append(col_roll_name)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i,arollmodel in enumerate(model_transformer_standardized_roll_ls):\n",
        "  print(f'Processing model: {arollmodel}')\n",
        "  col_name_roll_stand = f'{arollmodel}_stdscale'\n",
        "  # print(f'col_name_roll_stand: {col_name_roll_stand}')\n",
        "  model_roll_stand_np = np.array(corpus_transformer_df[arollmodel])\n",
        "  # .apply(lambda x: Scale_SentimentR*x))\n",
        "  \n",
        "  model_roll_stand_np = model_roll_stand_np.reshape((len(model_roll_stand_np), 1))\n",
        "\n",
        "  scaler = scaler.fit(model_roll_stand_np)\n",
        "  print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, np.sqrt(scaler.var_)))\n",
        "  model_roll_stand_xform_np = scaler.transform(model_roll_stand_np)\n",
        "\n",
        "  print(f'  Adding StdScaler Column: {col_name_roll_stand}')\n",
        "  corpus_transformer_df[col_name_roll_stand] = pd.Series(model_roll_stand_xform_np.flatten())\n",
        "\n",
        "  # Plot\n",
        "  corpus_transformer_df[col_name_roll_stand].plot(label=arollmodel) # label=col_name_roll_stand))\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Sentence Transformer Sentiments\\nMean Length-Normed MedianIQR Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16QqsYHTdYqY"
      },
      "source": [
        "#### **(ABOVE) Plotly SMA Sentence, (BELOW) Correlation Heatmap**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD3H_yQcLu8O"
      },
      "source": [
        "# Create a comparison DataFrame of Transformer Sentence Models\n",
        "# Create a comparison DataFrame of Transformer Sentence Models\n",
        "# Sentence Heatmap Correlation of StdScaler Roll100 Sentiments\n",
        "# Depends on 'col_stdscaler_rollwin_ls' defined in prior code cell\n",
        "\n",
        "Correlation_Algo = \"pearson\" #@param [\"pearson\", \"spearman\", \"kendall\"]\n",
        "\n",
        "Correlation_Algo\n",
        "\n",
        "corr_df = corpus_transformer_df[models_transformer_ls].corr(method=Correlation_Algo)\n",
        "\n",
        "# Customize the heatmap of the corr_meat correlation matrix and rotate the x-axis labels\n",
        "fig = sns.clustermap(corr_df,\n",
        "                     row_cluster=True,\n",
        "                     col_cluster=True,\n",
        "                     figsize=(10, 10))\n",
        "\n",
        "plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n",
        "plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
        "plt.title(f'{CORPUS_FULL} Sentence Sentiment for Transformer Model Sentiments\\n {Correlation_Algo.capitalize()} Correlation - StdScale Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkaD9lRIpsYV"
      },
      "source": [
        "#### **Sentence Sentiment DTW Hierarichal Clustering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqnwt6ygQJws"
      },
      "source": [
        "# Compare Sentence Transformer Standardized Sentiment Values\n",
        "\"\"\"\n",
        "model_transformers_ls = ['nlptown', 'roberta15lg',\n",
        "                         'yelp', 'hinglish',\n",
        "                         'imdb2way', 'huggingface',\n",
        "                         't5imdb50k', 'robertaxml8lang']\n",
        "\n",
        "model_trans_standardized_roll_ls = []\n",
        "for amodel in model_transformers_ls:\n",
        "  col_name = f'{amodel}_{roll_str}_stdscale'  # TODO: drop lnorm_medianiqr earlier and just Standardize here\n",
        "                                                     # NOTE: Simple SciPy StandardScaler works on SMA Series that don't have outliers like Raw Series\n",
        "  # print(f'col_name: {col_name}')\n",
        "  model_trans_standardized_roll_ls.append(col_name)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i,amodel in enumerate(model_trans_standardized_roll_ls):\n",
        "  col_name_roll_stand = f'{col_name}_stand'\n",
        "  # print(f'col_name_roll_stand: {col_name_roll_stand}')\n",
        "  model_roll_stand_np = np.array(corpus_transformer_df[amodel])\n",
        "  # .apply(lambda x: Scale_SentimentR*x))\n",
        "  \n",
        "  model_roll_stand_np = model_roll_stand_np.reshape((len(model_roll_stand_np), 1))\n",
        "\n",
        "  scaler = scaler.fit(model_roll_stand_np)\n",
        "  print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, np.sqrt(scaler.var_)))\n",
        "  model_roll_stand_xform_np = scaler.transform(model_roll_stand_np)\n",
        "\n",
        "  corpus_transformer_df[col_name_roll_stand] = pd.Series(model_roll_stand_xform_np.flatten())\n",
        "\n",
        "  # Plot\n",
        "  corpus_transformer_df[col_name_roll_stand].plot(label=amodel) # label=col_name_roll_stand))\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Sentence Transformer Sentiments\\nMean Length-Normed MedianIQR Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhnAu46O7aq_"
      },
      "source": [
        "#### **Top-n Crux Peaks and Valleys**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpKbmbsCNFI7"
      },
      "source": [
        "**Search Corpus for Substring**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* In [Search_for_Substring] enter a Substring to search for in the Corpus\n",
        "\n",
        "* Enter a Substring long enough/unique enough so only a reasonable number of Sentences will be returned\n",
        "\n",
        "* Substring can contain spaces/punctuation, for example: 'in the garden'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b35u0YDONFI9"
      },
      "source": [
        "# Search Corpus Sentences for Substring\n",
        "\n",
        "Search_for_Substring = \"love\" #@param {type:\"string\"}\n",
        "\n",
        "sentno_matching_ls = corpus_sents_df[corpus_sents_df['sent_raw'].str.contains(Search_for_Substring, regex=False)]['sent_no']\n",
        "\n",
        "for i, asentno in enumerate(sentno_matching_ls):\n",
        "  # sentno, sentraw = asent\n",
        "  print(f\"\\n\\nMatch #{i}: Sentence #{asentno}\\n\\n\")\n",
        "  sent_highlight = re.sub(Search_for_Substring, Search_for_Substring.upper(), corpus_sents_df.iloc[asentno]['sent_raw'])\n",
        "  print(f'    {sent_highlight}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTFCZI667arB"
      },
      "source": [
        "**Plot Top-n Crux Peaks/Valleys for selected Model**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Crux_Window_Percent] exclusive zone around Crux Points as a percentage of Corpus length\n",
        "\n",
        "* [Sentiment_Model] Select a Sentiment Analysis model\n",
        "\n",
        "* Select [Anomaly_Detction] to plot raw Sentiment values to detect outlier/anomaly Sentences. Leave unchecked to plot SMA smoothed Sentiment arc and detect Crux points\n",
        "\n",
        "* Select [Save_to_File] to also save plot to external *.png file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSmeqWhSx8Wt"
      },
      "source": [
        "models_transformer_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xeZ5Qhb7arB"
      },
      "source": [
        "Crux_Window_Percent = 5 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "Transformer_SMA_Model = \"RoBERTa XML 8 Languages\" #@param [\"RoBERTa Large 15 Databases\", \"NLPTown\", \"Yelp\", \"Hinglish\", \"IMDB 2 Sentiment\", \"Huggingface\", \"T5 IMDB 50k\", \"RoBERTa XML 8 Languages\"]\n",
        "Anomaly_Detection = False #@param {type:\"boolean\"}\n",
        "Vertical_Labels = True #@param {type:\"boolean\"}\n",
        "Vertical_Labels_Height = -1.7 #@param {type:\"slider\", min:-50, max:50, step:0.1}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "if Transformer_SMA_Model == 'RoBERTa Large 15 Databases':\n",
        "  model_selected = f'roberta15lg'\n",
        "if Transformer_SMA_Model == 'NLPTown':\n",
        "  model_selected = f'nlptown'\n",
        "if Transformer_SMA_Model == 'Yelp':\n",
        "  model_selected = f'yelp'\n",
        "if Transformer_SMA_Model == 'Hinglish':\n",
        "  model_selected = f'hinglish'\n",
        "if Transformer_SMA_Model == 'IMDB 2 Sentiment':\n",
        "  model_selected = f'imdb2way'\n",
        "if Transformer_SMA_Model == 'Huggingface':\n",
        "  model_selected = f'huggingface'\n",
        "if Transformer_SMA_Model == 'T5 IMDB 50k':\n",
        "  model_selected = f't5imdb50k'\n",
        "if Transformer_SMA_Model == 'RoBERTa XML 8 Languages':\n",
        "  model_selected = f'robertaxml8lang'\n",
        "\n",
        "if Anomaly_Detection == False:\n",
        "  # (a) Use Sentence SMA smoothed Sentiment models to detect Crux Points\n",
        "  model_selected_fullname = f'{model_selected}_{roll_str}_stdscale'\n",
        "else:\n",
        "  # (b)Use Sentence Raw Sentiment models to detect outliers\n",
        "  model_selected_fullname = f'{model_selected}'\n",
        "\n",
        "# TODO: enable multiple overlay crux points with underlying mean/median arc\n",
        "corpus_models_selected_ls = [model_selected_fullname]\n",
        "print(f'corpus_models_selected_ls: {corpus_models_selected_ls}')\n",
        "\n",
        "# Warning: requires definitions of: x, section_sents_df\n",
        "#          so Baseline models must be run first\n",
        "\n",
        "\n",
        "for amodel in corpus_models_selected_ls:\n",
        "  corpus_cruxes_all_dt[amodel] = get_crux_points(ts_df=corpus_transformer_df, \n",
        "                                         col_series=corpus_models_selected_ls, \n",
        "                                         # Manually adjust for special French Models\n",
        "                                         # col_series=['robertaxml8lang_roll10_stdscale'], \n",
        "                                         text_type='sentence', \n",
        "                                         win_per=Crux_Window_Percent, \n",
        "                                         sec_y_labels=Vertical_Labels,\n",
        "                                         sec_y_height=Vertical_Labels_Height, \n",
        "                                         subtitle_str='5% Crux - ', \n",
        "                                         do_plot=True, \n",
        "                                         save2file=False)\n",
        "  \n",
        "model_crux_ls = corpus_cruxes_all_dt[amodel]\n",
        "# model_crux_ls;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdGGia83NqcF"
      },
      "source": [
        "corpus_sentimentr_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utHumiBkNgeT"
      },
      "source": [
        "corpus_transformer_df.shape\n",
        "corpus_sents_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P34IC3Kh7arD"
      },
      "source": [
        "### **Context around Top-n Crux Peaks/Valleys**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Get_Peak_Cruxes] to retrieve Peaks (if unchecked Valleys are retrieved)\n",
        "\n",
        "* [Get_n_Cruxes] determines how many Top-n Cruxes to retrieve\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99RhVdHc7arE"
      },
      "source": [
        "# Crux Point Details\n",
        "Get_Peak_Cruxes = False #@param {type:\"boolean\"}\n",
        "Get_n_Cruxes = 20 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "Sort_by_SentenceNo = True #@param {type:\"boolean\"}\n",
        "\n",
        "# Context Details\n",
        "No_Paragraphs_on_Each_Side = 2 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "Highlight_Sentence = True #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "if Sort_by_SentenceNo == True:\n",
        "  sort_on = 'sent_no'\n",
        "else:\n",
        "  sort_on = 'sentiment_val'\n",
        "\n",
        "print(f'Crux Report --------------------\\n')\n",
        "print(f'            Corpus: {CORPUS_FULL}')\n",
        "print(f'            Model: {Transformer_SMA_Model}')\n",
        "print(f'            Crux Win%: {Crux_Window_Percent}')\n",
        "print(f'            SMA Win%: {roll_str}')\n",
        "\n",
        "if Save_to_Report == False:\n",
        "  crux_sortsents_report(model_crux_ls, \n",
        "                        ts_df = corpus_transformer_df,\n",
        "                        library_type='transformer',\n",
        "                        top_n=Get_n_Cruxes, \n",
        "                        get_peaks=Get_Peak_Cruxes, \n",
        "                        sort_by = sort_on, # sent_no, or abs(polarity)\n",
        "                        n_sideparags=No_Paragraphs_on_Each_Side,\n",
        "                        sentence_highlight=Highlight_Sentence)\n",
        "\n",
        "\n",
        "else:\n",
        "  # https://www.kite.com/python/answers/how-to-get-stdout-and-stderr-from-a-process-as-a-string-in-python\n",
        "  # process = subprocess.run([\"echo\", \"This goes to stdout\"], capture_output=True)\n",
        "  # stdout_as_str = process.stdout.decode(\"utf-8\")\n",
        "  # print(stdout_as_str)\n",
        "  temp_out = StringIO()\n",
        "  sys.stdout = temp_out\n",
        "  crux_sortsents_report(model_crux_ls, top_n=Get_n_Cruxes, get_peaks=Get_Peak_Cruxes, n_sideparags=No_Paragraphs_on_Each_Side)\n",
        "  print(temp_out)\n",
        "  # attempt to save temp_out to generated filename\n",
        "  sys.stdout = sys.__stdout__\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y90bCSB7arF"
      },
      "source": [
        "**Zoom in on Context surrounding a particular Crux Point**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Enter [Crux_Sentence_No] that matches a Crux point/Sentence No you want to explore\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFi5kyx-7arG"
      },
      "source": [
        "# Select details about the Crux Point Context to Retrieve\n",
        "\n",
        "# print(f'Last Sentence No: {corpus_sents_df.shape[0]}')\n",
        "Crux_Sentence_No =  1047#@param {type:\"number\"}\n",
        "No_Paragraphs_on_Each_Side = 3 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "Highlight_Crux_Sentence = True #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "corpus_sents_len = corpus_sents_df.shape[0]\n",
        "\n",
        "# if (Crux_Sentence_No >= No_Paragraphs_on_Each_Side) & (Crux_Sentence_No+No_Paragraphs_on_Each_Side <= corpus_parag_len):\n",
        "# get_sentnocontext_report()\n",
        "# try:\n",
        "\n",
        "# get_sentnocontext_report(the_sent_no=Crux_Sentence_No, the_n_sideparags=No_Paragraphs_on_Each_Side, the_sent_highlight=Highlight_Crux_Sentence)\n",
        "\n",
        "get_sentnocontext_report(ts_df=corpus_transformer_df, \n",
        "                         the_sent_no=Crux_Sentence_No, \n",
        "                         the_n_sideparags=No_Paragraphs_on_Each_Side, \n",
        "                         the_sent_highlight=Highlight_Crux_Sentence)\n",
        "# except:\n",
        "#   print('ERROR')\n",
        "# else:\n",
        "#   print(f'ERROR: The combination of your [Crux_Sentence_No] and [No_Pargraphs_on_Each_Side]\\n       results in a window outside the range of the Corpus Paragraphs.\\n\\n       Try again with different values.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Xv7Ah7zVpux"
      },
      "source": [
        "### **Stop Here (Paragraph Under Construction)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRjHsOIpXovL"
      },
      "source": [
        "##### **Paragraph Transformers SMA Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBrSjSA4Qytu"
      },
      "source": [
        "# (Optional) Read Paragraph Sentiment Data generated by Transformers into DataFrame: corpus_parags_trans_df\n",
        "#            SKIP if no Transformer Paragraph Sentiment datafile to read in\n",
        "\n",
        "sum_sentiment_parags_transformers_filename = 'sum_sentiments_sents_transformers_ianmcewan_machineslikeme.csv'\n",
        "corpus_parags_trans_df = pd.read_csv(sum_sentiment_parags_transformers_filename)\n",
        "\n",
        "# Optional columns to drop\n",
        "corpus_parags_trans_df.drop(columns=['bertsst_pol', 'bertsst_prob'], axis=1, inplace=True)\n",
        "\n",
        "corpus_parags_trans_df.head(2)\n",
        "corpus_parags_trans_df.info()\n",
        "corpus_parags_trans_df.columns\n",
        "\n",
        "\"\"\"\n",
        "corpus_parags_trans_len = corpus_parags_trans_df.shape[0]\n",
        "\n",
        "if corpus_parags_trans_len != corpus_sents_df.shape[0]:\n",
        "  print('\\n\\n\\n======================================================================\\n')\n",
        "  print(f'ERROR: sentence sentiment values read into corpus_syuzhetr (len={corpus_transformers_len})')\n",
        "  print(f'       is not the same length as corpus_parags_trans_df (len={corpus_parags_trans_df.shape[0]}) ')\n",
        "  print(f'\\nRECOMMENDATION: Use the preprocessed corpus output created by this notebook ')\n",
        "  print(f'                as input to SyuzhetR in RStudio to generate sentiment series')\n",
        "  print(f'                and then retry importing')\n",
        "  print('\\n======================================================================\\n')\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h1hIcSobYfQ"
      },
      "source": [
        "# Standardize all values with MedianIQR\n",
        "\n",
        "model_transformers_ls = ['nlptown', 'robertalg15', 'distillbertsst', 'bertsst']\n",
        "\n",
        "for model_transformer in model_transformers_ls:\n",
        "\n",
        "  # Normalize the Sentence Sentiment by dividing by Chapter Length\n",
        "  parags_len_ls = list(corpus_parags_trans_df['token_len'])\n",
        "  parags_sentiment_ls = list(corpus_parags_trans_df[model_transformer])\n",
        "  parags_sentiment_norm_ls = [parags_sentiment_ls[i]/parags_len_ls[i] for i in range(len(parags_len_ls))]\n",
        "\n",
        "  # RobustStandardize Sentence sentiment values\n",
        "  # corpus_parags_trans_df[col_lnorm_meanstd]  = mean_std_scaler.fit_transform(np.array(pd.Series(parags_sentiment_norm_ls)).reshape(-1, 1))\n",
        "  col_medianiqr = f'{model_transformer}_medianiqr'\n",
        "  corpus_parags_trans_df[col_medianiqr]  = median_iqr_scaler.fit_transform(np.array(corpus_parags_trans_df[model_transformer]).reshape(-1, 1))\n",
        "  col_lnorm_medianiqr = f'{model_transformer}_lnorm_medianiqr'\n",
        "  corpus_parags_trans_df[col_lnorm_medianiqr]  = median_iqr_scaler.fit_transform(np.array(pd.Series(parags_sentiment_norm_ls)).reshape(-1, 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2ee-U3HUbre"
      },
      "source": [
        "# Calculate Transformer Rolling Windows = win_per of Corpus (default 5%)\n",
        "\n",
        "\n",
        "\n",
        "win_per = 10           \n",
        "win_roll = int(win_per/100 * corpus_parags_trans_df.shape[0])\n",
        "\n",
        "# model_transformers_ls = ['nlptown', 'robertalg15', 'distillbertsst', 'bertsst']\n",
        "model_transformers_ls = ['nlptown_lnorm_medianiqr', 'robertalg15_lnorm_medianiqr', 'distillbertsst_lnorm_medianiqr', 'bertsst_lnorm_medianiqr']\n",
        "\n",
        "col_name_roll_ls = []\n",
        "# fig, ax = plt.subplots()\n",
        "for amodel in model_transformers_ls:\n",
        "  # if not(amodel.endswith('roll050')):\n",
        "  col_name_roll = f'{amodel}_roll050'\n",
        "  col_name_roll_ls.append(col_name_roll)\n",
        "  # else:\n",
        "  #   col_name_roll_ls.append(amodel)\n",
        "  corpus_parags_trans_df[col_name_roll] = corpus_parags_trans_df[amodel].rolling(win_roll, center=True).mean()\n",
        "\n",
        "corpus_parags_trans_df['mean_all_roll050'] = corpus_parags_trans_df[col_name_roll_ls].mean(axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Kh--NklUbmp"
      },
      "source": [
        "NLPTown_Arc = True #@param {type:\"boolean\"}\n",
        "RoBERTaLg15_Arc = True #@param {type:\"boolean\"}\n",
        "DistillBERTSST_Arc = True #@param {type:\"boolean\"}\n",
        "BERTSST_Arc = True #@param {type:\"boolean\"}\n",
        "Mean_Subset_Arc = True #@param {type:\"boolean\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr4Wqoh36V29"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "col_name_roll_ls = []\n",
        "# fig, ax = plt.subplots()\n",
        "for amodel in model_transformers_ls:\n",
        "  # if not(amodel.endswith('roll050')):\n",
        "  if len(str(win_per)) == 1:\n",
        "    roll_str = 'roll0' + str(win_per) + '0'\n",
        "  else:\n",
        "    roll_str = 'roll' + str(win_per) + '0'\n",
        "  col_name_roll = f'{amodel}_lnorm_medianiqr_{roll_str}'\n",
        "  col_name_roll_ls.append(col_name_roll)\n",
        "  # else:\n",
        "  #   col_name_roll_ls.append(amodel)\n",
        "  corpus_sents_trans_df[col_name_roll] = corpus_sents_trans_df[amodel].rolling(win_roll, center=True).mean()\n",
        "\n",
        "col_mean_roll = 'mean_' + roll_str\n",
        "model_transformers_lnorm_medianiqr_ls = []\n",
        "corpus_sents_trans_df[col_mean_roll] = corpus_sents_trans_df[model_transformers_lnorm_medianiqr_ls].mean(axis=1)\n",
        "\n",
        "col_mean_lnorm_median_roll = 'mean_lnorm_medianiqr_' + roll_str\n",
        "model_transformers_lnorm_medianiqr_ls = []\n",
        "for acol_name in model_transformers_ls:\n",
        "  model_transformers_lnorm_medianiqr_ls.append(acol_name+'_lnorm_medianiqr_'+roll_str)\n",
        "corpus_sents_trans_df[col_mean_lnorm_median_roll] = corpus_sents_trans_df[model_transformers_lnorm_medianiqr_ls].mean(axis=1)\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IVvASZFUbdJ"
      },
      "source": [
        "# Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "win_per = SMA_Window_Percent\n",
        "win_roll = int(win_per/100 * corpus_parags_trans_df.shape[0])\n",
        "\n",
        "if len(str(win_per)) == 1:\n",
        "  roll_str = 'roll0' + str(win_per)\n",
        "else:\n",
        "  roll_str = 'roll' + str(win_per)\n",
        "\n",
        "# display(corpus_sents_df.head())\n",
        "\n",
        "model_transformers_ls = ['nlptown', 'robertalg15', 'distillbertsst', 'bertsst']\n",
        "\n",
        "# list of (scale, center) adjustments for each model so they can be compared on same graph\n",
        "model_transformers_scale_ls = [(0.3, -0.6), (1,0.1), (1,0.1), (1,0.1)]\n",
        "\n",
        "col_name_roll_ls = []\n",
        "# fig, ax = plt.subplots()\n",
        "for amodel in model_transformers_ls:\n",
        "  # if not(amodel.endswith('roll050')):\n",
        "  col_name_roll = f'{amodel}_lnorm_medianiqr_{roll_str}'\n",
        "  col_name_roll_ls.append(col_name_roll)\n",
        "  # else:\n",
        "  #   col_name_roll_ls.append(amodel)\n",
        "  print(f'creating: {col_name_roll}')\n",
        "  corpus_parags_trans_df[col_name_roll] = corpus_parags_trans_df[amodel].rolling(win_roll, center=True).mean()\n",
        "\n",
        "col_mean_roll = 'mean_lnorm_medianiqr_' + roll_str\n",
        "# model_transformers_lnorm_medianiqr_ls = []\n",
        "corpus_parags_trans_df[col_mean_roll] = corpus_parags_trans_df[col_name_roll_ls].mean(axis=1)\n",
        "\n",
        "\"\"\"\n",
        "col_mean_lnorm_median_roll = 'mean_lnorm_medianiqr_' + roll_str\n",
        "# model_transformers_lnorm_medianiqr_ls = []\n",
        "for acol_name in model_transformers_ls:\n",
        "  model_transformers_lnorm_medianiqr_ls.append(acol_name)\n",
        "corpus_parags_trans_df[col_mean_lnorm_median_roll] = corpus_parags_trans_df[model_transformers_lnorm_medianiqr_ls].mean(axis=1)\n",
        "\"\"\";\n",
        "\n",
        "\n",
        "model_transformers_subset_ls = []\n",
        "if NLPTown_Arc == True:\n",
        "  # model_transformers_subset_ls.append('nlptown_lnorm_medianiqr_roll050')\n",
        "  model_transformers_subset_ls.append('nlptown_lnorm_medianiqr' + '_' + roll_str)\n",
        "if RoBERTaLg15_Arc == True:\n",
        "  model_transformers_subset_ls.append('robertalg15_lnorm_medianiqr' +'_' + roll_str)\n",
        "if DistillBERTSST_Arc == True:\n",
        "  model_transformers_subset_ls.append('distillbertsst_lnorm_medianiqr' + '_' + roll_str)\n",
        "if BERTSST_Arc == True:\n",
        "  model_transformers_subset_ls.append('bertsst_lnorm_medianiqr' + '_' + roll_str)\n",
        "\n",
        "\n",
        "palette = cycle(px.colors.qualitative.Safe)\n",
        "# palette = cycle(px.colors.sequential.PuBu)\n",
        "\n",
        "my_layout = go.Layout(\n",
        "    autosize=False,\n",
        "    width=1600,\n",
        "    height=800,\n",
        "    margin=go.layout.Margin(\n",
        "        l=10,\n",
        "        r=50,\n",
        "        b=100,\n",
        "        t=100,\n",
        "        pad = 1\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "fig = go.Figure(layout=my_layout)\n",
        "\n",
        "# add traces\n",
        "for i,amodel in enumerate(model_transformers_subset_ls):\n",
        "  fig.add_traces(go.Line(x = corpus_parags_trans_df['sent_no'],\n",
        "                        y = model_transformers_scale_ls[i][0]*corpus_parags_trans_df[amodel]+model_transformers_scale_ls[i][1],\n",
        "                        text = corpus_parags_trans_df['sent_raw'],\n",
        "                        name = amodel,\n",
        "                        hovertemplate = \"Model: <b>\"+amodel+\"</b><br>Sentence #<b>%{x}</b><br>Polarity <b>%{y:.4f}</b><br>Text: <b><i>%{text}</i></b>\", \n",
        "                        marker_color=next(palette)))\n",
        "\n",
        "if Mean_Subset_Arc == True:\n",
        "  mean_subset_col = 'mean_subset_roll050'\n",
        "  corpus_parags_trans_df[mean_subset_col] = corpus_parags_trans_df[model_transformers_subset_ls].mean(axis=1)\n",
        "  fig.add_traces(go.Line(x=corpus_parags_trans_df['sent_no'],\n",
        "                        y = corpus_parags_trans_df[mean_subset_col],\n",
        "                        line=dict(\n",
        "                              # color='#000000',\n",
        "                              width=5\n",
        "                              ),\n",
        "                        text = 'NA', # corpus_parags_trans_df['sent_raw'],\n",
        "                        name = mean_subset_col,\n",
        "                        hovertemplate = \"Model <b>%{mean_subset_col}</b><br>Sentence #<b>%{x}</b><br>Polarity <b>%{y:.4f}</b>\", \n",
        "                        marker_color=next(palette)))\n",
        "\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Paragraph Transformer Sentiment Models<b><i> \" + roll_str.upper() + \"</i></b>\",\n",
        "    xaxis_title=\"Paragraph Number\",\n",
        "    # yaxis_title=\"Sentiment Value\",\n",
        "    hoverlabel=dict(\n",
        "        bgcolor=\"white\",\n",
        "        font_size=16,\n",
        "        font_family=\"Rockwell\"\n",
        "    ),\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=18,\n",
        "        color=\"RebeccaPurple\"\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89X8Sz2QdMn-"
      },
      "source": [
        "##### **(ABOVE) Plotly SMA Paragraph Transformers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmbxdtyvQo3K"
      },
      "source": [
        "##### **Comparison of Paragraph Transformer Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIaxX1dEbvkE"
      },
      "source": [
        "# Compare Paragraph Transformer Standardized Sentiment Values\n",
        "\n",
        "model_trans_ls = ['nlptown', 'robertalg15', 'distillbertsst', 'bertsst']\n",
        "\n",
        "model_trans_standardized_roll_ls = []\n",
        "for amodel in model_trans_ls:\n",
        "  col_name = f'{amodel}_lnorm_medianiqr_{roll_str}'  # TODO: drop lnorm_medianiqr earlier and just Standardize here\n",
        "                                                     # NOTE: Simple SciPy StandardScaler works on SMA Series that don't have outliers like Raw Series\n",
        "  # print(f'col_name: {col_name}')\n",
        "  model_trans_standardized_roll_ls.append(col_name)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i,amodel in enumerate(model_trans_standardized_roll_ls):\n",
        "  col_name_roll_stand = f'{col_name}_stand'\n",
        "  # print(f'col_name_roll_stand: {col_name_roll_stand}')  # sent\n",
        "  model_roll_stand_np = np.array(corpus_parags_trans_df[amodel])\n",
        "  # .apply(lambda x: Scale_SentimentR*x))\n",
        "  \n",
        "  model_roll_stand_np = model_roll_stand_np.reshape((len(model_roll_stand_np), 1))\n",
        "\n",
        "  scaler = scaler.fit(model_roll_stand_np)\n",
        "  print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, np.sqrt(scaler.var_)))\n",
        "  model_roll_stand_xform_np = scaler.transform(model_roll_stand_np)\n",
        "\n",
        "  corpus_parags_trans_df[col_name_roll_stand] = pd.Series(model_roll_stand_xform_np.flatten())\n",
        "\n",
        "  # Plot\n",
        "  corpus_parags_trans_df[col_name_roll_stand].plot(label=amodel) # label=col_name_roll_stand))\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Paragraph Transformer Sentiments\\nMean Length-Normed MedianIQR Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtxzLN7CQo3R"
      },
      "source": [
        "# Create a comparison DataFrame of SentimentR Paragraph Models\n",
        "\n",
        "corr_transformers_models_ls = ['nlptown','robertalg15', 'distillbertsst','bertsst']\n",
        "\n",
        "corr_transformers_df = corpus_parags_trans_df[corr_transformers_models_ls].corr(method='spearman')\n",
        "\n",
        "# Customize the heatmap of the corr_meat correlation matrix and rotate the x-axis labels\n",
        "fig = sns.clustermap(corr_df,\n",
        "                     row_cluster=True,\n",
        "                     col_cluster=True,\n",
        "                     figsize=(10, 10))\n",
        "\n",
        "plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n",
        "plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dowF8jrw67W7"
      },
      "source": [
        "# Quick Sentence vs Paragraph Transformer Sentiment SMA Comparison\n",
        "\n",
        "plt.close()\n",
        "\n",
        "# Colab Jupyter wouldn't plot pd.Series from 2 different DataFrames on the same graph\n",
        "#   so combine into temporary DataFrame as a workaround\n",
        "\n",
        "temp_df = pd.DataFrame(columns = ['Sentences', 'Paragraphs'])\n",
        "\n",
        "y_col = f'mean_lnorm_medianiqr_{roll_str}'\n",
        "temp_df['Sentences'] = corpus_sents_trans_df[y_col]\n",
        "temp_df['Paragraphs'] = corpus_parags_trans_df[y_col]\n",
        "\n",
        "temp_df['Sentences'].plot(linewidth=10)\n",
        "temp_df['Paragraphs'].plot()\n",
        "\n",
        "\n",
        "# plt.plot(corpus_sents_trans_df[y_col], label='Sentences')\n",
        "\n",
        "# y_col = f'mean_lnorm_medianiqr_{roll_str}'\n",
        "# plt.plot(corpus_parags_trans_df[y_col], label='Paragraphs')\n",
        "\n",
        "# plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Paragraph Transformer Sentiments\\nMean Length-Normed MedianIQR Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJIK_j3wbx97"
      },
      "source": [
        "corpus_sents_trans_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZorifAHe7ye"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5CazR5rY_u2"
      },
      "source": [
        "##### **Explore Paragraph Crux Points and Contexts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHihplfSY_u4"
      },
      "source": [
        "**Plot Top-n Crux Peaks/Valleys for selected Model**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Crux_Window_Percent] exclusive zone around Crux Points as a percentage of Corpus length\n",
        "\n",
        "* [Sentiment_Model] Select a Sentiment Analysis model\n",
        "\n",
        "* Select [Anomaly_Detction] to plot raw Sentiment values to detect outlier/anomaly Sentences. Leave unchecked to plot SMA smoothed Sentiment arc and detect Crux points\n",
        "\n",
        "* Select [Save_to_File] to also save plot to external *.png file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvjvyLFxCFnz"
      },
      "source": [
        "%whos DataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHmCM9knCKEN"
      },
      "source": [
        "corpus_transformer_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvndYD2CY_u6"
      },
      "source": [
        "Crux_Window_Percent = 2 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "SentimentR_SMA_Model = \"RoBERTa Large 15 Databases\" #@param [\"NLPTown\", \"RoBERTa Large 15 Databases\", \"Distilled BERT SST\", \"BERT SST\"]\n",
        "Anomaly_Detection = False #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "if SentimentR_SMA_Model == 'NLPTown':\n",
        "  model_selected = f'nlptown'\n",
        "if SentimentR_SMA_Model == 'RoBERTa Large 15 Databases':\n",
        "  model_selected = f'robertalg15'\n",
        "if SentimentR_SMA_Model == 'Distilled BERT SST':\n",
        "  model_selected = f'distillbertsst'\n",
        "if SentimentR_SMA_Model == 'BERT SST':\n",
        "  model_selected = f'bertsst'\n",
        "\n",
        "if Anomaly_Detection == False:\n",
        "  # (a) Use Sentence SMA smoothed Sentiment models to detect Crux Points\n",
        "  # model_selected_fullname = f'{model_selected}_lnorm_medianiqr_{roll_str}'\n",
        "  model_selected_fullname = f'{model_selected}_stdscaler_{roll_str}'\n",
        "else:\n",
        "  # (b)Use Sentence Raw Sentiment models to detect outliers\n",
        "  model_selected_fullname = f'{model_selected}'\n",
        "\n",
        "\n",
        "# TODO: enable multiple overlay crux points with underlying mean/median arc\n",
        "corpus_models_stand_ls = [model_selected_fullname]\n",
        "\n",
        "# Warning: requires definitions of: x, section_sents_df\n",
        "#          so Baseline models must be run first\n",
        "\n",
        "for amodel in corpus_models_stand_ls:\n",
        "  corpus_cruxes_all_dt[amodel] = get_crux_points(ts_df=corpus_transformer_df,\n",
        "                                        # ts_df=corpus_sents_trans_df, \n",
        "                                        col_series=corpus_models_stand_ls, \n",
        "                                        text_type='sentence', \n",
        "                                        win_per=Crux_Window_Percent, \n",
        "                                        sec_y_height=0, \n",
        "                                        subtitle_str=' ', \n",
        "                                        do_plot=True, \n",
        "                                        save2file=False)\n",
        "  \n",
        "model_crux_ls = corpus_cruxes_all_dt[amodel]\n",
        "# model_crux_ls;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR0h5f7bY_u8"
      },
      "source": [
        "**Get Top-n Crux Peaks/Valleys with surrounding Context**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Get_Peak_Cruxes] to retrieve Peaks (if unchecked Valleys are retrieved)\n",
        "\n",
        "* [Get_n_Cruxes] determines how many Top-n Cruxes to retrieve\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beSU4keNY_u-"
      },
      "source": [
        "# Crux Details\n",
        "Get_Peak_Cruxes = True #@param {type:\"boolean\"}\n",
        "Get_n_Cruxes = 6 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "Sort_by_SentenceNo = True #@param {type:\"boolean\"}\n",
        "\n",
        "# Context Details\n",
        "No_Paragraphs_on_Each_Side = 3 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "if Save_to_Report == False:\n",
        "  crux_sortsents_report(model_crux_ls, \n",
        "                        library_type='transformers',\n",
        "                        top_n=Get_n_Cruxes, \n",
        "                        get_peaks=Get_Peak_Cruxes, \n",
        "                        sort_by = sort_on, # sent_no, or abs(polarity)\n",
        "                        n_sideparags=No_Paragraphs_on_Each_Side,\n",
        "                        sentence_highlight=Highlight_Sentence)\n",
        "else:\n",
        "  # https://www.kite.com/python/answers/how-to-get-stdout-and-stderr-from-a-process-as-a-string-in-python\n",
        "  # process = subprocess.run([\"echo\", \"This goes to stdout\"], capture_output=True)\n",
        "  # stdout_as_str = process.stdout.decode(\"utf-8\")\n",
        "  # print(stdout_as_str)\n",
        "  temp_out = StringIO()\n",
        "  sys.stdout = temp_out\n",
        "  crux_sortsents_report(model_crux_ls, top_n=Get_n_Cruxes, get_peaks=Get_Peak_Cruxes, n_sideparags=No_Paragraphs_on_Each_Side)\n",
        "  print(temp_out)\n",
        "  # attempt to save temp_out to generated filename\n",
        "  sys.stdout = sys.__stdout__\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG8t02zqY_vA"
      },
      "source": [
        "**Zoom in on Context surrounding a particular Crux Point**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Enter [Crux_Sentence_No] that matches a Crux point/Sentence No you want to explore\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2Sm942CY_vB"
      },
      "source": [
        "# Select details about the Crux Point Context to Retrieve\n",
        "\n",
        "# print(f'Last Sentence No: {corpus_sents_df.shape[0]}')\n",
        "Crux_Sentence_No =  4494#@param {type:\"number\"}\n",
        "No_Paragraphs_on_Each_Side = 3 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "Highlight_Crux_Sentence = True #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "corpus_sents_len = corpus_sents_df.shape[0]\n",
        "\n",
        "# if (Crux_Sentence_No >= No_Paragraphs_on_Each_Side) & (Crux_Sentence_No+No_Paragraphs_on_Each_Side <= corpus_parag_len):\n",
        "# get_sentnocontext_report()\n",
        "# try:\n",
        "get_sentnocontext_report(the_sent_no=Crux_Sentence_No, the_n_sideparags=No_Paragraphs_on_Each_Side, the_sent_highlight=Highlight_Crux_Sentence)\n",
        "# except:\n",
        "#   print('ERROR')\n",
        "# else:\n",
        "#   print(f'ERROR: The combination of your [Crux_Sentence_No] and [No_Pargraphs_on_Each_Side]\\n       results in a window outside the range of the Corpus Paragraphs.\\n\\n       Try again with different values.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGzFjfDQxJxb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtca4Wi1xKTU"
      },
      "source": [
        "## **EDA Supervised ML**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KodzP5KpxKTX"
      },
      "source": [
        "#### **(If not already exists) Import Supervised ML Sentiment Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba6ShUT7xKTX"
      },
      "source": [
        "# Verify Supervised ML Sentiment Files exported\n",
        "!pwd\n",
        "!ls -altr sum_sentiments*mlsup*.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MImpz5Q6xKTY"
      },
      "source": [
        "# Get SyuzhetR Sentiment Datafile (with data on 4 Models)\n",
        "\n",
        "mlsup_sentiment_datafile = 'sum_sentiments_sents_mlsupervised_cdickens_greatexpectations.csv' #@param {type:\"string\"}\n",
        "\n",
        "sum_sentiments_mlsup_filename = mlsup_sentiment_datafile\n",
        "\n",
        "!head -n 3 $sum_sentiments_mlsup_filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaRnX4d_xKTZ"
      },
      "source": [
        "corpus_mlsup_df = pd.read_csv(sum_sentiments_mlsup_filename)\n",
        "corpus_mlsup_df.head(2)\n",
        "corpus_mlsup_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MVlZS0CxKTZ"
      },
      "source": [
        "# corpus_sents_df = corpus_sents_df.loc[:, ~corpus_sents_df.columns.str.contains('^Unnamed')]\n",
        "\n",
        "corpus_mlsup_df.rename(columns={'Unnamed: 0':'sent_no'}, inplace=True)\n",
        "corpus_mlsup_df['sent_clean'] = corpus_mlsup_df['sent_clean'].astype('string')\n",
        "corpus_mlsup_df['sent_raw'] = corpus_mlsup_df['sent_clean']\n",
        "corpus_mlsup_df['sent_lemma'] = corpus_mlsup_df['sent_lemma'].astype('string')\n",
        "corpus_mlsup_df.head(2)\n",
        "corpus_mlsup_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXjA8AGNxKTb"
      },
      "source": [
        "# Add summary statistics\n",
        "\n",
        "corpus_mlsup_df['char_len'] = corpus_mlsup_df['sent_clean'].apply(lambda x: len(x))\n",
        "corpus_mlsup_df['token_len'] = corpus_mlsup_df['sent_clean'].apply(lambda x: len(x.split())) \n",
        "\n",
        "corpus_mlsup_df.head(2)\n",
        "corpus_mlsup_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br4wUs40xKTc"
      },
      "source": [
        "# Insert Sentence Numbers (sent_no)\n",
        "\"\"\"\n",
        "sent_ct = corpus_syuzhetr_df.shape[0]\n",
        "sent_no_ls = list(range(sent_ct))\n",
        "corpus_syuzhetr_df.insert(0, 'sent_no', sent_no_ls)\n",
        "corpus_syuzhetr_df.head(2)\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ysh6wapMxKTc"
      },
      "source": [
        "# Rename columns if necessary\n",
        "corpus_mlsup_df['sent_raw'] = corpus_mlsup_df['sent_raw'].astype('string')\n",
        "corpus_mlsup_df['sent_raw'] = corpus_mlsup_df['sent_raw'].apply(lambda x : re.sub(f'[^{re.escape(string.printable)}]', '', x))\n",
        "corpus_mlsup_df['sent_raw'] = corpus_mlsup_df['sent_raw'].apply(lambda x : filter_nonprintable(x))\n",
        "\n",
        "\n",
        "# create a clean version of Sentence in sent_clean column\n",
        "corpus_mlsup_df['sent_clean'] = corpus_mlsup_df['sent_raw'].apply(lambda x : clean_text(x))\n",
        "corpus_mlsup_df['sent_clean'] = corpus_mlsup_df['sent_clean'].astype('string')\n",
        "\n",
        "corpus_mlsup_df.head(2)\n",
        "corpus_mlsup_df.info()\n",
        "corpus_mlsup_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYswllp2xKTd"
      },
      "source": [
        "corpus_mlsup_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n8Xoy4WxKTd"
      },
      "source": [
        "print(*corpus_mlsup_df.columns, sep='\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UblHSc4TxKTe"
      },
      "source": [
        "# Create 4 Standardized versions of each Model: stdscaler, medianiqr both lnormed and not\n",
        "\n",
        "print('\\nBefore Standardization ----------')\n",
        "corpus_mlsup_df.columns\n",
        "\n",
        "# Need to deal with prefix 'imdb50k_' + 'linreg'\n",
        "# standardize_ts_ls(corpus_mlsup_df, models_mlsup_ls)\n",
        "\n",
        "print('\\nAfter Standardization ----------')\n",
        "corpus_mlsup_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNq1R2wNxKTf"
      },
      "source": [
        "#### **Interactive Sentence SMA Plots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__ToulDuxKTf"
      },
      "source": [
        "# Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "# display(corpus_sentimentr_df.head())\n",
        "\n",
        "win_per = SMA_Window_Percent             \n",
        "win_roll = int(win_per/100 * corpus_mlsup_df.shape[0])\n",
        "\n",
        "col_name_roll_ls = []\n",
        "# fig, ax = plt.subplots()\n",
        "for amodel in models_mlsup_ls:\n",
        "  # if not(amodel.endswith('roll050')):\n",
        "  if len(str(win_per)) == 1:\n",
        "    roll_str = 'roll0' + str(win_per)\n",
        "  else:\n",
        "    roll_str = 'roll' + str(win_per)\n",
        "  col_name_roll = f'{amodel}_{roll_str}'\n",
        "  col_name_roll_ls.append(col_name_roll)\n",
        "  # else:\n",
        "  #   col_name_roll_ls.append(amodel)\n",
        "  corpus_mlsup_df[col_name_roll] = corpus_mlsup_df[amodel].rolling(win_roll, center=True).mean()\n",
        "\n",
        "col_mean_roll = 'mean_' + roll_str\n",
        "corpus_mlsup_df[col_mean_roll] = corpus_mlsup_df[col_name_roll_ls].mean(axis=1)\n",
        "\n",
        "\n",
        "palette = cycle(px.colors.qualitative.Bold)\n",
        "# palette = cycle(px.colors.sequential.PuBu)\n",
        "\n",
        "my_layout = go.Layout(\n",
        "    autosize=False,\n",
        "    width=1600,\n",
        "    height=800,\n",
        "    margin=go.layout.Margin(\n",
        "        l=10,\n",
        "        r=50,\n",
        "        b=100,\n",
        "        t=100,\n",
        "        pad = 1\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "fig = go.Figure(layout=my_layout)\n",
        "\n",
        "# add traces\n",
        "\n",
        "model = 'mean_' + roll_str\n",
        "fig.add_traces(go.Line(x=corpus_mlsup_df['sent_no'],\n",
        "                       y = corpus_mlsup_df[model],\n",
        "                       line=dict(\n",
        "                            color='#000000',\n",
        "                            width=5\n",
        "                            ),\n",
        "                       text = corpus_mlsup_df.index.values,\n",
        "                       name = model,\n",
        "                       hovertemplate = \"Model <b>Mean: \"+str(win_per)+\"%</b><br>Sentence #<b>%{x}</b><br>Polarity <b>%{y}</b>\", \n",
        "                       marker_color=next(palette)))\n",
        "\n",
        "\n",
        "for amodel in models_syuzhetr_ls:\n",
        "  model_roll = f'{amodel}_' + roll_str\n",
        "  fig.add_traces(go.Line(x=corpus_mlsup_df['sent_no'],\n",
        "                        y = corpus_mlsup_df[model_roll],\n",
        "                        text = corpus_mlsup_df['sent_raw'],\n",
        "                        name = model_roll,\n",
        "                        hovertemplate = \"Model <b>\"+model_roll+\"</b><br>Sentence #<b>%{x}</b><br>Polarity <b>%{y:.4f}</b><br>Index: <b><i>%{text}</i></b>\", \n",
        "                        marker_color=next(palette)))\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Supervised ML Sentence Sentiment Models <b><i>\" + roll_str.upper() + '</i></b>',\n",
        "    xaxis_title=\"Sentence Number\",\n",
        "    # yaxis_title=\"Sentiment Value\",\n",
        "    hoverlabel=dict(\n",
        "        bgcolor=\"white\",\n",
        "        font_size=16,\n",
        "        font_family=\"Rockwell\"\n",
        "    ),\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=18,\n",
        "        color=\"RebeccaPurple\"\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlVk7khexKTf"
      },
      "source": [
        "#### **Comparison of Sentence SyuzhetR Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuhRrRUJxKTg"
      },
      "source": [
        "# Compare Sentence SyuzhetR Standardized Sentiment Values\n",
        "\n",
        "# model_syuzhetr_ls = ['syuzhet', 'bing', 'afinn', 'nrc']\n",
        "\n",
        "model_syuzhetr_standardized_roll_ls = []\n",
        "for amodel in models_syuzhetr_ls:\n",
        "  col_roll_name = f'{amodel}_{roll_str}'  # TODO: drop lnorm_medianiqr earlier and just Standardize here\n",
        "                                                     # NOTE: Simple SciPy StandardScaler works on SMA Series that don't have outliers like Raw Series\n",
        "  # print(f'col_name: {col_name}')\n",
        "  model_syuzhetr_standardized_roll_ls.append(col_roll_name)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i,arollmodel in enumerate(model_syuzhetr_standardized_roll_ls):\n",
        "  print(f'Processing model: {arollmodel}')\n",
        "  col_name_roll_stand = f'{arollmodel}_stdscale'\n",
        "  # print(f'col_name_roll_stand: {col_name_roll_stand}')\n",
        "  model_roll_stand_np = np.array(corpus_syuzhetr_df[arollmodel])\n",
        "  # .apply(lambda x: Scale_SentimentR*x))\n",
        "  \n",
        "  model_roll_stand_np = model_roll_stand_np.reshape((len(model_roll_stand_np), 1))\n",
        "\n",
        "  scaler = scaler.fit(model_roll_stand_np)\n",
        "  print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, np.sqrt(scaler.var_)))\n",
        "  model_roll_stand_xform_np = scaler.transform(model_roll_stand_np)\n",
        "\n",
        "  print(f'  Adding StdScaler Column: {col_name_roll_stand}')\n",
        "  corpus_syuzhetr_df[col_name_roll_stand] = pd.Series(model_roll_stand_xform_np.flatten())\n",
        "\n",
        "  # Plot\n",
        "  corpus_syuzhetr_df[col_name_roll_stand].plot(label=arollmodel) # label=col_name_roll_stand))\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Sentence SyuzhetR Sentiments\\nMean Length-Normed MedianIQR Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaPcUv6jxKTg"
      },
      "source": [
        "#### **(ABOVE) Plotly SMA Sentence, (BELOW) Correlation Heatmap**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy0foyhvxKTg"
      },
      "source": [
        "# Create a comparison DataFrame of SentimentR Sentence Models\n",
        "# Sentence Heatmap Correlation of StdScaler Roll100 Sentiments\n",
        "# Depends on 'col_stdscaler_rollwin_ls' defined in prior code cell\n",
        "\n",
        "Correlation_Algo = \"pearson\" #@param [\"pearson\", \"spearman\", \"kendall\"]\n",
        "\n",
        "corr_df = corpus_mlsup_df[models_mlsup_ls].corr(method=Correlation_Algo)\n",
        "\n",
        "# Customize the heatmap of the corr_meat correlation matrix and rotate the x-axis labels\n",
        "fig = sns.clustermap(corr_df,\n",
        "                     row_cluster=True,\n",
        "                     col_cluster=True,\n",
        "                     figsize=(10, 10))\n",
        "\n",
        "plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n",
        "plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
        "plt.title(f'{CORPUS_FULL} Sentence Sentiment for Supervised ML Model Sentiments\\n {Correlation_Algo.capitalize()} Correlation - StdScale Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL6veqiKxKTh"
      },
      "source": [
        "#### **Sentence Sentiment DTW Hierarichal Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zgJxOqNxKTh"
      },
      "source": [
        "#### **Top-n Crux Peaks and Valleys**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p3dLe1qxKTh"
      },
      "source": [
        "**Search Corpus for Substring**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* In [Search_for_Substring] enter a Substring to search for in the Corpus\n",
        "\n",
        "* Enter a Substring long enough/unique enough so only a reasonable number of Sentences will be returned\n",
        "\n",
        "* Substring can contain spaces/punctuation, for example: 'in the garden'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkTq2ocixKTh"
      },
      "source": [
        "# Search Corpus Sentences for Substring\n",
        "\n",
        "Search_for_Substring = \"death.\" #@param {type:\"string\"}\n",
        "\n",
        "sentno_matching_ls = corpus_sents_df[corpus_sents_df['sent_raw'].str.contains(Search_for_Substring, regex=False)]['sent_no']\n",
        "\n",
        "for i, asentno in enumerate(sentno_matching_ls):\n",
        "  # sentno, sentraw = asent\n",
        "  print(f\"\\n\\nMatch #{i}: Sentence #{asentno}\\n\\n\")\n",
        "  sent_highlight = re.sub(Search_for_Substring, Search_for_Substring.upper(), corpus_sents_df.iloc[asentno]['sent_raw'])\n",
        "  print(f'    {sent_highlight}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn5Oc3JsxKTi"
      },
      "source": [
        "**Plot Top-n Crux Peaks/Valleys for selected Model**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Crux_Window_Percent] exclusive zone around Crux Points as a percentage of Corpus length\n",
        "\n",
        "* [Sentiment_Model] Select a Sentiment Analysis model\n",
        "\n",
        "* Select [Anomaly_Detction] to plot raw Sentiment values to detect outlier/anomaly Sentences. Leave unchecked to plot SMA smoothed Sentiment arc and detect Crux points\n",
        "\n",
        "* Select [Save_to_File] to also save plot to external *.png file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiG9KbqwxKTi"
      },
      "source": [
        "Crux_Window_Percent = 5 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "Supervised_ML_Model = \"NRC\" #@param [\"Syuzhet\", \"Bing\", \"AFINN\", \"NRC\"]\n",
        "Anomaly_Detection = False #@param {type:\"boolean\"}\n",
        "Vertical_Labels = True #@param {type:\"boolean\"}\n",
        "Vertical_Labels_Height = 0.2 #@param {type:\"slider\", min:-5.0, max:5.0, step:0.05}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "if Supervised_ML_Model == 'Linear Regression (IMDB 50k)':\n",
        "  model_selected = f'linreg_imdb50k'\n",
        "if Supervised_ML_Model == 'SVC (IMDB 50k)':\n",
        "  model_selected = f'svc_imdb50k'\n",
        "if Supervised_ML_Model == 'Logistic Regression (IMDB 50k)':\n",
        "  model_selected = f'logreg_imdb50k'\n",
        "if Supervised_ML_Model == 'Decision Forrest (IMDB 50k)':\n",
        "  model_selected = f'dforest_imdb50k'\n",
        "if Supervised_ML_Model == 'Multinomial Naive Bayes (IMDB 50k)':\n",
        "  model_selected = f'multinb_imdb50k'\n",
        "\n",
        "if Anomaly_Detection == False:\n",
        "  # (a) Use Sentence SMA smoothed Sentiment models to detect Crux Points\n",
        "  model_selected_fullname = f'{model_selected}_{roll_str}'\n",
        "  print(f'model_selected_fullname: {model_selected_fullname}')\n",
        "else:\n",
        "  # (b)Use Sentence Raw Sentiment models to detect outliers\n",
        "  model_selected_fullname = f'{model_selected}'\n",
        "\n",
        "\n",
        "# TODO: enable multiple overlay crux points with underlying mean/median arc\n",
        "corpus_models_selected_ls = [model_selected_fullname]\n",
        "print(f'corpus_models_selected_ls: {corpus_models_selected_ls}')\n",
        "\n",
        "# Warning: requires definitions of: x, section_sents_df\n",
        "#          so Baseline models must be run first\n",
        "\n",
        "for amodel in corpus_models_selected_ls:\n",
        "  corpus_cruxes_all_dt[amodel] = get_crux_points(ts_df=corpus_syuzhetr_df, \n",
        "                                         col_series=corpus_models_selected_ls, \n",
        "                                         text_type='sentence', \n",
        "                                         win_per=Crux_Window_Percent, \n",
        "                                         sec_y_labels=Vertical_Labels,\n",
        "                                         sec_y_height=Vertical_Labels_Height, \n",
        "                                         subtitle_str='5% Crux - ', \n",
        "                                         do_plot=True, \n",
        "                                         save2file=False)\n",
        "  \n",
        "model_crux_ls = corpus_cruxes_all_dt[amodel]\n",
        "print(f'model_crux_ls: {model_crux_ls}');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqBQSf8xxKTj"
      },
      "source": [
        "### **Context around Top-n Crux Peaks/Valleys**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select [Get_Peak_Cruxes] to retrieve Peaks (if unchecked Valleys are retrieved)\n",
        "\n",
        "* [Get_n_Cruxes] determines how many Top-n Cruxes to retrieve\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxFL-UELxKTj"
      },
      "source": [
        "# Crux Details\n",
        "Get_Peak_Cruxes = False #@param {type:\"boolean\"}\n",
        "Get_n_Cruxes = 20 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "Sort_by_SentenceNo = True #@param {type:\"boolean\"}\n",
        "\n",
        "# Context Details\n",
        "No_Paragraphs_on_Each_Side = 2 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "Highlight_Sentence = True #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "if Sort_by_SentenceNo == True:\n",
        "  sort_on = 'sent_no'\n",
        "else:\n",
        "  sort_on = 'sentiment_val'\n",
        "\n",
        "print(f'Crux Report --------------------\\n')\n",
        "print(f'            Corpus: {CORPUS_FULL}')\n",
        "print(f'            Model: {SyuzhetR_SMA_Model}')\n",
        "print(f'            Crux Win%: {Crux_Window_Percent}')\n",
        "print(f'            SMA Win%: {roll_str}')\n",
        "\n",
        "\n",
        "if Save_to_Report == False:\n",
        "  crux_sortsents_report(model_crux_ls, \n",
        "                        ts_df = corpus_syuzhetr_df,\n",
        "                        library_type='syuzhetr',\n",
        "                        top_n=Get_n_Cruxes, \n",
        "                        get_peaks=Get_Peak_Cruxes, \n",
        "                        sort_by = sort_on, # sent_no, or abs(polarity)\n",
        "                        n_sideparags=No_Paragraphs_on_Each_Side,\n",
        "                        sentence_highlight=Highlight_Sentence)\n",
        "\n",
        "else:\n",
        "  # https://www.kite.com/python/answers/how-to-get-stdout-and-stderr-from-a-process-as-a-string-in-python\n",
        "  # process = subprocess.run([\"echo\", \"This goes to stdout\"], capture_output=True)\n",
        "  # stdout_as_str = process.stdout.decode(\"utf-8\")\n",
        "  # print(stdout_as_str)\n",
        "  temp_out = StringIO()\n",
        "  sys.stdout = temp_out\n",
        "  crux_sortsents_report(model_crux_ls, top_n=Get_n_Cruxes, get_peaks=Get_Peak_Cruxes, n_sideparags=No_Paragraphs_on_Each_Side)\n",
        "  print(temp_out)\n",
        "  # attempt to save temp_out to generated filename\n",
        "  sys.stdout = sys.__stdout__\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRw1GG3oxKTj"
      },
      "source": [
        "**Zoom in on Context surrounding a particular Crux Point**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Enter [Crux_Sentence_No] that matches a Crux point/Sentence No you want to explore\n",
        "\n",
        "* Enter [No_Paragraphs_on_Each_Side] to retrieve this many Paragraphs before and after the Paragraph containing your Crux Sentence (e.g. 2 will bring back 5 paragraphs centered around the Paragraph containing the Crux Sentence)\n",
        "\n",
        "* Select [Highlight_Crux_Sentence] to have the Crux Sentence converted to ALL CAPS for easier identification. The Paragraph containing the Crux Sentence will be prefaced with a '<*>' as well.\n",
        "\n",
        "* Select [Save_to_File] to also save output to external *.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEVckag1xKTj"
      },
      "source": [
        "# Select details about the Crux Point Context to Retrieve\n",
        "\n",
        "# print(f'Last Sentence No: {corpus_sents_df.shape[0]}')\n",
        "Crux_Sentence_No =  200#@param {type:\"number\"}\n",
        "No_Paragraphs_on_Each_Side = 5 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "Highlight_Crux_Sentence = True #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "corpus_sents_len = corpus_sents_df.shape[0]\n",
        "\n",
        "# if (Crux_Sentence_No >= No_Paragraphs_on_Each_Side) & (Crux_Sentence_No+No_Paragraphs_on_Each_Side <= corpus_parag_len):\n",
        "# get_sentnocontext_report()\n",
        "# try:\n",
        "\n",
        "get_sentnocontext_report(ts_df=corpus_syuzhetr_df, \n",
        "                         the_sent_no=Crux_Sentence_No, \n",
        "                         the_n_sideparags=No_Paragraphs_on_Each_Side, \n",
        "                         the_sent_highlight=Highlight_Crux_Sentence)\n",
        "\n",
        "# except:\n",
        "#   print('ERROR')\n",
        "# else:\n",
        "#   print(f'ERROR: The combination of your [Crux_Sentence_No] and [No_Pargraphs_on_Each_Side]\\n       results in a window outside the range of the Corpus Paragraphs.\\n\\n       Try again with different values.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISIf0aUPxe6y"
      },
      "source": [
        "# **Compare All Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAx6TUxysYoG"
      },
      "source": [
        "## **Review 4 Sentiment Model Groups**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zURjifUsh3t"
      },
      "source": [
        "**Process**\n",
        "\n",
        "NOTE: Assume only base_model Raw Sentiment Series exist in each of the 4 Library DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml635x83yFUp"
      },
      "source": [
        "### **12 Baseline Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nlyzYPL7soN"
      },
      "source": [
        "# StandardScaler SMA for Baseline Models\n",
        "\n",
        "SMA_Window_Percentage = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "\n",
        "corpus_plots_std_df = pd.DataFrame()\n",
        "\n",
        "# Convert the SMA Window from Percentage of Corpus to No of Sentences\n",
        "win_per = SMA_Window_Percentage\n",
        "win_sents = int(corpus_sents_df.shape[0]*win_per/100)\n",
        "\n",
        "baseline_plots_std_ls = []\n",
        "# Loop over every Group and within each Group, loop over each Model\n",
        "for amodel in models_baseline_ls:\n",
        "\n",
        "  # Print the current Group/Model that is being used\n",
        "  # print(f'Processing Model: {amodel:>15} in Group: Baselines')\n",
        "\n",
        "  # Generate new SMA col name\n",
        "  if len(str(win_per)) < 2:\n",
        "    col_sma_winper = f'{amodel}_roll0{str(win_per)}0'\n",
        "  else:\n",
        "    col_sma_winper = f'{amodel}_roll{str(win_per)}0'\n",
        "\n",
        "  # Create new SMA Column\n",
        "  # print(f'creating roll col: {col_sma_winper}')\n",
        "  corpus_sents_df[col_sma_winper] = corpus_sents_df[amodel].rolling(win_sents, center=True).mean()\n",
        "\n",
        "  # Standardize SMA Column\n",
        "  col_sma_winper_stdscale = f'{amodel}_stdscaler_{roll_str}'\n",
        "  # print(f'creating stdscale col of roll: {col_sma_winper_stdscale}')\n",
        "  series_stdscale_ls = get_standardscaler(amodel, corpus_sents_df[col_sma_winper])\n",
        "  corpus_sents_df[col_sma_winper_stdscale] = pd.Series(series_stdscale_ls)\n",
        "  corpus_plots_std_df[col_sma_winper_stdscale] = pd.Series(series_stdscale_ls)\n",
        "\n",
        "  # Plot\n",
        "  # corpus_sentimentr_df.iloc[200:1000][col_sma_winper_stdscale].plot()\n",
        "  print(f'       Plotting: {col_sma_winper_stdscale}\\n')\n",
        "  corpus_sents_df[col_sma_winper_stdscale].plot()\n",
        "  baseline_plots_std_ls.append(col_sma_winper_stdscale)\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Sentence Baseline 12 Models\\nStandardScaler of SMA Smoothed Arcs ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk86ubNB_Hzn"
      },
      "source": [
        "# StandardScaler SMA for Baseline Models\n",
        "\"\"\"\n",
        "SMA_Window_Percentage = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "\n",
        "corpus_plots_std_df = pd.DataFrame()\n",
        "\n",
        "# Convert the SMA Window from Percentage of Corpus to No of Sentences\n",
        "win_per = SMA_Window_Percentage\n",
        "win_sents = int(corpus_sents_df.shape[0]*win_per/100)\n",
        "\n",
        "baseline_plots_std_ls = []\n",
        "# Loop over every Group and within each Group, loop over each Model\n",
        "for amodel in models_baseline_ls:\n",
        "\n",
        "  # Print the current Group/Model that is being used\n",
        "  # print(f'Processing Model: {amodel:>15} in Group: Baselines')\n",
        "\n",
        "  # Generate new SMA col name\n",
        "  if len(str(win_per)) < 2:\n",
        "    col_sma_winper = f'{amodel}_roll0{str(win_per)}0'\n",
        "  else:\n",
        "    col_sma_winper = f'{amodel}_roll{str(win_per)}0'\n",
        "\n",
        "  # Create new SMA Column\n",
        "  # print(f'creating roll col: {col_sma_winper}')\n",
        "  corpus_sents_df[col_sma_winper] = corpus_sents_df[amodel].rolling(win_sents, center=True).mean()\n",
        "\n",
        "  # Standardize SMA Column\n",
        "  col_sma_winper_stdscale = f'{col_sma_winper}_stdscale'\n",
        "  # print(f'creating stdscale col of roll: {col_sma_winper_stdscale}')\n",
        "  series_stdscale_ls = get_standardscaler(amodel, corpus_sents_df[col_sma_winper])\n",
        "  corpus_sents_df[col_sma_winper_stdscale] = pd.Series(series_stdscale_ls)\n",
        "  corpus_plots_std_df[col_sma_winper_stdscale] = pd.Series(series_stdscale_ls)\n",
        "\n",
        "  # Plot\n",
        "  # corpus_sents_df.iloc[200:1000][col_sma_winper_stdscale].plot()\n",
        "  print(f'       Plotting: {col_sma_winper_stdscale}\\n')\n",
        "  corpus_sents_df[col_sma_winper_stdscale].plot()\n",
        "  baseline_plots_std_ls.append(col_sma_winper_stdscale)\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Sentence Baseline 12 Models\\nStandardScaler of SMA Smoothed Arcs ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKyNxuUmyH4z"
      },
      "source": [
        "### **7 SentimentR Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYh8EvZKqGPY"
      },
      "source": [
        "# StandardScaler SMA for SentimentR Models\n",
        "\n",
        "SMA_Window_Percentage = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "# Convert the SMA Window from Percentage of Corpus to No of Sentences\n",
        "win_per = SMA_Window_Percentage\n",
        "win_sents = int(corpus_sentimentr_df.shape[0]*win_per/100)\n",
        "\n",
        "sentimentr_plots_std_ls = []\n",
        "# Loop over every Group and within each Group, loop over each Model\n",
        "for amodel in models_sentimentr_ls:\n",
        "\n",
        "  # Print the current Group/Model that is being used\n",
        "  # print(f'Processing Model: {amodel:>15} in Group: Baselines')\n",
        "\n",
        "  # Generate new SMA col name\n",
        "  if len(str(win_per)) < 2:\n",
        "    col_sma_winper = f'{amodel}_roll0{str(win_per)}0'\n",
        "  else:\n",
        "    col_sma_winper = f'{amodel}_roll{str(win_per)}0'\n",
        "\n",
        "  # Create new SMA Column\n",
        "  # print(f'creating roll col: {col_sma_winper}')\n",
        "  corpus_sentimentr_df[col_sma_winper] = corpus_sentimentr_df[amodel].rolling(win_sents, center=True).mean()\n",
        "\n",
        "  # Standardize SMA Column\n",
        "  col_sma_winper_stdscale = f'{amodel}_stdscaler_{roll_str}'\n",
        "  # print(f'creating stdscale col of roll: {col_sma_winper_stdscale}')\n",
        "  series_stdscale_ls = get_standardscaler(amodel, corpus_sentimentr_df[col_sma_winper])\n",
        "  corpus_sentimentr_df[col_sma_winper_stdscale] = pd.Series(series_stdscale_ls)\n",
        "  corpus_plots_std_df[col_sma_winper_stdscale] = pd.Series(series_stdscale_ls)\n",
        "\n",
        "  # Plot\n",
        "  # corpus_sentimentr_df.iloc[200:1000][col_sma_winper_stdscale].plot()\n",
        "  print(f'       Plotting: {col_sma_winper_stdscale}\\n')\n",
        "  corpus_sentimentr_df[col_sma_winper_stdscale].plot()\n",
        "  sentimentr_plots_std_ls.append(col_sma_winper_stdscale)\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Sentence SentimentR 7 Models\\nStandardScaler of SMA Smoothed Arcs ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iGbNzPGyK8-"
      },
      "source": [
        "### **4 SyuzhetR Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnUuECApALc9"
      },
      "source": [
        "# StandardScaler SMA for SyuzhetR Models\n",
        "\n",
        "SMA_Window_Percentage = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "# Convert the SMA Window from Percentage of Corpus to No of Sentences\n",
        "win_per = SMA_Window_Percentage\n",
        "win_sents = int(corpus_syuzhetr_df.shape[0]*win_per/100)\n",
        "\n",
        "syuzhetr_plots_std_ls = []\n",
        "# Loop over every Group and within each Group, loop over each Model\n",
        "for amodel in models_syuzhetr_ls:\n",
        "\n",
        "  # Print the current Group/Model that is being used\n",
        "  # print(f'Processing Model: {amodel:>15} in Group: Baselines')\n",
        "\n",
        "  # Generate new SMA col name\n",
        "  if len(str(win_per)) < 2:\n",
        "    col_sma_winper = f'{amodel}_roll0{str(win_per)}0'\n",
        "  else:\n",
        "    col_sma_winper = f'{amodel}_roll{str(win_per)}0'\n",
        "\n",
        "  # Create new SMA Column\n",
        "  # print(f'creating roll col: {col_sma_winper}')\n",
        "  corpus_syuzhetr_df[col_sma_winper] = corpus_syuzhetr_df[amodel].rolling(win_sents, center=True).mean()\n",
        "\n",
        "  # Standardize SMA Column\n",
        "  col_sma_winper_stdscale = f'{amodel}_stdscaler_{roll_str}'\n",
        "  # print(f'creating stdscale col of roll: {col_sma_winper_stdscale}')\n",
        "  series_stdscale_ls = get_standardscaler(amodel, corpus_syuzhetr_df[col_sma_winper])\n",
        "  corpus_syuzhetr_df[col_sma_winper_stdscale] = pd.Series(series_stdscale_ls)\n",
        "  corpus_plots_std_df[col_sma_winper_stdscale] = pd.Series(series_stdscale_ls)\n",
        "  \n",
        "  # Plot\n",
        "  # corpus_syuzhetr_df.iloc[200:1000][col_sma_winper_stdscale].plot()\n",
        "  print(f'       Plotting: {col_sma_winper_stdscale}\\n')\n",
        "  corpus_syuzhetr_df[col_sma_winper_stdscale].plot()\n",
        "  syuzhetr_plots_std_ls.append(col_sma_winper_stdscale)\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Sentence Syuzhet 4 Models\\nStandardScaler of SMA Smoothed Arcs ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3iWkOCuyNB3"
      },
      "source": [
        "### **8 Transformer Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SN6gRLJALZP"
      },
      "source": [
        "# StandardScaler SMA for Transformer Models\n",
        "\n",
        "SMA_Window_Percentage = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "\"\"\"\n",
        "models_transformer_ls = ['roberta15lg',\n",
        "                         'nlptown',\n",
        "                         'yelp',\n",
        "                         'hinglish',\n",
        "                         'imdb2way',\n",
        "                         'huggingface',\n",
        "                         't5imdb50k',\n",
        "                         'robertaxml8lang']\n",
        "\"\"\"\n",
        "\n",
        "# Convert the SMA Window from Percentage of Corpus to No of Sentences\n",
        "win_per = SMA_Window_Percentage\n",
        "win_sents = int(corpus_transformer_df.shape[0]*win_per/100)\n",
        "\n",
        "transformer_plots_std_ls = []\n",
        "# Loop over every Group and within each Group, loop over each Model\n",
        "for amodel in models_transformer_ls:\n",
        "\n",
        "  # Print the current Group/Model that is being used\n",
        "  # print(f'Processing Model: {amodel:>15} in Group: Baselines')\n",
        "\n",
        "  # Generate new SMA col name\n",
        "  if len(str(win_per)) < 2:\n",
        "    col_sma_winper = f'{amodel}_roll0{str(win_per)}0'\n",
        "  else:\n",
        "    col_sma_winper = f'{amodel}_roll{str(win_per)}0'\n",
        "\n",
        "  # Create new SMA Column\n",
        "  # print(f'creating roll col: {col_sma_winper}')\n",
        "  corpus_transformer_df[col_sma_winper] = corpus_transformer_df[amodel].rolling(win_sents, center=True).mean()\n",
        "\n",
        "  # Standardize SMA Column\n",
        "  col_sma_winper_stdscale = f'{amodel}_stdscaler_{roll_str}'\n",
        "  # print(f'creating stdscale col of roll: {col_sma_winper_stdscale}')\n",
        "  series_stdscale_ls = get_standardscaler(amodel, corpus_transformer_df[col_sma_winper])\n",
        "  corpus_transformer_df[col_sma_winper_stdscale] = pd.Series(series_stdscale_ls)\n",
        "  corpus_plots_std_df[col_sma_winper_stdscale] = pd.Series(series_stdscale_ls)\n",
        "\n",
        "  # Plot\n",
        "  # corpus_transformer_df.iloc[200:1000][col_sma_winper_stdscale].plot()\n",
        "  print(f'       Plotting: {col_sma_winper_stdscale}\\n')\n",
        "  corpus_transformer_df[col_sma_winper_stdscale].plot()\n",
        "  transformer_plots_std_ls.append(col_sma_winper_stdscale)\n",
        "\n",
        "plt.grid()\n",
        "plt.title(f'{CORPUS_FULL} Compare Sentence Transformer 8 Models\\nStandardScaler of SMA Smoothed Arcs ({roll_str.capitalize()})')\n",
        "plt.legend(loc='best');\n",
        "\n",
        "\"\"\"\n",
        "for agroup in groups_ls:\n",
        "  for amodel in globals()[agroup]:\n",
        "    print(f'Processing Model: {amodel:>15} in Group: {agroup}')\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09fTREaV0Afb"
      },
      "source": [
        "## **Combine ALL 31 Sentence Models into Unified DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v4Tm6pXe-Zt"
      },
      "source": [
        "# Verfiy Consistent DataFrame across all 4 Libraries\n",
        "\n",
        "print(f'   Baseline Sentences shape: {corpus_sents_df.shape}')\n",
        "print(f' SentimentR Sentences shape: {corpus_sentimentr_df.shape}')\n",
        "print(f'   SyuzhetR Sentences shape: {corpus_syuzhetr_df.shape}')\n",
        "print(f'Transformer Sentences shape: {corpus_transformer_df.shape}')\n",
        "\n",
        "print('\\n----------[ Consistency Check on Sentence length of all Models ]----------\\n')\n",
        "\n",
        "if corpus_sents_df.shape[0] == corpus_sentimentr_df.shape[0] == corpus_syuzhetr_df.shape[0] == corpus_transformer_df.shape[0]:\n",
        "  print(f'Great! All models have the same Sentence lengths: {corpus_sents_df.shape[0]}')\n",
        "else:\n",
        "  print(f'ERROR: Sentence DataFrames have unequal lengths, check statistics above and fix')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHV1LEiPg7XL"
      },
      "source": [
        "corpus_sents_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bcPKU2ZhASh"
      },
      "source": [
        "corpus_sentimentr_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXRvty-ffZOZ"
      },
      "source": [
        "smaller_ls = list(corpus_sents_df['sent_raw'])\n",
        "bigger_ls = list(corpus_sentimentr_df['sent_raw'])\n",
        "\n",
        "# orig_ser.compare(new_ser)\n",
        "# s2[s2.isin(s1)]\n",
        "\n",
        "diff_ls = [x for x in bigger_ls if x in smaller_ls]\n",
        "print(f'diff_ls: {len(diff_ls)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCmKM0w2umQt"
      },
      "source": [
        "\"\"\"\n",
        "# Create 4 Standardized versions of each Model: stdscaler, medianiqr both lnormed and not\n",
        "\n",
        "corpus_unified_df = pd.DataFrame()\n",
        "\n",
        "print('\\nBefore Standardization ----------')\n",
        "corpus_unified_df.columns\n",
        "\n",
        "models_unified_ls = models_baseline_ls + models_sentimentr_ls + models_syuzhetr_ls + models_transformer_ls\n",
        "\n",
        "standardize_ts_ls(corpus_unified_df, models_unified_ls)\n",
        "\n",
        "print('\\nAfter Standardization ----------')\n",
        "corpus_unified_df.columns\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06NwK2PrmIV9"
      },
      "source": [
        "# Vertically Concatenate ALL 4 Sentiment Groups StandardizedScaled SMA Sentence Sentiment Series into 1 Big DataFrame\n",
        "\n",
        "corpus_unified_df = pd.DataFrame()\n",
        "\n",
        "# Get Baseline Model StandardScaled SMA column names\n",
        "cols_baseline_stdscaler_ls = []\n",
        "for amodel in models_baseline_ls:\n",
        "  col_roll_stdscale = f'{amodel}_stdscaler_{roll_str}'\n",
        "  cols_baseline_stdscaler_ls.append(col_roll_stdscale)\n",
        "# print(f'\\nBaseline StdScaled SMA Columns:\\n    {cols_baseline_stdscaler_ls}')\n",
        "\n",
        "temp_baseline_df = corpus_sents_df[cols_baseline_stdscaler_ls].copy()\n",
        "temp_baseline_df = temp_baseline_df.add_prefix('baseline_')\n",
        "temp_baseline_df.columns\n",
        "\n",
        "# Get SentimentR Model StandardScaled SMA column names\n",
        "cols_sentimentr_stdscaler_ls = []\n",
        "for amodel in models_sentimentr_ls:\n",
        "  col_roll_stdscale = f'{amodel}_stdscaler_{roll_str}'\n",
        "  cols_sentimentr_stdscaler_ls.append(col_roll_stdscale)\n",
        "# print(f'\\nSentimentR StdScaled SMA Columns:\\n    {cols_sentimentr_stdscaler_ls}')\n",
        "\n",
        "temp_sentimentr_df = corpus_sentimentr_df[cols_sentimentr_stdscaler_ls].copy()\n",
        "temp_sentimentr_df = temp_sentimentr_df.add_prefix('sentimentr_')\n",
        "temp_sentimentr_df.columns\n",
        "\n",
        "# Get SyuzhetR Model StandardScaled SMA column names\n",
        "cols_syuzhetr_stdscaler_ls = []\n",
        "for amodel in models_syuzhetr_ls:\n",
        "  col_roll_stdscaler = f'{amodel}_stdscaler_{roll_str}'\n",
        "  cols_syuzhetr_stdscaler_ls.append(col_roll_stdscaler)\n",
        "# print(f'\\nSyuzhetR StdScaled SMA Columns:\\n    {cols_syuzhetr_stdscaler_ls}')\n",
        "\n",
        "temp_syuzhetr_df = corpus_syuzhetr_df[cols_syuzhetr_stdscaler_ls].copy()\n",
        "temp_syuzhetr_df = temp_syuzhetr_df.add_prefix('syuzhetr_')\n",
        "temp_syuzhetr_df.columns\n",
        "\n",
        "# Get Transformer Model StandardScaled SMA column names\n",
        "cols_transformer_stdscaler_ls = []\n",
        "for amodel in models_transformer_ls:\n",
        "  col_roll_stdscale = f'{amodel}_stdscaler_{roll_str}'\n",
        "  cols_transformer_stdscaler_ls.append(col_roll_stdscale)\n",
        "# print(f'\\nTransformer StdScaled SMA Columns:\\n    {cols_transformer_stdscalerls}')\n",
        "\n",
        "# If Transformers Sentiment DataFrame exists, add it to the Unified DataFrame\n",
        "var_name = 'corpus_transformer_df'\n",
        "if var_name in globals():\n",
        "  # print(f'{var_name} is declared globally')\n",
        "  # print(eval(f'{var_name}.shape[0]'))\n",
        "  corpus_transformer_df_len = eval(f'{var_name}.shape[0]')\n",
        "  print(f'{var_name} has {corpus_transformer_df_len} Sentences')\n",
        "\n",
        "  temp_transformer_df = corpus_transformer_df[cols_transformer_stdscaler_ls].copy()\n",
        "  temp_transformer_df = temp_transformer_df.add_prefix('transformer_')\n",
        "  temp_transformer_df.columns\n",
        "\n",
        "  print(f'\\n\\n{var_name} IS declared\\n    so adding to Unified DataFrame')\n",
        "  corpus_unified_df = pd.concat([temp_baseline_df,\n",
        "                                  temp_sentimentr_df,\n",
        "                                  temp_syuzhetr_df,\n",
        "                                  temp_transformer_df],\n",
        "                                  axis=1)\n",
        "\n",
        "  temp_transformer_df = pd.DataFrame()\n",
        "\n",
        "else:\n",
        "  print(f'\\n\\n{var_name} IS NOT declared\\n    so NOT adding to Unified DataFrame')\n",
        "\n",
        "  corpus_unified_df = pd.concat([temp_baseline_df,\n",
        "                                  temp_sentimentr_df,\n",
        "                                  temp_syuzhetr_df],\n",
        "                                  axis=1)\n",
        "\n",
        "# Insert Sentence Number (sent_no) column\n",
        "sent_no_ls = list(range(corpus_unified_df.shape[0]))\n",
        "corpus_unified_df.insert(0, 'sent_no', sent_no_ls)\n",
        "sent_raw_ls = [str(x) for x in corpus_sents_df['sent_raw']]\n",
        "corpus_unified_df.insert(1, 'sent_raw', sent_raw_ls)\n",
        "# corpus_unified_df.insert(2, 'sent_clean', sent_no_ls)\n",
        "\n",
        "temp_baseline_df = pd.DataFrame()\n",
        "temp_sentimentr_df = pd.DataFrame()\n",
        "temp_syuzhetr_df = pd.DataFrame()\n",
        "\n",
        "print(f'\\corpus_unified_df.shape: {corpus_unified_df.shape}')\n",
        "corpus_unified_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWw-EKcETQWO"
      },
      "source": [
        "  corpus_plots_std_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USyCByrkibLp"
      },
      "source": [
        "# Optionally specificy and malformed models to exclude from Unified DataFrame\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "model_base_bad = 'pattern'\n",
        "\n",
        "# drop malformed models manually specified in prior code cell\n",
        "print(\"\\n=====================================================================\\n\")\n",
        "print(f\"    WARNING: Dropping Model >>>{model_base_bad}<<< and all it's derivatives\")\n",
        "print(\"\\n=====================================================================\\n\\n\")\n",
        "model_bad_ls = [x for x in corpus_unified_df.columns if model_base_bad in x]\n",
        "\n",
        "print(f'    DROPPED COLUMNS: {model_bad_ls}\\n')\n",
        "corpus_unified_df.drop(columns=model_bad_ls, inplace=True)\n",
        "print(f'    REMAINING COLUMNS: {corpus_unified_df.columns}')\n",
        "\n",
        "# Mirror changes in this plotting DataFrame too\n",
        "model_bad_ls = [x for x in corpus_plots_std_df.columns if model_base_bad in x]\n",
        "corpus_plots_std_df.drop(columns=model_bad_ls, inplace=True)\n",
        "\n",
        "# Also individually delete from all 4 composite DataFrames\n",
        "baseline_plots_std_ls = [x for x in baseline_plots_std_ls if not model_base_bad in x]\n",
        "sentimentr_plots_std_ls = [x for x in sentimentr_plots_std_ls if not model_base_bad in x]\n",
        "syuzhetr_plots_std_ls = [x for x in syuzhetr_plots_std_ls if not model_base_bad in x]\n",
        "transformer_plots_std_ls = [x for x in transformer_plots_std_ls if not model_base_bad in x]\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yzwajN3h9AK"
      },
      "source": [
        "baseline_plots_std_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OMIp6-AhYJp"
      },
      "source": [
        "corpus_plots_std_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_14bxPnjzzM"
      },
      "source": [
        "models_sentimentr_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQEPm1d2i3rF"
      },
      "source": [
        "# Create <model>_stdscaler_roll<dd> series\n",
        "\n",
        "# Step 1: Create the <model>_stdscaler\n",
        "# Baseline 12 Models\n",
        "test_df = process_timeseries(ts_df=corpus_sents_df, col_models_ls=models_baseline_ls, col_mod='std-stdscaler')\n",
        "corpus_sents_df = pd.concat([corpus_sents_df, test_df], axis=1)\n",
        "corpus_sents_df = corpus_sents_df.loc[:,~corpus_sents_df.columns.duplicated()]\n",
        "corpus_plots_std_df = pd.concat([corpus_plots_std_df, test_df], axis=1)\n",
        "corpus_plots_std_df = corpus_plots_std_df.loc[:,~corpus_plots_std_df.columns.duplicated()]\n",
        "\n",
        "# SentimentR 7 Models\n",
        "test_df = process_timeseries(ts_df=corpus_sentimentr_df, col_models_ls=models_sentimentr_ls, col_mod='std-stdscaler')\n",
        "corpus_sentimentr_df = pd.concat([corpus_sentimentr_df, test_df], axis=1)\n",
        "corpus_sentimentr_df = corpus_sentimentr_df.loc[:,~corpus_sentimentr_df.columns.duplicated()]\n",
        "corpus_plots_std_df = pd.concat([corpus_plots_std_df, test_df], axis=1)\n",
        "corpus_plots_std_df = corpus_plots_std_df.loc[:,~corpus_plots_std_df.columns.duplicated()]\n",
        "\n",
        "# SyuzhetR 4 Models\n",
        "test_df = process_timeseries(ts_df=corpus_syuzhetr_df, col_models_ls=models_syuzhetr_ls, col_mod='std-stdscaler')\n",
        "corpus_syuzhetr_df = pd.concat([corpus_syuzhetr_df, test_df], axis=1)\n",
        "corpus_syuzhetr_df = corpus_syuzhetr_df.loc[:,~corpus_syuzhetr_df.columns.duplicated()]\n",
        "corpus_plots_std_df = pd.concat([corpus_plots_std_df, test_df], axis=1)\n",
        "corpus_plots_std_df = corpus_plots_std_df.loc[:,~corpus_plots_std_df.columns.duplicated()]\n",
        "\n",
        "# Transformer 8 Models\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=models_transformer_ls, col_mod='std-stdscaler')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "corpus_plots_std_df = pd.concat([corpus_plots_std_df, test_df], axis=1)\n",
        "corpus_plots_std_df = corpus_plots_std_df.loc[:,~corpus_plots_std_df.columns.duplicated()]\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: Create the <model>_stdscaler_rollxx\n",
        "# Baseline 12 Models\n",
        "stdstdscaler_ls = [f'{x}_stdscaler' for x in models_baseline_ls]\n",
        "test_df = process_timeseries(ts_df=corpus_sents_df, col_models_ls=stdstdscaler_ls, col_mod='roll10')\n",
        "corpus_sents_df = pd.concat([corpus_sents_df, test_df], axis=1)\n",
        "corpus_sents_df = corpus_sents_df.loc[:,~corpus_sents_df.columns.duplicated()]\n",
        "corpus_plots_std_df = pd.concat([corpus_plots_std_df, test_df], axis=1)\n",
        "corpus_plots_std_df = corpus_plots_std_df.loc[:,~corpus_plots_std_df.columns.duplicated()]\n",
        "\n",
        "# SentimentR 7 Models\n",
        "stdstdscaler_ls = [f'{x}_stdscaler' for x in models_sentimentr_ls]\n",
        "test_df = process_timeseries(ts_df=corpus_sentimentr_df, col_models_ls=stdstdscaler_ls, col_mod='roll10')\n",
        "corpus_sentimentr_df = pd.concat([corpus_sentimentr_df, test_df], axis=1)\n",
        "corpus_sentimentr_df = corpus_sentimentr_df.loc[:,~corpus_sentimentr_df.columns.duplicated()]\n",
        "corpus_plots_std_df = pd.concat([corpus_plots_std_df, test_df], axis=1)\n",
        "corpus_plots_std_df = corpus_plots_std_df.loc[:,~corpus_plots_std_df.columns.duplicated()]\n",
        "\n",
        "# SyuzhetR 4 Models\n",
        "stdstdscaler_ls = [f'{x}_stdscaler' for x in models_syuzhetr_ls]\n",
        "test_df = process_timeseries(ts_df=corpus_syuzhetr_df, col_models_ls=stdstdscaler_ls, col_mod='roll10')\n",
        "corpus_syuzhetr_df = pd.concat([corpus_syuzhetr_df, test_df], axis=1)\n",
        "corpus_syuzhetr_df = corpus_syuzhetr_df.loc[:,~corpus_syuzhetr_df.columns.duplicated()]\n",
        "corpus_plots_std_df = pd.concat([corpus_plots_std_df, test_df], axis=1)\n",
        "corpus_plots_std_df = corpus_plots_std_df.loc[:,~corpus_plots_std_df.columns.duplicated()]\n",
        "\n",
        "# Transformer 8 Models\n",
        "stdstdscaler_ls = [f'{x}_stdscaler' for x in models_transformer_ls]\n",
        "test_df = process_timeseries(ts_df=corpus_transformer_df, col_models_ls=stdstdscaler_ls, col_mod='roll10')\n",
        "corpus_transformer_df = pd.concat([corpus_transformer_df, test_df], axis=1)\n",
        "corpus_transformer_df = corpus_transformer_df.loc[:,~corpus_transformer_df.columns.duplicated()]\n",
        "corpus_plots_std_df = pd.concat([corpus_plots_std_df, test_df], axis=1)\n",
        "corpus_plots_std_df = corpus_plots_std_df.loc[:,~corpus_plots_std_df.columns.duplicated()]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI_glR0-QuZL"
      },
      "source": [
        "# Combine Standardned Plots\n",
        "\n",
        "# NOTE: Baselinse has 'roll100_stdscale' vs 'stdscale_roll10' for the other 3 libraries\n",
        "unified_plots_std_ls = baseline_plots_std_ls + sentimentr_plots_std_ls + syuzhetr_plots_std_ls + transformer_plots_std_ls\n",
        "\n",
        "# Baseline plots need to be reduced/normalized on the y-axis to match other 3 libraries\n",
        "# unified_plots_std_ls = baseline_plots_std_ls + transformer_plots_std_ls\n",
        "# unified_plots_std_ls =  syuzhetr_plots_std_ls + sentimentr_plots_std_ls\n",
        "# unified_plots_std_ls = baseline_plots_std_ls + syuzhetr_plots_std_ls\n",
        "# unified_plots_std_ls = transformer_plots_std_ls + sentimentr_plots_std_ls + syuzhetr_plots_std_ls\n",
        "\n",
        "print(f'Plotting Standardized Plots for ALL \\n   {len(unified_plots_std_ls)} Models across the 4 libraries\\n')\n",
        "\n",
        "corpus_plots_std_df[unified_plots_std_ls].plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvyVLE1Yh-n2"
      },
      "source": [
        "corpus_unified_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrsydSPi43Yd"
      },
      "source": [
        "# Standardize all 31 Models (stdscaler_roll10) in Unified DataFrame for easy comparison\n",
        "\n",
        "# For Visual Check and Algo Clustering: https://www.listendata.com/2017/04/how-to-standardize-variable-in-regression.html\n",
        "\n",
        "unified_stdroll_ls = [x for x in corpus_unified_df.columns if x.endswith('roll10')]\n",
        "\n",
        "temp_df = corpus_unified_df[unified_stdroll_ls].copy(deep=True)\n",
        "temp_df.fillna(value=0, inplace=True)\n",
        "\n",
        "for amodel in unified_stdroll_ls:\n",
        "  print(amodel)\n",
        "\n",
        "  # temp_df = process_timeseries(ts_df=corpus_unified_df, col_models_ls=unified_stdroll_ls, col_mod='std-minmax')\n",
        "\n",
        "  col_mod_std = f'{amodel}_minmax'\n",
        "  # temp_std_np = minmax_scaler.fit_transform(np.array(temp_df[amodel].reshape(-1, 1)))\n",
        "  # temp_df[col_mod_std] = pd.Series(temp_std_np.ravel())\n",
        "\n",
        "\n",
        "  # corpus_unified_df = pd.concat([corpus_unified_df, temp_df], axis=1)\n",
        "  # corpus_unified_df = corpus_unified_df.loc[:,~corpus_unified_df.columns.duplicated()]\n",
        "  # temp_df = pd.concat([corpus_unified_df, temp_df], axis=1)\n",
        "  # temp_df = test.loc[:,~temp_df.columns.duplicated()]\n",
        "\n",
        "temp_df.head(2)\n",
        "temp_df.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoHelh9N0e8u"
      },
      "source": [
        "## **Correlation Heatmap for ALL StdScaler/Roll Sentence Sentiment Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yoglROBkH4_"
      },
      "source": [
        "corpus_plots_std_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qnmuzh9Xi4p"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "# Create a Correlation Heatmap for All Sentence Models\n",
        "\n",
        "# Sentence Heatmap Correlation of StdScaler Roll100 Sentiments\n",
        "# Depends on 'col_stdscaler_rollwin_ls' defined in prior code cell\n",
        "\n",
        "Correlation_Algo = \"pearson\" #@param [\"pearson\", \"spearman\", \"kendall\"]\n",
        "# corr_methods_ls = ['pearson', 'spearman', 'kendall']\n",
        "\n",
        "# corr_df = corpus_sents_syuzhetr_df[syuzhetr_corr_models_ls].corr(method='spearman')\n",
        "corr_df = corpus_plots_std_df.filter(like='roll').corr(method=Correlation_Algo)\n",
        "\n",
        "# Customize the heatmap of the corr_meat correlation matrix and rotate the x-axis labels\n",
        "fig = sns.clustermap(corr_df,\n",
        "                     row_cluster=True,\n",
        "                     col_cluster=True,\n",
        "                     figsize=(10, 10))\n",
        "\n",
        "plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n",
        "plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
        "# plt.title(f'{CORPUS_FULL} Sentence Sentiment for All Model Sentiments\\n StdScale Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.title(f'{CORPUS_FULL} Sentence Sentiment for Transformer Model Sentiments\\n {Correlation_Algo.capitalize()} Correlation Heatmap [StdScale -> SMA 10%] ({roll_str.capitalize()})')\n",
        "plt.show();\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-E48pxvt6Uw"
      },
      "source": [
        "corr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EeCGB0EFxeX"
      },
      "source": [
        "# Create a comparison DataFrame of SentimentR Sentence Models\n",
        "# Sentence Heatmap Correlation of StdScaler Roll100 Sentiments\n",
        "# Depends on 'col_stdscaler_rollwin_ls' defined in prior code cell\n",
        "\n",
        "Correlation_Algo = \"pearson\" #@param [\"pearson\", \"spearman\", \"kendall\"]\n",
        "\n",
        "corr_df = corpus_mlsup_df[models_mlsup_ls].corr(method=Correlation_Algo)\n",
        "\n",
        "# Customize the heatmap of the corr_meat correlation matrix and rotate the x-axis labels\n",
        "fig = sns.clustermap(corr_df,\n",
        "                     row_cluster=True,\n",
        "                     col_cluster=True,\n",
        "                     figsize=(10, 10))\n",
        "\n",
        "plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n",
        "plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
        "plt.title(f'{CORPUS_FULL} Sentence Sentiment for Supervised ML Model Sentiments\\n {Correlation_Algo.capitalize()} Correlation - StdScale Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeUoZ2VzGHrF"
      },
      "source": [
        "corpus_plots_std_df.iloc[1000:1005]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu6cAdPUG901"
      },
      "source": [
        "corpus_temp_std_df = corpus_plots_std_df.copy(deep=True)\n",
        "corpus_temp_std_df.fillna(0)\n",
        "corpus_temp_std_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghnyFqkvHaya"
      },
      "source": [
        "corpus_temp_std_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmuY4pF5HeZW"
      },
      "source": [
        "corpus_temp_std_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhVX5Z0HLP_T"
      },
      "source": [
        "corpus_temp_std_df.iloc[1000:1005]['pattern_stdscaler_roll10']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zruJI5D6LZJK"
      },
      "source": [
        "corpus_temp_std_df['pattern_stdscaler']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrLaKIaeIPRE"
      },
      "source": [
        "corpus_temp_std_df[corpus_temp_std_df['pattern_stdscaler_roll10'].apply(lambda x: isinstance(x, str))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r34lNnz0oeQN"
      },
      "source": [
        "# Create a Correlation Heatmap for All Sentence Models\n",
        "\n",
        "# Sentence Heatmap Correlation of StdScaler Roll100 Sentiments\n",
        "# Depends on 'col_stdscaler_rollwin_ls' defined in prior code cell\n",
        "\n",
        "Correlation_Algo = \"kendall\" #@param [\"pearson\", \"spearman\", \"kendall\"]\n",
        "# corr_methods_ls = ['pearson', 'spearman', 'kendall']\n",
        "\n",
        "# corr_df = corpus_sents_syuzhetr_df[syuzhetr_corr_models_ls].corr(method='spearman')\n",
        "# corr_df = corpus_unified_df.filter(like='stdscale').corr(method=Correlation_Algo)\n",
        "# corr_df = corpus_plots_std_df.filter(like='stdscale').corr(method=Correlation_Algo)\n",
        "# corr_df = corpus_temp_std_df.filter(like='stdscale_roll10').corr(method=Correlation_Algo)\n",
        "corr_df = corpus_temp_std_df[['sentimentr_stdscaler_roll10',\n",
        "                              'syuzhet_stdscaler_roll10',\n",
        "                              'bing_stdscaler_roll10',\n",
        "                              'sentiword_stdscaler_roll10',\n",
        "                              'senticnet_stdscaler_roll10', \n",
        "                              'nrc_stdscaler_roll10',\n",
        "                              'afinn_stdscaler_roll10',\n",
        "                              'vader_stdscaler_roll10',\n",
        "                              'textblob_stdscaler_roll10',\n",
        "                              'flair_stdscaler_roll10',\n",
        "                              # 'pattern_stdscaler_roll10',\n",
        "                              'stanza_stdscaler_roll10',\n",
        "                              'jockers_rinker_stdscaler_roll10',\n",
        "                              'jockers_stdscaler_roll10',\n",
        "                              'huliu_stdscaler_roll10',\n",
        "                              'lmcd_stdscaler_roll10',\n",
        "                              'roberta15lg_stdscaler_roll10',\n",
        "                              'nlptown_stdscaler_roll10',\n",
        "                              'yelp_stdscaler_roll10',\n",
        "                              'hinglish_stdscaler_roll10',\n",
        "                              'imdb2way_stdscaler_roll10',\n",
        "                              'huggingface_stdscaler_roll10',\n",
        "                              'huggingface_stdscaler_roll10',\n",
        "                              't5imdb50k_stdscaler_roll10',\n",
        "                              'robertaxml8lang_stdscaler_roll10']].corr(method=Correlation_Algo)\n",
        "\n",
        "# Customize the heatmap of the corr_meat correlation matrix and rotate the x-axis labels\n",
        "fig = sns.clustermap(corr_df,\n",
        "                     row_cluster=True,\n",
        "                     col_cluster=True,\n",
        "                     figsize=(10, 10))\n",
        "\n",
        "plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90)\n",
        "plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\n",
        "# plt.title(f'{CORPUS_FULL} Sentence Sentiment for All Model Sentiments\\n StdScale Sentiments SMA ({roll_str.capitalize()})')\n",
        "plt.title(f'{CORPUS_FULL} Sentence Sentiment for All 31 Models Sentiments\\n {Correlation_Algo.capitalize()} Correlation Heatmap [StdScale -> SMA 10%] ({roll_str.capitalize()})')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBbzrg1Tt95S"
      },
      "source": [
        "corr_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nznsrhwwioqq"
      },
      "source": [
        "# **Compare Subset of Unified Models** \n",
        "\n",
        "**Sentences (StdScaler/Roll)**\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "* Select any combination of Sentiment Models in order of the following four Groups: Baseline, SentimentR, SyuzhetR and Transformers\n",
        "\n",
        "* All Sentiment Time Series are StandardizedScaled version of SMA created in the notebook above this cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4h3V4Pa0voZ"
      },
      "source": [
        "#### **Interactive Sentence SMA Plots**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEaMXFw6hayU"
      },
      "source": [
        "Baseline_SentimentR = True #@param {type:\"boolean\"}\n",
        "Baseline_Syuzhet = False #@param {type:\"boolean\"}\n",
        "Baseline_Bing = False #@param {type:\"boolean\"}\n",
        "Baseline_SenticNet = False #@param {type:\"boolean\"}\n",
        "Baseline_SentiWord = True #@param {type:\"boolean\"}\n",
        "Baseline_NRC = True #@param {type:\"boolean\"}\n",
        "Baseline_AFINN = False #@param {type:\"boolean\"}\n",
        "Baseline_VADER = True #@param {type:\"boolean\"}\n",
        "Baseline_TextBlob = True #@param {type:\"boolean\"}\n",
        "Baseline_Flair = True #@param {type:\"boolean\"}\n",
        "Baseline_Pattern = False #@param {type:\"boolean\"}\n",
        "Baseline_Stanza = True #@param {type:\"boolean\"}\n",
        "# Baseline-Mean_All = False #@param {type:\"boolean\"}\n",
        "# Baseline-Mean_Subset = False #@param {type:\"boolean\"}\n",
        "# Baseline-MPQA = False #@param {type:\"boolean\"}\n",
        "# Baseline-SentiStrength = False #@param {type:\"boolean\"}\n",
        "\n",
        "SentimentR_JockersRinker = True #@param {type:\"boolean\"}\n",
        "SentimentR_Jockers = True #@param {type:\"boolean\"}\n",
        "SentimentR_HuLiu = False #@param {type:\"boolean\"}\n",
        "SentimentR_SenticNet = False #@param {type:\"boolean\"}\n",
        "SentimentR_SentiWord = False #@param {type:\"boolean\"}\n",
        "SentimentR_NRC = False #@param {type:\"boolean\"}\n",
        "SentimentR_LoughranMcDonald = False #@param {type:\"boolean\"}\n",
        "\n",
        "SyuzhetR_Syuzhet = True #@param {type:\"boolean\"}\n",
        "SyuzhetR_Bing = False #@param {type:\"boolean\"}\n",
        "SyuzhetR_AFINN = False #@param {type:\"boolean\"}\n",
        "SyuzhetR_NRC = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "Transformer_RoBERTaLg15 = True #@param {type:\"boolean\"}\n",
        "Transformer_T5IMDB50k = True #@param {type:\"boolean\"}\n",
        "Transformer_Huggingface = True #@param {type:\"boolean\"}\n",
        "Transformer_NLPTown = True #@param {type:\"boolean\"}\n",
        "Transformer_RoBERTaXML8lang = True #@param {type:\"boolean\"}\n",
        "Transformer_IMDB2way = False #@param {type:\"boolean\"}\n",
        "Transformer_Hinglish = False #@param {type:\"boolean\"}\n",
        "Transformer_Yelp = False #@param {type:\"boolean\"}\n",
        "# Mean_Subset_Arc = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkR7gXEehbbf"
      },
      "source": [
        "# Plotly Interactive/Zoom Sentiment Plots\n",
        "\n",
        "# SMA_Window_Percent = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "# win_per = SMA_Window_Percent\n",
        "# win_roll = int(win_per/100 * corpus_unified_df.shape[0])\n",
        "\n",
        "# NOTE: all 4 Groups need to be run with the same SMA roll_per (usually 5 or 10%)\n",
        "#       to compare Models from the 4 different Groups\n",
        "\n",
        "\n",
        "model_all_subset_ls = []\n",
        "\n",
        "if Baseline_SentimentR == True:\n",
        "  model_all_subset_ls.append('baseline_sentimentr_stdscaler_roll10')\n",
        "if Baseline_Syuzhet == True:\n",
        "  model_all_subset_ls.append('baseline_syuzhet_stdscaler_roll10')\n",
        "if Baseline_Bing == True:\n",
        "  model_all_subset_ls.append('baseline_bing_stdscaler_roll10')\n",
        "if Baseline_SenticNet == True:\n",
        "  model_all_subset_ls.append('baseline_senticnet_stdscaler_roll10')\n",
        "if Baseline_SentiWord == True:\n",
        "  model_all_subset_ls.append('baseline_sentiword_stdscaler_roll10')\n",
        "if Baseline_NRC == True:\n",
        "  model_all_subset_ls.append('baseline_nrc_stdscaler_roll10')\n",
        "if Baseline_AFINN == True:\n",
        "  model_all_subset_ls.append('baseline_afinn_stdscaler_roll10')\n",
        "if Baseline_VADER == True:\n",
        "  model_all_subset_ls.append('baseline_vader_stdscaler_roll10')\n",
        "if Baseline_TextBlob == True:\n",
        "  model_all_subset_ls.append('baseline_textblob_stdscaler_roll10')\n",
        "if Baseline_Flair == True:\n",
        "  model_all_subset_ls.append('baseline_flair_stdscaler_roll10')\n",
        "if Baseline_Pattern == True:\n",
        "  model_all_subset_ls.append('baseline_pattern_stdscaler_roll10')\n",
        "if Baseline_Stanza == True:\n",
        "  model_all_subset_ls.append('baseline_stanza_stdscaler_roll10')\n",
        "\n",
        "if SentimentR_JockersRinker == True:\n",
        "  model_all_subset_ls.append('sentimentr_jockers_rinker_stdscaler_roll10')\n",
        "if SentimentR_Jockers == True:\n",
        "  model_all_subset_ls.append('sentimentr_jockers_stdscaler_roll10')\n",
        "if SentimentR_HuLiu == True:\n",
        "  model_all_subset_ls.append('sentimentr_huliu_stdscaler_roll10')\n",
        "if SentimentR_SenticNet == True:\n",
        "  model_all_subset_ls.append('sentimentr_senticnet_stdscaler_roll10')\n",
        "if SentimentR_SentiWord == True:\n",
        "  model_all_subset_ls.append('sentimentr_sentiword_stdscaler_roll10')\n",
        "if SentimentR_NRC == True:\n",
        "  model_all_subset_ls.append('sentimentr_nrc_stdscaler_roll10')\n",
        "if SentimentR_LoughranMcDonald == True:\n",
        "  model_all_subset_ls.append('sentimentr_lmcd_stdscaler_roll10')\n",
        "\n",
        "\n",
        "if SyuzhetR_Syuzhet == True:\n",
        "  model_all_subset_ls.append('syuzhetr_syuzhet_stdscaler_roll10')\n",
        "if SyuzhetR_Bing == True:\n",
        "  model_all_subset_ls.append('syuzhetr_bing_stdscaler_roll10')\n",
        "if SyuzhetR_AFINN == True:\n",
        "  model_all_subset_ls.append('syuzhetr_afinn_stdscaler_roll10')\n",
        "if SyuzhetR_NRC == True:\n",
        "  model_all_subset_ls.append('syuzhetr_nrc_stdscaler_roll10')\n",
        "\n",
        "# Exclude Transformer Models if not loaded/defined\n",
        "var_name = 'corpus_transformer_df'\n",
        "if var_name in globals():\n",
        "  # print(f'{var_name} is declared globally')\n",
        "  # print(eval(f'{var_name}.shape[0]'))\n",
        "  corpus_transformer_df_len = eval(f'{var_name}.shape[0]')\n",
        "  print(f'{var_name} has {corpus_transformer_df_len} Sentences')\n",
        "\n",
        "  if Transformer_RoBERTaLg15 == True:\n",
        "    model_all_subset_ls.append('transformer_roberta15lg_stdscaler_roll10')\n",
        "  if Transformer_T5IMDB50k == True:\n",
        "    model_all_subset_ls.append('transformer_t5imdb50k_stdscaler_roll10')\n",
        "  if Transformer_Huggingface == True:\n",
        "    model_all_subset_ls.append('transformer_huggingface_stdscaler_roll10')\n",
        "  if Transformer_NLPTown == True:\n",
        "    model_all_subset_ls.append('transformer_nlptown_stdscaler_roll10')\n",
        "  if Transformer_RoBERTaXML8lang == True:\n",
        "    model_all_subset_ls.append('transformer_robertaxml8lang_stdscaler_roll10')\n",
        "  if Transformer_IMDB2way == True:\n",
        "    model_all_subset_ls.append('transformer_imdb2way_stdscaler_roll10')\n",
        "  if Transformer_Hinglish == True:\n",
        "    model_all_subset_ls.append('transformer_hinglish_stdscaler_roll10')\n",
        "  if Transformer_Yelp == True:\n",
        "    model_all_subset_ls.append('transformer_yelp_stdscaler_roll10')\n",
        "\n",
        "\n",
        "else:\n",
        "  print(f'ERROR: {var_name} IS NOT declared\\n    Go back and load Transformer Sentiment Datafile\\n    and re-run this code cell')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "palette = cycle(px.colors.qualitative.Safe)\n",
        "# palette = cycle(px.colors.sequential.PuBu)\n",
        "\n",
        "my_layout = go.Layout(\n",
        "    autosize=False,\n",
        "    width=1600,\n",
        "    height=800,\n",
        "    margin=go.layout.Margin(\n",
        "        l=10,\n",
        "        r=50,\n",
        "        b=100,\n",
        "        t=100,\n",
        "        pad = 1\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "fig = go.Figure(layout=my_layout)\n",
        "\n",
        "\n",
        "# Add Sentiment Arc Plot Traces\n",
        "for i,amodel in enumerate(model_all_subset_ls):\n",
        "  print(f'Processing Model: {amodel}')\n",
        "  # TODO: Fix this discrepency at source\n",
        "  if amodel.startswith('baseline'):\n",
        "    scale_factor = 10\n",
        "  else:\n",
        "    scale_factor = 1\n",
        "  fig.add_traces(go.Line(x = corpus_unified_df.index.values,\n",
        "                        y = scale_factor * corpus_unified_df[amodel],\n",
        "                        text = corpus_sents_df['sent_raw'], # corpus_sents_df.iloc[x]['sent_raw'],\n",
        "                        name = amodel,\n",
        "                        hovertemplate = \"Model: <b>\"+amodel+\"</b><br>Sentence #<b>%{x}</b><br>Polarity <b>%{y}</b><br>Text: <b><i>%{text}</i></b>\", \n",
        "                        marker_color=next(palette)))\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    title=CORPUS_FULL + \"<br>Compare Sentence StandardizedScaled SMA Sentiment Models<b><i> \" + roll_str.upper() + \"</i></b>\",\n",
        "    xaxis_title=\"Sentence Number\",\n",
        "    # yaxis_title=\"Sentiment Value\",\n",
        "    hoverlabel=dict(\n",
        "        bgcolor=\"white\",\n",
        "        font_size=16,\n",
        "        font_family=\"Rockwell\"\n",
        "    ),\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=18,\n",
        "        color=\"RebeccaPurple\"\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQvLaYbcsNWr"
      },
      "source": [
        "#### **Hierarichal Clustering**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH7beIkM1Xzg"
      },
      "source": [
        "#### **Top-n Crux Peaks and Valleys**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBRQB7Gi1Oyb"
      },
      "source": [
        "Get_Peak_Cruxes = True #@param {type:\"boolean\"}\n",
        "Get_n_Cruxes = 20 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "No_Paragraphs_on_Each_Side = 0 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "Highlight_Sentence = True #@param {type:\"boolean\"}\n",
        "Save_to_Report = False #@param {type:\"boolean\"}\n",
        "\n",
        "if Sort_by_SentenceNo == True:\n",
        "  sort_on = 'sent_no'\n",
        "else:\n",
        "  sort_on = 'sentiment_val'\n",
        "  \n",
        "if Save_to_Report == False:\n",
        "  crux_sortsents_report(model_crux_ls, \n",
        "                        ts_df = corpus_unified_df,\n",
        "                        library_type='unified',\n",
        "                        top_n=Get_n_Cruxes, \n",
        "                        get_peaks=Get_Peak_Cruxes, \n",
        "                        sort_by = sort_on, # sent_no, or abs(polarity)\n",
        "                        n_sideparags=No_Paragraphs_on_Each_Side,\n",
        "                        sentence_highlight=Highlight_Sentence)\n",
        "\n",
        "\n",
        "else:\n",
        "  # https://www.kite.com/python/answers/how-to-get-stdout-and-stderr-from-a-process-as-a-string-in-python\n",
        "  # process = subprocess.run([\"echo\", \"This goes to stdout\"], capture_output=True)\n",
        "  # stdout_as_str = process.stdout.decode(\"utf-8\")\n",
        "  # print(stdout_as_str)\n",
        "  temp_out = StringIO()\n",
        "  sys.stdout = temp_out\n",
        "  crux_sortsents_report(model_crux_ls, top_n=Get_n_Cruxes, get_peaks=Get_Peak_Cruxes, n_sideparags=No_Paragraphs_on_Each_Side)\n",
        "  print(temp_out)\n",
        "  # attempt to save temp_out to generated filename\n",
        "  sys.stdout = sys.__stdout__\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yz3pVMy4y0v"
      },
      "source": [
        "corpus_unified_df[model_all_subset_ls].head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64ytlcCd9eQS"
      },
      "source": [
        "# Verify selected models and DataFrame shapes\n",
        "\n",
        "model_all_subset_ls\n",
        "print('\\n')\n",
        "corpus_unified_df.shape\n",
        "print('\\n')\n",
        "corpus_unified_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDP1T4Vo9535"
      },
      "source": [
        "len(corpus_unified_df['transformer_robertaxml8lang_stdscaler_roll10'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnPA8Eci-3hl"
      },
      "source": [
        "# def get_crux_points(ts_df, col_series, text_type='sentence', win_per=5, sec_y_labels=True, sec_y_height=0, subtitle_str=' ', do_plot=True, save2file=False):\n",
        "get_crux_points(corpus_unified_df, 'baseline_flair_stdscaler_roll10', text_type='sentence', win_per=5, sec_y_labels=False, do_plot=False )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaZxD8kbV271"
      },
      "source": [
        "cruxes_unified_dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZtx8NfhowLJ"
      },
      "source": [
        "# minIndex = myList.index(min(myList))\n",
        "# min(sentiment_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAfMs8Bmz2vE"
      },
      "source": [
        "#### **Crux Points: Table**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQE4lt_ZvTw2"
      },
      "source": [
        "# Compute Crux Values for selected Models\n",
        "\n",
        "cruxes_unified_dt = {}\n",
        "Crux_Window_Percent = 10\n",
        "\n",
        "for i,amodel in enumerate(model_all_subset_ls):\n",
        "  print(f'Processing Model: {amodel}')\n",
        "  # cruxes_unified_dt[amodel]\n",
        "  amodel_cruxes_ls = get_crux_points(ts_df=corpus_unified_df, \n",
        "                                         col_series=amodel, \n",
        "                                         text_type='sentence', \n",
        "                                         win_per=5, \n",
        "                                         sec_y_height=0, \n",
        "                                         subtitle_str=' Selected Models ', \n",
        "                                         do_plot=False, \n",
        "                                         save2file=False)\n",
        "  \n",
        "  print(f'    {len(amodel_cruxes_ls)} Cruxes found for {amodel}\\n')\n",
        "\n",
        "  cruxes_unified_dt[amodel] = amodel_cruxes_ls\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb3-IZu5KjWR"
      },
      "source": [
        "# Create Unified Crux Points DataFrame for selected models\n",
        "\n",
        "model_ls = []\n",
        "type_ls = []\n",
        "sent_no_ls = []\n",
        "sentiment_ls = []\n",
        "sent_raw_ls = []\n",
        "for model_name, model_crux_ls in cruxes_unified_dt.items():\n",
        "\n",
        "  print(f'Model: {model_name} with {len(model_crux_ls)} Cruxes')\n",
        "\n",
        "  for i, acrux_tup in enumerate(model_crux_ls):\n",
        "    model_ls.append(model_name)\n",
        "\n",
        "    atype, asent_no, asentiment = acrux_tup \n",
        "    type_ls.append(atype)\n",
        "    sent_no_ls.append(asent_no)\n",
        "    sentiment_ls.append(asentiment)\n",
        "\n",
        "    sent_raw = corpus_sents_df.iloc[asent_no]['sent_raw']\n",
        "    sent_raw_ls.append(sent_raw)\n",
        "\n",
        "\n",
        "# Hack: scale sentiment from approx -1.0-+1.0 to -100-+100\n",
        "sentiment_min = min(sentiment_ls)\n",
        "if sentiment_min < 0:\n",
        "  add_adj = np.abs(sentiment_min)\n",
        "sentiment100_ls = [x+add_adj for x in sentiment_ls]\n",
        "print(f'BEFORE: min of sentiment100_ls is {min(sentiment100_ls)}')\n",
        "print(f'BEFORE: max of sentiment100_ls is {max(sentiment100_ls)}')\n",
        "sentiment100_ls = [int(x*10) for x in sentiment100_ls]\n",
        "print(f'AFTER: min of sentiment100_ls is {min(sentiment100_ls)}')\n",
        "print(f'AFTER: max of sentiment100_ls is {max(sentiment100_ls)}')\n",
        "\n",
        "unified_crux_df = pd.DataFrame({'model':pd.Series(model_ls,dtype='string'),\n",
        "                                'type':pd.Series(type_ls,dtype='string'),\n",
        "                                'sent_no':pd.Series(sent_no_ls,dtype='int'),\n",
        "                                'sent_raw':pd.Series(sent_raw_ls,dtype='str'),\n",
        "                                'sentiment':pd.Series(sentiment_ls,dtype='float'),\n",
        "                                'sentiment100':pd.Series(sentiment100_ls,dtype='int')})\n",
        "\n",
        "# Add token_len column\n",
        "unified_crux_df['token_len'] = unified_crux_df['sent_raw'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Add Abbreviated raw_sent column\n",
        "unified_crux_df['sent_raw_abbr'] = unified_crux_df['sent_raw'].apply(lambda x: x[:100])\n",
        "\n",
        "# Trim suffix '_stdscaler_roll10' off Model name\n",
        "unified_crux_df['model'] = unified_crux_df['model'].apply(lambda x: '_'.join(x.split('_')[:2]))\n",
        "\n",
        "# Sort by sent_no\n",
        "unified_crux_df = unified_crux_df.sort_values(by=['sent_no','model'], ascending=True)\n",
        "\n",
        "\n",
        "# Verify\n",
        "print('\\n')\n",
        "unified_crux_df.head(10)\n",
        "print('\\n')\n",
        "print(f'{unified_crux_df.shape[0]} Cruxes were found in the Subset of the Unified Models.')\n",
        "print('\\n\\n')\n",
        "\n",
        "# Save table of Cruxes (extracted from a subset of models) to file\n",
        "title_str = ''.join(title_str.split('.')).lower()\n",
        "datetime_now = datetime.utcnow().strftime(\"%Y%m%d_%H%M\")\n",
        "\n",
        "# Save Preprocessed Corpus Sentences DataFrame\n",
        "unifed_crux_filename = f'cruxes_table_unified_subset_{author_abbr_str}_{title_str}_{datetime_now}.csv'\n",
        "unified_crux_df.to_csv(unifed_crux_filename)\n",
        "\n",
        "print(f'Saving Cruxs found in these Models:\\n\\n')\n",
        "print(*model_all_subset_ls, sep=os.linesep)\n",
        "\n",
        "print(f\"\\n\\nSaving to file:\\n\\n{unifed_crux_filename}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_HCP_gKJzQ3"
      },
      "source": [
        "# Download *csv table of Unified Crux Points from Selected Models\n",
        "\n",
        "files.download(unifed_crux_filename)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DzDgKJp0Cl0"
      },
      "source": [
        "#### **Crux Points: 2D Interactive Clusters**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dCf8C3iYzGd"
      },
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Emphasize token_len\n",
        "# fig = px.scatter(unified_crux_df, x=\"sent_no\", y=\"sentiment\", symbol='type', symbol_map={'peak':5, 'valley':6}, color=\"model\", opacity=0.5, size='token_len', hover_data=['sent_raw_abbr'])\n",
        "\n",
        "# Emphasize Peak/Valley\n",
        "fig = px.scatter(unified_crux_df, x=\"sent_no\", y=\"sentiment\", symbol='type', symbol_map={'peak':5, 'valley':6}, color=\"model\", opacity=0.5, size='sentiment100', hover_data=['sent_raw_abbr'])\n",
        "\n",
        "fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8lLn8jZmyxh"
      },
      "source": [
        "# Create Mean of selected Models\n",
        "\n",
        "if 'mean_roll10' in model_all_subset_ls:\n",
        "  model_all_subset_ls.remove('mean_roll10')\n",
        "models_all_subset_mean_ser = corpus_unified_df[model_all_subset_ls].mean(axis=1)\n",
        "# unified_crux_df.insert(5, 'mean_roll', list(models_all_subset_mean_ser))\n",
        "\n",
        "# Create Median of selected Models\n",
        "# unified_crux_df['model'] = unified_crux_df['model'].apply(lambda x: '_'.join(x.split('_')[:2]))\n",
        "\n",
        "models_all_subset_mean_ser.plot()\n",
        "plt.title(f'{CORPUS_FULL}\\nSentence Mean of SMA 10% for {len(model_all_subset_ls)} Selected Models')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfBR_bpzq7qh"
      },
      "source": [
        "# Create Mean of selected Models\n",
        "\n",
        "if 'mean_roll10' in model_all_subset_ls:\n",
        "  model_all_subset_ls.remove('mean_roll10')\n",
        "models_all_subset_mean_ser = corpus_unified_df[model_all_subset_ls].mean(axis=1)\n",
        "# unified_crux_df.insert(5, 'mean_roll', list(models_all_subset_mean_ser))\n",
        "\n",
        "# Create Median of selected Models\n",
        "# unified_crux_df['model'] = unified_crux_df['model'].apply(lambda x: '_'.join(x.split('_')[:2]))\n",
        "\n",
        "# models_all_subset_mean_ser.plot()\n",
        "\n",
        "sns.scatterplot(\n",
        "    data=unified_crux_df, x=\"sent_no\", y=\"sentiment\", hue=\"sentiment\", size=\"sentiment100\", sizes=(20, 200), style='model', hue_norm=(0, 7), legend=\"auto\"\n",
        ")\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohUZSIpduuDs"
      },
      "source": [
        "# dbscan clustering\n",
        "\n",
        "\n",
        "EPS_Max_Distance = 5\n",
        "\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.cluster import DBSCAN\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# define dataset\n",
        "X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "\n",
        "# define the model\n",
        "model = DBSCAN(eps=EPS_Max_Distance, min_samples=4)\n",
        "\n",
        "# create numpy array of crux subset values\n",
        "crux_subset_np = unified_crux_df[['sent_no','sentiment']].to_numpy()\n",
        "crux_subset_np.shape\n",
        "\n",
        "# fit model and predict clusters\n",
        "yhat = model.fit_predict(crux_subset_np)\n",
        "\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "\n",
        "# create scatter plot for samples from each cluster\n",
        "for cluster in clusters:\n",
        "\t# get row indexes for samples with this cluster\n",
        "\trow_ix = where(yhat == cluster)\n",
        "\t# create scatter of these samples\n",
        "\tpyplot.scatter(crux_subset_np[row_ix, 0], crux_subset_np[row_ix, 1])\n",
        " \n",
        "# show the plot\n",
        "plt.title(f'{CORPUS_FULL} DBSCAN (eps={EPS_Max_Distance}) Clusters of Cruxes\\nSentence Mean of SMA 10% for {len(model_all_subset_ls)} Selected Models')\n",
        "pyplot.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SY5jcKfx82Z"
      },
      "source": [
        "# AutoML find opt eps based upon dataset neighborhood distances\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "neigh = NearestNeighbors(n_neighbors=2)\n",
        "nbrs = neigh.fit(crux_subset_np)\n",
        "distances, indices = nbrs.kneighbors(X)\n",
        "\n",
        "distances = np.sort(distances, axis=0)\n",
        "distances = distances[:,1]\n",
        "plt.plot(distances)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "565hDwuex8ud"
      },
      "source": [
        "m = DBSCAN(eps=50, min_samples=5)\n",
        "\n",
        "m.fit(crux_subset_np)\n",
        "\n",
        "clusters = m.labels_\n",
        "\n",
        "colors = ['royalblue', 'maroon', 'forestgreen', 'mediumorchid', 'tan', 'deeppink', 'olive', 'goldenrod', 'lightcyan', 'navy']\n",
        "\n",
        "vectorizer = np.vectorize(lambda x: colors[x % len(colors)])\n",
        "\n",
        "plt.scatter(crux_subset_np[:,0], crux_subset_np[:,1], c=vectorizer(clusters))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6993R3tMut_W"
      },
      "source": [
        "# k-means clustering\n",
        "\n",
        "How_Many_Clusters = 15 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "\n",
        "\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.cluster import KMeans\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# define dataset\n",
        "X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n",
        "\n",
        "# define the model\n",
        "model = KMeans(n_clusters=How_Many_Clusters)\n",
        "\n",
        "# fit the model\n",
        "model.fit(crux_subset_np)\n",
        "\n",
        "# assign a cluster to each example\n",
        "yhat = model.predict(crux_subset_np)\n",
        "\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "\n",
        "# create scatter plot for samples from each cluster\n",
        "for cluster in clusters:\n",
        "\t# get row indexes for samples with this cluster\n",
        "\trow_ix = where(yhat == cluster)\n",
        "\t# create scatter of these samples\n",
        "\tpyplot.scatter(crux_subset_np[row_ix, 0], crux_subset_np[row_ix, 1])\n",
        "# show the plot\n",
        "plt.title(f'{CORPUS_FULL} kMeans (k={How_Many_Clusters}) Clusters of Cruxes\\nSentence Mean of SMA 10% for {len(model_all_subset_ls)} Selected Models')\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qda1yIqM0Qvw"
      },
      "source": [
        "#### **Crux Points: 1D Interactive Clusters**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB8r3yrPcHwi"
      },
      "source": [
        "y0_ls = [0] * unified_crux_df.shape[0]\n",
        "\n",
        "df = px.data.iris()\n",
        "fig = px.scatter(unified_crux_df, x=\"sent_no\", y=y0_ls, symbol='type', symbol_map={'peak':5, 'valley':6}, color=\"model\", opacity=0.5, size='token_len', hover_data=['sent_raw_abbr'])\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7WUuj1j4XW7"
      },
      "source": [
        "## **Save Checkpoint**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18kf77WgvsK-"
      },
      "source": [
        "# Save Corpus DataFrames\n",
        "\n",
        "save_dataframes(df_ls=['everything'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_j92DSgyhGc"
      },
      "source": [
        "# **END OF WORKING**"
      ]
    }
  ]
}