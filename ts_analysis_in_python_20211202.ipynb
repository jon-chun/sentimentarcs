{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ts_analysis_in_python_20211202.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0DVV03pgj+tPrQfDr75aC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jon-chun/sentimentarcs/blob/main/ts_analysis_in_python_20211202.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXOhubizMT_B"
      },
      "source": [
        "* https://www.machinelearningplus.com/time-series/time-series-analysis-python/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttS_4jZdU0dD"
      },
      "source": [
        "# Import a Time Series into Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ3yywS1-Ksh"
      },
      "source": [
        "from dateutil.parser import parse \n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "plt.rcParams.update({'figure.figsize': (10, 7), 'figure.dpi': 120})\n",
        "\n",
        "# Import as Dataframe\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', parse_dates=['date'])\n",
        "df.head()\n",
        "\n",
        "\"\"\"\n",
        "# Alternatively import as Series\n",
        "ser = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', parse_dates=['date'], index_col='date')\n",
        "ser.head()\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-trwpS9MStE"
      },
      "source": [
        "# dataset source: https://github.com/rouseguy\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/MarketArrivals.csv')\n",
        "df = df.loc[df.market=='MUMBAI', :]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-buhzSSM0I8"
      },
      "source": [
        "# Time series data source: fpp pacakge in R.\n",
        "import matplotlib.pyplot as plt\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', parse_dates=['date'], index_col='date')\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnLahICCU3ej"
      },
      "source": [
        "# Plot with Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4gL0zDLMhz0"
      },
      "source": [
        "\n",
        "# Draw Plot\n",
        "def plot_df(df, x, y, title=\"\", xlabel='Date', ylabel='Value', dpi=100):\n",
        "    plt.figure(figsize=(16,5), dpi=dpi)\n",
        "    plt.plot(x, y, color='tab:red')\n",
        "    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
        "    plt.show()\n",
        "\n",
        "plot_df(df, x=df.index, y=df.value, title='Monthly anti-diabetic drug sales in Australia from 1992 to 2008.')   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yoGWW_xNlmK"
      },
      "source": [
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dGlpsO4OJrF"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktXDHUnpNP7l"
      },
      "source": [
        "# Import data\n",
        "# df = pd.read_csv('datasets/AirPassengers.csv', parse_dates=['date'])\n",
        "pd.to_datetime(df.index,infer_datetime_format=True)\n",
        "# # x = df['date'].values\n",
        "# y1 = df['value'].values\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0etzHAfhMmDT"
      },
      "source": [
        "# Import data\n",
        "# df = pd.read_csv('datasets/AirPassengers.csv', parse_dates=['date'])\n",
        "# df['date'] = pd.to_datetime(df['date'])\n",
        "x = df.index\n",
        "y1 = df['value'].values\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(1, 1, figsize=(16,5), dpi= 120)\n",
        "plt.fill_between(x, y1=y1, y2=-y1, alpha=0.5, linewidth=2, color='seagreen')\n",
        "# plt.ylim(-800, 800)\n",
        "plt.title('Air Passengers (Two Side View)', fontsize=16)\n",
        "plt.hlines(y=0, xmin=np.min(df.index), xmax=np.max(df.index), linewidth=.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fXDXwR3PA3p"
      },
      "source": [
        "# Import Data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', parse_dates=['date'], index_col='date')\n",
        "df.reset_index(inplace=True)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgB6Su2RPEoC"
      },
      "source": [
        "# Prepare data\n",
        "df['year'] = [d.year for d in df.date]\n",
        "df['month'] = [d.strftime('%b') for d in df.date]\n",
        "years = df['year'].unique()\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-0OrgOFPR4k"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_pus2Z-MqOH"
      },
      "source": [
        "# Prep Colors\n",
        "np.random.seed(100)\n",
        "mycolors = np.random.choice(list(mpl.colors.XKCD_COLORS.keys()), len(years), replace=False)\n",
        "\n",
        "# Draw Plot\n",
        "plt.figure(figsize=(16,12), dpi= 80)\n",
        "for i, y in enumerate(years):\n",
        "    if i > 0:        \n",
        "        plt.plot('month', 'value', data=df.loc[df.year==y, :], color=mycolors[i], label=y)\n",
        "        plt.text(df.loc[df.year==y, :].shape[0]-.9, df.loc[df.year==y, 'value'][-1:].values[0], y, fontsize=12, color=mycolors[i])\n",
        "\n",
        "# Decoration\n",
        "plt.gca().set(xlim=(-0.3, 11), ylim=(2, 30), ylabel='$Drug Sales$', xlabel='$Month$')\n",
        "plt.yticks(fontsize=12, alpha=.7)\n",
        "plt.title(\"Seasonal Plot of Drug Sales Time Series\", fontsize=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVb10KxmO8KA"
      },
      "source": [
        "# Import Data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', parse_dates=['date'], index_col='date')\n",
        "df.reset_index(inplace=True)\n",
        "\n",
        "# Prepare data\n",
        "df['year'] = [d.year for d in df.date]\n",
        "df['month'] = [d.strftime('%b') for d in df.date]\n",
        "years = df['year'].unique()\n",
        "\n",
        "# Draw Plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20,7), dpi= 80)\n",
        "sns.boxplot(x='year', y='value', data=df, ax=axes[0])\n",
        "sns.boxplot(x='month', y='value', data=df.loc[~df.year.isin([1991, 2008]), :])\n",
        "\n",
        "# Set Title\n",
        "axes[0].set_title('Year-wise Box Plot\\n(The Trend)', fontsize=18); \n",
        "axes[1].set_title('Month-wise Box Plot\\n(The Seasonality)', fontsize=18)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWPnaGRWVCeM"
      },
      "source": [
        "# Patterns in Time Series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox0h8qsbPjch"
      },
      "source": [
        "fig, axes = plt.subplots(1,3, figsize=(20,4), dpi=100)\n",
        "pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/guinearice.csv', parse_dates=['date'], index_col='date').plot(title='Trend Only', legend=False, ax=axes[0])\n",
        "\n",
        "pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/sunspotarea.csv', parse_dates=['date'], index_col='date').plot(title='Seasonality Only', legend=False, ax=axes[1])\n",
        "\n",
        "pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/AirPassengers.csv', parse_dates=['date'], index_col='date').plot(title='Trend and Seasonality', legend=False, ax=axes[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAjzrjtIU9_4"
      },
      "source": [
        "# Decompose Time Series (Additive & Multiplicative)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87uU1jVWPzII"
      },
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from dateutil.parser import parse\n",
        "\n",
        "# Import Data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', parse_dates=['date'], index_col='date')\n",
        "\n",
        "# Multiplicative Decomposition \n",
        "result_mul = seasonal_decompose(df['value'], model='multiplicative', extrapolate_trend='freq')\n",
        "\n",
        "# Additive Decomposition\n",
        "result_add = seasonal_decompose(df['value'], model='additive', extrapolate_trend='freq')\n",
        "\n",
        "# Plot\n",
        "plt.rcParams.update({'figure.figsize': (10,10)})\n",
        "result_mul.plot().suptitle('Multiplicative Decompose', fontsize=22)\n",
        "result_add.plot().suptitle('Additive Decompose', fontsize=22)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cuyY3KHP4qS"
      },
      "source": [
        "# Extract the Components ----\n",
        "# Actual Values = Product of (Seasonal * Trend * Resid)\n",
        "df_reconstructed = pd.concat([result_mul.seasonal, result_mul.trend, result_mul.resid, result_mul.observed], axis=1)\n",
        "df_reconstructed.columns = ['seas', 'trend', 'resid', 'actual_values']\n",
        "df_reconstructed.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTPfZQGCQibG"
      },
      "source": [
        "# Test for Stationarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8W9_8JuQJCh"
      },
      "source": [
        "from statsmodels.tsa.stattools import adfuller, kpss\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', parse_dates=['date'])\n",
        "\n",
        "# ADF Test\n",
        "result = adfuller(df.value.values, autolag='AIC')\n",
        "print(f'ADF Statistic: {result[0]}')\n",
        "print(f'p-value: {result[1]}')\n",
        "for key, value in result[4].items():\n",
        "    print('Critial Values:')\n",
        "    print(f'   {key}, {value}')\n",
        "\n",
        "# KPSS Test\n",
        "result = kpss(df.value.values, regression='c')\n",
        "print('\\nKPSS Statistic: %f' % result[0])\n",
        "print('p-value: %f' % result[1])\n",
        "for key, value in result[3].items():\n",
        "    print('Critial Values:')\n",
        "    print(f'   {key}, {value}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD_d9dZzQzYb"
      },
      "source": [
        "# White Noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV12zwEkQkb0"
      },
      "source": [
        "randvals = np.random.randn(1000)\n",
        "pd.Series(randvals).plot(title='Random White Noise', color='k')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Li_e6t4Q_tV"
      },
      "source": [
        "# Detrend"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC53xh32Q0eZ"
      },
      "source": [
        "# Using scipy: Subtract the line of best fit\n",
        "from scipy import signal\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', parse_dates=['date'])\n",
        "detrended = signal.detrend(df.value.values)\n",
        "plt.plot(detrended)\n",
        "plt.title('Drug Sales detrended by subtracting the least squares fit', fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KnqPM9SROrR"
      },
      "source": [
        "# Using scipy: Subtract the line of best fit\n",
        "from scipy import signal\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', parse_dates=['date'])\n",
        "detrended = signal.detrend(df.value.values)\n",
        "plt.plot(detrended)\n",
        "plt.title('Drug Sales detrended by subtracting the least squares fit', fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp4wiY9vRAo8"
      },
      "source": [
        "# Using statmodels: Subtracting the Trend Component.\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', parse_dates=['date'], index_col='date')\n",
        "result_mul = seasonal_decompose(df['value'], model='multiplicative', extrapolate_trend='freq')\n",
        "detrended = df.value.values - result_mul.trend\n",
        "plt.plot(detrended)\n",
        "plt.title('Drug Sales detrended by subtracting the trend component', fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5AxnvjyRX37"
      },
      "source": [
        "# Deseasonalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glg-4a1cRDIS"
      },
      "source": [
        "# Subtracting the Trend Component.\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', parse_dates=['date'], index_col='date')\n",
        "\n",
        "# Time Series Decomposition\n",
        "result_mul = seasonal_decompose(df['value'], model='multiplicative', extrapolate_trend='freq')\n",
        "\n",
        "# Deseasonalize\n",
        "deseasonalized = df.value.values / result_mul.seasonal\n",
        "\n",
        "# Plot\n",
        "plt.plot(deseasonalized)\n",
        "plt.title('Drug Sales Deseasonalized', fontsize=16)\n",
        "plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF5LBZeWRY-O"
      },
      "source": [
        "\"\"\"\n",
        "If dividing by the seasonal index does not work well, try taking a log of the series and then do the deseasonalizing. You can later restore to the original scale by taking an exponential.\n",
        "\"\"\";\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x--X5zykRtzU"
      },
      "source": [
        "# Test for Seasonality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26Ey7dEZRi9p"
      },
      "source": [
        "from pandas.plotting import autocorrelation_plot\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv')\n",
        "\n",
        "# Draw Plot\n",
        "plt.rcParams.update({'figure.figsize':(9,5), 'figure.dpi':120})\n",
        "autocorrelation_plot(df.value.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DugO6c4iRu6T"
      },
      "source": [
        "\"\"\"\n",
        "Alternately, if you want a statistical test, the CHTest can determine if seasonal differencing is required to stationarize the series.\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHPaKBBNR-gm"
      },
      "source": [
        "# Fill Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7qiZ2DHR0d0"
      },
      "source": [
        "# # Generate dataset\n",
        "from scipy.interpolate import interp1d\n",
        "from sklearn.metrics import mean_squared_error\n",
        "df_orig = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', parse_dates=['date'], index_col='date').head(100)\n",
        "df = pd.read_csv('datasets/a10_missings.csv', parse_dates=['date'], index_col='date')\n",
        "\n",
        "fig, axes = plt.subplots(7, 1, sharex=True, figsize=(10, 12))\n",
        "plt.rcParams.update({'xtick.bottom' : False})\n",
        "\n",
        "## 1. Actual -------------------------------\n",
        "df_orig.plot(title='Actual', ax=axes[0], label='Actual', color='red', style=\".-\")\n",
        "df.plot(title='Actual', ax=axes[0], label='Actual', color='green', style=\".-\")\n",
        "axes[0].legend([\"Missing Data\", \"Available Data\"])\n",
        "\n",
        "## 2. Forward Fill --------------------------\n",
        "df_ffill = df.ffill()\n",
        "error = np.round(mean_squared_error(df_orig['value'], df_ffill['value']), 2)\n",
        "df_ffill['value'].plot(title='Forward Fill (MSE: ' + str(error) +\")\", ax=axes[1], label='Forward Fill', style=\".-\")\n",
        "\n",
        "## 3. Backward Fill -------------------------\n",
        "df_bfill = df.bfill()\n",
        "error = np.round(mean_squared_error(df_orig['value'], df_bfill['value']), 2)\n",
        "df_bfill['value'].plot(title=\"Backward Fill (MSE: \" + str(error) +\")\", ax=axes[2], label='Back Fill', color='firebrick', style=\".-\")\n",
        "\n",
        "## 4. Linear Interpolation ------------------\n",
        "df['rownum'] = np.arange(df.shape[0])\n",
        "df_nona = df.dropna(subset = ['value'])\n",
        "f = interp1d(df_nona['rownum'], df_nona['value'])\n",
        "df['linear_fill'] = f(df['rownum'])\n",
        "error = np.round(mean_squared_error(df_orig['value'], df['linear_fill']), 2)\n",
        "df['linear_fill'].plot(title=\"Linear Fill (MSE: \" + str(error) +\")\", ax=axes[3], label='Cubic Fill', color='brown', style=\".-\")\n",
        "\n",
        "## 5. Cubic Interpolation --------------------\n",
        "f2 = interp1d(df_nona['rownum'], df_nona['value'], kind='cubic')\n",
        "df['cubic_fill'] = f2(df['rownum'])\n",
        "error = np.round(mean_squared_error(df_orig['value'], df['cubic_fill']), 2)\n",
        "df['cubic_fill'].plot(title=\"Cubic Fill (MSE: \" + str(error) +\")\", ax=axes[4], label='Cubic Fill', color='red', style=\".-\")\n",
        "\n",
        "# Interpolation References:\n",
        "# https://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html\n",
        "# https://docs.scipy.org/doc/scipy/reference/interpolate.html\n",
        "\n",
        "## 6. Mean of 'n' Nearest Past Neighbors ------\n",
        "def knn_mean(ts, n):\n",
        "    out = np.copy(ts)\n",
        "    for i, val in enumerate(ts):\n",
        "        if np.isnan(val):\n",
        "            n_by_2 = np.ceil(n/2)\n",
        "            lower = np.max([0, int(i-n_by_2)])\n",
        "            upper = np.min([len(ts)+1, int(i+n_by_2)])\n",
        "            ts_near = np.concatenate([ts[lower:i], ts[i:upper]])\n",
        "            out[i] = np.nanmean(ts_near)\n",
        "    return out\n",
        "\n",
        "df['knn_mean'] = knn_mean(df.value.values, 8)\n",
        "error = np.round(mean_squared_error(df_orig['value'], df['knn_mean']), 2)\n",
        "df['knn_mean'].plot(title=\"KNN Mean (MSE: \" + str(error) +\")\", ax=axes[5], label='KNN Mean', color='tomato', alpha=0.5, style=\".-\")\n",
        "\n",
        "## 7. Seasonal Mean ----------------------------\n",
        "def seasonal_mean(ts, n, lr=0.7):\n",
        "    \"\"\"\n",
        "    Compute the mean of corresponding seasonal periods\n",
        "    ts: 1D array-like of the time series\n",
        "    n: Seasonal window length of the time series\n",
        "    \"\"\"\n",
        "    out = np.copy(ts)\n",
        "    for i, val in enumerate(ts):\n",
        "        if np.isnan(val):\n",
        "            ts_seas = ts[i-1::-n]  # previous seasons only\n",
        "            if np.isnan(np.nanmean(ts_seas)):\n",
        "                ts_seas = np.concatenate([ts[i-1::-n], ts[i::n]])  # previous and forward\n",
        "            out[i] = np.nanmean(ts_seas) * lr\n",
        "    return out\n",
        "\n",
        "df['seasonal_mean'] = seasonal_mean(df.value, n=12, lr=1.25)\n",
        "error = np.round(mean_squared_error(df_orig['value'], df['seasonal_mean']), 2)\n",
        "df['seasonal_mean'].plot(title=\"Seasonal Mean (MSE: \" + str(error) +\")\", ax=axes[6], label='Seasonal Mean', color='blue', alpha=0.5, style=\".-\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6KGV7CGST-9"
      },
      "source": [
        "# Autocorrelation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUxquwO5R_iM"
      },
      "source": [
        "from statsmodels.tsa.stattools import acf, pacf\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv')\n",
        "\n",
        "# Calculate ACF and PACF upto 50 lags\n",
        "# acf_50 = acf(df.value, nlags=50)\n",
        "# pacf_50 = pacf(df.value, nlags=50)\n",
        "\n",
        "# Draw Plot\n",
        "fig, axes = plt.subplots(1,2,figsize=(16,3), dpi= 100)\n",
        "plot_acf(df.value.tolist(), lags=50, ax=axes[0])\n",
        "plot_pacf(df.value.tolist(), lags=50, ax=axes[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R8GGw3ASgX1"
      },
      "source": [
        "# Lag Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXDoRA2lSVXP"
      },
      "source": [
        "from pandas.plotting import lag_plot\n",
        "plt.rcParams.update({'ytick.left' : False, 'axes.titlepad':10})\n",
        "\n",
        "# Import\n",
        "ss = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/sunspotarea.csv')\n",
        "a10 = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv')\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(1, 4, figsize=(10,3), sharex=True, sharey=True, dpi=100)\n",
        "for i, ax in enumerate(axes.flatten()[:4]):\n",
        "    lag_plot(ss.value, lag=i+1, ax=ax, c='firebrick')\n",
        "    ax.set_title('Lag ' + str(i+1))\n",
        "\n",
        "fig.suptitle('Lag Plots of Sun Spots Area \\n(Points get wide and scattered with increasing lag -> lesser correlation)\\n', y=1.15)    \n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(10,3), sharex=True, sharey=True, dpi=100)\n",
        "for i, ax in enumerate(axes.flatten()[:4]):\n",
        "    lag_plot(a10.value, lag=i+1, ax=ax, c='firebrick')\n",
        "    ax.set_title('Lag ' + str(i+1))\n",
        "\n",
        "fig.suptitle('Lag Plots of Drug Sales', y=1.05)    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zT59CnGuSzv2"
      },
      "source": [
        "# Estimate Forecastability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ7XdnbgShYq"
      },
      "source": [
        "# https://en.wikipedia.org/wiki/Approximate_entropy\n",
        "ss = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/sunspotarea.csv')\n",
        "a10 = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv')\n",
        "rand_small = np.random.randint(0, 100, size=36)\n",
        "rand_big = np.random.randint(0, 100, size=136)\n",
        "\n",
        "def ApEn(U, m, r):\n",
        "    \"\"\"Compute Aproximate entropy\"\"\"\n",
        "    def _maxdist(x_i, x_j):\n",
        "        return max([abs(ua - va) for ua, va in zip(x_i, x_j)])\n",
        "\n",
        "    def _phi(m):\n",
        "        x = [[U[j] for j in range(i, i + m - 1 + 1)] for i in range(N - m + 1)]\n",
        "        C = [len([1 for x_j in x if _maxdist(x_i, x_j) <= r]) / (N - m + 1.0) for x_i in x]\n",
        "        return (N - m + 1.0)**(-1) * sum(np.log(C))\n",
        "\n",
        "    N = len(U)\n",
        "    return abs(_phi(m+1) - _phi(m))\n",
        "\n",
        "print(ApEn(ss.value, m=2, r=0.2*np.std(ss.value)))     # 0.651\n",
        "print(ApEn(a10.value, m=2, r=0.2*np.std(a10.value)))   # 0.537\n",
        "print(ApEn(rand_small, m=2, r=0.2*np.std(rand_small))) # 0.143\n",
        "print(ApEn(rand_big, m=2, r=0.2*np.std(rand_big)))     # 0.716"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnH_lHy9S1NC"
      },
      "source": [
        "# https://en.wikipedia.org/wiki/Sample_entropy\n",
        "def SampEn(U, m, r):\n",
        "    \"\"\"Compute Sample entropy\"\"\"\n",
        "    def _maxdist(x_i, x_j):\n",
        "        return max([abs(ua - va) for ua, va in zip(x_i, x_j)])\n",
        "\n",
        "    def _phi(m):\n",
        "        x = [[U[j] for j in range(i, i + m - 1 + 1)] for i in range(N - m + 1)]\n",
        "        C = [len([1 for j in range(len(x)) if i != j and _maxdist(x[i], x[j]) <= r]) for i in range(len(x))]\n",
        "        return sum(C)\n",
        "\n",
        "    N = len(U)\n",
        "    return -np.log(_phi(m+1) / _phi(m))\n",
        "\n",
        "print(SampEn(ss.value, m=2, r=0.2*np.std(ss.value)))      # 0.78\n",
        "print(SampEn(a10.value, m=2, r=0.2*np.std(a10.value)))    # 0.41\n",
        "print(SampEn(rand_small, m=2, r=0.2*np.std(rand_small)))  # 1.79\n",
        "print(SampEn(rand_big, m=2, r=0.2*np.std(rand_big)))      # 2.42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WPbyWY0TGq-"
      },
      "source": [
        "# Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPwr5ItNTfLI"
      },
      "source": [
        "df_orig = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', parse_dates=True, index_col='date')\n",
        "df_orig.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z-Ca6Q8S3-l"
      },
      "source": [
        "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
        "plt.rcParams.update({'xtick.bottom' : False, 'axes.titlepad':5})\n",
        "\n",
        "# Import\n",
        "# df_orig = pd.read_csv('datasets/elecequip.csv', parse_dates=['date'], index_col='date')\n",
        "# df_orig = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/sunspotarea.csv')\n",
        "df_orig = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', parse_dates=True, index_col='date')\n",
        "\n",
        "# 1. Moving Average\n",
        "df_ma = df_orig.value.rolling(3, center=True, closed='both').mean()\n",
        "\n",
        "# 2. Loess Smoothing (5% and 15%)\n",
        "df_loess_5 = pd.DataFrame(lowess(df_orig.value, np.arange(len(df_orig.value)), frac=0.05)[:, 1], index=df_orig.index, columns=['value'])\n",
        "df_loess_15 = pd.DataFrame(lowess(df_orig.value, np.arange(len(df_orig.value)), frac=0.15)[:, 1], index=df_orig.index, columns=['value'])\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(4,1, figsize=(7, 7), sharex=True, dpi=120)\n",
        "df_orig['value'].plot(ax=axes[0], color='k', title='Original Series')\n",
        "df_loess_5['value'].plot(ax=axes[1], title='Loess Smoothed 5%')\n",
        "df_loess_15['value'].plot(ax=axes[2], title='Loess Smoothed 15%')\n",
        "df_ma.plot(ax=axes[3], title='Moving Average (3)')\n",
        "fig.suptitle('How to Smoothen a Time Series', y=0.95, fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcgh96ssTGjA"
      },
      "source": [
        "# Granger Causality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZvoqW9vTIUM"
      },
      "source": [
        "from statsmodels.tsa.stattools import grangercausalitytests\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', parse_dates=['date'])\n",
        "df['month'] = df.date.dt.month\n",
        "grangercausalitytests(df[['value', 'month']], maxlag=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQGEISaWTHmX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}