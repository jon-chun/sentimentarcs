{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "name": "sentimentarcs_cruxes.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fLpdPoYZswu7",
        "HFJtnCYhi_N4",
        "vkGeLuCwEfty"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "311.997px",
        "left": "719px",
        "top": "111px",
        "width": "416.267px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jon-chun/sentimentarcs/blob/main/sentimentarcs_cruxes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j637s-I4vbg_"
      },
      "source": [
        "# **SentimentArcs Part 7: Join Norm**\n",
        "\n",
        "Jon Chun\n",
        "15 Sep 2021\n",
        "\n",
        "* https://colab.research.google.com/github/chengjun/mybook/blob/main/11-4-sentiment-classifier.ipynb#scrollTo=c749tKCSZpbw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y_ryJo3kuFU"
      },
      "source": [
        "# **Sandbox Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eezrxk__kxYr"
      },
      "source": [
        "!pip install alpha_vantage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMF4EZ7dktvv"
      },
      "source": [
        "# https://algotrading101.com/learn/python-correlation-guide/\n",
        "\n",
        "import pandas as pd\n",
        "from alpha_vantage.timeseries import TimeSeries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cojcf0jMktrq"
      },
      "source": [
        "#grab tickers from csv file\n",
        "\n",
        "# watchlist_df = pd.read_csv('watchlist.csv', header=None)\n",
        "# watchlist = watchlist_df.iloc[0].tolist()\n",
        "\n",
        "watchlist = ['AAPL', 'MSFT', 'GLD', 'XOM', 'NFLX']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TUnL3MMlmbd"
      },
      "source": [
        "%env ALPHAVANTAGE_API_KEY='8BK5HZ2RTSMFHG9U'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjVSshXLlA6d"
      },
      "source": [
        "#instantiate TimeSeries class from alpha_vantage library\n",
        "app = TimeSeries(output_format='pandas')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKMVHGZzlA27"
      },
      "source": [
        "#itter through watchlist and retrieve daily price data\n",
        "stocks_df = pd.DataFrame()\n",
        "for ticker in watchlist:\n",
        "    alphav_df = app.get_daily_adjusted(ticker)\n",
        "    # print(f'alphav header:\\n    {type(alphav_df)}')\n",
        "    alphav_df = alphav_df[0]\n",
        "    alphav_df.columns = [i.split(' ')[1] for i in alphav_df.columns]\n",
        "\n",
        "    stocks_df[ticker] = alphav_df['adjusted'].pct_change()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KvovZSEmgvQ"
      },
      "source": [
        "stocks_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EZ4CiHnmdN3"
      },
      "source": [
        "stocks_df.iloc[0]['AAPL'] # .isna().all()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKwa79Mem080"
      },
      "source": [
        "stocks_df[stocks_df.isna().any(axis=1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhLfywyEk5UG"
      },
      "source": [
        "stocks_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy6faxT-k5OL"
      },
      "source": [
        "print(stocks_df.AAPL.corr(stocks_df.MSFT))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzR9VKH1nXC2"
      },
      "source": [
        "print(stocks_df.AAPL.corr(stocks_df.NFLX))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9StqzT4nW-s"
      },
      "source": [
        "print(stocks_df.AAPL.corr(stocks_df.NFLX, method='spearman'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-Fzz0UJktmJ"
      },
      "source": [
        "print(stocks_df.AAPL.corr(stocks_df.NFLX, method='kendall'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua4B3QuMnnT7"
      },
      "source": [
        "stocks_df.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHWb8WoGnnPh"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ax = sns.heatmap(stocks_df.corr())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgfJ2PDxoxOZ"
      },
      "source": [
        "ax = sns.heatmap(stocks_df.corr(), cmap='RdYlGn', linewidths=.1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph0O4GA-oxKV"
      },
      "source": [
        "nflx_corr_df = stocks_df.corr().NFLX\n",
        "print(nflx_corr_df.idxmax())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oexAShTGphDM"
      },
      "source": [
        "nflx_corr_df[ nflx_corr_df < 1 ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg61S3_DpVn8"
      },
      "source": [
        "  print(nflx_corr_df[ nflx_corr_df < 1 ].idxmax())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zje2Bix-pVja"
      },
      "source": [
        "print(nflx_corr_df.idxmin())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAyaMDYmoxEv"
      },
      "source": [
        "stocks_df.cov()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPBjy8n_qwlw"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIsyBnBKq2lH"
      },
      "source": [
        "print(stocks_df.AAPL.corr(stocks_df.NFLX, method='spearman'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH0TzXakpxLS"
      },
      "source": [
        "print(np.square(stocks_df.AAPL.corr(stocks_df.NFLX, method='spearman')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMEGqRLapxG4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGMdLc4ipxCr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSQ-I05UnnKz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilw75IeETnUU"
      },
      "source": [
        "# **Install and Load Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8ds1sz9kjep"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGfcL2r2kowI"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import io\n",
        "import glob\n",
        "import pickle\n",
        "\n",
        "import re\n",
        "import string\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbKryb7nrpWZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6StEk2YW1OLY"
      },
      "source": [
        "!pip install texthero"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8nlljoA1P_t"
      },
      "source": [
        "import texthero as hero\n",
        "from texthero import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McslKTBZZpbU"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8F9Djjr9NA_"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exL5Iu1E3ayR"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve, plot_precision_recall_curve\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer, HashingVectorizer\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR1wMm3mudlN"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler   # To normalize time series\n",
        "from sklearn.preprocessing import StandardScaler # To Standardize time series: center(sub mean) and rescale within 1 SD (only for well-behaved guassian distributions)\n",
        "from sklearn.preprocessing import RobustScaler   # To Standardize time series: center(sub median) and rescale within 25%-75% (1st-3rd) IQR (better for noisy, outliers distributions)\n",
        "\n",
        "minmax_scaler = MinMaxScaler()\n",
        "mean_std_scaler = StandardScaler()\n",
        "median_iqr_scaler = RobustScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKPSE6ZU1bNp"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "porter=PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLpdPoYZswu7"
      },
      "source": [
        "# **Configure Jupyter**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CkX9gONAsmp"
      },
      "source": [
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK8zKENjsyig"
      },
      "source": [
        "# Configure Jupyter\n",
        "\n",
        "# Enable multiple outputs from one code cell\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "from IPython.display import display\n",
        "from ipywidgets import widgets, interactive\n",
        "\n",
        "# Configure Google Colab\n",
        "\n",
        "# %load_ext google.colab.data_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beGB-p4T7wCC"
      },
      "source": [
        "from IPython.display import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH1Ad3OxsyqC"
      },
      "source": [
        "# Text wrap\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho0zbRFZTFNe"
      },
      "source": [
        "# Enlarge matplotlib plot size\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (20, 40)\n",
        "\n",
        "# temporarily\n",
        "# from matplotlib.pyplot import figure\n",
        "# figure(figsize=(8, 6), dpi=80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d43OmkheT_Vt"
      },
      "source": [
        "# **Connect to gDrive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G64etjAUOOSm"
      },
      "source": [
        "# Connect to Google gDrive\n",
        "\n",
        "# Flag to indicate first run through code \n",
        "flag_first_run = True\n",
        "\n",
        "from google.colab import drive, files\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfpfvAvRUMpW"
      },
      "source": [
        "%cd ./research/2021/sa_book_code/books_sa/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFJtnCYhi_N4"
      },
      "source": [
        "# **Globals**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knAxs8VYU8u5"
      },
      "source": [
        "# List of Corpora\n",
        "\n",
        "corpora_ls = ['cdickens_achristmascarol',\n",
        "              'cdickens_greatexpectations',\n",
        "              'ddefoe_robinsoncrusoe',\n",
        "              'emforster_howardsend',\n",
        "              'fbaum_thewonderfulwizardofoz',\n",
        "              'fdouglass_narrativelifeofaslave',\n",
        "              'fscottfitzgerald_thegreatgatsby',\n",
        "              'geliot_middlemarch',\n",
        "              'hjames_portraitofalady',\n",
        "              'homer-ewilson_odyssey',\n",
        "              'imcewan_machineslikeme',\n",
        "              'jausten_prideandprejudice', # missing RoBERTaXML8lang\n",
        "              'jconrad_heartofdarkness',\n",
        "              'jjoyce_portraitoftheartist',\n",
        "              'jkrowling_1sorcerersstone',  \n",
        "              'mproust-mtreharne_3guermantesway', # missing all Transformers\n",
        "              'mshelley_frankenstein',\n",
        "              'mtwain_huckleberryfinn',\n",
        "              'staugustine_confessions9end',\n",
        "              'tmorrison_beloved',\n",
        "              'vnabokov_palefire',\n",
        "              'vwoolf_mrsdalloway',\n",
        "              'vwoolf_orlando',\n",
        "              'vwoolf_thewaves',\n",
        "              'vwoolf_tothelighthouse']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G-sL4VjU8nA"
      },
      "source": [
        "# Taxonomy of Models \n",
        "\n",
        "groups_ls = ['models_baseline_ls',\n",
        "                'models_sentimentr_ls',\n",
        "                'models_syuzhetr_ls',\n",
        "                'models_transformer_ls']\n",
        "\n",
        "# Could add suffix '_sst2' if classifiers trained on SST2 (currently requires 30m on Colab Pro/GPU+RAM)\n",
        "models_supervised_ls = ['linreg_imdb50k',\n",
        "                   'svc_imdb50k',\n",
        "                   'logreg_imdb50k',\n",
        "                   'dforest_imdb50k',\n",
        "                   'multinb_imdb50k']\n",
        "\n",
        "models_baseline_ls = ['sentimentr',\n",
        "                      'syuzhet',\n",
        "                      'bing',\n",
        "                      'sentiword',\n",
        "                      'senticnet',\n",
        "                      'nrc',\n",
        "                      'afinn',\n",
        "                      'vader',\n",
        "                      'textblob',\n",
        "                      'flair',\n",
        "                      'pattern',\n",
        "                      'stanza']\n",
        "\n",
        "models_sentimentr_ls = ['jockers_rinker',\n",
        "                        'jockers',\n",
        "                        'huliu',\n",
        "                        'senticnet',\n",
        "                        'sentiword',\n",
        "                        'nrc',\n",
        "                        'lmcd']\n",
        "\n",
        "models_syuzhetr_ls = ['syuzhet',\n",
        "                      'bing',\n",
        "                      'afinn',\n",
        "                      'nrc']\n",
        "\n",
        "models_transformer_ls = ['roberta15lg', \n",
        "                         'nlptown', \n",
        "                         'yelp', \n",
        "                         'hinglish',\n",
        "                         'imdb2way', \n",
        "                         'huggingface', \n",
        "                         't5imdb50k', \n",
        "                         'robertaxml8lang']\n",
        "\n",
        "models_ml_ls = ['multinb',\n",
        "             'logreg',\n",
        "             'logreg_cv',\n",
        "             'rf',\n",
        "             'xgb',\n",
        "             'flaml',\n",
        "             'autogluon']\n",
        "             \n",
        "models_dnn_ls = ['fcn',\n",
        "              'lstm',\n",
        "              'cnn']\n",
        "\n",
        "# Temporarily redefine from English to French Transformer Models\n",
        "# models_transformer_ls = ['flaubert', 'nlptown', 'robertaxml8lang']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8NF_KUmUb-b"
      },
      "source": [
        "corpora_full_dt = {\n",
        "    'cdickens_achristmascarol':'A Christmas Carol by Charles Dickens',\n",
        "    'cdickens_greatexpectations':'Great Expectations by Charles Dickens',\n",
        "    'ddefoe_robinsoncrusoe':'Robinson Crusoe by Daniel Defoe',\n",
        "    'emforster_howardsend':'Howards End by E.M.Forster',\n",
        "    'fbaum_thewonderfulwizardofoz':'The Wonderful Wizard of Oz by Frank Baum',\n",
        "    'fdouglass_narrativelifeofaslave':'Narrative of the Life of Frederick Douglass, An American Slave',\n",
        "    'fscottfitzgerald_thegreatgatsby':'The Great Gatsby by F.Scott Fitzgerald',\n",
        "    'geliot_middlemarch':'Middlemarch by George Eliot',\n",
        "    'hjames_portraitofalady':'Portrait of a Lady by Henry James',\n",
        "    'homer-ewilson_odyssey':'The Odyssey by Homer (trans. Emily Wilson)',\n",
        "    'imcewan_machineslikeme':'Machines Like Me by Ian McEwan',\n",
        "    'jausten_prideandprejudice':'Pride and Prejudice by Jane Austen',\n",
        "    'jconrad_heartofdarkness':'Heart of Darkness by Joseph Conrad',\n",
        "    'jjoyce_portraitoftheartist':'A Portrait of the Artist as a Young Man by James Joyce',\n",
        "    'jkrowling_1sorcerersstone':'Harry Potter and the Sorcerers Stone by J.K.Rowling',\n",
        "    'mproust-mtreharne_3guermantesway':'The Guermantes Way by Marcel Proust',\n",
        "    'mshelley_frankenstein':'Frankenstein by Mary Shelley',\n",
        "    'mtwain_huckleberryfinn':'Huckleberry Finn by Mark Twain',\n",
        "    'staugustine_confessions9end':'Confessions (thru Book 9) by St. Augustine',\n",
        "    'tmorrison_beloved':'Beloved by Toni Morrison',\n",
        "    'vnabokov_palefire':'Palefire by Vladimir Nabokov',\n",
        "    'vwoolf_mrsdalloway':'Mrs. Dalloway by Virginia Woolf',\n",
        "    'vwoolf_orlando':'Orlando by Virginia Woolf',\n",
        "    'vwoolf_thewaves':'The Waves by Virginia Woolf',\n",
        "    'vwoolf_tothelighthouse':'To The Lighthouse by Virginia Woolf'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SSwoDSmjAyd"
      },
      "source": [
        "# Master Dictionary of DataFrames (one per Corpus), each column with raw sentiment polarities from a given model \n",
        "#   declare early to minimize accidental clobbering/deletion\n",
        "\n",
        "corpora_all_dt = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h_KDF-a29ir"
      },
      "source": [
        "# **Custom Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qoLaZ-U2_hz"
      },
      "source": [
        "# https://www.kaggle.com/aditya6040/7-models-on-imdb-dataset-best-score-88-2/notebook\n",
        "\n",
        "def get_metrics(model,x,y):\n",
        "    y_pred = model.predict(x)\n",
        "    acc = accuracy_score(y, y_pred)\n",
        "    f1=f1_score(y, y_pred)\n",
        "    cm=confusion_matrix(y, y_pred)\n",
        "    report=classification_report(y,y_pred)\n",
        "    plt.figure(figsize=(4,4))\n",
        "    sns.heatmap(cm,annot=True,cmap='Blues',xticklabels=[0,1],fmt='d',annot_kws={\"fontsize\":19})\n",
        "    plt.xlabel(\"Predicted\",fontsize=16)\n",
        "    plt.ylabel(\"Actual\",fontsize=16)\n",
        "    plt.show()\n",
        "    print(\"\\nAccuracy: \",round(acc,2))\n",
        "    print(\"\\nF1 Score: \",round(f1,2))\n",
        "#     print(\"\\nConfusion Matrix: \\n\",cm)\n",
        "    print(\"\\nReport:\",report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT3eoNO5To5X"
      },
      "source": [
        "# **Read Every Model Sentiment Data**\n",
        "\n",
        "* https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EidAawQwn861"
      },
      "source": [
        "# Get list of files in data subdir\n",
        "\n",
        "data_dir = './data_corpora_sa'\n",
        "\n",
        "filenames_ls = os.listdir(data_dir)\n",
        "filenames_ls\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrBaJODOFsi2"
      },
      "source": [
        "## **Read Individual Models [corpora_sa_df]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTseQdxTILEE"
      },
      "source": [
        "%%time\n",
        "\n",
        "# NOTE: 1m10s\n",
        "\n",
        "# Read in all models sentiment values in *.csv files located in data_dir\n",
        "#   into Global Dict (corpora_sa_dt) \n",
        "#   with keys=corpora and values=models sentiment values\n",
        "\n",
        "corpora_sa_dt = {}\n",
        "model_group_set = set()\n",
        "\n",
        "def read_csvfiles(folder_path):\n",
        "\n",
        "  for i,afile in enumerate(filenames_ls):\n",
        "    print(f'Reading in afile #{i}: {afile}')\n",
        "    full_path = f'{folder_path}/{afile}'\n",
        "    print(f'  full_path: {full_path}')\n",
        "    model_name = '_'.join(afile.split('_')[1:])\n",
        "    model_name = model_name.split('.')[0]\n",
        "    print(f'  model_name: {model_name}')\n",
        "    corpora_sa_dt[model_name] = pd.read_csv(full_path) # .to_dict()\n",
        "    model_group = model_name.split('_')[0]\n",
        "    print(f'  model_group: {model_group}')\n",
        "    model_group_set.add(model_group)\n",
        "\n",
        "read_csvfiles(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QLHuLhddpI-"
      },
      "source": [
        "# Show model groups based upon datafile prefix (e.g. 'baseline_' or 'dnn_')\n",
        "\n",
        "print(f'model_group_set:\\n  {model_group_set}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOGOpDEzKw5B"
      },
      "source": [
        "# Verify the number and names of Corpora read\n",
        "\n",
        "[i for i in corpora_sa_dt.keys()]\n",
        "\n",
        "print(f'\\n\\n    Read {len(corpora_sa_dt.keys())} Corpora')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUSWMSxRckWP"
      },
      "source": [
        "corpora_sa_dt['ml_vwoolf_thewaves'].columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfNCyat2IK_u"
      },
      "source": [
        "corpora_sa_dt['baseline_cdickens_achristmascarol'].head(1)\n",
        "corpora_sa_dt['baseline_cdickens_achristmascarol'].info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7SJHQ4tFyxb"
      },
      "source": [
        "## **Merge all Models together for each Corpus [corpora_all_df]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbNrTHDrH3KT"
      },
      "source": [
        "# Get common corpus roots \n",
        "\n",
        "corpus_root_set = set()\n",
        "\n",
        "# print(f'\\nStarting with {len(filenames_ls)} total corpus x model combinations\\n')\n",
        "for acorpus_model in filenames_ls:\n",
        "  corpus_model_root = '_'.join(acorpus_model.split('_')[2:])\n",
        "  corpus_model_root = corpus_model_root.split('.')[0]\n",
        "  print(f'corpus_model_root: {corpus_model_root}')\n",
        "  corpus_root_set.add(corpus_model_root)\n",
        "\n",
        "corpus_root_ls = list(corpus_root_set)\n",
        "print(f'\\nThese {len(filenames_ls)} original (corpus)x(model) combination files\\n  were reduced to {len(corpus_root_ls)} unique corpus roots')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C28Kt6rfCs9"
      },
      "source": [
        "corpora_sa_dt.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRLHxCvqe3ry"
      },
      "source": [
        "# Verify sample Model features\n",
        "\n",
        "corpora_sa_dt['ml_fdouglass_narrativelifeofaslave'].info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl0cIoHpgfx0"
      },
      "source": [
        "corpora_all_dt = {}\n",
        "\n",
        "models_dnn_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnskdy8CppY9"
      },
      "source": [
        "# Create corpus_all_df that merges all Models for a given Corpus\n",
        "\n",
        "model_dfs_ls = []\n",
        "\n",
        "for i,acorpus in enumerate(corpus_root_ls):\n",
        "  model_dfs_ls = []\n",
        "\n",
        "  # Get all the 'corpus_model' keys for each 'corpus'\n",
        "  for j, agroup in enumerate(model_group_set):\n",
        "    corpus_model = f'{agroup}_{acorpus}'\n",
        "    print(f'\\n\\n{agroup.upper()} Models #{i*len(model_group_set) + j}: {corpus_model}.csv')\n",
        "    model_cols_ls = corpora_sa_dt[corpus_model].columns\n",
        "    print(f'  Cols: {model_cols_ls}')\n",
        "    corpus_model_path = f'{data_dir}/models_{corpus_model}.csv'\n",
        "    # adf = pd.DataFrame()\n",
        "    adf = pd.read_csv(corpus_model_path, index_col=None)\n",
        "    model_dfs_ls.append(adf)\n",
        "  \n",
        "  # Merge the 3 DataFrames (baseline_, ml_, dnn_)\n",
        "  corpus_all_df = model_dfs_ls[0].merge(model_dfs_ls[1], on='sent_no').merge(model_dfs_ls[2], on='sent_no') # pd.concat(model_dfs_ls, axis=0, ignore_index=True)\n",
        "  corpus_all_df = corpus_all_df.loc[:, ~corpus_all_df.columns.str.contains('Unnamed')]\n",
        "  corpus_all_df = corpus_all_df.loc[:, ~corpus_all_df.columns.str.contains('stdscaler')]\n",
        "  corpus_all_df = corpus_all_df.loc[:, ~corpus_all_df.columns.str.contains('scores')]\n",
        "  corpus_all_df = corpus_all_df.loc[:, ~corpus_all_df.columns.str.contains('_len')]\n",
        "  corpus_all_df = corpus_all_df.loc[:, ~corpus_all_df.columns.str.contains('_x')]\n",
        "  corpus_all_df = corpus_all_df.loc[:, ~corpus_all_df.columns.str.contains('_y')]\n",
        "  print('\\n')\n",
        "  corpora_all_dt[acorpus] = corpus_all_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWJMWIVsqegZ"
      },
      "source": [
        "# Check copora and model counts\n",
        "\n",
        "col_nonmodel_ct = 5 # non model columns (e.g. sent_no, parag_no, sect_no, sent_raw, sent_clean)\n",
        "\n",
        "print('SUMMARY ----------')\n",
        "print(f'{len(corpora_all_dt)} Corpora in dataset')\n",
        "print(f\"{len(corpora_all_dt['hjames_portraitofalady'].columns) - col_nonmodel_ct} Models for each Corpus\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GumwGGXkj3C"
      },
      "source": [
        "corpora_sa_dt['ml_hjames_portraitofalady'].head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIlIrHb3j_aI"
      },
      "source": [
        "corpora_all_dt['hjames_portraitofalady'].head(2)\n",
        "# corpora_all_dt['hjames_portraitofalady'].info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2uLLLyMGMPZ"
      },
      "source": [
        "corpora_all_dt['cdickens_achristmascarol'].info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zJu46WerCrj"
      },
      "source": [
        "# corpora_all_dt['tmorrison_beloved']['pattern'].rolling(400, center=True).mean().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS-M-Ovxrb0k"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54-DVAq4rd6f"
      },
      "source": [
        "# temp_df = pd.read_csv('./tmorrison_beloved/beloved_pattern.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VTdyJJernNa"
      },
      "source": [
        "# temp_df['pattern'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPvDpZPltVdD"
      },
      "source": [
        "# **Standardize and Smooth**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYoOhRWfAOCv"
      },
      "source": [
        "## **Get Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw-8Pr1SEZ1H"
      },
      "source": [
        "### **Option (a): Read in zScore/SMA 10% DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uSPn44UtX6l"
      },
      "source": [
        "# ERROR: must get median_z\n",
        "\n",
        "# Read all models with orignal and zscore values\n",
        "\n",
        "subdir_all = 'data_corpora_all'\n",
        "\n",
        "corpora_all_dt = {}\n",
        "\n",
        "cols_drop_ls = ['fcn', 'lstm', 'cnn', 'multinb', 'logreg', 'logreg_cv', 'rf', 'xgb', 'flaml', 'autogluon',\n",
        "                'sentimentr', 'syuzhet', 'bing', 'sentiword', 'senticnet', 'nrc',\n",
        "                'afinn', 'vader', 'textblob', 'pattern', 'stanza', 'flair',\n",
        "                'jockers_rinker', 'jockers', 'huliu', 'lmcd', 'roberta15lg', 'yelp',\n",
        "                'nlptown', 'huggingface', 'hinglish', 'imdb2way', 't5imdb50k',\n",
        "                'robertaxml8lang']\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "\n",
        "  filepath = f'./{subdir_all}/models_all_{acorpus}.csv'\n",
        "\n",
        "  print(f'Reading {acorpus} from:\\n    {filepath}\\n')\n",
        "\n",
        "  corpora_all_dt[acorpus] = pd.read_csv(filepath, index_col=[0])\n",
        "  corpora_all_dt[acorpus].drop(columns=cols_drop_ls, axis=1, inplace=True)\n",
        "  # corpus_all_df = corpus_all_df.loc[:, corpus_all_df.columns.str.contains('_z')]\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTf-S3I3Ghem"
      },
      "source": [
        "# Verify a Model columns for both regular and z-Score values\n",
        "\n",
        "corpora_all_dt['cdickens_achristmascarol'].shape\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "corpora_all_dt['cdickens_achristmascarol'].columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3_njibNmXy4"
      },
      "source": [
        "corpora_all_dt['cdickens_achristmascarol'].head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxNO6r4tZV5S"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (40,20)\n",
        "\n",
        "win10per = int(0.1*corpora_all_dt['cdickens_achristmascarol'].shape[0])\n",
        "               \n",
        "corpora_all_dt['cdickens_achristmascarol']['median_z'].rolling(win10per, center=True, min_periods=1).mean().plot();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA_OJZUvZwkT"
      },
      "source": [
        "### **Execute for both Option (a) and Option (b)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NosICvotX3B"
      },
      "source": [
        "models_ls = corpora_all_dt.keys()\n",
        "print(models_ls)\n",
        "print(f'\\nThere are {len(models_ls)} Corpora')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tRkCLrjtXzd"
      },
      "source": [
        "model_all_cols_ls = corpora_all_dt['cdickens_achristmascarol'].columns\n",
        "print(model_all_cols_ls)\n",
        "\n",
        "print(f'\\nEach Corpus has {len(model_all_cols_ls)} Columns')\n",
        "\n",
        "model_noncols_ls = ['sent_no', 'parag_no', 'sect_no', 'sent_raw', 'sent_clean']\n",
        "print(f'\\n  {len(model_noncols_ls)} Columns are meta-information (not Models)\\n  {model_noncols_ls}')\n",
        "\n",
        "\n",
        "model_cols_ls = list(set(model_all_cols_ls) - set(model_noncols_ls))\n",
        "print(f'\\n  {len(model_cols_ls)} Columns are these Models:\\n  {[i for i in model_cols_ls]}')\n",
        "\n",
        "# Get list of zScore Model Columns in Corpus DataFrame\n",
        "model_z_cols_ls = [i for i in model_cols_ls if i.endswith('_z')]\n",
        "print(f'\\n  {len(model_z_cols_ls)} zScore Columns are these Models:\\n  {[i for i in model_z_cols_ls]}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkGeLuCwEfty"
      },
      "source": [
        "### **Option (b): Generate zScore/SMA 10% DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMUbr-euFOoN"
      },
      "source": [
        "# Specific types for Corpus columns\n",
        "\n",
        "print('Before specifying Corpus column types:')\n",
        "corpora_all_dt['cdickens_achristmascarol'].info()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(f'Processing Corpus: {acorpus}')\n",
        "  for j, amodel in enumerate(model_cols_ls):\n",
        "    corpora_all_dt[acorpus][amodel] = corpora_all_dt[acorpus][amodel].astype('float')\n",
        "  corpora_all_dt[acorpus]['sent_raw'] = corpora_all_dt[acorpus]['sent_raw'].astype('string')\n",
        "  corpora_all_dt[acorpus]['sent_clean'] = corpora_all_dt[acorpus]['sent_clean'].astype('string')\n",
        "\n",
        "\n",
        "print('After specifying Corpus column types:')\n",
        "corpora_all_dt['cdickens_achristmascarol'].info()\n",
        "# corpora_all_dt[acorpus][amodel].astype(np.float64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uigsoBWaKa-q"
      },
      "source": [
        "# Setup\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "stdscaler = StandardScaler()\n",
        "\n",
        "# fit and transform the data\n",
        "# scaled_data = scaler.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKtMMpBINLc6"
      },
      "source": [
        "type(stdscaler.fit_transform(np.asarray(corpora_all_dt['cdickens_achristmascarol']['xgb']).reshape(1,-1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhKDeen6Pb1n"
      },
      "source": [
        "# corpora_all_dt['cdickens_achristmascarol']['xgb_stdscaler'] = stdscaler.fit_transform(np.asarray(corpora_all_dt['cdickens_achristmascarol']['xgb']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuc-HFHPJTnG"
      },
      "source": [
        "# Setup\n",
        "\n",
        "from scipy.stats import zscore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JlbXeI5R0zc"
      },
      "source": [
        "# Test scipy zscore with plot\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (40,20)\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "# stats.zscore(a)\n",
        "temp_np = np.asarray(corpora_all_dt['cdickens_achristmascarol']['vader'])\n",
        "temp_z_np = zscore(temp_np)\n",
        "\n",
        "# temp_std_ser = stdscaler.fit_transform(np.asarray(temp_ser).reshape(1,-1)).ravel()\n",
        "# pd.Series(temp_std_ser)\n",
        "temp_df['test'] = pd.Series(temp_z_np)\n",
        "win10per = int(0.1*temp_df.shape[0])\n",
        "temp_df['test'].rolling(win10per, center=True, min_periods=1).mean().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WikuAp_UV7D0"
      },
      "source": [
        "# Compute z-scores for all Model Time Series and add to corpora_all_dt[acorpus] DataFrame\n",
        "\n",
        "# corpora_allz_dt = {}\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "pattern_z = re.compile(r'_z$')\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(f'Processing Corpus: {acorpus}')\n",
        "  for j, amodel in enumerate(model_cols_ls):\n",
        "    # print(f'Corpus #{i} {acorpus} with Model #{j} {amodel}: has {len(corpora_all_dt[acorpus].columns)} columns but only {len(model_cols_ls)} model columns')\n",
        "\n",
        "    # Skip existing z-Scores\n",
        "    if not pattern_z.search(amodel): \n",
        "      print(f'  processing model: {amodel}')\n",
        "      temp_np = np.asarray(corpora_all_dt[acorpus][amodel])\n",
        "      temp_z_np = zscore(temp_np)\n",
        "\n",
        "      amodel_z = f'{amodel}_z'\n",
        "      corpora_all_dt[acorpus][amodel_z] = pd.Series(temp_z_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7vEHmbtKw7k"
      },
      "source": [
        "# Verify zScores for all Models are computed\n",
        "\n",
        "corpora_all_dt[acorpus].loc[:, corpora_all_dt[acorpus].columns.str.contains('_z')].columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYde92c4Wgi9"
      },
      "source": [
        "# Compute the median_z for all individual zScore Models in each Corpus\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(f'Processing Corpus: {acorpus}')\n",
        "\n",
        "  if 'median_z' in corpora_all_dt[acorpus].columns:\n",
        "    print(f'  Skip, median_z already exists')\n",
        "  else:\n",
        "    print(f'  Added median_z')\n",
        "    corpora_all_dt[acorpus]['median_z'] = corpora_all_dt[acorpus].loc[:, corpora_all_dt[acorpus].columns.str.contains('_z')].median(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cgC2LXzL-9e"
      },
      "source": [
        "corpora_all_dt['cdickens_achristmascarol']['median_z']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4kPKtgsLzci"
      },
      "source": [
        "# Test median calculation with plot\n",
        "\n",
        "win10per = int(0.1*temp_df.shape[0])\n",
        "corpora_all_dt['cdickens_achristmascarol']['median_z'].plot()\n",
        "win10per = int(0.1*corpora_all_dt['cdickens_achristmascarol'].shape[0]) \n",
        "corpora_all_dt['cdickens_achristmascarol']['median_z'].rolling(win10per, center=True, min_periods=1).mean().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkFdxJ4EKge3"
      },
      "source": [
        "# Test scipy zscore with plot\n",
        "\"\"\"\n",
        "plt.rcParams[\"figure.figsize\"] = (40,20)\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "# stats.zscore(a)\n",
        "temp_np = np.asarray(corpora_all_dt['cdickens_achristmascarol']['median_z'])\n",
        "temp_z_np = zscore(temp_np)\n",
        "\n",
        "# temp_std_ser = stdscaler.fit_transform(np.asarray(temp_ser).reshape(1,-1)).ravel()\n",
        "# pd.Series(temp_std_ser)\n",
        "temp_df['test'] = pd.Series(temp_z_np)\n",
        "win10per = int(0.1*temp_df.shape[0])\n",
        "temp_df['test'].rolling(win10per, center=True).mean().plot()\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07bZS85silLE"
      },
      "source": [
        "corpora_all_dt['cdickens_achristmascarol'].columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rk3OZXJUYHD"
      },
      "source": [
        "## **Plot zScore/SMA 10%**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0_BhjBeZ6MD"
      },
      "source": [
        "corpora_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAkyN2_naCJV"
      },
      "source": [
        "model_cols_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ysIcCxRaFhn"
      },
      "source": [
        "%whos list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX0ejxhvUitK"
      },
      "source": [
        "\"\"\"\n",
        "ax = sns.lineplot(data=france_impact_df[['anglo','north','south']], linewidth=20)\n",
        "ax.grid(True)\n",
        "ax.set_title('French Music Charts: Origin of Most Popular Songs (1950-2020)', fontsize=40)\n",
        "# ax.set(xlabel='Decade', ylabel='Weighted Percent of Top Songs', fontsize=10)\n",
        "# ax.set_xlabel('Decade', fontsize=20)\n",
        "ax.set_ylabel('Percent of Top Songs (weighted)', fontsize=30)\n",
        "ax.set_xticklabels(us_impact_df.decade, size=30)\n",
        "ax.legend(fontsize=20, title='Song Origin', title_fontsize='20');\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuC2GCmQeh-l"
      },
      "source": [
        "corpora_all_dt['cdickens_achristmascarol'].head(2)\n",
        "corpora_all_dt['cdickens_achristmascarol'].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcuY9-AwjcoJ"
      },
      "source": [
        "corpora_all_dt['cdickens_achristmascarol'].columns.str.endswith('_z')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHdmhh2iUt0c"
      },
      "source": [
        "# Plot zScore + SMA 10% for all Models in each Corpus (including bold median_z)\n",
        "\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
        "\n",
        "save_plot = True\n",
        "\n",
        "subdir_name = 'data_corpora_plots'\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls[:2]):\n",
        "  print(f'Processing Corpus: {acorpus}...')\n",
        "  win10per = int(0.1*corpora_all_dt[acorpus]['median_z'].shape[0])\n",
        "\n",
        "  for j, amodel_z in enumerate(model_z_cols_ls): # model_cols_ls):\n",
        "\n",
        "    print(f'Corpus #{i} {acorpus} with Model #{j} {amodel_z}: has {len(corpora_all_dt[acorpus].columns)} columns but only {len(model_cols_ls)} model columns')\n",
        "\n",
        "    # amodel_z = f'{amodel}_z'\n",
        "    # corpora_all_dt[acorpus][amodel_z].rolling(win10per, center=True, min_periods=1).mean().plot(label=f'z-Score {amodel_z}', alpha=0.3) # , style=['r*-'], linewidth=2.0)\n",
        "    corpora_all_dt[acorpus][amodel_z].rolling(win10per, center=True, min_periods=1).mean().plot(label=f'{amodel_z}', alpha=0.3) # , style=['r*-'], linewidth=2.0)\n",
        "\n",
        "  # ax = corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True, min_periods=1).mean().plot(label='z-Score Median', style=['r'], linewidth=3, alpha=0.9)\n",
        "  ax = corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True, min_periods=1).mean().plot(label='z-Score Median', style=['r'], linewidth=3, alpha=0.9)\n",
        "\n",
        "  ax.grid(True)\n",
        "  ax.set_title(f'{corpora_full_dt[acorpus]}\\n zScore and SMA 10%', fontsize=20)\n",
        "  # ax.set(xlabel='Decade', ylabel='Weighted Percent of Top Songs', fontsize=10)\n",
        "  ax.set_xlabel('Line Number', fontsize=14)\n",
        "  ax.set_ylabel('Standardized Sentiment Value', fontsize=14)\n",
        "  # ax.set_xticklabels(us_impact_df.decade, size=30)\n",
        "  ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10, title='Model', title_fontsize=14);\n",
        "\n",
        "  if save_plot:\n",
        "    filename_plt = f'./{subdir_name}/plt_sma10_{acorpus}.png'\n",
        "    plt.savefig(filename_plt)\n",
        "    print(f'Saved plot to filepath: {filename_plt}\\n\\n')\n",
        "\n",
        "  plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ostEXF5gPJP_"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "# Plot zScore + SMA 10% for all Models in each Corpus (including bold median_z)\n",
        "\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
        "\n",
        "save_plot = True\n",
        "\n",
        "subdir_name = 'data_corpora_plots'\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls[:2]): # [:2]):\n",
        "  print(f'Processing Corpus: {acorpus}...')\n",
        "  win10per = int(0.1*corpora_all_dt[acorpus]['median_z'].shape[0])\n",
        "\n",
        "  for j, amodel_z in enumerate(model_z_cols_ls): # model_cols_ls):\n",
        "\n",
        "    print(f'Corpus #{i} {acorpus} with Model #{j} {amodel_z}: has {len(corpora_all_dt[acorpus].columns)} columns but only {len(model_cols_ls)} model columns')\n",
        "\n",
        "    # amodel_z = f'{amodel}_z'\n",
        "    corpora_all_dt[acorpus][amodel_z].rolling(win10per, center=True, min_periods=1).mean().plot(label=f'z-Score {amodel_z}', alpha=0.3) # , style=['r*-'], linewidth=2.0)\n",
        "\n",
        "  corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True, min_periods=1).mean().plot(label='z-Score Median', style=['r'], linewidth=5.0)\n",
        "\n",
        "  plt.title(f'{corpora_full_dt[acorpus]}\\n zScore and SMA 10%', fontsize=20)    \n",
        "  plt.legend(loc='best', fontsize=12, title='Model', title_fontsize=16)\n",
        "  # corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True, min_periods=1).mean().plot(label='z-Score Median', style=['r'], linewidth=3.0)\n",
        "  plt.xlabel = 'Novel Line Number'\n",
        "  plt.ylabel = 'Standardized Sentiment Value'\n",
        "  if save_plot:\n",
        "    filename_plt = f'./{subdir_name}/plt_sma10_{acorpus}.png'\n",
        "    plt.savefig(filename_plt)\n",
        "\n",
        "  plt.show();\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TIrSDJDWNyH"
      },
      "source": [
        "## **Skip to [Save zScore] below**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYubpcv6FmlX"
      },
      "source": [
        "# Create list of all <model>_z DataFrames\n",
        "\n",
        "pattern_z = re.compile(r'_z$')\n",
        "pattern_zz = re.compile(r'_z_z$')\n",
        "models_z_dt = {}\n",
        "models_z_ls = []\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls): # [:2]):\n",
        "  print(f'Processing Corpus: {acorpus}')\n",
        "\n",
        "  acorpus_model_ls = corpora_allz_dt[acorpus].columns\n",
        "  for j, amodel in enumerate(acorpus_model_ls):\n",
        "\n",
        "    # win10per = int(0.10*corpora_all_dt[acorpus].shape[0])\n",
        "\n",
        "    if pattern_z.search(amodel) and not pattern_zz.search(amodel):\n",
        "      models_z_ls.append(amodel)\n",
        "\n",
        "  models_z_dt[acorpus] = copy.deepcopy(models_z_ls) # .copy(deep=True)\n",
        "  models_z_ls = []\n",
        "\n",
        "  print(f'models_z_dt[acorpus]: {models_z_dt[acorpus]}\\n\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OpyH9A5Ifv0"
      },
      "source": [
        "models_z_dt['cdickens_achristmascarol']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJmibPasHYo_"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (40,20)\n",
        "\n",
        "subdir_name = 'data_corpora_plots'\n",
        "pattern_z = re.compile(r'_z$')\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls): # [:2]):\n",
        "  print(acorpus)\n",
        "\n",
        "  models_z_ls = models_z_dt[acorpus]\n",
        "  win10per = int(0.1*corpora_allz_dt[acorpus]['median_z'].shape[0])\n",
        "\n",
        "  corpora_allz_dt[acorpus][models_z_ls].rolling(win10per, center=True).mean().plot(label=amodel_z, alpha=0.3)\n",
        "\n",
        "  # if i == (len(corpora_ls)):\n",
        "  #   corpora_all_dt[amodel]['median_z'].rolling(win10per, center=True).mean().plot(alpha=0.6, color='black', width=2)\n",
        "  #   plt.title(f'{acorpus} Simple Moving Average')\n",
        "  #  plt.legend(loc='best')\n",
        "  \n",
        "  # atitle = f'{acorpus}\\n z-Score SMA 10%'\n",
        "  # ax.title(atitle)\n",
        "  plt.title(f'{acorpus}\\n z-Score SMA 10%')    \n",
        "  plt.legend(loc='best')\n",
        "  \n",
        "  # corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True).mean().plot(label='z-Score Median', style=['r*-'], linewidth=2.0)\n",
        "\n",
        "  filename_plt = f'./{subdir_name}/plt_zsma10_{amodel}.png'\n",
        "  plt.savefig(filename_plt)\n",
        "\n",
        "  fig.show()\n",
        "  # plt.show();  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAW9c88odV9K"
      },
      "source": [
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (40,20)\n",
        "\n",
        "subdir_name = 'data_corpora_plots'\n",
        "pattern_z = re.compile(r'_z$')\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls): # [:2]):\n",
        "  print(acorpus)\n",
        "  # fig,ax = plt.subplots()\n",
        "\n",
        "  for j, amodel in enumerate(model_cols_ls):\n",
        "\n",
        "    # win10per = int(0.1*corpora_all_dt[acorpus]['median_z'].shape[0])\n",
        "\n",
        "    # if j == 0:\n",
        "    #   corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True).mean().plot(label='z-Score Median', style=['r*-'], linewidth=2.0)\n",
        "\n",
        "    # print(f'Corpus #{i} {acorpus} with Model #{j} {amodel}: has {len(corpora_all_dt[acorpus].columns)} columns but only {len(model_cols_ls)} model columns')\n",
        "    win10per = int(0.10*corpora_all_dt[acorpus].shape[0])\n",
        "\n",
        "    # Skip existing z-Scores\n",
        "    if pattern_z.search(amodel):    \n",
        "\n",
        "      # amodel_z = f'{amodel}_z'\n",
        "\n",
        "      # corpora_all_dt[acorpus][amodel_z].rolling(win10per, center=True).mean().plot(label=amodel_z, alpha=0.3)\n",
        "\n",
        "      # corpora_all_dt[acorpus][amodel].astype(np.float64)\n",
        "      # temp_df[amodel] = corpora_all_dt[acorpus][amodel].value.rolling(win10per, min_periods=1,center=True).apply(zscore)\n",
        "      \n",
        "      # temp_df[amodel] = pd.Series(type(stdscaler.fit_transform(np.asarray(corpora_all_dt[acorpus][amodel]).reshape(-1,1)))) # .reshape(-1,1))\n",
        "      # print(f'temp_df[amodel]: {temp_df[amodel]}')\n",
        "      # print(f'len(temp_df[amodel]: {len(temp_df[amodel])}')\n",
        "\n",
        "      # corpora_all_dt[acorpus][amodel_z].rolling(win10per, min_periods=1,center=True).mean().plot() # .mean().plot(label=amodel)\n",
        "\n",
        "      # ax.plot(corpora_all_dt[acorpus][amodel_z].index, corpora_all_dt[acorpus][amodel_z].rolling(win10per, min_periods=1,center=True).mean(), label=amodel_z)\n",
        "      # ax.set_xlabel('Sentence No.')\n",
        "      # ax.set_ylabel('Sentiment (z-Score')\n",
        "      # ax.legend(loc='best')\n",
        "\n",
        "      # plt.title(f'{acorpus}\\n z-Score SMA 10%')\n",
        "      # plt.legend(loc='best') \n",
        "      pass\n",
        "\n",
        "    corpora_all_dt[acorpus][amodel_z].rolling(win10per, center=True).mean().plot(label=amodel_z, alpha=0.3)\n",
        "\n",
        "  # if i == (len(corpora_ls)):\n",
        "  #   corpora_all_dt[amodel]['median_z'].rolling(win10per, center=True).mean().plot(alpha=0.6, color='black', width=2)\n",
        "  #   plt.title(f'{acorpus} Simple Moving Average')\n",
        "  #  plt.legend(loc='best')\n",
        "  \n",
        "  atitle = f'{acorpus}\\n z-Score SMA 10%'\n",
        "  ax.title(atitle)\n",
        "  # plt.title(f'{acorpus}\\n z-Score SMA 10%')    \n",
        "  # plt.legend(loc='best')\n",
        "  \n",
        "  # corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True).mean().plot(label='z-Score Median', style=['r*-'], linewidth=2.0)\n",
        "\n",
        "  filename_plt = f'./{subdir_name}/plt_sma10_{amodel}.png'\n",
        "  plt.savefig(filename_plt)\n",
        "\n",
        "  fig.show()\n",
        "  # plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ8M0zj6FCRC"
      },
      "source": [
        "## **Patch TMorrison's Beloved Errors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I11EaPcYtFuK"
      },
      "source": [
        "corpora_all_dt['tmorrison_beloved'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZd9y_bnvBxR"
      },
      "source": [
        "%whos dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI7O_mOcvIjD"
      },
      "source": [
        "corpora_sa_dt.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RDoSHcCu76i"
      },
      "source": [
        "# TODO: Fix error (all 0) for tmorrison_beloved/pattern model (leads to NaN in zScore/SMA/LTTB)\n",
        "\n",
        "corpora_sa_dt['baseline_tmorrison_beloved']['pattern'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGxJfDo4tJds"
      },
      "source": [
        "corpora_all_dt['tmorrison_beloved']['pattern'].value_counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itjLd_i5uCXe"
      },
      "source": [
        "corpora_all_dt['tmorrison_beloved']['pattern'].rolling(400, center=True, min_periods=1).mean().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yw7hbYCtPkd"
      },
      "source": [
        "corpora_all_dt['tmorrison_beloved']['pattern_z'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecpWwI8fuKQz"
      },
      "source": [
        "corpora_all_dt['tmorrison_beloved']['pattern_z'].rolling(400, center=True, min_periods=1).mean().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph5YmLX6zUw2"
      },
      "source": [
        "## **Save zScore/SMA 10% DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY9g47jj7i8O"
      },
      "source": [
        "# Save all models with orignal and zscore values\n",
        "\n",
        "subdir_out = 'data_corpora_all'\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(acorpus)\n",
        "  # acorpus_sent_len = corpora_all_dt[acorpus]['xgb'].shape[0]\n",
        "\n",
        "  filename_out = f'models_zall_{acorpus}.csv'\n",
        "  fullpath_out = f'./{subdir_out}/{filename_out}'\n",
        "\n",
        "  print(f'\\nSaving Corpus: {acorpus}...')\n",
        "  corpora_all_dt[acorpus].to_csv(fullpath_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqqMG-C_evDa"
      },
      "source": [
        "# **Identify Crux Points**\n",
        "\n",
        "* https://pythonawesome.com/overview-of-the-peaks-dectection-algorithms-available-in-python/\n",
        "\n",
        "* https://eddwardo.github.io/posts/2019-06-05-finding-local-extreams-in-pandas-time-series/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al9PAC4g2y3i"
      },
      "source": [
        "from scipy.signal import argrelextrema"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlLAeseueu4B"
      },
      "source": [
        "corpora_all_dt['cdickens_achristmascarol'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa5HvXy-q4gB"
      },
      "source": [
        "corpus_root_ls[:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNBKGw8OtuNB"
      },
      "source": [
        "## **SMA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYnTLz0leuu_"
      },
      "source": [
        "acorpus = 'cdickens_achristmascarol'\n",
        "\n",
        "win5_per = int(corpora_all_dt[acorpus].shape[0]*0.05)\n",
        "\n",
        "for i in range(1,5):\n",
        "  win_size = i*win5_per\n",
        "  win_per = 5*i\n",
        "  corpora_all_dt[acorpus]['vader_z'].rolling(i*win5_per, center=True, min_periods=1).mean().plot(label=f'Win={win_per}%')\n",
        "plt.ylabel('Sentiment (z-score standardize)', fontsize=12)\n",
        "plt.xlabel('Line No', fontsize=12)\n",
        "plt.title(f'{corpora_full_dt[acorpus]}\\n Sentiment Time Series (z-score, SMA)', fontsize=16)\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYpn47qtsvP7"
      },
      "source": [
        "acorpus = 'cdickens_achristmascarol'\n",
        "\n",
        "win5_per = int(corpora_all_dt[acorpus].shape[0]*0.05)\n",
        "win1_per = int(corpora_all_dt[acorpus].shape[0]*0.01)\n",
        "\n",
        "for i in range(1,7):\n",
        "  win_size = (i-1)*win1_per + win5_per\n",
        "  win_per = 5 + (i-1)\n",
        "  corpora_all_dt[acorpus]['vader_z'].rolling(i*win5_per, center=True, min_periods=1).mean().plot(label=f'Win={win_per}%')\n",
        "plt.ylabel('Sentiment (z-score standardize)', fontsize=12)\n",
        "plt.xlabel('Line No', fontsize=12)\n",
        "plt.title(f'{corpora_full_dt[acorpus]}\\n Sentiment Time Series (z-score, SMA)', fontsize=16)\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcmHQ0nUnIHy"
      },
      "source": [
        "for i, acorpus in enumerate(corpus_root_ls[:2]):\n",
        "\n",
        "  win5_per = int(corpora_all_dt[acorpus].shape[0]*0.05)\n",
        "\n",
        "  for i in range(1,5):\n",
        "    win_size = i*win5_per\n",
        "    win_per = 5*i\n",
        "    corpora_all_dt[acorpus]['vader_z'].rolling(i*win5_per, center=True, min_periods=1).mean().plot(label=f'Win={win_per}%')\n",
        "  plt.ylabel('Sentiment (z-score standardize)', fontsize=12)\n",
        "  plt.xlabel('Line No', fontsize=12)\n",
        "  plt.title(f'{corpora_full_dt[acorpus]}\\n Sentiment Time Series (z-score, SMA)', fontsize=16)\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svdQJcoirUVO"
      },
      "source": [
        "model_z_cols_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuzERRZPnIC0"
      },
      "source": [
        "for i, acorpus in enumerate(corpus_root_ls[:2]):\n",
        "\n",
        "  win5_per = int(corpora_all_dt[acorpus].shape[0]*0.05)\n",
        "\n",
        "  for i in range(1,3):\n",
        "    win_size = i*win5_per\n",
        "    win_per = 5*i\n",
        "    for j, amodel in enumerate(model_z_cols_ls):\n",
        "      corpora_all_dt[acorpus][amodel].rolling(i*win5_per, center=True, min_periods=1).mean().plot(label=f'{amodel}: Win={win_per}%')\n",
        "  plt.ylabel('Sentiment (z-score standardize)', fontsize=12)\n",
        "  plt.xlabel('Line No', fontsize=12)\n",
        "  plt.title(f'{corpora_full_dt[acorpus]}\\n Sentiment Time Series (z-score, SMA)', fontsize=16)\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcItgYmJtyqo"
      },
      "source": [
        "## **LOWESS**\n",
        "\n",
        "* https://james-brennan.github.io/posts/lowess_conf/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLzODPVgt9jf"
      },
      "source": [
        "from statsmodels.nonparametric.smoothers_lowess import lowess as  sm_lowess"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEBORNAot6ga"
      },
      "source": [
        "acorpus = 'cdickens_achristmascarol'\n",
        "\n",
        "win5_per = int(corpora_all_dt[acorpus].shape[0]*0.05)\n",
        "\n",
        "for i in range(1,5):\n",
        "  win_size = i*win5_per\n",
        "  win_per = 5*i\n",
        "  corpora_all_dt[acorpus]['vader_z'].rolling(i*win5_per, center=True, min_periods=1).mean().plot(label=f'Win={win_per}%')\n",
        "plt.ylabel('Sentiment (z-score standardize)', fontsize=12)\n",
        "plt.xlabel('Line No', fontsize=12)\n",
        "plt.title(f'{corpora_full_dt[acorpus]}\\n Sentiment Time Series (z-score, SMA)', fontsize=16)\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtcevtxjuaHX"
      },
      "source": [
        "corpora_all_dt[acorpus][amodel].plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVykbIh0vQrD"
      },
      "source": [
        "for acorpus in corpora_ls:\n",
        "  print(f'Corpus: {acorpus}')\n",
        "  for amodel in model_z_cols_ls:\n",
        "    amin = corpora_all_dt[acorpus][amodel].min()\n",
        "    amax = corpora_all_dt[acorpus][amodel].max()\n",
        "    print(f'    Model: {amodel}')\n",
        "    print(f'      Min={amin:.2f}')\n",
        "    print(f'      Max={amax:.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmT8AYidJxhw"
      },
      "source": [
        "### **Identify Crux Points**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrbT7qTTnH9w"
      },
      "source": [
        "acorpus = 'cdickens_achristmascarol'\n",
        "amodel = 'vader_z'\n",
        "\n",
        "crux_halfwin = 20\n",
        "\n",
        "lowess_dt = {}\n",
        "\n",
        "y = corpora_all_dt[acorpus][amodel]\n",
        "x_len = len(corpora_all_dt[acorpus][amodel])\n",
        "x = range(x_len)\n",
        "\n",
        "# Crux LOWESS Extrema (frac=1./5.)\n",
        "crux_x_min_ls = []\n",
        "crux_x_max_ls = []\n",
        "# Smoothed LOWESS Extrema (frac=1./5.)\n",
        "sm_y_05frac = np.empty(shape=(x_len))\n",
        "# Smoothed LOWESS Baseline (frac=1./20.)\n",
        "sm_y_20frac = np.empty(shape=(x_len))\n",
        "# Inbetween LOWESS plots (frac= [1./7., 1./10., 1./15.] )\n",
        "sm_y_07frac = np.empty(shape=(x_len))\n",
        "sm_y_10frac = np.empty(shape=(x_len))\n",
        "sm_y_15frac = np.empty(shape=(x_len))\n",
        "\n",
        "# frac_ls = [1./5., 1./7., 1./10., 1./15., 1./20.]\n",
        "# NOTE: Order dependent, need to get baseline 1./20. first to calc distances\n",
        "frac_ls = [1./20., 1./15., 1./10., 1./7., 1./5.]\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(20, 10))\n",
        "\n",
        "fig = plt.figure(figsize=(20, 10), dpi=80)\n",
        "ax = fig.add_subplot(111)\n",
        "# lines = ax1.plot(df_copy['Date'], df_copy['Open'], label='Open values')\n",
        "# ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
        "\n",
        "for i,afrac in enumerate(frac_ls):\n",
        "  # afrac = 1./frac_div\n",
        "  sm_x, sm_y = sm_lowess(y, x,  frac=afrac, it=5, return_sorted = True).T\n",
        "\n",
        "  # Set axis ranges; by default this will put major ticks every 25.\n",
        "  # ax.set_xlim(0, len(sm_x))\n",
        "  # ax.set_ylim(0, len(sm_y))\n",
        "\n",
        "  # Save Baseline arc (frac = 1./5.)\n",
        "  if (afrac == 1./5.):\n",
        "    sm_y_05frac = sm_y.copy()\n",
        "  \n",
        "  # Save Extreme arc (frac = 1./20.) and Plot Crux Points\n",
        "  elif (afrac == 1./20.):\n",
        "    sm_y_20frac = sm_y.copy()\n",
        "    crux_x_min_ls = argrelextrema(sm_y, np.less_equal, order=crux_halfwin)[0]\n",
        "    crux_x_max_ls = argrelextrema(sm_y, np.greater_equal, order=crux_halfwin)[0]\n",
        "    plt.plot(crux_x_max_ls, sm_y[crux_x_max_ls], 'k^', markersize=10)\n",
        "    plt.plot(crux_x_min_ls, sm_y[crux_x_min_ls], 'rv', markersize=10)\n",
        "    1./20., 1./15., 1./10., 1./7., 1./5.\n",
        "  elif (afrac == 1./7.):\n",
        "    sm_y_07frac = sm_y.copy()\n",
        "  elif (afrac == 1./10.):\n",
        "    sm_y_10frac = sm_y.copy()\n",
        "  elif (afrac == 1./15.):\n",
        "    sm_y_15frac = sm_y.copy()\n",
        "  else:\n",
        "      print(f'ERROR: illegal value for afrac={afrac}, must be one of {frac_ls}')\n",
        "\n",
        "  corpus_model_frac_key = f'{acorpus}:{amodel}:{afrac:.2f}'\n",
        "  lowess_dt[corpus_model_frac_key] = sm_y\n",
        "  lines = ax.plot(sm_x, sm_y, label=f'frac={afrac:.2f}') #, color='tomato')\n",
        "  \n",
        "\n",
        "  # plt.plot(ilocs_max, style='.', lw=10, color='red', marker=\"v\");\n",
        "  # df.iloc[ilocs_min].price.plot(style='.', lw=10, color='green', marker=\"^\");\n",
        "\n",
        "plt.ylabel('Sentiment (z-score standardize)', fontsize=12)\n",
        "plt.xlabel('Line No', fontsize=12)\n",
        "plt.title(f'{corpora_full_dt[acorpus]}\\n Sentiment Time Series (z-score, SMA)', fontsize=16)\n",
        "plt.legend(loc='best')\n",
        "\n",
        "# Major ticks every 20, minor ticks every 5\n",
        "major_ticks = np.arange(0, x_len, 100)\n",
        "minor_ticks = np.arange(0, x_len, 50)\n",
        "\n",
        "ax.set_xticks(major_ticks)\n",
        "ax.set_xticks(minor_ticks, minor=True)\n",
        "# ax.set_yticks(major_ticks)\n",
        "# ax.set_yticks(minor_ticks, minor=True)\n",
        "\n",
        "# And a corresponding grid\n",
        "# ax.grid(which='both')\n",
        "\n",
        "# Or if you want different settings for the grids:\n",
        "ax.grid(which='minor', alpha=0.2)\n",
        "ax.grid(which='major', alpha=0.5)\n",
        "\n",
        "# plt.grid(True)\n",
        "# plt.grid(True, alpha=0.3, markevery=100)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U_1yTWk-kZs"
      },
      "source": [
        "temp_df = pd.DataFrame(sm_y_20frac)\n",
        "temp_df.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49P_HwqkCa_i"
      },
      "source": [
        "crux_x_min_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL6SlyGICa59"
      },
      "source": [
        "crux_x_max_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qwz5e2EJ5H8"
      },
      "source": [
        "### **Crux Significance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-2vlC9zCzC5"
      },
      "source": [
        "# For Crux Minimums, calculate the Distance between the Baseline and Extrema LOWESS Crux Points\n",
        "\n",
        "crux_min_dist_ls = []\n",
        "\n",
        "crux_min_len = len(crux_x_min_ls)\n",
        "crux_type_ls = ['min']*crux_min_len\n",
        "\n",
        "for amin_crux in crux_x_min_ls:\n",
        "  amin_crux_dist = abs(sm_y_20frac[amin_crux] - sm_y_05frac[amin_crux])\n",
        "  crux_min_dist_ls.append(amin_crux_dist)\n",
        "  # print(f'At Line: {amin_crux} the abs(base-extreme) distance: {amin_crux_dist}')\n",
        "\n",
        "# crux_min_dist_ls.sort(reverse=True)\n",
        "\n",
        "crux_min_points_df = pd.DataFrame(\n",
        "    {'type' : crux_type_ls,\n",
        "     'line_no' : crux_x_min_ls,\n",
        "     'dist' : crux_min_dist_ls})\n",
        "\n",
        "# crux_min_points_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGNAkHcJGHkX"
      },
      "source": [
        "# For Crux Maximums, calculate the Distance between the Baseline and Extrema LOWESS Crux Points\n",
        "\n",
        "crux_max_dist_ls = []\n",
        "\n",
        "crux_max_len = len(crux_x_max_ls)\n",
        "crux_type_ls = ['max']*crux_max_len\n",
        "\n",
        "for amax_crux in crux_x_max_ls:\n",
        "  amax_crux_dist = abs(sm_y_20frac[amax_crux] - sm_y_05frac[amax_crux])\n",
        "  crux_max_dist_ls.append(amax_crux_dist)\n",
        "  # print(f'At Line: {amax_crux} the abs(base-extreme) distance: {amax_crux_dist}')\n",
        "\n",
        "# crux_max_dist_ls.sort(reverse=True)\n",
        "\n",
        "crux_max_points_df = pd.DataFrame(\n",
        "    {'type' : crux_type_ls,\n",
        "     'line_no' : crux_x_max_ls,\n",
        "     'dist' : crux_max_dist_ls})\n",
        "\n",
        "# crux_max_points_df.head(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmMB5QG4GoD1"
      },
      "source": [
        "# Vertically concatenate and reverse sort the Min and Max Crux Distance DataFrames\n",
        "\n",
        "crux_points_df = crux_max_points_df.append(crux_min_points_df, ignore_index=True)\n",
        "crux_points_df.sort_values('dist', ascending=False, inplace=True)\n",
        "crux_points_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MgUlcZBhNn_"
      },
      "source": [
        "crux_points_df['dist'].plot(kind='bar', label='type')\n",
        "\n",
        "plt.ylabel('Distance from Baseline', fontsize=12)\n",
        "plt.xlabel('Line No', fontsize=12)\n",
        "plt.title(f'{corpora_full_dt[acorpus]}\\n Crux Significance (larger, more prominent)', fontsize=16)\n",
        "plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzCuSClzKCVN"
      },
      "source": [
        "### **Crux Sentiment Coherence**\n",
        "\n",
        "* Normed agreement between Baseline-Extrema LOWESS arcs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Plinaja0Cmtz"
      },
      "source": [
        "crux_all_ls = crux_points_df.line_no.to_list()\n",
        "type(crux_all_ls)\n",
        "crux_all_ls\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAmHT-70Wpcf"
      },
      "source": [
        "type(crux_points_df.dist.to_list())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAFU7ZK4XC1f"
      },
      "source": [
        "abs(sm_y_15frac[crux_all_ls]-sm_y_05frac[crux_all_ls])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_gVRbXGSQ-3"
      },
      "source": [
        "# Calculate Sentiment Coherence proportional to agreement of 3 inbetween LOWESS curves with extrema curve\n",
        "\n",
        "s_coherence = (abs(sm_y_15frac[crux_all_ls]-sm_y_05frac[crux_all_ls]) + \\\n",
        "abs(sm_y_10frac[crux_all_ls]-sm_y_05frac[crux_all_ls]) + \\\n",
        "abs(sm_y_07frac[crux_all_ls]-sm_y_05frac[crux_all_ls])) # / np.array(crux_points_df.dist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKYvlMroej5n"
      },
      "source": [
        "type(dist_sum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWB9Z4qVhnvA"
      },
      "source": [
        "from scipy.stats import iqr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doMYA8dZhq1M"
      },
      "source": [
        "iqr(dist_sum, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__sX17MClcwG"
      },
      "source": [
        "def trimOutliers(x, outlierConstant):\n",
        "  a = np.array(x)\n",
        "  upper_quartile = np.percentile(a, 75)\n",
        "  lower_quartile = np.percentile(a, 25)\n",
        "  IQR = (upper_quartile - lower_quartile) * outlierConstant\n",
        "  quartileSet = (lower_quartile - IQR, upper_quartile + IQR)\n",
        "  # print(f'IQR: {IQR}')\n",
        "  # print(f'  upper_quartile: {upper_quartile}')\n",
        "  # print(f'  lower_quartile: {lower_quartile}')\n",
        "  resultList = []\n",
        "  for y in a.tolist():\n",
        "    if y >= quartileSet[0] and y <= quartileSet[1]:\n",
        "      resultList.append(y)\n",
        "    elif y < quartileSet[0]:\n",
        "      resultList.append(quartileSet[0]) # lower_quartile)\n",
        "    elif y > quartileSet[1]:\n",
        "      resultList.append(quartileSet[1]) # upper_quartile)\n",
        "    else:\n",
        "      print(f'ERROR: illegal array value y: {y}')\n",
        "  return resultList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZa4l7WjkERV"
      },
      "source": [
        "len(dist_sum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJlpXDcKj180"
      },
      "source": [
        "len(trimOutliers(dist_sum, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab7llL9TmaqI"
      },
      "source": [
        "type(trimOutliers(dist_sum, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7PTshpUmqra"
      },
      "source": [
        "trimOutliers(dist_sum, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUhOin0HmWQu"
      },
      "source": [
        "temp_ls = trimOutliers(dist_sum, 1.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juzXOqlWktyL"
      },
      "source": [
        "plt.plot(temp_ls)\n",
        "plt.ylabel('Distance from Baseline', fontsize=12)\n",
        "plt.xlabel('Line No', fontsize=12)\n",
        "plt.title(f'{corpora_full_dt[acorpus]}\\n Crux Significance (larger, more prominent)', fontsize=16)\n",
        "plt.legend(loc='best')\n",
        "plt.plot();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sALZrb0TofNf"
      },
      "source": [
        "# Plot Distance from Baseline (frac=1./20.)\n",
        "\n",
        "plt.plot(abs(sm_y_07frac-sm_y_05frac), alpha=0.3)\n",
        "plt.plot(abs(sm_y_10frac-sm_y_05frac), alpha=0.3)\n",
        "plt.plot(abs(sm_y_15frac-sm_y_05frac), alpha=0.3)\n",
        "plt.plot(abs(sm_y_20frac-sm_y_05frac), alpha=0.3)\n",
        "\n",
        "# Raw Sum of Distances\n",
        "dist_sum = abs(sm_y_07frac-sm_y_05frac) + abs(sm_y_10frac-sm_y_05frac) + abs(sm_y_15frac-sm_y_05frac) + abs(sm_y_20frac-sm_y_05frac)\n",
        "\n",
        "# Normalized Sum of Distances\n",
        "# dist_sum = (abs(sm_y_07frac-sm_y_05frac) + abs(sm_y_10frac-sm_y_05frac) + abs(sm_y_15frac-sm_y_05frac)) / abs(sm_y_20frac-sm_y_05frac)\n",
        "# IQR\n",
        "\"\"\"\n",
        "Q1 = np.percentile(dist_sum, 25, interpolation = 'midpoint')\n",
        "Q3 = np.percentile(dist_sum, 75, interpolation = 'midpoint')\n",
        "IQR = Q3 - Q1\n",
        "upper_lim = Q3+1.5*IQR\n",
        "print(f'IQR = {IQR} and upper_lim: {upper_lim}')\n",
        "\n",
        "dist_sum_trim_ls = trimOutliers(dist_sum, 10)\n",
        "\n",
        "dist_sum_trim_norm_ls = [x/20 for x in dist_sum_trim_ls]\n",
        "\"\"\";\n",
        "\n",
        "# Draw Crux Min vertical lines\n",
        "xcoords = crux_points_df[crux_points_df.type == 'min']['line_no'].to_list()\n",
        "for xc in xcoords:\n",
        "    plt.axvline(x=xc, color='r', alpha=0.3)\n",
        "    plt.text(xc, 1.75,f'Line #{xc}',rotation=90)\n",
        "\n",
        "# Draw Crux Max vertical lines\n",
        "xcoords = crux_points_df[crux_points_df.type == 'max']['line_no'].to_list()\n",
        "for xc in xcoords:\n",
        "    plt.axvline(x=xc, color='k', alpha=0.3)\n",
        "    plt.text(xc, 2,f'Line #{xc}',rotation=90);\n",
        "\n",
        "plt.ylabel('Raw Sum of Distances between Curves', fontsize=12)\n",
        "plt.xlabel('Line No', fontsize=12)\n",
        "plt.title(f'{corpora_full_dt[acorpus]}\\n Raw Sentiment Coherence', fontsize=16)\n",
        "plt.legend(loc='best')\n",
        "\n",
        "\n",
        "plt.plot(dist_sum, linewidth=3);\n",
        "\n",
        "# plt.plot(sm_y_07frac)\n",
        "# plt.plot(sm_y_15frac)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVmn2jgLXyO8"
      },
      "source": [
        "# Plot Distance from Baseline (frac=1./20.)\n",
        "\n",
        "plt.plot(abs(sm_y_07frac-sm_y_05frac), alpha=0.3)\n",
        "plt.plot(abs(sm_y_10frac-sm_y_05frac), alpha=0.3)\n",
        "plt.plot(abs(sm_y_15frac-sm_y_05frac), alpha=0.3)\n",
        "plt.plot(abs(sm_y_20frac-sm_y_05frac), alpha=0.3)\n",
        "\n",
        "# Raw Sum of Distances\n",
        "# dist_sum = abs(sm_y_07frac-sm_y_05frac) + abs(sm_y_10frac-sm_y_05frac) + abs(sm_y_15frac-sm_y_05frac) + abs(sm_y_20frac-sm_y_05frac)\n",
        "\n",
        "# Normalized Sum of Distances\n",
        "dist_sum = (abs(sm_y_07frac-sm_y_05frac) + abs(sm_y_10frac-sm_y_05frac) + abs(sm_y_15frac-sm_y_05frac)) / abs(sm_y_20frac-sm_y_05frac)\n",
        "# IQR\n",
        "Q1 = np.percentile(dist_sum, 25, interpolation = 'midpoint')\n",
        "Q3 = np.percentile(dist_sum, 75, interpolation = 'midpoint')\n",
        "IQR = Q3 - Q1\n",
        "upper_lim = Q3+1.5*IQR\n",
        "print(f'IQR = {IQR} and upper_lim: {upper_lim}')\n",
        "\n",
        "dist_sum_trim_ls = trimOutliers(dist_sum, 10)\n",
        "\n",
        "dist_sum_trim_norm_ls = [x/20 for x in dist_sum_trim_ls]\n",
        "\n",
        "# Draw Crux Min vertical lines\n",
        "xcoords = crux_points_df[crux_points_df.type == 'min']['line_no'].to_list()\n",
        "for xc in xcoords:\n",
        "    plt.axvline(x=xc, color='r', alpha=0.3)\n",
        "    plt.text(xc, 0.5,f'Line #{xc}',rotation=90)\n",
        "\n",
        "# Draw Crux Max vertical lines\n",
        "xcoords = crux_points_df[crux_points_df.type == 'max']['line_no'].to_list()\n",
        "for xc in xcoords:\n",
        "    plt.axvline(x=xc, color='k', alpha=0.3)\n",
        "    plt.text(xc, 0.75,f'Line #{xc}',rotation=90);\n",
        "\n",
        "plt.ylabel('Normed Distances between Curves', fontsize=12)\n",
        "plt.xlabel('Line No', fontsize=12)\n",
        "plt.title(f'{corpora_full_dt[acorpus]}\\n Normalized Sentiment Coherence', fontsize=16)\n",
        "plt.legend(loc='best')\n",
        "\n",
        "plt.plot(dist_sum_trim_norm_ls, linewidth=3);\n",
        "\n",
        "# plt.plot(sm_y_07frac)\n",
        "# plt.plot(sm_y_15frac)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKS1hTI1dS4_"
      },
      "source": [
        "[crux_all_ls]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeTQoeXkUYIG"
      },
      "source": [
        "# crux_points_df['s_coherence'] = pd.Series(s_coherence)\n",
        "\n",
        "# crux_points_df['s_coherence'] = dist_sum[crux_all_ls]\n",
        "\n",
        "crux_points_df['s_coherence'] = np.array(dist_sum_trim_norm_ls)[crux_all_ls]\n",
        "\n",
        "print(crux_points_df.sort_values(by = 's_coherence'))\n",
        "# crux_points_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoTHFocTdnEx"
      },
      "source": [
        "crux_points_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfaSi_Ebc5C8"
      },
      "source": [
        "dist_sum[crux_all_ls]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rezTjlrrpPf2"
      },
      "source": [
        "len(dist_sum)\n",
        "print('\\n')\n",
        "len(dist_sum_trim_norm_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nop6MZ3DKOey"
      },
      "source": [
        "### **Crux Temporal Coherence**\n",
        "\n",
        "* Direction\n",
        "* Span\n",
        "* Peaks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ni0w_AGKOPS"
      },
      "source": [
        "acorpus = 'cdickens_achristmascarol'\n",
        "amodel = 'vader_z'\n",
        "\n",
        "crux_halfwin = 20\n",
        "\n",
        "corpora_cruxes_dt = {}\n",
        "\n",
        "y = corpora_all_dt[acorpus][amodel]\n",
        "x_len = len(corpora_all_dt[acorpus][amodel])\n",
        "x = range(x_len)\n",
        "\n",
        "# Crux LOWESS Extrema (frac=1./5.)\n",
        "crux_x_min_ls = []\n",
        "crux_x_max_ls = []\n",
        "# Smoothed LOWESS Extrema (frac=1./5.)\n",
        "sm_y_05frac = np.empty(shape=(x_len))\n",
        "# Smoothed LOWESS Baseline (frac=1./20.)\n",
        "sm_y_20frac = np.empty(shape=(x_len))\n",
        "# Inbetween LOWESS plots (frac= [1./7., 1./10., 1./15.] )\n",
        "sm_y_07frac = np.empty(shape=(x_len))\n",
        "sm_y_10frac = np.empty(shape=(x_len))\n",
        "sm_y_15frac = np.empty(shape=(x_len))\n",
        "\n",
        "# frac_ls = [1./5., 1./7., 1./10., 1./15., 1./20.]\n",
        "# NOTE: Order dependent, need to get baseline 1./20. first to calc distances\n",
        "frac_ls = [1./20., 1./15., 1./10., 1./7., 1./5.]\n",
        "\n",
        "for i,afrac in enumerate(frac_ls):\n",
        "  # afrac = 1./frac_div\n",
        "  sm_x, sm_y = sm_lowess(y, x,  frac=afrac, it=5, return_sorted = True).T\n",
        "\n",
        "  crux_x_min_ls = argrelextrema(sm_y, np.less_equal, order=crux_halfwin)[0]\n",
        "  crux_x_max_ls = argrelextrema(sm_y, np.greater_equal, order=crux_halfwin)[0]\n",
        "\n",
        "  corpus_model_key = f'{acorpus}:{amodel}:{int(np.round(afrac*100))}'\n",
        "  corpora_cruxes_dt[corpus_model_key] = {'min':crux_x_min_ls, 'max':crux_x_max_ls}\n",
        "\n",
        "  alabel=f'{int(np.round(afrac*100))}'\n",
        "  if (afrac == 1./20.):\n",
        "    plt.plot(crux_x_max_ls, sm_y[crux_x_max_ls], 'k^', markersize=20, alpha=0.3)\n",
        "    for k in range(len(crux_x_max_ls)):\n",
        "      plt.annotate(alabel, (crux_x_max_ls[k], sm_y[crux_x_max_ls[k]]))\n",
        "    plt.plot(crux_x_min_ls, sm_y[crux_x_min_ls], 'rv', markersize=20, alpha=0.3) # , label=alabel);\n",
        "    for k in range(len(crux_x_min_ls)):\n",
        "      plt.annotate(alabel, (crux_x_min_ls[k], sm_y[crux_x_min_ls[k]]), color='r')\n",
        "  else:\n",
        "    plt.plot(crux_x_max_ls, sm_y[crux_x_max_ls], 'k^', markersize=10, alpha=0.2) # , label=f'{int(np.round(afrac*100))}')\n",
        "    for k in range(len(crux_x_max_ls)):\n",
        "      plt.annotate(alabel, (crux_x_max_ls[k], sm_y[crux_x_max_ls[k]]))\n",
        "    plt.plot(crux_x_min_ls, sm_y[crux_x_min_ls], 'rv', markersize=10, alpha=0.2) # , label=alabel);\n",
        "    for k in range(len(crux_x_min_ls)):\n",
        "      plt.annotate(alabel, (crux_x_min_ls[k], sm_y[crux_x_min_ls[k]]), color='r')\n",
        "\n",
        "plt.ylabel('Normed Distances between Curves', fontsize=12)\n",
        "plt.xlabel('Line No', fontsize=12)\n",
        "plt.title(f'{corpora_full_dt[acorpus]}\\n Crux Temporal Coherence', fontsize=16)\n",
        "# plt.legend(loc='best')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKNA7cP6t8bX"
      },
      "source": [
        "corpora_cruxes_dt.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ebqjoGcuHb1"
      },
      "source": [
        "corpora_cruxes_dt['cdickens_achristmascarol:vader_z:5']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wHp6HXEz-MA"
      },
      "source": [
        "crux_line_df = crux_points_df[['type','line_no']].copy(deep=True)\n",
        "crux_line_df['frac'] = 'frac20'\n",
        "crux_line_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBzLE5SbuHIh"
      },
      "source": [
        "acorpus = 'cdickens_achristmascarol'\n",
        "amodel = 'vader_z'\n",
        "\n",
        "crux_line_max_df = pd.DataFrame()\n",
        "crux_line_min_df = pd.DataFrame()\n",
        "\n",
        "for afrac in [5,7,10,14,20]:\n",
        "  crux_key = f'{acorpus}:{amodel}:{afrac}'\n",
        "\n",
        "  crux_max_ls = corpora_cruxes_dt[crux_key]['max']\n",
        "  type_max_ls = ['max']*len(crux_max_ls)\n",
        "  frac_max_ls = [afrac]*len(crux_max_ls)\n",
        "\n",
        "  crux_line_max_df = crux_line_max_df.append(pd.DataFrame({'type':type_max_ls,\n",
        "                                  'line_no':crux_max_ls,\n",
        "                                  'frac':frac_max_ls}), ignore_index=True)\n",
        "  \n",
        "  crux_min_ls = corpora_cruxes_dt[crux_key]['min']\n",
        "  type_min_ls = ['min']*len(crux_min_ls)\n",
        "  frac_min_ls = [afrac]*len(crux_min_ls)\n",
        "\n",
        "  crux_line_min_df = crux_line_min_df.append(pd.DataFrame({'type':type_min_ls,\n",
        "                                  'line_no':crux_min_ls,\n",
        "                                  'frac':frac_min_ls}), ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHOOGmWHz4rJ"
      },
      "source": [
        "crux_line_min_df.shape\n",
        "print('\\n')\n",
        "crux_line_max_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWRCnHDI4QHb"
      },
      "source": [
        "# Create unified DataFrame of all cruxes sorted by line_no\n",
        "\n",
        "crux_lines_df = crux_line_max_df.append(crux_line_min_df, ignore_index=True)\n",
        "crux_lines_df.sort_values(by='line_no', inplace=True)\n",
        "crux_lines_df.head(20)\n",
        "crux_lines_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3PRt5179Tl5"
      },
      "source": [
        "crux_lines_df.tail(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf8ViqfY4oT_"
      },
      "source": [
        "crux_lines_df.groupby('line_no')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR5huI4v4n7u"
      },
      "source": [
        "last_type = 'min'\n",
        "cur_type = 'min'\n",
        "cur_cluster_ls = []\n",
        "cluster_all_ls = [] # list of tuples (frac, line_no, type)\n",
        "\n",
        "for i, arow in crux_lines_df.iterrows():\n",
        "  # Special processing for first row\n",
        "  if i == 0:\n",
        "    last_type = arow['type']\n",
        "    cur_cluster_ls.append((arow['frac'],arow['line_no'],arow['type']))\n",
        "    continue\n",
        "  # Regular processing for second row onward\n",
        "  else:\n",
        "    cur_type = arow['type']\n",
        "    if cur_type != last_type:\n",
        "      # Process last cluster\n",
        "      cluster_all_ls.append(cur_cluster_ls)\n",
        "      cur_cluster_ls = [(arow['frac'],arow['line_no'],arow['type'])]\n",
        "      last_type = cur_type\n",
        "    else:\n",
        "      cur_cluster_ls.append((arow['frac'],arow['line_no'],arow['type']))\n",
        "\n",
        "# Save last cluster\n",
        "cluster_all_ls.append(cur_cluster_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd2Hup9z5_gw"
      },
      "source": [
        "cluster_all_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB07qvzs5_Zk"
      },
      "source": [
        "crux_type = ''\n",
        "span_ls_ls = []\n",
        "cluster_no_ls = []\n",
        "\n",
        "for i, acrux_ls in enumerate(cluster_all_ls):\n",
        "  print(f'Crux #{i} has {len(acrux_ls)} datapoint(s)')\n",
        "\n",
        "  # Get crux type\n",
        "  crux_type = acrux_ls[0][2]\n",
        "\n",
        "  crux_line_ls = []\n",
        "  for j, acrux in enumerate(acrux_ls):\n",
        "    crux_line_ls.append(acrux[1])\n",
        "    cluster_no_ls.append(i)\n",
        "  crux_span = max(crux_line_ls) - min(crux_line_ls)\n",
        "  print(f'  Span: {crux_span}')\n",
        "\n",
        "  span_ls_ls.append([crux_span]*len(acrux_ls))\n",
        "  span_ls = [item for sublist in span_ls_ls for item in sublist]\n",
        "\n",
        "  # flat_list = [item for sublist in t for item in sublist]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QDJmnZe5_UI"
      },
      "source": [
        "len(span_ls)\n",
        "print('\\n')\n",
        "span_ls[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7wQJID2_5it"
      },
      "source": [
        "crux_lines_df['span'] = span_ls\n",
        "crux_lines_df.insert(0,'cluster_no',cluster_no_ls)\n",
        "crux_lines_df.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCRd0EzDCWsT"
      },
      "source": [
        "crux_lines_df.groupby('cluster_no')['span'].mean().plot(kind='bar')\n",
        "\n",
        "plt.ylabel('Crux Span in #Lines', fontsize=12)\n",
        "plt.xlabel('Crux No', fontsize=12)\n",
        "plt.title(f'{corpora_full_dt[acorpus]}\\n Crux Temporal Coherence (smaller, more coherent)', fontsize=16)\n",
        "# plt.legend(loc='best')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uTGpwzXKUjw"
      },
      "source": [
        "### **Crux Semantic Coherence**\n",
        "\n",
        "* SBert: https://www.sbert.net/docs/pretrained_models.html \n",
        "* Top2Vec: https://github.com/ddangelov/Top2Vec\n",
        "* BERTopic: https://github.com/MaartenGr/BERTopic\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h2qPmrwKUS5"
      },
      "source": [
        "crux_lines_df.head(10)\n",
        "crux_lines_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39RL7Fe2EdQg"
      },
      "source": [
        "!pip install sentence_transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk-coc7xEamr"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Glv_qxgBEagS"
      },
      "source": [
        "# Two lists of sentences\n",
        "sentences1 = ['The cat sits outside',\n",
        "             'A man is playing guitar',\n",
        "             'The new movie is awesome']\n",
        "\n",
        "sentences2 = ['The dog plays in the garden',\n",
        "              'A woman watches TV',\n",
        "              'The new movie is so great']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnRu-PpzEq9A"
      },
      "source": [
        "#Compute embedding for both lists\n",
        "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
        "embeddings2 = model.encode(sentences2, convert_to_tensor=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcPNpZrWEq3g"
      },
      "source": [
        "#Compute cosine-similarits\n",
        "cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBMRXm2SD-Af"
      },
      "source": [
        "#Output the pairs with their score\n",
        "for i in range(len(sentences1)):\n",
        "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odICmAB2D95r"
      },
      "source": [
        "crux_lines_df.head(10)\n",
        "crux_lines_df.info()\n",
        "crux_lines_df.tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGCdF2_FD9wd"
      },
      "source": [
        "acorpus = 'cdickens_achristmascarol'\n",
        "\n",
        "corpora_all_dt[acorpus].head(2)\n",
        "corpora_all_dt[acorpus].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-9qRc6_F3Rg"
      },
      "source": [
        "crux_lines_df.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mgr3BkUD9ps"
      },
      "source": [
        "len(cluster_all_ls)\n",
        "print('\\n')\n",
        "cluster_all_ls[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGFAX9c4D9iw"
      },
      "source": [
        "cluster_linenos_dt = {}\n",
        "\n",
        "for i, acluster_ls in enumerate(cluster_all_ls):\n",
        "  cluster_linenos_dt[i] = set()\n",
        "  for j, acluster in enumerate(acluster_ls):\n",
        "    afrac, alineno, acruxtype = acluster\n",
        "    cluster_no = i\n",
        "    print(f'Cluster #{i}: afrac={afrac}, alineno={alineno}, acruxtype={acruxtype}')\n",
        "    cluster_linenos_dt[i].add(alineno)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3nepUR2fOtY"
      },
      "source": [
        "corpora_all_dt['cdickens_achristmascarol'].columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7ro_jV4D9bj"
      },
      "source": [
        "cluster_lines_dt = {}\n",
        "temp_df = corpora_all_dt[acorpus]\n",
        "\n",
        "for key, lines_st in cluster_linenos_dt.items():\n",
        "  print(f'key: {key}, value: {lines_st}')\n",
        "  cluster_lines_ls = []\n",
        "  cluster_linenos_ls = []\n",
        "  for aline_no in lines_st:\n",
        "    aline_str = temp_df.iloc[aline_no]['sent_raw']\n",
        "    print(f\"  aline: {aline_no}: {aline_str}\")\n",
        "    cluster_linenos_ls.append(aline_no)\n",
        "    cluster_lines_ls.append(aline_str)\n",
        "  \n",
        "  cluster_lines_dt[key] = pd.DataFrame({'line_no':cluster_linenos_ls, 'sent_raw':cluster_lines_ls})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGpxE4mngVhD"
      },
      "source": [
        "temp_df.iloc[-5:]['sent_raw']\n",
        "temp_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1_asRgk9ZjH"
      },
      "source": [
        "import matplotlib\n",
        "\n",
        "matplotlib.rcParams['figure.figsize'] = (20, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjLr1rXyIgqy"
      },
      "source": [
        "cluster_lines_dt[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLcGNXfxkI2M"
      },
      "source": [
        "%%time\n",
        "\n",
        "def get_sem_coh(acorpus_df, acrux_df, min_sents=21):\n",
        "  '''\n",
        "  Given a DataFrame[['line_no','sent_raw']]\n",
        "  Return a Semantic Coherence score based upon\n",
        "    a sequential BERT coherence scores of sliding window over/near crux lines\n",
        "  '''\n",
        "  corpus_len = acorpus_df.shape[0]\n",
        "  \n",
        "  print(acrux_df.head())\n",
        "\n",
        "  lines_ls = acrux_df.line_no.to_list()\n",
        "  line_start = min(lines_ls)\n",
        "  line_end = max(lines_ls)\n",
        "  line_span = line_end - line_start\n",
        "\n",
        "  if line_span < min_sents:\n",
        "    # Extracted Crux range > min_sents requirement\n",
        "    # win_size = min_sents - line_span\n",
        "    win_full = min_sents - line_span\n",
        "    win_half = int(win_full/2)\n",
        "\n",
        "    # Calc front padding, if needed\n",
        "    pad_start = line_start - win_half\n",
        "    pad_end = line_end + win_half\n",
        "    if pad_start < 0:\n",
        "      # Adjust if not enough padding up front\n",
        "      pad_front = line_start\n",
        "      pad_back = win_full - pad_front\n",
        "      line_start = 0\n",
        "      line_end = line_end + pad_back\n",
        "    elif (pad_end > corpus_len-1):\n",
        "      # Adjust if not enough padding in back\n",
        "      pad_back = line_end - corpus_len-1\n",
        "      pad_front = win_full - pad_back\n",
        "      line_start = line_start - pad_front\n",
        "      line_end = corpus_len-1\n",
        "    else:\n",
        "      # Enough front/back padding \n",
        "      line_start = line_start - win_half\n",
        "      line_end   = line_end + (win_full - win_half)\n",
        "  else:\n",
        "\n",
        "    line_span = line_end - line_start\n",
        "\n",
        "  print(f'Start: {line_start}, End: {line_end}, Span: {line_span}')\n",
        "\n",
        "  lines_str_ls = corpora_all_dt[acorpus].iloc[line_start:line_end-1]['sent_raw'].to_list()\n",
        "  lines_str_1fwd_ls = corpora_all_dt[acorpus].iloc[line_start+1:line_end]['sent_raw'].to_list()\n",
        "\n",
        "  # lines_str_ls = corpora_all_dt[acorpus].iloc[line_start:line_end-3]['sent_raw'].to_list()\n",
        "  # lines_str_3fwd_ls = corpora_all_dt[acorpus].iloc[line_start+3:line_end]['sent_raw'].to_list()\n",
        "  # lines_str_ls = a_df.iloc[line_start:line_end,:].sent_raw.to_list()\n",
        "  # print(lines_str_ls)\n",
        "\n",
        "  #Compute embedding for both lists\n",
        "  embeddings1 = model.encode(lines_str_ls, convert_to_tensor=True)\n",
        "  embeddings2 = model.encode(lines_str_1fwd_ls, convert_to_tensor=True)\n",
        "  # embeddings3 = model.encode(lines_str_3fwd_ls, convert_to_tensor=True)\n",
        "\n",
        "  #Compute cosine-similarits\n",
        "  cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
        "\n",
        "  #Output the pairs with their score\n",
        "  cosine_ls = []\n",
        "  for i in range(len(lines_str_ls)):\n",
        "    # print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(lines_str_ls[i], lines_str_1back_ls[i], cosine_scores[i][i]))\n",
        "    # print(f\"  line:  {lines_str_ls[i]}\")\n",
        "    # print(f\"  line-1:{lines_str_1fwd_ls[i]}\")\n",
        "    # print(f\"    cosine_scores: {cosine_scores[i][i]:.2f}\\n\")\n",
        "    cosine_ls.append(cosine_scores[i][i])\n",
        "  print(f'Median: {np.median(cosine_ls)}')\n",
        "\n",
        "  cosine_dist_ls = [x.item() for x in cosine_ls]\n",
        "\n",
        "  return line_start, line_end-1, cosine_dist_ls\n",
        "\n",
        "# TEST \n",
        "\n",
        "line_start, line_end, cosine_dist_ls = get_sem_coh(corpora_all_dt['cdickens_achristmascarol'], cluster_lines_dt[35])\n",
        "\n",
        "# cosine_dist_ls = [x.item() for x in cosine_dist_ls]\n",
        "\n",
        "# print(f'Returned with cosine_dist_ls: {cosine_dist_ls}')\n",
        "line_ls = range(line_start, line_end)\n",
        "cosine_dist_df = pd.DataFrame({'line_no':line_ls, 'cosine': cosine_dist_ls})\n",
        "cosine_median = np.median(cosine_dist_df.cosine.values)\n",
        "cosine_std = np.std(cosine_dist_df.cosine.values)\n",
        "\n",
        "sns.barplot(x='line_no', y='cosine', data=cosine_dist_df)\n",
        "# plt.xlim(line_start, line_end)\n",
        "plt.ylabel('BERT Cosine Similarity between successive Sentences', fontsize=12)\n",
        "plt.xlabel('Sentence No.', fontsize=12)\n",
        "plt.title(f'{corpora_full_dt[acorpus]}\\n Crux Semantic Coherence by Sentence (BERT Cosine Similiarity)', fontsize=18)\n",
        "# plt.legend(loc='best')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.axhline(cosine_median, color=\"orange\", linestyle=\"dashed\", linewidth=3)\n",
        "plt.annotate(f\"median: {cosine_median:.3f} (std={cosine_std:.3f})\", xy=(0.5,cosine_median),\n",
        "             xycoords=plt.gca().get_yaxis_transform(), ha=\"center\", fontsize=18)\n",
        "plt.show();\n",
        "# plt.plot(cosine_dist_df['cosine'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb1QE0nYGzdE"
      },
      "source": [
        "len(cosine_dist_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHyNdV6tDXk9"
      },
      "source": [
        "cluster_lines_dt[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO_X1YbEDVoE"
      },
      "source": [
        "# TEST \n",
        "\n",
        "line_start, line_end, cosine_dist_ls = get_sem_coh(corpora_all_dt['cdickens_achristmascarol'], cluster_lines_dt[3])\n",
        "\n",
        "# cosine_dist_ls = [x.item() for x in cosine_dist_ls]\n",
        "\n",
        "# print(f'Returned with cosine_dist_ls: {cosine_dist_ls}')\n",
        "line_ls = range(line_start, line_end)\n",
        "cosine_dist_df = pd.DataFrame({'line_no':line_ls, 'cosine': cosine_dist_ls})\n",
        "cosine_median = np.median(cosine_dist_df.cosine.values)\n",
        "cosine_std = np.std(cosine_dist_df.cosine.values)\n",
        "\n",
        "sns.barplot(x='line_no', y='cosine', data=cosine_dist_df)\n",
        "# plt.xlim(line_start, line_end)\n",
        "plt.ylabel('BERT Cosine Similarity between successive Sentences', fontsize=12)\n",
        "plt.xlabel('Sentence No.', fontsize=12)\n",
        "plt.title(f'{corpora_full_dt[acorpus]}\\n Crux Semantic Coherence (BERT Cosine Similiarity)', fontsize=18)\n",
        "# plt.legend(loc='best')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.axhline(cosine_median, color=\"orange\", linestyle=\"dashed\", linewidth=3)\n",
        "plt.annotate(f\"median: {cosine_median:.3f} (std={cosine_std:.3f})\", xy=(0.5,cosine_median),\n",
        "             xycoords=plt.gca().get_yaxis_transform(), ha=\"center\", fontsize=18)\n",
        "plt.show();\n",
        "# plt.plot(cosine_dist_df['cosine'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRgVDRdYD6KW"
      },
      "source": [
        "line_start\n",
        "line_end"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVWxv9qeDkT7"
      },
      "source": [
        "len(line_ls)\n",
        "len(cosine_dist_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrtWTRpj5oh9"
      },
      "source": [
        "sns.lineplot(x='line_no', y='cosine', data=cosine_dist_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmE-ZPG__A9t"
      },
      "source": [
        "cosine_dist_df.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyMq2wr4_QZi"
      },
      "source": [
        "cluster_lines_dt[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX0-1kur_qYv"
      },
      "source": [
        "cluster_all_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIPHmtNTCyqZ"
      },
      "source": [
        "cluster_lines_dt[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjzfZ7Za-nLD"
      },
      "source": [
        "cluster_sem_ls = []\n",
        "\n",
        "acorpus = 'cdickens_achristmascarol'\n",
        "\n",
        "for key, values in cluster_lines_dt.items():\n",
        "  # for key in range(1,25):\n",
        "  print(f'Processing Crux #{key}...')\n",
        "  line_start, line_end, cosine_dist_ls = get_sem_coh(corpora_all_dt[acorpus], cluster_lines_dt[key])\n",
        "  # cosine_dist_ls = [x.item() for x in cosine_dist_ls]\n",
        "  crux_median = np.median(cosine_dist_ls)\n",
        "  crux_std = np.std(cosine_dist_ls)\n",
        "  print(f' Adding: median={crux_median:.2f}, std={crux_std:.2f}')\n",
        "  cluster_sem_ls.append((crux_median, crux_std))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eioAhBdj3AEM"
      },
      "source": [
        "cluster_sem_median_ls = [x[0] for x in cluster_sem_ls]\n",
        "cluster_sem_std_ls = [x[1] for x in cluster_sem_ls]\n",
        "cluster_lineno_ls = list(range(len(cluster_sem_median_ls)))\n",
        "cluster_semantic_df = pd.DataFrame({'line_no':cluster_lineno_ls, 'median':cluster_sem_median_ls, 'std':cluster_sem_std_ls})\n",
        "\n",
        "cluster_sem_median = np.median(cluster_sem_median_ls)\n",
        "cluster_sem_std = np.std(cluster_sem_median_ls)\n",
        "\n",
        "sns.barplot(x='line_no', y='median', data=cluster_semantic_df)\n",
        "# plt.xlim(line_start, line_end)\n",
        "plt.ylabel('BERT Cosine Similarity by Crux Cluster No.', fontsize=12)\n",
        "plt.xlabel('Crux No.', fontsize=12)\n",
        "plt.title(f'{corpora_full_dt[acorpus]}\\n Crux Semantic Coherence (BERT Cosine Similiarity)', fontsize=18)\n",
        "# plt.legend(loc='best')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.axhline(cluster_sem_median, color=\"orange\", linestyle=\"dashed\", linewidth=3)\n",
        "plt.annotate(f\"median: {cluster_sem_median:.3f} (std={cluster_sem_std:.3f})\", xy=(0.5,cluster_sem_median),\n",
        "             xycoords=plt.gca().get_yaxis_transform(), ha=\"center\", fontsize=18)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL1MNGrP2Qa-"
      },
      "source": [
        "temp_ls = [x.item() for x in cosine_dist_ls]\n",
        "type(temp_ls[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VrAyFoU2xxJ"
      },
      "source": [
        "c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6yaNIOwlt-m"
      },
      "source": [
        "cluster_lines_dt[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TohFKQ1uKQg-"
      },
      "source": [
        "for key, lines_df in cluster_lines_dt.items():\n",
        "  print(f'Cluster #{key}:')\n",
        "  print(f'  {lines_df}')\n",
        "  sem_coh = get_sem_coh(lines_df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_76eIjkbiGfS"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Two lists of sentences\n",
        "sentences1 = ['The cat sits outside',\n",
        "             'A man is playing guitar',\n",
        "             'The new movie is awesome']\n",
        "\n",
        "sentences2 = ['The dog plays in the garden',\n",
        "              'A woman watches TV',\n",
        "              'The new movie is so great']\n",
        "\n",
        "#Compute embedding for both lists\n",
        "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
        "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
        "\n",
        "#Compute cosine-similarits\n",
        "cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
        "\n",
        "#Output the pairs with their score\n",
        "for i in range(len(sentences1)):\n",
        "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZwejaU6iGXD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG7A4cLOL1qo"
      },
      "source": [
        "# **END OF NOTEBOOK**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LANyX7BZ26to"
      },
      "source": [
        "ilocs_min = argrelextrema(df.price.values, np.less_equal, order=3)[0]\n",
        "ilocs_max = argrelextrema(df.price.values, np.greater_equal, order=3)[0]\n",
        "\n",
        "df.price.plot(figsize=(20,8), alpha=.3)\n",
        "# filter prices that are peaks and plot them differently to be visable on the plot\n",
        "df.iloc[ilocs_max].price.plot(style='.', lw=10, color='red', marker=\"v\");\n",
        "df.iloc[ilocs_min].price.plot(style='.', lw=10, color='green', marker=\"^\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i07WWang0aMe"
      },
      "source": [
        "lowess_dt.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A8TPPrn0aHf"
      },
      "source": [
        "temp_df = pd.DataFrame(lowess_dt['cdickens_achristmascarol:vader_z:0.05'])\n",
        "temp_df.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXUdagLd0aBh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v2bY6vqnH4Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF8PT9ILFkyo"
      },
      "source": [
        "# **Model-Corpus Compatibility (MCC) per Corpus**\n",
        "\n",
        "MCC(corpus) = 1 / ( | amodel(corpus)- median(corpus) | / len(corpus) )\n",
        "\n",
        "For each Corpus, compute a Coherence Metric for all Models by:\n",
        "* Computing the Euclidian Distance of each zScore/SMA Model from the zScore/SMA Median\n",
        "* Sum all Euclidian Distances \n",
        "* Identify and record furtherest outliers per Corpus/Model\n",
        "* Sum all Euclidian Distances after removing 2-3 of ~35 outliers (5-10% discard)\n",
        "* Normalize 2 Sums of Euclidian Distances over the entire set of Corpora\n",
        "* Rank order the Corpora in terms of Coherence\n",
        "* Rank Order Models in terms of Outlier frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86gBdkVDKZhw"
      },
      "source": [
        "%whos list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLqUMQ_CKTXE"
      },
      "source": [
        "corpora_all_dt['cdickens_achristmascarol'].info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMSuxca_zyju"
      },
      "source": [
        "model_z_cols_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZlfwGiv7T59"
      },
      "source": [
        "np.sum(np.abs(corpora_all_dt['cdickens_achristmascarol']['vader_z'] - corpora_all_dt['cdickens_achristmascarol']['median_z']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5e9iUQkFkk_"
      },
      "source": [
        "# Calculate MCC Metric for each corpus:model combination\n",
        "\n",
        "subdir_out = 'data_corpora_all'\n",
        "\n",
        "median_model_area_ls = []\n",
        "mcc_ls = []                   # Model-Corpus Compatibility (MCC) \n",
        "\n",
        "corpora_median_area_dt = {}\n",
        "corpora_mcc_dt = {}\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(f'Processing Corpus #{i}: {acorpus}')\n",
        "\n",
        "  # median_model_area_ls = []\n",
        "  mcc_ls = []\n",
        "\n",
        "  for j, amodel_z in enumerate(model_z_cols_ls):\n",
        "    print(f'  with Model #{j}: {amodel_z}')\n",
        "\n",
        "    median_model_area = np.sum(np.abs(corpora_all_dt[acorpus][amodel_z] - corpora_all_dt[acorpus]['median_z']))\n",
        "    print(f'    Area between Median: {median_model_area}')\n",
        "\n",
        "    mcc = 1 / (median_model_area / corpora_all_dt[acorpus].shape[0])\n",
        "\n",
        "    # median_model_area_ls.append((amodel_z, median_model_area))\n",
        "    mcc_ls.append((amodel_z, mcc)) \n",
        "    # print(f'      Growing list: {median_model_area_ls}')\n",
        "    print(f'      Growing mcc_ls: {mcc_ls}')\n",
        "\n",
        "  # median_model_area_sorted_ls = copy.deepcopy(median_model_area_ls) # .sort(key=lambda x:x[1]) #  # .sort(key=lambda x: float(x[1])) # .sort(key=lambda y: y[1]) # .sort(key=lambda y: y[1])\n",
        "  # median_model_area_sorted_ls.sort(key=lambda x:x[1], reverse=True)\n",
        "  # print(f'        Copying sorted list: {median_model_area_sorted_ls}')\n",
        "\n",
        "  mcc_sorted_ls = copy.deepcopy(mcc_ls) # .sort(key=lambda x:x[1]) #  # .sort(key=lambda x: float(x[1])) # .sort(key=lambda y: y[1]) # .sort(key=lambda y: y[1])\n",
        "  # median_model_area_sorted_ls.sort(key=lambda x:x[1], reverse=True)\n",
        "  print(f'        Copying sorted list: {mcc_sorted_ls}')\n",
        "\n",
        "\n",
        "  # corpora_median_area_dt[acorpus] = copy.deepcopy(median_model_area_sorted_ls)\n",
        "\n",
        "  corpora_mcc_dt[acorpus] = copy.deepcopy(mcc_sorted_ls)\n",
        "\n",
        "  # corpora_all_dt[acorpus][model_z_cols_ls].head(2)\n",
        "\n",
        "  # TODO: Check for NaN and Impute\n",
        "\n",
        "  # corpora_all_dt[acorpus]['all_z_std'] = corpora_all_dt[acorpus][model_z_cols_ls].std(axis=1)\n",
        "\n",
        "  # acorpus_sent_len = corpora_all_dt[acorpus]['xgb'].shape[0]\n",
        "\n",
        "  # filename_out = f'models_all_{acorpus}.csv'\n",
        "  # fullpath_out = f'./{subdir_out}/{filename_out}'\n",
        "\n",
        "  # print(f'\\nSaving Corpus: {acorpus}...')\n",
        "  # corpora_all_dt[acorpus].to_csv(fullpath_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-AledYmeXb7"
      },
      "source": [
        "corpora_mcc_dt['cdickens_greatexpectations']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7n02Sef5SVx"
      },
      "source": [
        "corpora_mcc_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C15P5d_75qn_"
      },
      "source": [
        "corpora_mcc_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_QMEvpS6mWM"
      },
      "source": [
        "corpora_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcOvZw5rAgus"
      },
      "source": [
        "## **MCC Ranked Models for Each Corpus**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7b51idbFTF2"
      },
      "source": [
        "print(temp_maxmcc_df.model_z.to_list())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdPrLsoB6XTs"
      },
      "source": [
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 8)\n",
        "\n",
        "save_plot = False\n",
        "\n",
        "maxmc_dt = {}\n",
        "\n",
        "for acorpus in corpora_ls:\n",
        "\n",
        "  temp_df = corpora_mcc_df[corpora_mcc_df['corpus']==acorpus]\n",
        "  temp_df = temp_df.sort_values('mcc', ascending=False)\n",
        "  temp_df = temp_df[temp_df.model_z != 'median_z']\n",
        "  # print(f'temp_df: {temp_df.shape}')\n",
        "  # if (acorpus == 'cdickens_achristmascarol'):\n",
        "  temp_maxmcc_df = temp_df[['model_z','mcc']].reset_index(drop=True)\n",
        "  maxmc_dt[acorpus] = temp_maxmcc_df.copy(deep=True)\n",
        "  # print(f'For Corpus: {acorpus}:\\n\\n  {maxmc_dt[acorpus]}')\n",
        "  # model_ls = temp_df['model_z']\n",
        "  # mcc_ls = temp_df['mcc']\n",
        "  # merged_list = tuple(zip(model_ls, mcc_ls)) \n",
        "  # print(f'merged_list: {merged_list}')\n",
        "\n",
        "  # temp_maxmcc_df.plot()\n",
        "  # plt.title(f'{acorpus.upper()} MCC Ranked Models')\n",
        "  # plt.legend('off')\n",
        "  # plt.xticks('model_z')\n",
        "\n",
        "  # fig, ax = plt.subplots(1, 1)\n",
        "  # fig = plt.figure()\n",
        "  # ax = fig.add_subplot(111)\n",
        "\n",
        "  ax = temp_maxmcc_df.plot(label=acorpus, linewidth=3)\n",
        "  # ax = corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True, min_periods=1).mean().plot(label='z-Score Median', style=['r'], linewidth=3, alpha=0.9)\n",
        "\n",
        "  ax.grid(True)\n",
        "  ax.set_title(f'Model Rank by MCC: {acorpus}', fontsize=18)\n",
        "  # ax.set(xlabel='Decade', ylabel='Weighted Percent of Top Songs', fontsize=10)\n",
        "  # ax.set_xlabel('Line Number', fontsize=14)\n",
        "  ax.set_ylabel('MCC Score', fontsize=14)\n",
        "  # ax.set_xticks(df.Date.values)\n",
        "  # xticks_ls = temp_maxmcc_df.model_z.to_list()\n",
        "  # ax.set_xticklabels(temp_maxmcc_df.model_z.values, size=8, rotation=90)\n",
        "  ax.set_xticklabels(temp_maxmcc_df.model_z, rotation=90) # , size=8, rotation=90)\n",
        "  # ax.set_xticklabels(xticks_ls, size=6, rotation=90)\n",
        "  ax.legend('off') # loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10, title='Model', title_fontsize=14);\n",
        "\n",
        "  if save_plot:\n",
        "    filename_plt = f'./{subdir_name}/plt_metric_mcc_ranked_{acorpus}.png'\n",
        "    plt.savefig(filename_plt)\n",
        "    print(f'Saved plot to filepath: {filename_plt}\\n\\n')\n",
        "\n",
        "  plt.show();\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUEknMkM5tiq"
      },
      "source": [
        "print(list(corpora_mcc_df.groupby(['corpus'])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP7lnMUNak9r"
      },
      "source": [
        "len(corpora_mcc_dt.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEdFQzb9auag"
      },
      "source": [
        "len(list(corpora_mcc_dt.values())[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTfk7C2ec4Bc"
      },
      "source": [
        "len(list(corpora_mcc_dt.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e80W_c7Sf5yC"
      },
      "source": [
        "# Gather the Error/Area between Model zScore and Median zScore for all Corpora in one DataFrame\n",
        "\n",
        "# corpora_median_area_df = pd.DataFrame()\n",
        "corpora_mcc_df = pd.DataFrame()\n",
        "\n",
        "first_loop_fl = True\n",
        "\n",
        "# for acorpus, area_tup_ls in corpora_median_area_dt.items():\n",
        "for acorpus, model_mccls_tup_ls in corpora_mcc_dt.items():\n",
        "  \n",
        "  print(f'\\nCorpus: {acorpus}\\n') #   {area_tup_ls}')\n",
        "  print(f'\\nlen(model_mccls_tup_ls): {len(model_mccls_tup_ls)}\\n') #   {area_tup_ls}')\n",
        "\n",
        "  # areas_ls = [i[1] for i in area_tup_ls]\n",
        "  mcc_ls = [i[1] for i in model_mccls_tup_ls]\n",
        "  models_ls = [i[0] for i in model_mccls_tup_ls]\n",
        "\n",
        "  # print(f'  areas_ls: {areas_ls}')\n",
        "  print(f'  len(models_ls): {len(models_ls)}')\n",
        "  print(f'  len(mcc_ls): {len(mcc_ls)}')\n",
        "\n",
        "  # temp_df = pd.DataFrame({'model_z' : models_ls,'area_z' : areas_ls})\n",
        "  temp_df = pd.DataFrame({'model_z' : models_ls,'mcc' : mcc_ls})\n",
        "  print(f'    temp_df.shape(): {temp_df.shape}')\n",
        "  temp_len = temp_df.shape[0]\n",
        "  # temp_df['area_z_norm'] = temp_df['area_z']/corpora_all_dt[acorpus].shape[0]\n",
        "  model_col = [acorpus] * temp_len\n",
        "  first_ser = pd.Series(model_col)\n",
        "  temp_df = pd.concat([first_ser, temp_df], axis=1)\n",
        "  temp_df.rename(columns={0:'corpus'}, inplace=True)\n",
        "  print(f'     temp_df.shape() after horizontal concat(): {temp_df.shape}')\n",
        "  \n",
        "  temp_df.head()\n",
        "\n",
        "  if first_loop_fl:\n",
        "    print(f'  Adding {acorpus} as first DataFrame')\n",
        "    # corpora_model_area_df = temp_df.copy(deep=True)\n",
        "    corpora_mcc_df = temp_df.copy(deep=True)\n",
        "    first_loop_fl = False\n",
        "  else:\n",
        "    # temp_copy_df = temp_df.copy(deep=True)\n",
        "    print(f'  Adding {acorpus} as successive DataFrame')\n",
        "    # corpora_model_area_df = pd.concat([corpora_model_area_df, temp_df], axis=0)\n",
        "    corpora_mcc_df = pd.concat([corpora_mcc_df, temp_df], axis=0)\n",
        "\n",
        "  # pd.DataFrame(model_col, columns=['corpus'])], axis=1, join='inner')\n",
        "\n",
        "  # lst = pd.Series([0.25,1.24865,2.541,3.1,4.4582]) # <-converted to series\n",
        "  # pd.concat([pd.Series(lst), df], axis=1)\n",
        "\n",
        "  temp_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx6_pU7EvJS8"
      },
      "source": [
        "# corpora_median_area_df.head()\n",
        "\n",
        "corpora_mcc_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ptiPx0dwsKq"
      },
      "source": [
        "# should be 875\n",
        "\n",
        "corpora_mcc_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-xnVhvbwLQ6"
      },
      "source": [
        "# corpora_model_area_df.tail()\n",
        "corpora_mcc_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9QiJxJFZ4iW"
      },
      "source": [
        "corpora_mcc_df[(corpora_mcc_df['corpus']=='vwoolf_tothelighthouse') & (corpora_mcc_df['model_z']=='xgb_z')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4aTa_1AJdrc"
      },
      "source": [
        "corpora_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqfWZQwETwfb"
      },
      "source": [
        "model_z_cols_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MwjqAGyhpXO"
      },
      "source": [
        "# should be 875\n",
        "\n",
        "corpora_mcc_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwDLdSlBhqgp"
      },
      "source": [
        "# Save MCC for all Models\n",
        "\n",
        "subdir_out = 'data_corpora_all'\n",
        "filename_out = f'models_mcc.csv'\n",
        "\n",
        "fullpath_out = f'./{subdir_out}/{filename_out}'\n",
        "\n",
        "print(f'\\nSaving MCC in file: {fullpath_out}')\n",
        "corpora_mcc_df.to_csv(fullpath_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_pz2pM7jhYJ"
      },
      "source": [
        "## **MCC Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB-QYJQvkWFf"
      },
      "source": [
        "corpora_mcc_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_BwQk3vkf3a"
      },
      "source": [
        "# corpora_ls = list(corpora_mcc_df.corpus.unique())\n",
        "corpora_ls\n",
        "print('\\n')\n",
        "len(corpora_ls)\n",
        "print('\\n')\n",
        "type(corpora_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiICyCXNlFqv"
      },
      "source": [
        "type(corpora_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S57Y3E03nNnD"
      },
      "source": [
        "corpora_mcc_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QELMkR8-mS9a"
      },
      "source": [
        "temp_df = pd.DataFrame(corpora_mcc_df.groupby('model_z'))\n",
        "temp_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny7KdidOn0RA"
      },
      "source": [
        "# Standardize (MinMax) MCC Metrics\n",
        "\n",
        "corpora_mcc_minmax_df = corpora_mcc_df.pivot_table(index='corpus', columns='model_z', values='mcc').T\n",
        "\n",
        "# Replacing infinite with nan\n",
        "corpora_mcc_minmax_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "  \n",
        "# Dropping all the rows with nan values\n",
        "corpora_mcc_minmax_df.dropna(inplace=True)\n",
        "\n",
        "corpora_mcc_minmax_df\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8V0nxHvrKcr"
      },
      "source": [
        "model_ls = list(corpora_mcc_minmax_df.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCkXJBusmvac"
      },
      "source": [
        "# corpora_mcc_minmax_df.groupby('model_z').min()\n",
        "\n",
        "# from scipy.stats import zscore\n",
        "# corpora_mcc_std_df.apply(zscore)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "numeric_cols = corpora_mcc_minmax_df.select_dtypes(include=[np.number]).columns\n",
        "# model_col = list(corpora_mcc_minmax_df.index)\n",
        "\n",
        "corpora_mcc_minmax_df = pd.DataFrame(scaler.fit_transform(corpora_mcc_minmax_df), columns=numeric_cols)\n",
        "corpora_mcc_minmax_df.index = pd.Series(model_ls)\n",
        "corpora_mcc_minmax_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rcyGgVCsUS8"
      },
      "source": [
        "corpora_mcc_rank_dt = {}\n",
        "\n",
        "for acorpus in corpora_ls:\n",
        "  corpora_mcc_rank_dt[acorpus] = corpora_mcc_minmax_df[acorpus].rank(ascending=False)\n",
        "\n",
        "corpora_mcc_rank_dt.keys()\n",
        "\n",
        "corpora_mcc_rank_df = pd.DataFrame(corpora_mcc_rank_dt)\n",
        "corpora_mcc_rank_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bm85PzstuFi"
      },
      "source": [
        "corpora_mcc_rank_df['cdickens_achristmascarol'].sort_values()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mqIPtI7ujjz"
      },
      "source": [
        "corpora_mcc_rank_df.T.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hscaax8C0JBj"
      },
      "source": [
        "# https://lost-stats.github.io/Presentation/Figures/line_graph_with_labels_at_the_beginning_or_end.html \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "plt.rcParams['figure.figsize'] = 20,10\n",
        "\n",
        "# Read in the data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/LOST-STATS/LOST-STATS.github.io/master/Presentation/Figures/Data/Line_Graph_with_Labels_at_the_Beginning_or_End_of_Lines/Research_Nobel_Google_Trends.csv', parse_dates=['date'])\n",
        "# df = corpora_mcc_rank_df.T\n",
        "\n",
        "# Create the column we wish to plot\n",
        "title = 'Log of Google Trends Index'\n",
        "df[title] = np.log(df['hits'])\n",
        "\n",
        "# Set a style for the plot\n",
        "plt.style.use('ggplot')\n",
        "plt.style.use('default')\n",
        "\n",
        "# Make a plot\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Add lines to it\n",
        "sns.lineplot(ax=ax, data=df, x=\"corpus\", y=title, hue=\"name\", legend=None)\n",
        "\n",
        "# Add the text--for each line, find the end, annotate it with a label, and\n",
        "# adjust the chart axes so that everything fits on.\n",
        "for line, name in zip(ax.lines, df.columns.tolist()):\n",
        "\ty = line.get_ydata()[-1]\n",
        "\tx = line.get_xdata()[-1]\n",
        "\tif not np.isfinite(y):\n",
        "\t    y=next(reversed(line.get_ydata()[~line.get_ydata().mask]),float(\"nan\"))\n",
        "\tif not np.isfinite(y) or not np.isfinite(x):\n",
        "\t    continue     \n",
        "\ttext = ax.annotate(name,\n",
        "\t\t       xy=(x, y),\n",
        "\t\t       xytext=(0, 0),\n",
        "\t\t       color=line.get_color(),\n",
        "\t\t       xycoords=(ax.get_xaxis_transform(),\n",
        "\t\t\t\t ax.get_yaxis_transform()),\n",
        "\t\t       textcoords=\"offset points\")\n",
        "\ttext_width = (text.get_window_extent(\n",
        "\tfig.canvas.get_renderer()).transformed(ax.transData.inverted()).width)\n",
        "\tif np.isfinite(text_width):\n",
        "\t\tax.set_xlim(ax.get_xlim()[0], text.xy[0] + text_width * 1.05)\n",
        "\n",
        "# Format the date axis to be prettier.\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%d'))\n",
        "ax.xaxis.set_minor_locator(mdates.DayLocator())\n",
        "ax.xaxis.set_major_locator(mdates.AutoDateLocator(interval_multiples=False))\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeYeWl0ZuJ73"
      },
      "source": [
        "plt.style.use('default')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLqTzbiMGuXz"
      },
      "source": [
        "corpora_mcc_rank_df.T.head()\n",
        "temp_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfbS-yvOJWdd"
      },
      "source": [
        "temp_df['corpus'] = temp_df.index\n",
        "temp_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klmcaEuWHDWF"
      },
      "source": [
        "temp_df = corpora_mcc_rank_df.T\n",
        "temp_cols = temp_df.columns\n",
        "# Make a plot\n",
        "fig, ax = plt.subplots()\n",
        "sns.lineplot(ax=ax, data=temp_df, x=temp_df.index, y=temp_df.flair_z ,palette='Accent', linewidth=1, alpha=0.9)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76lcg03-JtH3"
      },
      "source": [
        "temp_models_ls = temp_df.columns.to_list()\n",
        "temp_models_ls = [x for x in temp_models_ls if x.endswith('_z')]\n",
        "temp_models_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN9odX7cKH8L"
      },
      "source": [
        "temp_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYXOLcoCvB4J"
      },
      "source": [
        "temp_df['corpus'] = temp_df.index\n",
        "temp_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkY1WMWbI72j"
      },
      "source": [
        "# pd.melt(df, id_vars='date', value_vars=['AA', 'BB', 'CC'])\n",
        "\n",
        "temp_models_ls = temp_df.columns.to_list()\n",
        "\n",
        "temp_tall_df = pd.melt(temp_df, id_vars='model', value_vars=temp_models_ls)\n",
        "temp_tall_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOxsi30WLImT"
      },
      "source": [
        "temp_df.melt(id_vars='corpus')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P_5w7bJFqlO"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# Read in the data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/LOST-STATS/LOST-STATS.github.io/master/Presentation/Figures/Data/Line_Graph_with_Labels_at_the_Beginning_or_End_of_Lines/Research_Nobel_Google_Trends.csv',\n",
        "                 parse_dates=['date'])\n",
        "\n",
        "# Create the column we wish to plot\n",
        "title = 'Log of Google Trends Index'\n",
        "df[title] = np.log(df['hits'])\n",
        "\n",
        "df = temp_df.melt(id_vars='corpus')\n",
        "\n",
        "# Set a style for the plot\n",
        "# plt.style.use('ggplot')\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = 10,8\n",
        "# plt.grid(True)\n",
        "\n",
        "# Make a plot\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Add lines to it\n",
        "# sns.lineplot(ax=ax, data=df, x=\"date\", y=title, hue=\"name\", legend=None)\n",
        "# sns.lineplot(ax=ax, data=df, x=\"date\", y=title, hue=\"name\", legend=None)\n",
        "sns.lineplot(ax=ax, data=df, x='value', y='variable', hue='corpus', legend=None) # palette='Accent', linewidth=1, alpha=0.9)\n",
        "\n",
        "# Add the text--for each line, find the end, annotate it with a label, and\n",
        "# adjust the chart axes so that everything fits on.\n",
        "# for line, name in zip(ax.lines, df.columns.tolist()):\n",
        "for line, name in zip(ax.lines, df.columns.tolist()):\n",
        "\ty = line.get_ydata()[-1]\n",
        "\tx = line.get_xdata()[-1]\n",
        "\tif not np.isfinite(y):\n",
        "\t    y=next(reversed(line.get_ydata()[~line.get_ydata().mask]),float(\"nan\"))\n",
        "\tif not np.isfinite(y) or not np.isfinite(x):\n",
        "\t    continue     \n",
        "\ttext = ax.annotate(name,\n",
        "\t\t       xy=(x, y),\n",
        "\t\t       xytext=(0, 0),\n",
        "\t\t       color=line.get_color(),\n",
        "\t\t       xycoords=(ax.get_xaxis_transform(),\n",
        "\t\t\t\t ax.get_yaxis_transform()),\n",
        "\t\t       textcoords=\"offset points\")\n",
        "\ttext_width = (text.get_window_extent(\n",
        "\tfig.canvas.get_renderer()).transformed(ax.transData.inverted()).width)\n",
        "\tif np.isfinite(text_width):\n",
        "\t\tax.set_xlim(ax.get_xlim()[0], text.xy[0] + text_width * 1.05)\n",
        "\n",
        "# Format the date axis to be prettier.\n",
        "# ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%d'))\n",
        "# ax.xaxis.set_minor_locator(mdates.DayLocator())\n",
        "# ax.xaxis.set_major_locator(mdates.AutoDateLocator(interval_multiples=False))\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaiJfStVEPnf"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "seaborn palettes:\n",
        "\n",
        "'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', \n",
        "'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', \n",
        "'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', \n",
        "'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', \n",
        "'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', \n",
        "'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', \n",
        "'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', \n",
        "'coolwarm_r', 'copper', 'copper_r', 'crest', 'crest_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'flare', 'flare_r', 'gist_earth', \n",
        "'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', \n",
        "'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', \n",
        "'hot_r', 'hsv', 'hsv_r', 'icefire', 'icefire_r', 'inferno', 'inferno_r', 'jet', 'jet_r'\n",
        "\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C3Mib2AvXVg"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = 12,14\n",
        "\n",
        "save_plot = True\n",
        "\n",
        "subdir_name = 'data_corpora_plots'\n",
        "\n",
        "# plt.figure(facecolor='white')\n",
        "\n",
        "ax = sns.lineplot(data=corpora_mcc_rank_df.T, palette='Accent', linewidth=3) # , alpha=0.5)\n",
        "ax.grid(True, alpha=0.3) # True, alpha=0.3)\n",
        "ax.set_title('Model MCC Rank Across Corpora', fontsize=20)\n",
        "# ax.set(xlabel='Decade', ylabel='Weighted Percent of Top Songs', fontsize=10)\n",
        "# ax.set_xlabel('Decade', fontsize=20)\n",
        "ax.set_ylabel('MCC Rank', fontsize=15)\n",
        "ax.set_xticklabels(corpora_mcc_rank_df.columns, size=12, rotation=90)\n",
        "# ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
        "leg = ax.legend(fontsize=10, title='Model', title_fontsize='14', bbox_to_anchor=(1.05, 1), loc='top')\n",
        "for line in leg.get_lines():\n",
        "  line.set_linewidth(3.0);\n",
        "\n",
        "if save_plot:\n",
        "  filename_plt = f'./{subdir_name}/plt_metric_mcc_line_rank.png'\n",
        "  plt.savefig(filename_plt)\n",
        "  print(f'Saved plot to filepath: {filename_plt}\\n\\n')\n",
        "\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbAE9gCkwrSb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AXhWg_pL-XV"
      },
      "source": [
        "plt.style.use('default')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDwbe8GuLtDX"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = 12,8\n",
        "\n",
        "ax = corpora_mcc_rank_df.T.plot()\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_title('Model MCC Rank Across Corpora (Starting at Bottom)', fontsize=20)\n",
        "# ax.set(xlabel='Decade', ylabel='Weighted Percent of Top Songs', fontsize=10)\n",
        "# ax.set_xlabel('Decade', fontsize=20)\n",
        "ax.set_ylabel('Rank', fontsize=15)\n",
        "ax.set_xticklabels(corpora_mcc_rank_df.columns, size=10, rotation=90)\n",
        "# ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
        "ax.legend(fontsize=10, title='Model', title_fontsize='14', bbox_to_anchor=(1.05, 1), loc='upper left');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsS00If7ujbI"
      },
      "source": [
        "ax = corpora_mcc_rank_df.T.plot()\n",
        "ax.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARPg-A7d037x"
      },
      "source": [
        "corpora_mcc_rank_df.T.describe().loc['mean']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns6Xozls4WH_"
      },
      "source": [
        "corpora_mcc_rank_df.T.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oflTLaWUwfp"
      },
      "source": [
        "describe_num_df = corpora_mcc_rank_df.T.describe(include=['int64','float64'])\n",
        "describe_num_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsQUhgcSVfZg"
      },
      "source": [
        "describe_num_df.rename(columns={'index':'stat'}, inplace=True)\n",
        "describe_num_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRuOI1uIVylX"
      },
      "source": [
        "# describe_num_df = describe_num_df.set_index('stat')\n",
        "# describe_num_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ_tV3XhV_XX"
      },
      "source": [
        "describe_num_T_df = describe_num_df.T\n",
        "describe_num_T_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUHqmSMmbFkA"
      },
      "source": [
        "describe_num_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM4Jb1ynv3_-"
      },
      "source": [
        "# Boxplot of Model MCC Statistics\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "\n",
        "save_plot = True\n",
        "subdir_name = 'data_corpora_plots'\n",
        "\n",
        "describe_num_sorted_df = describe_num_df.T.sort_values(['mean'])\n",
        "# describe_num_sorted_df.T.boxplot()\n",
        "# plt.xticks(rotation=90)\n",
        "\n",
        "ax = describe_num_sorted_df.T.boxplot()\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_title('Sorted Model MCC Statistics', fontsize=20)\n",
        "# ax.set(xlabel='Decade', ylabel='Weighted Percent of Top Songs', fontsize=10)\n",
        "# ax.set_xlabel('Decade', fontsize=20)\n",
        "ax.set_ylabel('MCC Metric', fontsize=15)\n",
        "ax.set_xticklabels(describe_num_sorted_df.T.columns, size=10, rotation=90)\n",
        "# ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
        "# ax.legend(fontsize=10, title='Model', title_fontsize='14', bbox_to_anchor=(1.05, 1), loc='upper left');\n",
        "\n",
        "if save_plot:\n",
        "  filename_plt = f'./{subdir_name}/plt_metric_mcc_box_stats.png'\n",
        "  plt.savefig(filename_plt)\n",
        "  print(f'Saved plot to filepath: {filename_plt}\\n\\n')\n",
        "\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T74Tut2BWfRH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqc5zyWnWfLe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SJG_Zk-aZWF"
      },
      "source": [
        "\n",
        "save_plot = False\n",
        "\n",
        "\n",
        "describe_num_sorted_df = describe_num_df.T.sort_values(['mean'])\n",
        "# describe_num_sorted_df.T.boxplot()\n",
        "# plt.xticks(rotation=90)\n",
        "\n",
        "ax = describe_num_sorted_df.T.boxplot()\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "ax = corpora_mcc_rank_df.T.plot()\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_title('Model MCC Rank Across Corpora (Starting at Bottom)', fontsize=20)\n",
        "# ax.set(xlabel='Decade', ylabel='Weighted Percent of Top Songs', fontsize=10)\n",
        "# ax.set_xlabel('Decade', fontsize=20)\n",
        "ax.set_ylabel('Rank', fontsize=15)\n",
        "ax.set_xticklabels(corpora_mcc_rank_df.columns, size=10, rotation=90)\n",
        "# ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
        "ax.legend(fontsize=10, title='Model', title_fontsize='14', bbox_to_anchor=(1.05, 1), loc='upper left');\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5AKBWQrWkxH"
      },
      "source": [
        "describe_num_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZAokrFGY-9E"
      },
      "source": [
        "corpora_mcc_rank_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfBLYeYsUdWK"
      },
      "source": [
        "describe_num_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPP91gm3UEER"
      },
      "source": [
        "describe_num_T_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLG3OlQpVB04"
      },
      "source": [
        "describe_num_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZViTtejIUsmq"
      },
      "source": [
        "describe_num_df.T.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9a2qDQVVUmi"
      },
      "source": [
        "describe_num_df = describe_num_df.sort_values('mean')\n",
        "describe_num_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UlvA3nDVch7"
      },
      "source": [
        "describe_num_T_df = describe_num_df.describe(include=['int64','float64'])\n",
        "describe_num_T_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hJEZMIgX-nY"
      },
      "source": [
        "describe_num_df = describe_num_df.sort_values('mean')\n",
        "\n",
        "describe_num_T_df = describe_num_df.describe(include=['int64','float64'])\n",
        "describe_num_T_df.head(2)\n",
        "\n",
        "# describe_num_df = describe_num_df.sort_values(['mean','std'])\n",
        "# describe_num_T_df.sort_values('mean')\n",
        "describe_num_T_df.T.boxplot()\n",
        "plt.xticks(rotation=90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JHYmR-RUBLT"
      },
      "source": [
        "# https://medium.com/analytics-vidhya/how-to-visualize-pandas-descriptive-statistics-functions-480c3f2ea87c\n",
        "\n",
        "describe_num_df = corpora_mcc_rank_df.T.describe(include=['int64','float64'])\n",
        "\n",
        "# describe_num_df.reset_index(inplace=True)\n",
        "\n",
        "# Make a plot\n",
        "# fig, ax = plt.subplots(5,5)\n",
        "# fig, axes = plt.subplots(5,5, figsize=(15,10))\n",
        "\n",
        "# Add lines to it\n",
        "# sns.lineplot(ax=ax, data=df, x=\"corpus\", y=title, hue=\"name\", legend=None)\n",
        "\n",
        "\n",
        "sns.boxplot(describe_num_df)\n",
        "\n",
        "\"\"\"\n",
        "# To remove any variable from plot\n",
        "# describe_num_df = describe_num_df[describe_num_df['index'] != 'count']\n",
        "num_col = describe_num_df.columns\n",
        "for i,acol in enumerate(num_col):\n",
        "  if acol in ['index','count']:\n",
        "    continue  \n",
        "  ax_row = i // 5\n",
        "  ax_col = i % 5\n",
        "  axes[ax_row, ax_col] = sns.factorplot(x='index', y=acol, data=describe_num_df.reset_index())  \n",
        "  plt.ylabel('Numeric Value')\n",
        "  plt.xlabel('Statistic')\n",
        "  plt.title(f'MCC Descriptive Statistics\\n{acol}')\n",
        "  # sns.regplot(data = df_comments.reset_index(), x = 'index', y = 'score')\n",
        "  plt.show();\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxFMBgYZ3Ag9"
      },
      "source": [
        "# https://medium.com/analytics-vidhya/how-to-visualize-pandas-descriptive-statistics-functions-480c3f2ea87c\n",
        "\n",
        "describe_num_df = corpora_mcc_rank_df.T.describe(include=['int64','float64'])\n",
        "\n",
        "# describe_num_df.reset_index(inplace=True)\n",
        "\n",
        "# Make a plot\n",
        "# fig, ax = plt.subplots(5,5)\n",
        "fig, axes = plt.subplots(5,5, figsize=(15,10))\n",
        "\n",
        "# Add lines to it\n",
        "# sns.lineplot(ax=ax, data=df, x=\"corpus\", y=title, hue=\"name\", legend=None)\n",
        "\n",
        "\n",
        "\n",
        "# To remove any variable from plot\n",
        "# describe_num_df = describe_num_df[describe_num_df['index'] != 'count']\n",
        "num_col = describe_num_df.columns\n",
        "for i,acol in enumerate(num_col):\n",
        "  if acol in ['index','count']:\n",
        "    continue  \n",
        "  ax_row = i // 5\n",
        "  ax_col = i % 5\n",
        "  axes[ax_row, ax_col] = sns.factorplot(x='index', y=acol, data=describe_num_df.reset_index())  \n",
        "  plt.ylabel('Numeric Value')\n",
        "  plt.xlabel('Statistic')\n",
        "  plt.title(f'MCC Descriptive Statistics\\n{acol}')\n",
        "  # sns.regplot(data = df_comments.reset_index(), x = 'index', y = 'score')\n",
        "  plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeRTSTZn2BnM"
      },
      "source": [
        "corrmat = corpora_mcc_rank_df.T.corr()\n",
        "# print(corrmat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxjqcX4AYlAk"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (20,20)\n",
        "\n",
        "ax = sns.heatmap(corrmat, vmax=1, annot=True, linewidths=.5)\n",
        "\n",
        "# ax.grid(True, alpha=0.3)\n",
        "ax.set_title('Model MCC Correlation Matrix', fontsize=20)\n",
        "# ax.set(xlabel='Decade', ylabel='Weighted Percent of Top Songs', fontsize=10)\n",
        "# ax.set_xlabel('Decade', fontsize=20)\n",
        "# ax.set_ylabel('Rank', fontsize=15)\n",
        "# ax.set_xticklabels(corpora_mcc_rank_df.columns, size=10, rotation=40)\n",
        "# ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
        "# ax.legend(fontsize=10, title='Model', title_fontsize='14', bbox_to_anchor=(1.05, 1), loc='upper left');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLyEkPK51mp8"
      },
      "source": [
        "plt.figure(figsize=(30, 30))\n",
        "\n",
        "sns.heatmap(corrmat, vmax=1, annot=True, linewidths=.5)\n",
        "plt.xticks(rotation=30) # , horizontalalignment=right)\n",
        "plt.title()\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "710rxl5FkYw9"
      },
      "source": [
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for acorpus in corpora_ls:\n",
        "  temp_df = corpora_mcc_df.groupby('model_z')\n",
        "  temp_df = temp_df[temp_df['model_z'] == ]\n",
        "  print(f'{acorpus}: \\n\\ntemp_df: {temp_df.head()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyyis-VCjo7S"
      },
      "source": [
        "corpora_mcc_df.groupby('model_z').mean().sort_values('mcc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmSMkGcFjovx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhnimzsJwkw7"
      },
      "source": [
        "## **MCC Ranking of Models for each Corpus**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48vjZnvSfWjw"
      },
      "source": [
        "corpora_mcc_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhuKX1oervGw"
      },
      "source": [
        "# Plot Rank of Model Area from Median per Corpus\n",
        "\n",
        "save_plot = True\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
        "\n",
        "subdir_name = 'data_corpora_plots'\n",
        "\n",
        "models_all_order_dt = {}\n",
        "for acorpus in corpora_ls:\n",
        "  if acorpus != 'median_z':\n",
        "    models_all_order_dt[acorpus] = []\n",
        "  # for amodel_z in model_z_cols_ls:\n",
        "  #   models_all_order_dt[acorpus][amodel_z] = []\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(f'Plotting Model-Median Area for Corpus #{i}: {acorpus}')\n",
        "  # temp_df = corpora_model_area_df[corpora_model_area_df.corpus == acorpus]\n",
        "  temp_df = corpora_mcc_df[corpora_mcc_df.corpus == acorpus]\n",
        "\n",
        "  # Drop the 'median_z' row\n",
        "  temp_df = temp_df[temp_df.model_z != 'median_z']\n",
        "\n",
        "  # Sort in place \n",
        "  temp_df.sort_values(by=['mcc'], inplace=True, ascending=False)\n",
        "  # temp_df.head(2) # area_z.plot(kind='bar')\n",
        "  # temp_df.area_z.plot(kind='bar' x=model_z, y=area_z)\n",
        "\n",
        "  # Store order for each Model\n",
        "  models_order_ls = temp_df.model_z.to_list()\n",
        "  # for j, amodel_ord in enumerate(models_order_ls):\n",
        "  #   models_all_order_dt[acorpus][amodel_ord].append(str(j)) \n",
        "  # models_order_ls.reverse()  # Reverses in-place\n",
        "  models_order_ls.sort()\n",
        "  models_all_order_dt[acorpus] = models_order_ls\n",
        "\n",
        "  #ax = temp_df.plot.bar(x='model_z', y='area_z', rot=90)\n",
        "\n",
        "  plt.barh('model_z', 'mcc', data=temp_df)\n",
        "  # plt.xticks(fontsize=20) # , rotation=0)\n",
        "  # plt.yticks(fontsize=20) # , rotation=0)\n",
        "  plt.rcParams.update({'font.size': 8})\n",
        "  plt.title(f'{corpora_full_dt[acorpus]}\\n Model-Corpus Compatibility (MCC) Metric', pad=20, fontdict={'fontsize':10})\n",
        "\n",
        "  if save_plot:\n",
        "    subdir_name = 'data_corpora_plots'\n",
        "    filename_plt = f'./{subdir_name}/plt_mcc_rank_{acorpus}.png'\n",
        "    plt.savefig(filename_plt)\n",
        "\n",
        "  plt.show()\n",
        "  plt.close();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct6MDByLUmO4"
      },
      "source": [
        "print(models_all_order_dt['cdickens_achristmascarol'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U4ywQ9Iwroc"
      },
      "source": [
        "## **Plot Rank and Spread by Model over the Corpora**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWFSxYrrXbgE"
      },
      "source": [
        "# Create a Dict (Models) of Lists (Ranks)\n",
        "\n",
        "models_all_rank_dt = {}\n",
        "\n",
        "models_z_rank_ls = models_all_order_dt['cdickens_achristmascarol']\n",
        "for amodel_z in models_z_rank_ls:\n",
        "  models_all_rank_dt[amodel_z] = []\n",
        "\n",
        "for key, values in models_all_order_dt.items():\n",
        "  print(f'Corpus: {key}')\n",
        "  for i, amodel in enumerate(values):\n",
        "    print(f' Model #{i}: {amodel}')\n",
        "    models_all_rank_dt[amodel].append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTGW9o9SYmBN"
      },
      "source": [
        "# models_all_rank_dt.keys()\n",
        "\n",
        "models_z_rank_ls = models_all_order_dt['cdickens_achristmascarol']\n",
        "models_mean_ls = []\n",
        "models_std_ls = []\n",
        "models_max_ls = []\n",
        "models_min_ls = []\n",
        "models_ranks_ls_ls = []\n",
        "\n",
        "for i, amodel_z in enumerate(models_z_rank_ls):\n",
        "  print(f'For Model: {amodel_z}:')\n",
        "  model_mean = np.mean(models_all_rank_dt[amodel_z])\n",
        "  print(f'  Mean: {model_mean}')\n",
        "  models_mean_ls.append(model_mean)\n",
        "\n",
        "  model_std = np.std(models_all_rank_dt[amodel_z])\n",
        "  print(f'  STD: {model_std}')\n",
        "  models_std_ls.append(model_std)\n",
        "\n",
        "  model_min = np.min(models_all_rank_dt[amodel_z])\n",
        "  print(f'  Min: {model_min}')\n",
        "  models_min_ls.append(model_min)\n",
        "\n",
        "  model_max = np.max(models_all_rank_dt[amodel_z])\n",
        "  print(f'  Max: {model_max}')\n",
        "  models_max_ls.append(model_max)\n",
        "\n",
        "  model_ranks_ls = models_all_rank_dt[amodel_z]\n",
        "  print(f' Ranks: {model_ranks_ls}')\n",
        "  models_ranks_ls_ls.append(model_ranks_ls)\n",
        "\n",
        "\n",
        "models_rank_dt = {'model_z': models_z_rank_ls,\n",
        "                  'mean':models_mean_ls,\n",
        "                  'std':models_std_ls,\n",
        "                  'min':models_min_ls,\n",
        "                  'max':models_max_ls,\n",
        "                  'ranks':models_ranks_ls_ls}\n",
        "\n",
        "models_rank_df = pd.DataFrame.from_dict(models_rank_dt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgxCt6Jud1lv"
      },
      "source": [
        "models_rank_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjISpq2GlD7c"
      },
      "source": [
        "models_labels_ls = ['-'.join(i.split('_')[:-1]) for i in models_rank_df.model_z.to_list()]\n",
        "models_labels_ls\n",
        "len(models_labels_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVZ_nDWumFxv"
      },
      "source": [
        "len(models_labels_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVezKhsPiEym"
      },
      "source": [
        "# models_labels_ls = models_rank_df.model_z.to_list()\n",
        "# models_labels_ls = ['-'.join(i.split('_')[:-1]) for i in models_labels_ls]\n",
        "# models_labels_ls = [w.replace('_', '-') for w in models_labels_ls]\n",
        "# models_labels_ls = [i.split('_')[:-1] for i in models_rank_df.model_z.to_list()]\n",
        "\n",
        "# models_box_ready_df = pd.DataFrame(np.array(models_rank_df.ranks.to_list()).T, columns=models_labels_ls)\n",
        "models_box_ready_df = pd.DataFrame(np.array(models_rank_df.ranks.to_list()).T, columns=models_labels_ls)\n",
        "models_box_ready_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irsjV5afiEq7"
      },
      "source": [
        "# Plot Rank and Spread of Models across all 25 Corpora\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
        "\n",
        "save_plot = True\n",
        "subdir_name = 'data_corpora_plots'\n",
        "\n",
        "ax = models_box_ready_df.plot(kind='box')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax.set_ylabel('Rank', fontsize=12)\n",
        "ax.set_xticklabels(corpora_mcc_rank_df.columns, size=10, rotation=40)\n",
        "# ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
        "\n",
        "# ax.invert_yaxis()\n",
        "\n",
        "plt.xticks(fontsize=20, rotation=90)\n",
        "# plt.yticks(fontsize=20) # , rotation=0)\n",
        "# plt.rcParams.update({'font.size': 20})\n",
        "# plt.title(f'{corpora_full_dt[acorpus]}\\n Error Area between zScore Models and Median', pad=20, fontdict={'fontsize':24})\n",
        "plt.grid(alpha=0.3)\n",
        "plt.title('Rank and Spread of Models across all 25 Corpora')\n",
        "\n",
        "ax = corpora_mcc_rank_df.T.plot()\n",
        "\n",
        "ax.set_title('Model MCC Rank Across Corpora (Starting at Bottom)', fontsize=20)\n",
        "# ax.set(xlabel='Decade', ylabel='Weighted Percent of Top Songs', fontsize=10)\n",
        "# ax.set_xlabel('Decade', fontsize=20)\n",
        "ax.set_ylabel('Rank', fontsize=15)\n",
        "ax.set_xticklabels(corpora_mcc_rank_df.columns, size=10, rotation=40)\n",
        "# ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
        "ax.legend(fontsize=10, title='Model', title_fontsize='14', bbox_to_anchor=(1.05, 1), loc='upper left');\n",
        "\n",
        "\n",
        "if save_plot:\n",
        "  filename_plt = f'./{subdir_name}/plt_models_all_rank_spread.png'\n",
        "  plt.savefig(filename_plt)\n",
        "\n",
        "plt.show()\n",
        "plt.close();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFjeXSt2ho6d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVWavYihaJSJ"
      },
      "source": [
        "\n",
        "models_z_rank_ls = models_all_order_dt['cdickens_achristmascarol']\n",
        "\n",
        "for amodel_z in models_z_rank_ls:\n",
        "  models_all_rank_dt[amodel_z] = []\n",
        "\n",
        "for key, values in models_all_order_dt.items():\n",
        "  print(f'Corpus: {key}')\n",
        "  for i, amodel in enumerate(values):\n",
        "    print(f' Model #{i}: {amodel}')\n",
        "    # models_all_rank_dt[amodel].append(i)\n",
        "\n",
        "  models_all_rank_dt['logreg_cv_z']\n",
        "  print('\\n')\n",
        "\n",
        "  model_median = np.median(models_all_rank_dt['logreg_cv_z'])\n",
        "  print(f'  Model Median: {model_median}')\n",
        "\n",
        "  model_std = np.std(models_all_rank_dt['logreg_cv_z'])\n",
        "  print(f'  Model STD: {model_std}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn-XJ-XkaJOi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfm-9gljaJI7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS9ExZhsEKTI"
      },
      "source": [
        "# Create DataFrame from Dictionaries\n",
        "\n",
        "corpora_median_area_dt = {}\n",
        "temp_df = pd.DataFrame()\n",
        "first_loop_fl = True\n",
        "\n",
        "for acorpus, area_tup_ls in corpora_median_area_dt.items():\n",
        "  \n",
        "  print(f'\\nCorpus: {acorpus}\\n   {area_tup_ls}')\n",
        "\n",
        "  areas_ls = [i[1] for i in area_tup_ls]\n",
        "  model_ls = [i[0] for i in area_tup_ls]\n",
        "  temp_df = pd.DataFrame(areas_ls, columns=['area_z'] )\n",
        "  print(f'temp_df.head():\\n{temp_df.head()}')\n",
        "  if first_loop_fl:\n",
        "    corpora_median_area_dt[acorpus] = temp_df.copy(deep=True)\n",
        "    first_loop_fl = False\n",
        "  else:\n",
        "    corpora_median_area_dt = pd.merge(corpora_median_area_dt, temp_df, how='inner', on = 'model_z')\n",
        "\n",
        "# corpora_median_area_df = pd.DataFrame(corpora_median_area_dt, columns=['model_z', 'area_z'])\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "for acorpus, area_tup_ls in corpora_median_area_dt.items():\n",
        "  \n",
        "  print(f'Corpus: {acorpus}\\n   {area_tup_ls}')\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(f'Processing Corpus #{i}: {acorpus}')\n",
        "\n",
        "  median_model_area_ls = []\n",
        "\n",
        "  for j, amodel_z in enumerate(model_z_cols_ls):\n",
        "    print(f'  with Model #{j}: {amodel_z}')\n",
        "\n",
        "    median_model_area = np.sum(np.abs(corpora_all_dt[acorpus][amodel_z] - corpora_all_dt[acorpus]['median_z']))\n",
        "    print(f'    Area between Median: {median_model_area}')\n",
        "\n",
        "    median_model_area_ls.append((amodel_z, median_model_area))\n",
        "\n",
        "\n",
        "corpora_median_area_dt['cdickens_achristmascarol'].plot(kind=bar)\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5XsT-ogeIr9"
      },
      "source": [
        "corpora_median_area_dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pVZYLfaJy06"
      },
      "source": [
        "corpora_median_area_dt.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_uAmi1kJs33"
      },
      "source": [
        "corpora_median_area_dt['cdickens_achristmascarol']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN_ajoJ4G1pW"
      },
      "source": [
        "corpora_median_area_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p6Oa6rvAPRw"
      },
      "source": [
        "print(corpora_median_area_dt['cdickens_achristmascarol'][0][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZrRbAanC09h"
      },
      "source": [
        "print(corpora_median_area_dt['cdickens_achristmascarol'].sort(key=lambda x:x[0][1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZaUNdEZ-TZb"
      },
      "source": [
        "print(corpora_median_area_dt['cdickens_achristmascarol']) #.sort(key=lambda y: y[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yb3qxjN8vra"
      },
      "source": [
        "mx = max(corpora_median_area_dt['cdickens_achristmascarol'], key=lambda e: int(e[1]))\n",
        "print(mx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shMPbC_L8vjC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5APUrlWa7Vbz"
      },
      "source": [
        "# **Ensemble-Corpus Compatibility (ECC)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcbHQ4IQ7VRB"
      },
      "source": [
        "corpora_mcc_minmax_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlQJi9yd7VLm"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (6, 6)\n",
        "\n",
        "subdir_name = 'data_corpora_plots'\n",
        "\n",
        "corpora_mcc_minmax_df.sum().sort_values().plot(kind='bar')\n",
        "plt.title(f'Ensemble-Corpus Compatility (ECC) Metric by Novel')\n",
        "\n",
        "plt.ylabel('ECC Value')\n",
        "# plt.xticks(fontsize=20) # , rotation=0)\n",
        "# plt.yticks(fontsize=20) # , rotation=0)\n",
        "plt.rcParams.update({'font.size': 8})\n",
        "plt.title(f'{corpora_full_dt[acorpus]}\\n Model-Corpus Compatibility (MCC) Metric', pad=20, fontdict={'fontsize':10})\n",
        "\n",
        "if save_plot:\n",
        "\n",
        "  filename_plt = f'./{subdir_name}/plt_ecc_corpora.png'\n",
        "  plt.savefig(filename_plt)\n",
        "\n",
        "plt.show()\n",
        "plt.close();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf3q1tiT82wH"
      },
      "source": [
        "# **Model Family Coherence (MFC)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEyLT2pL8B62"
      },
      "source": [
        "corpora_mcc_minmax_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua6naKuz9G1O"
      },
      "source": [
        "corpora_mcc_minmax_df.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2bxVRW39M-Q"
      },
      "source": [
        "model_family_map_dt = {'afinn_z':'lexicon',\n",
        "                   'autogluon_z':'dnn', \n",
        "                   'bing_z':'lexicon', \n",
        "                   'cnn_z':'dnn', \n",
        "                   'fcn_z':'dnn', \n",
        "                   'flair_z':'dnn',\n",
        "                   'flaml_z':'dnn', \n",
        "                   'hinglish_z':'transformer', \n",
        "                   'huggingface_z':'transformer', \n",
        "                   'huliu_z':'lexicon', \n",
        "                   'imdb2way_z':'transformer',\n",
        "                   'jockers_rinker_z':'heuristic', \n",
        "                   'jockers_z':'lexicon', \n",
        "                   'lmcd_z':'heuristic', \n",
        "                   'logreg_cv_z':'ml', \n",
        "                   'logreg_z':'ml',\n",
        "                   'lstm_z':'heuristic', \n",
        "                   'multinb_z':'ml', \n",
        "                   'nlptown_z':'transformer', \n",
        "                   'nrc_z':'heuristic', \n",
        "                   'rf_z':'ml', \n",
        "                   'roberta15lg_z':'transformer',\n",
        "                   'robertaxml8lang_z':'transformer', \n",
        "                   'senticnet_z':'heuristic', \n",
        "                   'sentimentr_z':'lexicon', \n",
        "                   'sentiword_z':'heuristic',\n",
        "                   'stanza_z':'dnn', \n",
        "                   'syuzhet_z':'lexicon', \n",
        "                   't5imdb50k_z':'transformer', \n",
        "                   'textblob_z':'ml', \n",
        "                   'vader_z':'heuristic',\n",
        "                   'xgb_z':'ml', \n",
        "                   'yelp_z':'transformer'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lQ1nn3LAunS"
      },
      "source": [
        "# corpora_mfc_df.drop(columns=['model_z'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5KGxu9X-8c9"
      },
      "source": [
        "corpora_mfc_df = pd.DataFrame(corpora_mcc_minmax_df)\n",
        "\n",
        "# corpora_mfc_df.insert(loc=0, column='model_z', value=corpora_mfc_df.index)\n",
        "\n",
        "corpora_mfc_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8RStKfXCmDA"
      },
      "source": [
        "# del corpora_mfc_df\n",
        "corpora_mfc_df['model'] = corpora_mfc_df.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVcrDGITzKtd"
      },
      "source": [
        "corpora_mfc_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF4zZbHZzssj"
      },
      "source": [
        "corpora_mfc_df.iloc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTJjK1MIzPek"
      },
      "source": [
        "\n",
        "for index, arow in corpora_mfc_df.iterrows():\n",
        "  print(arow['model'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM9J7gnZ-8L6"
      },
      "source": [
        "\n",
        "zfamily_ls = []\n",
        "\n",
        "for index, arow in corpora_mfc_df.iterrows():\n",
        "  zmodel = arow['model']\n",
        "  zfamily = model_family_map_dt[zmodel]\n",
        "  print(f'Model: {zmodel} belongs to Family: {zfamily}')\n",
        "  zfamily_ls.append(zfamily)\n",
        "\n",
        "print(f'zfamily_ls: {zfamily_ls}')\n",
        "\n",
        "corpora_mfc_df.insert(loc=0, column='family', value=zfamily_ls)\n",
        "corpora_mfc_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq5jve388-Is"
      },
      "source": [
        "mfc_family_df = corpora_mfc_df.groupby('family').describe()\n",
        "mfc_family_df.shape\n",
        "# mfc_family_df.plot() # ['mean'].plot(kind='bar')\n",
        "print('\\n')\n",
        "mfc_family_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q8Ka4qu8-Ef"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
        "\n",
        "save_plot = True\n",
        "\n",
        "subdir_name = 'data_corpora_plots'\n",
        "\n",
        "family_types_ls = ['lexicon', 'heuristic', 'dnn', 'ml', 'transformer']\n",
        "\n",
        "family_means_ls = []\n",
        "family_mins_ls = []\n",
        "family_maxs_ls = []\n",
        "family_stds_ls = []\n",
        "\n",
        "for afamily in family_types_ls:\n",
        "  family_means_ls.append(mfc_family_df.T[afamily].mean())\n",
        "  family_mins_ls.append(mfc_family_df.T[afamily].min())\n",
        "  family_maxs_ls.append(mfc_family_df.T[afamily].max())\n",
        "  family_stds_ls.append(mfc_family_df.T[afamily].std())\n",
        "\n",
        "\n",
        "# family_means_df = pd.DataFrame()\n",
        "family_stats_df = pd.DataFrame({'zfamily':family_types_ls, \n",
        "                                'zmean':family_means_ls,\n",
        "                                'zmin':family_mins_ls,\n",
        "                                'zmax':family_maxs_ls,\n",
        "                                'zstd':family_stds_ls,\n",
        "                                }) #  = pd.DataFrame(family_means_dt)\n",
        "family_stats_df.index = family_stats_df.zfamily\n",
        "\n",
        "family_stats_df.head()\n",
        "family_stats_df.info()\n",
        "# family_means_df['min'].sort_values().plot(kind='bar')\n",
        "\n",
        "# Plot MFC \n",
        "\n",
        "# plt.rcParams['axes.grid'] = True\n",
        "# plt.rcParams['grid.alpha'] = 1\n",
        "# plt.rcParams['grid.color'] = \"#cccccc\"\n",
        "\n",
        "# fig, ax = plt.subplots()\n",
        "\n",
        "family_stats_df.sort_values(by='zmean').plot(kind='bar')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend(loc='best')\n",
        "# plt.xlabel('Model Family', size=20)\n",
        "plt.ylabel('MFC Value', size=10)\n",
        "# plt.axis('off')\n",
        "# plt.xlabel.set_visible(False)\n",
        "plt.xticks(size=10, rotation=10)\n",
        "# plt.title('Model Family Coherence (MFC) Over Entire Corpus', size=16)\n",
        "\n",
        "# plt.rcParams.update({'font.size': 8})\n",
        "plt.title(f'{corpora_full_dt[acorpus]}\\n Model-Corpus Compatibility (MCC) Metric', pad=20, fontdict={'fontsize':16})\n",
        "\n",
        "if save_plot:\n",
        "\n",
        "  filename_plt = f'./{subdir_name}/plt_mfc_corpora.png'\n",
        "  plt.savefig(filename_plt)\n",
        "\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyzYcSpyID-K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2uyFWyLbt7_"
      },
      "source": [
        "# **Downsample with LTTB**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvihcAuIm92t"
      },
      "source": [
        "!pip install lttb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52w1bQiqm9gW"
      },
      "source": [
        "import lttb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0iyVTICEwTi"
      },
      "source": [
        "## **Option (a): Read in SMA 10%/LTTB DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiSG9vASE3Ip"
      },
      "source": [
        "# Save all Corpora with both old and new LTTB reduced Models\n",
        "\n",
        "corpora_all25_dt = {}\n",
        "\n",
        "subdir_all = 'data_corpora_all'\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "\n",
        "\n",
        "  # acorpus_sent_len = corpora_all_dt[acorpus]['xgb'].shape[0]\n",
        "\n",
        "  filename_out = f'models_all25_{acorpus}.csv'\n",
        "  fullpath_out = f'./{subdir_all}/{filename_out}'\n",
        "  print(f'Reading Corpus: {acorpus} from file: {fullpath_out}')\n",
        "\n",
        "  corpora_all25_dt[acorpus] = pd.read_csv(fullpath_out, index_col=[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4y5DW1WYENZ"
      },
      "source": [
        "%whos list "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ysO-EHFE4A3"
      },
      "source": [
        "## **Option (b): Generate SMA 10%/LTTB DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "059Ty0n6btrn"
      },
      "source": [
        "!pip install lttb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwL2wKM9cnre"
      },
      "source": [
        "import lttb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEjycZNecj_4"
      },
      "source": [
        "acorpus = 'cdickens_achristmascarol'\n",
        "\n",
        "print(f'Corpus: {acorpus} has {corpora_all_dt[acorpus].shape[0]} time values')\n",
        "\n",
        "win10per = int(0.1*corpora_all_dt[acorpus].shape[0])\n",
        "corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True, min_periods=1).mean().plot(label='z-Score Median', linewidth=1)\n",
        "plt.title('A Christmas Carol by Charles Dickesn \\n z-Score Standardized and 10% Simple Moving Average')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67HtX5mefOeC"
      },
      "source": [
        "acorpus = 'cdickens_achristmascarol'\n",
        "model_z = 'nrc_z'\n",
        "\n",
        "type(corpora_all_dt[acorpus][model_z].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APkuuQpre5e4"
      },
      "source": [
        "# Downsample to n_pts points:\n",
        "\n",
        "n_pts = 50\n",
        "\n",
        "x_np = corpora_all_dt[acorpus]['median_z'].shape[0]\n",
        "\n",
        "# Generate an example data set of 100 random points:\n",
        "#  - column 0 represents time values (strictly increasing)\n",
        "#  - column 1 represents the metric of interest: CPU usage, stock price, etc.\n",
        "\n",
        "y_np = corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True, min_periods=1).mean().values\n",
        "data = np.array([range(x_np), y_np]).T # np.random.random(100)]).T\n",
        "\n",
        "# Downsample it to 20 points:\n",
        "small_data = lttb.downsample(data, n_out=n_pts)\n",
        "assert small_data.shape == (n_pts, 2)\n",
        "\n",
        "# temp_np = corpora_all_dt[acorpus]['median_z'].values.reshape(1,-1) # ).ravel()\n",
        "# print(f'Shape temp_np: {temp_np.shape}')\n",
        "# small_data = lttb.downsample(temp_np, n_out=20)\n",
        "# assert small_data.shape == (20, 2)\n",
        "\n",
        "plt.plot(small_data.T[0],small_data.T[1])\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IHlfu-Th0nB"
      },
      "source": [
        "n_pts = 25\n",
        "\n",
        "x_np = corpora_all_dt[acorpus]['median_z'].shape[0]\n",
        "\n",
        "# Generate an example data set of 100 random points:\n",
        "#  - column 0 represents time values (strictly increasing)\n",
        "#  - column 1 represents the metric of interest: CPU usage, stock price, etc.\n",
        "\n",
        "y_np = corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True, min_periods=1).mean().values\n",
        "data = np.array([range(x_np), y_np]).T # np.random.random(100)]).\n",
        "# Downsample it to 20 points:\n",
        "small_data = lttb.downsample(data, n_out=n_pts)\n",
        "assert small_data.shape == (n_pts, 2)\n",
        "print(f'type small_data: {type(small_data)}')\n",
        "print(f'small_data.shape: {small_data.shape}')\n",
        "\n",
        "# temp_np = corpora_all_dt[acorpus]['median_z'].values.reshape(1,-1) # ).ravel()\n",
        "# print(f'Shape temp_np: {temp_np.shape}')\n",
        "# small_data = lttb.downsample(temp_np, n_out=20)\n",
        "# assert small_data.shape == (20, 2)\n",
        "\n",
        "plt.plot(small_data.T[0],small_data.T[1])\n",
        "plt.title('A Christmas Carol by Charles Dickens\\n LTTB Downsampled from 1,399 to 25 data points')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKOgg7VAZyL2"
      },
      "source": [
        "## **Plot zScore/SMA 10% with Downsampling via LTTB**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlKqdcoogg-E"
      },
      "source": [
        "# Anomaly: tmorrison_beloved/pattern is all 0s\n",
        "\n",
        "corpora_all_dt['tmorrison_beloved'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqH86gAtwho7"
      },
      "source": [
        "# For Corpora 'tmorrison_beloved' both 'pattern' and thus 'pattern_z' are 0 and NaN respectively\n",
        "#   for now, just fillna both with '0' as place holders for this one model (pattern) to view all other Models\n",
        "\n",
        "corpora_all_dt['tmorrison_beloved']['pattern_z'] = corpora_all_dt['tmorrison_beloved']['pattern_z'].fillna(0)\n",
        "\n",
        "# corpora_all_dt['tmorrison_beloved']['pattern_z'] = corpora_all_dt['tmorrison_beloved']['syuzhet_z']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKlgKxNywhad"
      },
      "source": [
        "# Verify corpora_all_dt['tomorrison-beloved']['pattern_z'] are all (NaN -> 0)\n",
        "\n",
        "corpora_all_dt['tmorrison_beloved'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOc5Os1IgP8H"
      },
      "source": [
        "# Check if any NaN in tmorrison_beloved\n",
        "# corpora_all_dt[corpora_all_dt['tmorrison_beloved'].isnull().any(axis=1)]\n",
        "\n",
        "corpora_all_dt['tmorrison_beloved'].isnull().any(axis=1).any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9W6GLNJamm3"
      },
      "source": [
        "model_all_cols_ls = corpora_all_dt['cdickens_achristmascarol'].columns\n",
        "print(model_all_cols_ls)\n",
        "\n",
        "print(f'\\nEach Corpus has {len(model_all_cols_ls)} Columns')\n",
        "\n",
        "# Get list of non-Model Columns in Corpus DataFrame\n",
        "model_noncols_ls = ['sent_no', 'parag_no', 'sect_no', 'sent_raw', 'sent_clean']\n",
        "print(f'\\n  {len(model_noncols_ls)} Columns are meta-information (not Models) [model_noncols_ls]:  \\n  {model_noncols_ls}')\n",
        "\n",
        "# Get list of Model Columns in Corpus DataFrame\n",
        "model_cols_ls = list(set(model_all_cols_ls) - set(model_noncols_ls))\n",
        "print(f'\\n  {len(model_cols_ls)} Columns are these Models [model_cols_ls]:\\n  {[i for i in model_cols_ls]}')\n",
        "\n",
        "# Get list of zScore Model Columns in Corpus DataFrame\n",
        "model_z_cols_ls = [i for i in model_cols_ls if i.endswith('_z')]\n",
        "print(f'\\n  {len(model_z_cols_ls)} Columns are zScore Models [model_z_cols_ls]:\\n  {model_z_cols_ls}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK4ok9hKhB3I"
      },
      "source": [
        "corpora_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbiiZeSwhLCs"
      },
      "source": [
        "# Workaround to deal with break at NaN in tmorrison_beloved/pattern_z \n",
        "#   change NaN->0 and continue execution for the rest of these Corpora\n",
        "\n",
        "corpora_temp_ls = [\n",
        "                    'tmorrison_beloved',\n",
        "                    'vnabokov_palefire',\n",
        "                    'vwoolf_mrsdalloway',\n",
        "                    'vwoolf_orlando',\n",
        "                    'vwoolf_thewaves',\n",
        "                    'vwoolf_tothelighthouse'\n",
        "                    ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIuFBoyy5CcS"
      },
      "source": [
        "model_z_cols_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6pwb4Rwaq_l"
      },
      "source": [
        "# Downsample all z-Score Model Series to n_pts with LTTB Algo\n",
        "\n",
        "lttb_pts = 25\n",
        "\n",
        "plt.style.use('default')\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (14,8)\n",
        "\n",
        "save_plot = True\n",
        "\n",
        "subdir_name = 'data_corpora_plots'\n",
        "\n",
        "corpora_all25_dt = {}\n",
        "\n",
        "for acorpus in corpora_ls:\n",
        "  corpora_all25_dt[acorpus] = pd.DataFrame()\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls): # corpora_ls): # corpora_temp_ls): # [:2]):\n",
        "  print(acorpus)\n",
        "  # acorpus_sent_len = corpora_all_dt[acorpus]['xgb'].shape[0]\n",
        "\n",
        "  for j, amodel_z in enumerate(model_z_cols_ls):\n",
        "    # if j == 0:\n",
        "    #   corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True).mean().plot(label='z-Score Median', style=['r*-'], linewidth=2.0)\n",
        "\n",
        "    print(f'Corpus #{i} {acorpus} with Model #{j} {amodel_z}: has {len(corpora_all_dt[acorpus].columns)} columns but only {len(model_cols_ls)} model columns')\n",
        "\n",
        "    amodel_z_nlttb = f'{amodel_z}_{lttb_pts}lttb'\n",
        "\n",
        "    x_np = corpora_all_dt[acorpus][amodel_z].index # shape[0]\n",
        "    y_np = corpora_all_dt[acorpus][amodel_z].rolling(win10per, center=True, min_periods=1).mean().values\n",
        "    # data = np.array([range(x_np), y_np]).T\n",
        "    data = np.array([x_np, y_np]).T\n",
        "\n",
        "    # Downsample it to lttb_pts points:\n",
        "    small_data = lttb.downsample(data, n_out=lttb_pts)\n",
        "    assert small_data.shape == (lttb_pts, 2)\n",
        "\n",
        "    temp_ser = pd.Series()\n",
        "    temp_ser = pd.Series(small_data.T[1].tolist()) # small_data.T[0], small_data.T[1])\n",
        "    corpora_all25_dt[acorpus][amodel_z_nlttb] = temp_ser.copy(deep=True) # = pd.Series(small_data.T[1].tolist()) # small_data.T[0], small_data.T[1])\n",
        "\n",
        "    # temp_np = corpora_all_dt[acorpus]['vader_z'].values.reshape(1,-1) # ).ravel()\n",
        "    # print(f'Shape temp_np: {temp_np.shape}')\n",
        "    # small_data = lttb.downsample(temp_np, n_out=20)\n",
        "    # assert small_data.shape == (20, 2)\n",
        "\n",
        "    \n",
        "    # ax = corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True, min_periods=1).mean().plot(label='z-Score Median', style=['r'], linewidth=3, alpha=0.9)\n",
        "    plt.plot(small_data.T[0],small_data.T[1], label=amodel_z)\n",
        "    # ax = corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True, min_periods=1).mean().plot(label='z-Score Median', style=['r'], linewidth=3, alpha=0.9)\n",
        "\n",
        "  # ax.grid(True)\n",
        "  # ax.set_title(f'{corpora_full_dt[acorpus]}\\n LTTB Downsampled zScore/SMA 10% Time Series', fontsize=20)\n",
        "  plt.title(f'{corpora_full_dt[acorpus]}\\n zScore/SMA 10% Downsampled to {lttb_pts} Points with LTTB', fontsize=16)\n",
        "  plt.ylabel('Standardized Sentiment Values', fontsize=12)\n",
        "  plt.xlabel('LTTB Simplified Narrative Time', fontsize=12)\n",
        "  # ax.set(xlabel='Decade', ylabel='Weighted Percent of Top Songs', fontsize=10)\n",
        "  # plt.xlabel('Line Number') # , fontsize=14)\n",
        "  # plt.ylabel('Standardized Sentiment Value') # , fontsize=14)\n",
        "  # ax.set_xticklabels(us_impact_df.decade, size=30)\n",
        "  # plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10, title='Model', title_fontsize=14);\n",
        "  # plt.legend(loc='best')\n",
        "  plt.legend(bbox_to_anchor=(1.0, 1.0), title='Models', fontsize=8, title_fontsize=10)\n",
        "  # plt.grid()\n",
        "  \n",
        "  if save_plot:\n",
        "    filename_plt = f'./{subdir_name}/plt_lttb{lttb_pts}_{acorpus}.png'\n",
        "    plt.savefig(filename_plt)\n",
        "    print(f'Saved plot to filepath: {filename_plt}\\n\\n')\n",
        "\n",
        "  plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKK_508HYvIJ"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "# Downsample all z-Score Model Series to n_pts with LTTB Algo\n",
        "\n",
        "lttb_pts = 25\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
        "\n",
        "save_plot = False\n",
        "\n",
        "subdir_name = 'data_corpora_plots'\n",
        "\n",
        "corpora_all25_dt = {}\n",
        "\n",
        "for acorpus in corpora_ls:\n",
        "  corpora_all25_dt[acorpus] = pd.DataFrame()\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls): # [:1]): # corpora_ls): # corpora_temp_ls): # [:2]):\n",
        "  print(acorpus)\n",
        "  # acorpus_sent_len = corpora_all_dt[acorpus]['xgb'].shape[0]\n",
        "\n",
        "  for j, amodel_z in enumerate(model_z_cols_ls):\n",
        "    # if j == 0:\n",
        "    #   corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True).mean().plot(label='z-Score Median', style=['r*-'], linewidth=2.0)\n",
        "\n",
        "    print(f'Corpus #{i} {acorpus} with Model #{j} {amodel_z}: has {len(corpora_all_dt[acorpus].columns)} columns but only {len(model_cols_ls)} model columns')\n",
        "\n",
        "    amodel_z_nlttb = f'{amodel_z}_{lttb_pts}lttb'\n",
        "\n",
        "    x_np = corpora_all_dt[acorpus][amodel_z].index # shape[0]\n",
        "    y_np = corpora_all_dt[acorpus][amodel_z].rolling(win10per, center=True, min_periods=1).mean().values\n",
        "    # data = np.array([range(x_np), y_np]).T\n",
        "    data = np.array([x_np, y_np]).T\n",
        "\n",
        "    # Downsample it to lttb_pts points:\n",
        "    small_data = lttb.downsample(data, n_out=lttb_pts)\n",
        "    assert small_data.shape == (lttb_pts, 2)\n",
        "\n",
        "    temp_ser = pd.Series()\n",
        "    temp_ser = pd.Series(small_data.T[1].tolist()) # small_data.T[0], small_data.T[1])\n",
        "    corpora_all25_dt[acorpus][amodel_z_nlttb] = temp_ser.copy(deep=True) # = pd.Series(small_data.T[1].tolist()) # small_data.T[0], small_data.T[1])\n",
        "\n",
        "    # temp_np = corpora_all_dt[acorpus]['vader_z'].values.reshape(1,-1) # ).ravel()\n",
        "    # print(f'Shape temp_np: {temp_np.shape}')\n",
        "    # small_data = lttb.downsample(temp_np, n_out=20)\n",
        "    # assert small_data.shape == (20, 2)\n",
        "\n",
        "    \n",
        "    # ax = corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True, min_periods=1).mean().plot(label='z-Score Median', style=['r'], linewidth=3, alpha=0.9)\n",
        "    plt.plot(small_data.T[0],small_data.T[1], label=amodel_z)\n",
        "    # ax = corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True, min_periods=1).mean().plot(label='z-Score Median', style=['r'], linewidth=3, alpha=0.9)\n",
        "\n",
        "  # ax.grid(True)\n",
        "  # ax.set_title(f'{corpora_full_dt[acorpus]}\\n LTTB Downsampled zScore/SMA 10% Time Series', fontsize=20)\n",
        "  plt.title(f'{corpora_full_dt[acorpus]}\\n zScore/SMA 10% Downsampled to {lttb_pts} Points with LTTB', fontsize=20)\n",
        "  # ax.set(xlabel='Decade', ylabel='Weighted Percent of Top Songs', fontsize=10)\n",
        "  # plt.xlabel('Line Number') # , fontsize=14)\n",
        "  # plt.ylabel('Standardized Sentiment Value') # , fontsize=14)\n",
        "  # ax.set_xticklabels(us_impact_df.decade, size=30)\n",
        "  # plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10, title='Model', title_fontsize=14);\n",
        "  plt.legend()\n",
        "  # plt.grid()\n",
        "  \n",
        "  if save_plot:\n",
        "    filename_plt = f'./{subdir_name}/plt_lttb{lttb_pts}_{amodel}.png'\n",
        "    plt.savefig(filename_plt)\n",
        "    print(f'Saved plot to filepath: {filename_plt}\\n\\n')\n",
        "\n",
        "  plt.show();\n",
        "\n",
        "  \"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0mYaYw41IJb"
      },
      "source": [
        "# import copy\n",
        "\n",
        "# corpora_all25_dt = copy.deepcopy(corpora_all50_dt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FsUDlMcy8A6"
      },
      "source": [
        "corpora_all25_dt.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-X1By-StQJG"
      },
      "source": [
        "# Verify the LTTB Dim-Red corpora dimensions\n",
        "\n",
        "corpora_all25_dt['cdickens_achristmascarol'].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1pVcBv_2AWQ"
      },
      "source": [
        "corpora_all25_dt['cdickens_achristmascarol'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2-JGSzpy-TG"
      },
      "source": [
        "# Verify the LTTB Dim-Red corpora dimensions\n",
        "\n",
        "corpora_all25_dt['vnabokov_palefire'].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQmeMFqmtS2Q"
      },
      "source": [
        "corpora_all25_dt['vnabokov_palefire'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fq6KSP2Z1zM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiYEOKZZXIdQ"
      },
      "source": [
        "### **Plot LTTB Sentiment Arcs for each Corpus**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0t96JyDYEHZ"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
        "\n",
        "save_plot = False\n",
        "\n",
        "subdir_name = 'data_copora_plots'\n",
        "\n",
        "lttb_pts = 25\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls[:1]):\n",
        "\n",
        "  ax = sns.lineplot(data=corpora_mcc_rank_df.T, palette='Accent', linewidth=3) # , alpha=0.5)\n",
        "  ax.grid(True, alpha=0.3) # True, alpha=0.3)\n",
        "  ax.set_title(f'{corpora_full_dt[acorpus]}\\n zScore/SMA 10% Downsampled to {lttb_pts} Points with LTTB', fontdict = {'fontsize' : 16})\n",
        "  ax.set_ylabel('Standardized Sentiment Values', fontsize=15)\n",
        "  ax.set_xlabel('LTTB Reduced Novel Time')\n",
        "  ax.set_xticklabels(corpora_mcc_rank_df.columns, size=12, rotation=90)\n",
        "  # # ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
        "  ax.legend(fontsize=10, title='Model', title_fontsize='14', bbox_to_anchor=(1.05, 1), loc='top')\n",
        "\n",
        "\n",
        "  # corpora_all25_dt[acorpus].plot()\n",
        "  # plt.title(f'{corpora_full_dt[acorpus]}\\n zScore/SMA 10% Downsampled to {lttb_pts} Points with LTTB', fontdict = {'fontsize' : 16})\n",
        "  # plt.ylabel('Standardized Sentiment Values')\n",
        "  # plt.xlabel('LTTB Reduced Novel Time')\n",
        "  # plt.legend(loc='best') \n",
        "  # plt.legend(fontsize=10, title='Model', title_fontsize='14', bbox_to_anchor=(1.05, 1), loc='top right')\n",
        "\n",
        "\"\"\"\n",
        "ax = sns.lineplot(data=corpora_mcc_rank_df.T, palette='Accent', linewidth=3) # , alpha=0.5)\n",
        "ax.grid(True, alpha=0.3) # True, alpha=0.3)\n",
        "ax.set_title('Model MCC Rank Across Corpora', fontsize=20)\n",
        "# ax.set(xlabel='Decade', ylabel='Weighted Percent of Top Songs', fontsize=10)\n",
        "# ax.set_xlabel('Decade', fontsize=20)\n",
        "ax.set_ylabel('MCC Rank', fontsize=15)\n",
        "ax.set_xticklabels(corpora_mcc_rank_df.columns, size=12, rotation=90)\n",
        "# ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
        "leg = ax.legend(fontsize=10, title='Model', title_fontsize='14', bbox_to_anchor=(1.05, 1), loc='top')\n",
        "for line in leg.get_lines():\n",
        "  line.set_linewidth(3.0)\n",
        "\"\"\";\n",
        "\n",
        "if save_plot:\n",
        "\n",
        "  filename_plt = f'./{subdir_name}/plt_ecc_corpora.png'\n",
        "  plt.savefig(filename_plt)\n",
        "\n",
        "plt.show()\n",
        "plt.close();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q26cE0480t4R"
      },
      "source": [
        "## **Skip to [Save zScore/SMA/LTTB DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfgIUex00myY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywL3vL3uf-9e"
      },
      "source": [
        "# If only a few missing, could've interpolated missing values from surrounding non-NaN values\n",
        "\n",
        "# corpora_all_dt[corpora_all_dt['tmorrison_beloved'].interpolate(method='linear', limit_direction='both')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEUgYI5cbU4k"
      },
      "source": [
        "corpora_all_dt['cdickens_achristmascarol'].columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOY3ek-PCF-k"
      },
      "source": [
        "# Downsample all z-Score Model Series to n_pts with LTTB Algo\n",
        "\n",
        "lttb_pts = 50\n",
        "\n",
        "subdir_name = 'data_corpora_plots'\n",
        "\n",
        "corpora_all50_dt = {}\n",
        "\n",
        "for acorpus in corpora_ls:\n",
        "  corpora_all50_dt[acorpus] = pd.DataFrame()\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls): # [:2]):\n",
        "  print(acorpus)\n",
        "  # acorpus_sent_len = corpora_all_dt[acorpus]['xgb'].shape[0]\n",
        "\n",
        "  for j, amodel in enumerate(model_cols_ls):\n",
        "    if j == 0:\n",
        "      corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True).mean().plot(label='z-Score Median', style=['r*-'], linewidth=2.0)\n",
        "\n",
        "    print(f'Corpus #{i} {acorpus} with Model #{j} {amodel}: has {len(corpora_all_dt[acorpus].columns)} columns but only {len(model_cols_ls)} model columns')\n",
        "\n",
        "    amodel_z = f'{amodel}_z'\n",
        "\n",
        "    x_np = corpora_all_dt[acorpus][amodel_z].shape[0]\n",
        "    y_np = corpora_all_dt[acorpus][amodel_z].rolling(win10per, center=True, min_periods=1).mean().values\n",
        "    data = np.array([range(x_np), y_np]).T\n",
        "\n",
        "    # Downsample it to lttb_pts points:\n",
        "    small_data = lttb.downsample(data, n_out=lttb_pts)\n",
        "    assert small_data.shape == (lttb_pts, 2)\n",
        "\n",
        "    corpora_all50_dt[acorpus][amodel] = pd.Series(small_data.tolist()) # small_data.T[0], small_data.T[1])\n",
        "\n",
        "    # temp_np = corpora_all_dt[acorpus]['vader_z'].values.reshape(1,-1) # ).ravel()\n",
        "    # print(f'Shape temp_np: {temp_np.shape}')\n",
        "    # small_data = lttb.downsample(temp_np, n_out=20)\n",
        "    # assert small_data.shape == (20, 2)\n",
        "\n",
        "    plt.plot(small_data.T[0],small_data.T[1], label=amodel)\n",
        "\n",
        "  plt.title(f'{acorpus}\\n SMA 10% Followed by LTTB Downsampled to {lttb_pts} Points')\n",
        "  plt.legend(loc='best') \n",
        "  filename_plt = f'./{subdir_name}/plt_lttb{lttb_pts}_{amodel}.png'\n",
        "  plt.savefig(filename_plt)\n",
        "  plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5Dtwn9QD0KP"
      },
      "source": [
        "corpora_all50_dt['cdickens_achristmascarol']['vader'][:5]\n",
        "type(corpora_all50_dt['cdickens_achristmascarol']['vader'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO8-1qjN_zs-"
      },
      "source": [
        "# Save all models with orignal and zscore values\n",
        "\n",
        "subdir_out = 'data_corpora_all'\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(acorpus)\n",
        "  # acorpus_sent_len = corpora_all_dt[acorpus]['xgb'].shape[0]\n",
        "\n",
        "  filename_out = f'models_all50_{acorpus}.csv'\n",
        "  fullpath_out = f'./{subdir_out}/{filename_out}'\n",
        "\n",
        "  print(f'\\nSaving Corpus: {acorpus}...')\n",
        "  corpora_all50_dt[acorpus].to_csv(fullpath_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUnEPAU_FJ8l"
      },
      "source": [
        "## **Save zScore/SMA/LTTB DataFrames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9g1eqwzFJrX"
      },
      "source": [
        "# Save all Corpora with both old and new LTTB reduced Models\n",
        "\n",
        "subdir_out = 'data_corpora_all'\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(acorpus)\n",
        "  # acorpus_sent_len = corpora_all_dt[acorpus]['xgb'].shape[0]\n",
        "\n",
        "  filename_out = f'models_all25_{acorpus}.csv'\n",
        "  fullpath_out = f'./{subdir_out}/{filename_out}'\n",
        "\n",
        "  print(f'\\nSaving Corpus: {acorpus}...')\n",
        "  corpora_all25_dt[acorpus].to_csv(fullpath_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z02wV6y6_w0C"
      },
      "source": [
        "# **[DEFUNCT] LOWESS Smoothing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGuuDFcb3LNz"
      },
      "source": [
        "# from statsmodels.nonparametric.smoothers_lowess import lowess\n",
        "\n",
        "import statsmodels.api as sm\n",
        "lowess = sm.nonparametric.lowess"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAMP4J6bEc26"
      },
      "source": [
        "# Downsample all z-Score Model Series to n_pts with LTTB Algo\n",
        "\n",
        "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
        "\n",
        "afrac = 0.1 \n",
        "\n",
        "def make_lowess(series, frac=0.1):\n",
        "    endog = series.values\n",
        "    exog = series.index.values\n",
        "\n",
        "    smooth = lowess(endog, exog, frac)\n",
        "    index, data = np.transpose(smooth)\n",
        "\n",
        "    return pd.Series(data, index=pd.to_datetime(index)) \n",
        "\n",
        "for acorpus in corpora_ls:\n",
        "  corpora_all50_dt[acorpus] = pd.DataFrame()\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls[:2]):\n",
        "  print(acorpus)\n",
        "  # acorpus_sent_len = corpora_all_dt[acorpus]['xgb'].shape[0]\n",
        "\n",
        "  for j, amodel in enumerate(model_cols_ls):\n",
        "    if j == 0:\n",
        "      corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True).mean().plot(label='z-Score Median', style=['r*-'], linewidth=2.0)\n",
        "\n",
        "    print(f'Corpus #{i} {acorpus} with Model #{j} {amodel}: has {len(corpora_all_dt[acorpus].columns)} columns but only {len(model_cols_ls)} model columns')\n",
        "\n",
        "    amodel_lowess = f\"{amodel}_lowess{''.join(str(afrac).split('.'))}\"\n",
        "    print(f'amodel_lowess: {amodel_lowess}')\n",
        "\n",
        "    temp_np = make_lowess(corpora_all_dt[acorpus][amodel], frac=afrac)\n",
        "    # plt.plot(temp_np[0], temp_np[1], label=amodel)\n",
        "\n",
        "    corpora_all_dt[acorpus][amodel_lowess] = pd.Series(temp_np.tolist()) # small_data.T[0], small_data.T[1])\n",
        "\n",
        "\n",
        "\n",
        "    # temp_np = corpora_all_dt[acorpus]['vader_z'].values.reshape(1,-1) # ).ravel()\n",
        "    # print(f'Shape temp_np: {temp_np.shape}')\n",
        "    # small_data = lttb.downsample(temp_np, n_out=20)\n",
        "    # assert small_data.shape == (20, 2)\n",
        "\n",
        "    # plt.plot(small_data.T[0],small_data.T[1], label=amodel)\n",
        "\n",
        "  plt.title(f'{acorpus} LTTB Downsampled SMA 10%')\n",
        "  plt.legend(loc='best') \n",
        "  plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OceHxv73Zbi"
      },
      "source": [
        "x = np.random.uniform(low = -2*np.pi, high = 2*np.pi, size=500)\n",
        "y = np.sin(x) + np.random.normal(size=len(x))\n",
        "\n",
        "z = lowess(y, x)\n",
        "w = lowess(y, x, frac=1./3)\n",
        "\n",
        "# plt.plot(w)\n",
        "\n",
        "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
        "\n",
        "def make_lowess(series, frac=0.1):\n",
        "    endog = series.values\n",
        "    exog = series.index.values\n",
        "\n",
        "    smooth = lowess(endog, exog, frac)\n",
        "    index, data = np.transpose(smooth)\n",
        "\n",
        "    return pd.Series(data, index=pd.to_datetime(index)) \n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "temp_df['test'] = make_lowess(corpora_all_dt['cdickens_achristmascarol']['vader_z'], frac=0.1)\n",
        "\n",
        "temp_df['test'].plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnR-Hmjk7Okb"
      },
      "source": [
        "temp_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pk8LZyRPdmTh"
      },
      "source": [
        "# Downsample all z-Score Model Series to n_pts with LTTB Algo\n",
        "\n",
        "n_pts = 100\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for i, acorpus in enumerate(corpora_ls[:2]):\n",
        "  print(acorpus)\n",
        "  # acorpus_sent_len = corpora_all_dt[acorpus]['xgb'].shape[0]\n",
        "\n",
        "  for j, amodel in enumerate(model_cols_ls):\n",
        "    if j == 0:\n",
        "      corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True).mean().plot(label='z-Score Median', style=['r*-'], linewidth=2.0)\n",
        "\n",
        "    print(f'Corpus #{i} {acorpus} with Model #{j} {amodel}: has {len(corpora_all_dt[acorpus].columns)} columns but only {len(model_cols_ls)} model columns')\n",
        "\n",
        "    amodel_z = f'{amodel}_z'\n",
        "    \n",
        "    x_np = corpora_all_dt[acorpus][amodel_z].shape[0]\n",
        "    y_np = corpora_all_dt[acorpus][amodel_z].rolling(win10per, center=True, min_periods=1).mean().values\n",
        "    data = np.array([range(x_np), y_np]).T\n",
        "\n",
        "    # Downsample it to n_pts points:\n",
        "    small_data = lttb.downsample(data, n_out=n_pts)\n",
        "    assert small_data.shape == (n_pts, 2)\n",
        "\n",
        "    # temp_np = corpora_all_dt[acorpus]['vader_z'].values.reshape(1,-1) # ).ravel()\n",
        "    # print(f'Shape temp_np: {temp_np.shape}')\n",
        "    # small_data = lttb.downsample(temp_np, n_out=20)\n",
        "    # assert small_data.shape == (20, 2)\n",
        "\n",
        "    plt.plot(small_data.T[0],small_data.T[1], label=amodel)\n",
        "\n",
        "  plt.title(f'{acorpus} LTTB Downsampled SMA 10%')\n",
        "  plt.legend(loc='best') \n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    win10per = int(0.10*corpora_all_dt[acorpus].shape[0])\n",
        "\n",
        "    temp_np = np.asarray(corpora_all_dt[acorpus][amodel])\n",
        "    temp_z_np = zscore(temp_np)\n",
        "\n",
        "    # temp_std_ser = stdscaler.fit_transform(np.asarray(temp_ser).reshape(1,-1)).ravel()\n",
        "    # pd.Series(temp_std_ser)\n",
        "    amodel_z = f'{amodel}_z'\n",
        "    corpora_all_dt[acorpus][amodel_z] = pd.Series(temp_z_np)\n",
        "    corpora_all_dt[acorpus][amodel_z].rolling(win10per, center=True).mean().plot(label=amodel_z, alpha=0.3)\n",
        "\n",
        "    # corpora_all_dt[acorpus][amodel].astype(np.float64)\n",
        "    # temp_df[amodel] = corpora_all_dt[acorpus][amodel].value.rolling(win10per, min_periods=1,center=True).apply(zscore)\n",
        "    \n",
        "    # temp_df[amodel] = pd.Series(type(stdscaler.fit_transform(np.asarray(corpora_all_dt[acorpus][amodel]).reshape(-1,1)))) # .reshape(-1,1))\n",
        "    # print(f'temp_df[amodel]: {temp_df[amodel]}')\n",
        "    # print(f'len(temp_df[amodel]: {len(temp_df[amodel])}')\n",
        "    # temp_df[amodel].rolling(win10per, min_periods=1,center=True).mean().plot() # .mean().plot(label=amodel)\n",
        "\n",
        "    # plt.title(f'{acorpus} Simple Moving Average')\n",
        "    # plt.legend(loc='best') \n",
        "\n",
        "  # if i == (len(corpora_ls)):\n",
        "  #   corpora_all_dt[amodel]['median_z'].rolling(win10per, center=True).mean().plot(alpha=0.6, color='black', width=2)\n",
        "  #   plt.title(f'{acorpus} Simple Moving Average')\n",
        "  #  plt.legend(loc='best')\n",
        "  plt.title(f'{acorpus} Simple Moving Average')    \n",
        "  plt.legend(loc='best')\n",
        "  corpora_all_dt[acorpus]['median_z'].rolling(win10per, center=True).mean().plot(label='z-Score Median', style=['r*-'], linewidth=2.0)\n",
        "  plt.show();\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx_98LiHdmPe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGAyLsV2btn2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYRtM17Pb11c"
      },
      "source": [
        "# **DTW Hierarchical Clustering**\n",
        "\n",
        "* https://github.com/wannesm/dtaidistance\n",
        "\n",
        "* https://dtaidistance.readthedocs.io/en/latest/usage/clustering.html\n",
        "\n",
        "* DTW w/Hierachical Clustering https://github.com/wannesm/dtaidistance\n",
        "\n",
        "* HITL/Interactive Clustering (DTAIDistance+COBRAS) https://github.com/ML-KULeuven/cobras \n",
        "\n",
        "* https://github.com/markdregan/K-Nearest-Neighbors-with-Dynamic-Time-Warping\n",
        "\n",
        "* https://github.com/timeseriesAI/tsai\n",
        "\n",
        "* https://github.com/tslearn-team/tslearn\n",
        "\n",
        "* https://stats.stackexchange.com/questions/131281/dynamic-time-warping-clustering\n",
        "\n",
        "* https://stats.stackexchange.com/questions/109343/dynamic-time-warping-for-irregular-time-series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc25Hc2E8K5L"
      },
      "source": [
        "!pip install dtaidistance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOgda-tJLv4b"
      },
      "source": [
        "from dtaidistance import dtw\n",
        "from dtaidistance import clustering\n",
        "from dtaidistance import dtw_visualisation as dtwvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shTeMM6abtjy"
      },
      "source": [
        "corpora_all25_dt.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXPAVORq7wpW"
      },
      "source": [
        "corpora_all25_dt['cdickens_achristmascarol'].columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF0YbYyuKgG5"
      },
      "source": [
        "models_all25_ls = corpora_all25_dt['cdickens_achristmascarol'].columns.tolist()\n",
        "type(models_all25_ls)\n",
        "models_all25_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJpLhuD8OSO5"
      },
      "source": [
        "list(corpora_all25_dt.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aVxVK9IeuzD"
      },
      "source": [
        "mpl.rcParams.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q9DOnZMKT8w"
      },
      "source": [
        "%%capture\n",
        "\n",
        "# DTW Hierarchical Clustering for every Model per each Corpus\n",
        "\n",
        "import matplotlib as mpl\n",
        "\n",
        "# Flag to indicate save plot to file\n",
        "save_plots = False\n",
        "\n",
        "subdir_name = 'data_corpora_plots'\n",
        "\n",
        "plt.style.use('default')\n",
        "mpl.rcParams['font.size'] = 12\n",
        "mpl.rcParams['lines.linewidth'] = 1\n",
        "# mpl.rcParams['figure.figsize'] = (10,10)\n",
        "# mpl.rcParams['figure.titlesize'] = 30\n",
        "\"\"\"\n",
        "mpl.rcParams['axes.labelsize'] = 'large'\n",
        "mpl.rcParams['figure.titlesize'] = 16\n",
        "mpl.rcParams['lines.markersize'] = 16\n",
        "mpl.rcParams['axes.linewidth'] = 20\n",
        "mpl.rcParams['patch.linewidth'] = 1.0\n",
        "mpl.rcParams['xtick.labelsize'] = 'large'\n",
        "mpl.rcParams['xtick.major.size'] = 10\n",
        "mpl.rcParams['boxplot.boxprops.linewidth'] = 1.0\n",
        "\"\"\" \n",
        "\n",
        "# mpl.rcParams['xtick.major.size'] = 10\n",
        "# mpl.rcParams['xtick.labelsize'] = 'large'\n",
        "# mpl.rcParams['xtick.major.size'] = 10\n",
        "# plt.rcParams[\"figure.figsize\"] = (14,8)\n",
        "\n",
        "# Dict[Corpus] of all Distance Matricies \n",
        "corpora_all_dist_dt = {}\n",
        "\n",
        "# Create list of 1D vectorized distance matricies (one for each Corpus with Model distances)\n",
        "corpora_all25vec_dt = {}\n",
        "\n",
        "# Get lists of LTTB Dimensionality-Reduced Corpora/Models\n",
        "corpora_all25_ls = list(corpora_all25_dt.keys())\n",
        "\n",
        "for i, acorpus in enumerate(corpora_all25_ls[:1]): # [:2]): # [:2]):\n",
        "  # print(f'Processing Corpus: {acorpus}')\n",
        "\n",
        "  models_all25_ls = corpora_all25_dt[acorpus].columns.tolist()\n",
        "\n",
        "  models_all25_ls = [i if i != 'logreg_cv_z_25lttb' else 'logreg-cv_z_25lttb' for i in models_all25_ls]\n",
        "  models_all25_ls = [i if i != 'jockers_rinker_z_25lttb' else 'jockers-rinker_z_25lttb' for i in models_all25_ls]\n",
        "\n",
        "  models_all25_ls = [i.split('_')[0] for i in models_all25_ls]\n",
        "\n",
        "  print(f'Corpus #{i} {acorpus} has {len(corpora_all25_dt[acorpus].columns)} model columns')\n",
        "\n",
        "  aseries = corpora_all25_dt[acorpus].to_numpy().T\n",
        "\n",
        "  ds = dtw.distance_matrix_fast(aseries) #  block=((1, 4), (3, 5)))\n",
        "  corpora_all_dist_dt[acorpus] = ds\n",
        "\n",
        "  # Convert upper triangular part of this Distance Matrix (not incl diag) into 1D vector\n",
        "  ds_1d = ds[np.triu_indices(ds.shape[0], k = 1)] # offset\n",
        "  corpora_all25vec_dt[acorpus] = ds_1d\n",
        "\n",
        "  # Custom Hierarchical clustering\n",
        "  model1 = clustering.Hierarchical(dtw.distance_matrix, {})\n",
        "  cluster_idx = model1.fit(aseries)\n",
        "  # Augment Hierarchical object to keep track of the full tree\n",
        "  model2 = clustering.HierarchicalTree(model1, tr_left_margin=0) # , tr_label_margin=-10)\n",
        "  cluster_idx = model2.fit(aseries)\n",
        "\n",
        "  # SciPy linkage clustering\n",
        "  model3 = clustering.LinkageTree(dtw.distance_matrix, {})\n",
        "  cluster_idx = model3.fit(aseries)\n",
        "\n",
        "  # Plot Agglomerative Hierarchical Tree and Save as file\n",
        "  fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 12))\n",
        "  # show_ts_label = lambda idx: \"ts-\" + str(idx)\n",
        "  show_ts_label = lambda idx: models_all25_ls[idx]\n",
        "  # fig.tight_layout()\n",
        "  fig.subplots_adjust(top=0.95)\n",
        "  corpus_title = f'{acorpus}: DTW Agglomerative Hierarchical Clustering'\n",
        "  fig.suptitle(corpus_title, fontsize=16)\n",
        "  acorpus = f'{acorpus}'\n",
        "  filename_path = f'./data_corpora_plots/plot_hclust_{acorpus}.png'\n",
        "  if save_plots:\n",
        "    # Save Plot to File\n",
        "    model2.plot(filename_path, axes=ax, show_ts_label=show_ts_label, # True, # lttb_cols_ls,\n",
        "              show_tr_label=True, ts_label_margin=0,\n",
        "              ts_left_margin=0, tr_label_margin=0.1) #  ts_sample_length=1)\n",
        "    # Display Plot File\n",
        "    Image(filename_path)\n",
        "    plt.margins(x=0.1, y=0.5)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "  else:\n",
        "    # Just Display Plots (no save to file)\n",
        "    model2.plot(axes=ax, show_ts_label=show_ts_label, # True, # lttb_cols_ls,\n",
        "              show_tr_label=True, ts_label_margin=0,\n",
        "              ts_left_margin=0, tr_label_margin=0.1) #  ts_sample_length=1)\n",
        "    plt.margins(x=0.1, y=0.5)\n",
        "    plt.show()    \n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7TCMX1ZM0c3"
      },
      "source": [
        "\n",
        "\n",
        "print(corpora_all_dist_dt['cdickens_achristmascarol'].shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yQLH4FlMlY5"
      },
      "source": [
        "type(corpora_all25vec_dt['cdickens_achristmascarol'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSbgT2X5krhB"
      },
      "source": [
        "temp_df = pd.DataFrame(corpora_all_dist_dt['cdickens_achristmascarol'])\n",
        "temp_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT2cyqmxNRHQ"
      },
      "source": [
        "with np.printoptions(threshold=np.inf):\n",
        "  print(corpora_all_dist_dt['cdickens_achristmascarol'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE85DmL0UbLP"
      },
      "source": [
        "## **Save Distance Matrices and Vectorizations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l12l46VCXTFg"
      },
      "source": [
        "import pickle\n",
        "  \n",
        "\n",
        "corpora_all25vec_dt\n",
        "\n",
        "corpora_all_dist_dt\n",
        "\n",
        "  \n",
        "try:\n",
        "    geeky_file = open('geekyfile', 'wb')\n",
        "    pickle.dump(dictionary, geeky_file)\n",
        "    geeky_file.close()\n",
        "  \n",
        "except:\n",
        "    print(\"Something went wrong\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx3jugEgUaXR"
      },
      "source": [
        "# Save all Corpora with both old and new LTTB reduced Models\n",
        "\n",
        "# SAVE: corpora_all25vec_dt\n",
        "\n",
        "subdir_out = 'data_corpora_all'\n",
        "\n",
        "filename_out = f'models_all25vec'\n",
        "fullpath_out = f'./{subdir_out}/{filename_out}'\n",
        "\n",
        "try:\n",
        "  fp = open(fullpath_out, 'wb')\n",
        "  pickle.dump(corpora_all25vec_dt, fp)\n",
        "  fp.close()\n",
        "  print(f'Saved {fullpath} to pickle file')\n",
        "  \n",
        "except:\n",
        "    print(f'ERROR: Could not save {fullpath_out} to pickle file')\n",
        "\n",
        "\n",
        "# SAVE: corpora_all_dist_dt\n",
        "\n",
        "filename_out = f'models_allvec_dist'\n",
        "fullpath_out = f'./{subdir_out}/{filename_out}'\n",
        "\n",
        "try:\n",
        "  fp = open(fullpath_out, 'wb')\n",
        "  pickle.dump(corpora_all_dist_dt, fp)\n",
        "  fp.close()\n",
        "  print(f'Saved {fullpath_out} to pickle file')\n",
        "\n",
        "except:\n",
        "    print(f'ERROR: Could not save {fullpath} to pickle file')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMBcHf3RHZSP"
      },
      "source": [
        "# **Model Stability in Hierarchical Tree**\n",
        "\n",
        "Per Corpus and across all Corpora, compute a Stability Metric per Model and Model Type:\n",
        "\n",
        "* Model Type Stability: Lexicon, AutoML, DNN, BERT by Weighted Clustering Formula\n",
        "* Individual Model Stability: by %variability of every other model by degree of closeness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvq5NHL-HZIB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mtBpLm2HZEp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj8hm5EhHZAN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfkH4TrwUA-w"
      },
      "source": [
        "# **Cluster Distance Matrices**\n",
        "\n",
        "* https://machinelearningmastery.com/clustering-algorithms-with-python/\n",
        "\n",
        "* https://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html \n",
        "\n",
        "* https://www.geeksforgeeks.org/implementing-dbscan-algorithm-using-sklearn/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXppIVltJDYm"
      },
      "source": [
        "## **Option (a) Read Universal Matrix of Distance Matricies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2ycANx6JC19"
      },
      "source": [
        "# DOES NOT WORK\n",
        "\n",
        "# Read Universal Matrix of all Vectorized Distance Matricies (one per Corpus)\n",
        "\n",
        "subdir_name = 'data_corpora_all'\n",
        "\n",
        "filename_data = f'models_all_dist_matrix.csv'\n",
        "fullpath_name = f'./{subdir_name}/{filename_data}'\n",
        "\n",
        "dist_vecs_df = pd.read_csv(fullpath_name)\n",
        "\n",
        "print(f'\\n\\n  Read Universal Matrix with shape: {dist_vecs_df.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eggKYVADJNBd"
      },
      "source": [
        "## **Option (b): Generate Universal Matrix of Distance Matricies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elpzhIpnUG29"
      },
      "source": [
        "# Vectorized 1D Distance Matrices saved in corpora_all25v_dt\n",
        "\n",
        "corpora_all25v_dt.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TYMFf8yaSf2"
      },
      "source": [
        "corpora_all25v_dt['cdickens_achristmascarol']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILNoJI9UaxgJ"
      },
      "source": [
        "# Convert Dictionary of Vectors into Numpy Array\n",
        "\n",
        "dist_vecs_obj = corpora_all25v_dt.values()\n",
        "models_obj = corpora_all25v_dt.items()\n",
        "\n",
        "# Convert object to a list\n",
        "data_ls = list(dist_vecs_obj)\n",
        "model_ls = list(models_obj)\n",
        "\n",
        "# Convert list to an array\n",
        "dist_np = np.array(data_ls)\n",
        "  \n",
        "# print the numpy array\n",
        "print(dist_np)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYngloXab3oa"
      },
      "source": [
        "dist_vecs_df = pd.DataFrame(corpora_all25v_dt)\n",
        "dist_vecs_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3g1FWtPJZBk"
      },
      "source": [
        "## **Save Universal Matrix of all Vectorized Distance Matricies (one per Corpus)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ3y_WTUURzs"
      },
      "source": [
        "# # Save Vectorized Distance Matricies\n",
        "\n",
        "subdir_out = 'data_corpora_all'\n",
        "\n",
        "filename_out = f'models_all_dist_matrix.csv'\n",
        "fullpath_out = f'./{subdir_out}/{filename_out}'\n",
        "\n",
        "print(f'\\nSaving Single Matrix containing a row of 1D Vectorized Distance Matricies for each of the {dist_vecs_df.shape[1]} Corpus (distance between Models)')\n",
        "dist_vecs_df.to_csv(fullpath_out)\n",
        "\n",
        "print(f'\\n\\n  Matrix shape: {dist_vecs_df.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fFvPobVJgfc"
      },
      "source": [
        "## **Heatmap of Universal Matrix of Vectorized Distance Matricies (one per Corpus)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B39LCVPtbNHo"
      },
      "source": [
        "import seaborn as sns; sns.set(color_codes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKPTg8LkjwiD"
      },
      "source": [
        "dist_vecs_T_df = pd.DataFrame()\n",
        "dist_vecs_T_df = dist_vecs_df.T # pivot(columns=[i for i in range(35)])\n",
        "dist_vecs_T_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QjM-UB-b_jy"
      },
      "source": [
        "dist_vecs_T_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spO_uA5QbRXb"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Hint:\n",
        "\n",
        "# Cluster \n",
        "# https://colab.research.google.com/github/saskeli/data-analysis-with-python-summer-2019/blob/master/clustering.ipynb#scrollTo=8u0WPsxaYUkZ\n",
        "\n",
        "\n",
        "# iris = sns.load_dataset(\"iris\")\n",
        "# species = iris.pop(\"species\")   # Remove the species column\n",
        "# print(species.unique())         # The samples seems to be from these three species\n",
        "\n",
        "# plt.rcParams[\"figure.figsize\"] = (40,40)\n",
        "# sns.set(rc={'figure.figsize':(20, 20)})\n",
        "# plt.figure(figsize=(40,40))\n",
        "# fig, ax = plt.subplots()\n",
        "# fig.set_size_inches(20, 20)\n",
        "\n",
        "sns.set(font_scale=1.8)\n",
        "# g = sns.clustermap(dist_vecs_T_df, method=\"ward\", col_cluster=False, cbar_kws={'label': 'distance'}, figsize=(30,30)); # Cluster only the rows\n",
        "# g = sns.clustermap(dist_vecs_T_df, method=\"ward\", col_cluster=False, cbar_kws={'label': 'distance'}, z_score=0, cmap=\"vlag\", figsize=(30,30)); # Cluster only the rows\n",
        "g = sns.clustermap(dist_vecs_T_df, method=\"ward\", col_cluster=False, cbar_kws={'label': 'distance'}, standard_scale=1, cmap=\"vlag\", figsize=(30,30)); # Cluster only the rows\n",
        "g.fig.suptitle('Distance Between Corpora based upon Sentiment Model Distances') \n",
        "#plt.colorbar().ax.set_title('This is a title')\n",
        "#plt.gca().images[-1].colorbar.ax.set_title(\"title\")\n",
        "\n",
        "subdir_out = 'data_corpora_plots'\n",
        "\n",
        "filename_out = f'models_all_dist_matrix.png'\n",
        "fullpath_out = f'./{subdir_out}/{filename_out}'\n",
        "\n",
        "plt.savefig(fullpath_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GujUuHAO1RK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb8MIfWTO1M0"
      },
      "source": [
        "# https://towardsdatascience.com/heatmap-basics-with-pythons-seaborn-fb92ea280a6c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgylMAYFOix5"
      },
      "source": [
        "# read dataset\n",
        "df = pd.read_csv('data/cereal.csv')\n",
        "# get correlations\n",
        "df_corr = df.corr()\n",
        "# irrelevant fields\n",
        "fields = ['rating', 'shelf', 'cups', 'weight']\n",
        "# drop rows\n",
        "df_corr.drop(fields, inplace=True)\n",
        "# drop cols\n",
        "df_corr.drop(fields, axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NytpBybmOitC"
      },
      "source": [
        "mask = np.triu(np.ones_like(df_corr, dtype=np.bool))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZBYVD-lOinh"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "# mask\n",
        "mask = np.triu(np.ones_like(df_corr, dtype=np.bool))\n",
        "# adjust mask and df\n",
        "mask = mask[1:, :-1]\n",
        "corr = df_corr.iloc[1:,:-1].copy()\n",
        "# plot heatmap\n",
        "sb.heatmap(corr, mask=mask, annot=True, fmt=\".2f\", cmap='Blues',\n",
        "           vmin=-1, vmax=1, cbar_kws={\"shrink\": .8})\n",
        "# yticks\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66aZ3bJtOzQg"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "# mask\n",
        "mask = np.triu(np.ones_like(df_corr, dtype=np.bool))\n",
        "# adjust mask and df\n",
        "mask = mask[1:, :-1]\n",
        "corr = df_corr.iloc[1:,:-1].copy()\n",
        "# color map\n",
        "cmap = sb.diverging_palette(0, 230, 90, 60, as_cmap=True)\n",
        "# plot heatmap\n",
        "sb.heatmap(corr, mask=mask, annot=True, fmt=\".2f\", \n",
        "           linewidths=5, cmap=cmap, vmin=-1, vmax=1, \n",
        "           cbar_kws={\"shrink\": .8}, square=True)\n",
        "# ticks\n",
        "yticks = [i.upper() for i in corr.index]\n",
        "xticks = [i.upper() for i in corr.columns]\n",
        "plt.yticks(plt.yticks()[0], labels=yticks, rotation=0)\n",
        "plt.xticks(plt.xticks()[0], labels=xticks)\n",
        "# title\n",
        "title = 'CORRELATION MATRIX\\nSAMPLED CEREALS COMPOSITION\\n'\n",
        "plt.title(title, loc='left', fontsize=18)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rElLLMt-OzMX"
      },
      "source": [
        "# Scatter and kde Density Plot\n",
        "\n",
        "fig, ax = plt.subplots(1, figsize=(12,8))\n",
        "sb.kdeplot(df.potass, df.fiber, cmap='Blues',\n",
        "           shade=True, shade_lowest=False, clip=(-1,300))\n",
        "plt.scatter(df.potass, df.fiber, color='orangered')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwG9SCMcOzHc"
      },
      "source": [
        "# https://towardsdatascience.com/reordering-pandas-dataframe-columns-thumbs-down-on-standard-solutions-1ff0bc2941d5\n",
        "\n",
        "def movecol(df, cols_to_move=[], ref_col='', place='After'):\n",
        "    \n",
        "    cols = df.columns.tolist()\n",
        "    if place == 'After':\n",
        "        seg1 = cols[:list(cols).index(ref_col) + 1]\n",
        "        seg2 = cols_to_move\n",
        "    if place == 'Before':\n",
        "        seg1 = cols[:list(cols).index(ref_col)]\n",
        "        seg2 = cols_to_move + [ref_col]\n",
        "    \n",
        "    seg1 = [i for i in seg1 if i not in seg2]\n",
        "    seg3 = [i for i in cols if i not in seg1 + seg2]\n",
        "    \n",
        "    return(df[seg1 + seg2 + seg3])\n",
        "  \n",
        "# Test\n",
        "\n",
        "df = movecol(df, \n",
        "             cols_to_move=['Score','Grade'], \n",
        "             ref_col='Room',\n",
        "             place='After')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy5KAzFtOigI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvjVjrrJejsU"
      },
      "source": [
        "# DBSCAN Clustering\n",
        "\n",
        "# https://www.geeksforgeeks.org/implementing-dbscan-algorithm-using-sklearn/\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "  \n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiWIWlpsejo8"
      },
      "source": [
        "# Scaling the data to bring all the attributes to a comparable level\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(dist_vecs_df)\n",
        "  \n",
        "# Normalizing the data so that \n",
        "# the data approximately follows a Gaussian distribution\n",
        "X_normalized = normalize(X_scaled)\n",
        "  \n",
        "# Converting the numpy array into a pandas DataFrame\n",
        "X_normalized = pd.DataFrame(X_normalized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVPjdrgWejjs"
      },
      "source": [
        "#  Reducing the dimensionality of the data to make it visualizable\n",
        "\n",
        "pca = PCA(n_components = 2)\n",
        "X_principal = pca.fit_transform(X_normalized)\n",
        "X_principal = pd.DataFrame(X_principal)\n",
        "X_principal.columns = ['P1', 'P2']\n",
        "print(X_principal.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F04IoCFUejfT"
      },
      "source": [
        "# Numpy array of all the cluster labels assigned to each data point\n",
        "\n",
        "db_default = DBSCAN(eps = 0.0375, min_samples = 2).fit(X_principal)\n",
        "labels = db_default.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpfG-taUfbqk"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpUtSo4pgkIk"
      },
      "source": [
        "np.min(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVNKyEH6gtYC"
      },
      "source": [
        "np.max(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlX1jwhggtND"
      },
      "source": [
        "np.unique(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aykrwmzehANB"
      },
      "source": [
        "4%3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCXlJni8ejaw"
      },
      "source": [
        "# Building the label to colour mapping\n",
        "\n",
        "# https://www.geeksforgeeks.org/implementing-dbscan-algorithm-using-sklearn/ \n",
        "\n",
        "colours = {}\n",
        "\n",
        "label_max = np.max(labels)\n",
        "for i in range(label_max+1):\n",
        "  i_scaled = (i/label_max)\n",
        "  colours[i] = (i_scaled, i_scaled, i_scaled)\n",
        "\n",
        "\n",
        "# colours[0] = 'r'\n",
        "# colours[1] = 'g'\n",
        "# colours[2] = 'b'\n",
        "colours[-1] = 'k'\n",
        "# colours[3] = 'k'\n",
        "\n",
        "# Building the colour vector for each data point\n",
        "cvec = [colours[label%4] for label in labels]\n",
        "  \n",
        "# For the construction of the legend of the plot\n",
        "r = plt.scatter(X_principal['P1'], X_principal['P2'], color ='r');\n",
        "g = plt.scatter(X_principal['P1'], X_principal['P2'], color ='g');\n",
        "b = plt.scatter(X_principal['P1'], X_principal['P2'], color ='b');\n",
        "k = plt.scatter(X_principal['P1'], X_principal['P2'], color ='k');\n",
        "  \n",
        "# Plotting P1 on the X-Axis and P2 on the Y-Axis \n",
        "# according to the colour vector defined\n",
        "plt.figure(figsize =(9, 9))\n",
        "plt.scatter(X_principal['P1'], X_principal['P2'], c = cvec)\n",
        "  \n",
        "# Building the legend\n",
        "plt.legend((r, g, b, k), ('Label 0', 'Label 1', 'Label 2', 'Label -1'))\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww2Nn1OZejW_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WUmUHbPf2CV"
      },
      "source": [
        "# https://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html \n",
        "\n",
        "print(__doc__)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# #############################################################################\n",
        "# Generate sample data\n",
        "centers = [[1, 1], [-1, -1], [1, -1]]\n",
        "X, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,\n",
        "                            random_state=0)\n",
        "\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "# #############################################################################\n",
        "# Compute DBSCAN\n",
        "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
        "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
        "core_samples_mask[db.core_sample_indices_] = True\n",
        "labels = db.labels_\n",
        "\n",
        "# Number of clusters in labels, ignoring noise if present.\n",
        "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "n_noise_ = list(labels).count(-1)\n",
        "\n",
        "print('Estimated number of clusters: %d' % n_clusters_)\n",
        "print('Estimated number of noise points: %d' % n_noise_)\n",
        "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
        "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
        "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
        "print(\"Adjusted Rand Index: %0.3f\"\n",
        "      % metrics.adjusted_rand_score(labels_true, labels))\n",
        "print(\"Adjusted Mutual Information: %0.3f\"\n",
        "      % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
        "print(\"Silhouette Coefficient: %0.3f\"\n",
        "      % metrics.silhouette_score(X, labels))\n",
        "\n",
        "# #############################################################################\n",
        "# Plot result\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Black removed and is used for noise instead.\n",
        "unique_labels = set(labels)\n",
        "colors = [plt.cm.Spectral(each)\n",
        "          for each in np.linspace(0, 1, len(unique_labels))]\n",
        "for k, col in zip(unique_labels, colors):\n",
        "    if k == -1:\n",
        "        # Black used for noise.\n",
        "        col = [0, 0, 0, 1]\n",
        "\n",
        "    class_member_mask = (labels == k)\n",
        "\n",
        "    xy = X[class_member_mask & core_samples_mask]\n",
        "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
        "             markeredgecolor='k', markersize=14)\n",
        "\n",
        "    xy = X[class_member_mask & ~core_samples_mask]\n",
        "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
        "             markeredgecolor='k', markersize=6)\n",
        "\n",
        "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SElJId3if19Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEl-kUECf14F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhgdDasqbWNa"
      },
      "source": [
        "iris.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o99xq6oCc_zG"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (40,40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOm_kie4UGu1"
      },
      "source": [
        "# Cluster \n",
        "# https://colab.research.google.com/github/saskeli/data-analysis-with-python-summer-2019/blob/master/clustering.ipynb#scrollTo=8u0WPsxaYUkZ\n",
        "\n",
        "\n",
        "iris = sns.load_dataset(\"iris\")\n",
        "species = iris.pop(\"species\")   # Remove the species column\n",
        "print(species.unique())         # The samples seems to be from these three species\n",
        "sns.clustermap(iris, method=\"ward\", col_cluster=False, cbar_kws={'label': 'centimeters'}); # Cluster only the rows\n",
        "#plt.colorbar().ax.set_title('This is a title')\n",
        "#plt.gca().images[-1].colorbar.ax.set_title(\"title\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlP_IZpTUVka"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ySYwtCXUGqs"
      },
      "source": [
        "# Dimensionality Reduction and Visualization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78o89FHOUVYI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqk9FgF6QhY3"
      },
      "source": [
        "# **END OF NOTEBOOK**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bul5lZQJL0os"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP22YKd2L0hX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoalZBHO8BM-"
      },
      "source": [
        "s1 = np.array([0., 0, 1, 2, 1, 0, 1, 0, 0, 2, 1, 0, 0, 0, 1, 1])\n",
        "s2 = np.array([0., 1, 2, 3, 1, 0, 0, 0, 2, 1, 0, 0, 0])\n",
        "path = dtw.warping_path(s1, s2)\n",
        "\n",
        "dtwvis.plot_warping(s1, s2, path, filename=\"warp.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE9sL1ciuH6f"
      },
      "source": [
        "from IPython.display import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yK38I0A8BJC"
      },
      "source": [
        "Image('warp.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAyFuoqfD8mK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x2G4B-luwLS"
      },
      "source": [
        "corpora_all25_dt.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZWr1THiuwLT"
      },
      "source": [
        "lttb_cols_ls = corpora_all25_dt['cdickens_achristmascarol'].columns.to_list()\n",
        "# lttb_cols_ls.sort()\n",
        "\n",
        "\n",
        "lttb_cols_ls = [i if i != 'logreg_cv_z_25lttb' else 'logreg-cv_z_25lttb' for i in lttb_cols_ls]\n",
        "lttb_cols_ls = [i if i != 'jockers_rinker_z_25lttb' else 'jockers-rinker_z_25lttb' for i in lttb_cols_ls]\n",
        "\n",
        "lttb_cols_ls = [i.split('_')[0] for i in lttb_cols_ls]\n",
        "print(lttb_cols_ls)\n",
        "len(lttb_cols_ls)\n",
        "\n",
        "# [unicode(x.strip()) if x is not None else '' for x in row]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qeoj9B6juzBu"
      },
      "source": [
        "corpora_all25_dt['cdickens_achristmascarol'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywjxux9XvJLq"
      },
      "source": [
        "series = corpora_all25_dt['cdickens_achristmascarol'].to_numpy().T\n",
        "series"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ7vdyxVUdV-"
      },
      "source": [
        "series.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8aHuwMLulgZ"
      },
      "source": [
        "%%time\n",
        "\n",
        "# NOTE:\n",
        "\n",
        "ds = dtw.distance_matrix_fast(series) #  block=((1, 4), (3, 5)))\n",
        "\n",
        "# OR\n",
        "\n",
        "# ds = dtw.distance_matrix(series) # , block=((1, 4), (3, 5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVCtbPmp6udC"
      },
      "source": [
        "ds = dtw.distance_matrix(series) # , compact=True) # , block=((1, 4), (3, 5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhAhhr4S7AcD"
      },
      "source": [
        "ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJWuOxgfUivw"
      },
      "source": [
        "ds.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgF0VQvUVabf"
      },
      "source": [
        "35*35"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLnw8UiUUpiI"
      },
      "source": [
        "X = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
        "#array([[1, 2, 3],\n",
        "#       [4, 5, 6],\n",
        "#       [7, 8, 9]])\n",
        "\n",
        "#get the upper triangular part of this matrix\n",
        "v = X[np.triu_indices(X.shape[0], k = 1)] # offset\n",
        "print(v)\n",
        "# [2 3 6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0atbQhFVOO9"
      },
      "source": [
        "ds_1d = ds[np.triu_indices(ds.shape[0], k=1)]\n",
        "len(ds_1d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjavk1KCVOKn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geKdAmiAVOG_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrmChaciH7xc"
      },
      "source": [
        "import seaborn as sns; sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K_BtZXtH4ld"
      },
      "source": [
        "ax = sns.heatmap(ds, annot=True, fmt=\"d\")\n",
        "\n",
        "plt.title(\"How to visualize (plot) \\n a numpy array in python using seaborn ?\",fontsize=12)\n",
        "\n",
        "plt.savefig(\"visualize_numpy_array_01.png\", bbox_inches='tight', dpi=100)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHxBS773wCZL"
      },
      "source": [
        "%%time\n",
        "\n",
        "# NOTE:\n",
        "\n",
        "# Custom Hierarchical clustering\n",
        "model1 = clustering.Hierarchical(dtw.distance_matrix, {})\n",
        "cluster_idx = model1.fit(series)\n",
        "\n",
        "# Augment Hierarchical object to keep track of the full tree\n",
        "model2 = clustering.HierarchicalTree(model1, tr_left_margin=0) # , tr_label_margin=-10)\n",
        "cluster_idx = model2.fit(series)\n",
        "\n",
        "# SciPy linkage clustering\n",
        "model3 = clustering.LinkageTree(dtw.distance_matrix, {})\n",
        "cluster_idx = model3.fit(series)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAOHLFQ34_1L"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmKbTzIi5Jct"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (40, 40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTMxmAb24OHN"
      },
      "source": [
        "%%time\n",
        "\n",
        "# NOTE:\n",
        "\n",
        "# model2.plot(ts_label_margin=0, show_ts_label=lttb_cols_ls, show_tr_label=True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1B1_qiUCLSo"
      },
      "source": [
        "plt.rcParams.update({'font.size': 20})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z5_8fgc_KJa"
      },
      "source": [
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(40,40))\n",
        "# show_ts_label = lambda idx: \"ts-\" + str(idx)\n",
        "show_ts_label = lambda idx: lttb_cols_ls[idx]\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(top=0.95)\n",
        "corpus_title = 'A Christmas Carol by Charles Dickens'\n",
        "fig.suptitle(corpus_title)\n",
        "acorpus = f'cdickens_achristmascarol'\n",
        "filename_path = f'./data_corpora_plots/plot_dtw25_{acorpus}.png'\n",
        "model2.plot(filename_path, axes=ax, show_ts_label=show_ts_label, # True, # lttb_cols_ls,\n",
        "           show_tr_label=True, ts_label_margin=0,\n",
        "           ts_left_margin=0, tr_label_margin=0.1) #  ts_sample_length=1)\n",
        "\n",
        "Image(filename_plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZOlPRGgFSAn"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUhaLAr0wCZN"
      },
      "source": [
        "model2.plot(\"myplot.png\", show_ts_label=True, show_tr_label=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7j2LdO30z2N"
      },
      "source": [
        "Image('myplot.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJJqLI4nulXY"
      },
      "source": [
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(40,40))\n",
        "# show_ts_label = lambda idx: \"ts-\" + str(idx)\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(top=0.95)\n",
        "fig.suptitle('A Christmas Carol by Charles Dickens')\n",
        "# fig.title('A Christmas Carol by Charles Dickens')\n",
        "model3.plot(axes=ax, show_ts_label=lttb_cols_ls,\n",
        "           show_tr_label=True, ts_label_margin=0,\n",
        "           ts_left_margin=0, tr_label_margin=0.1) #  ts_sample_length=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8nL-axuulUD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpqAfeq4ulQQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZNgdGyeulMm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0bX-TL677-H"
      },
      "source": [
        "# **END OF NOTEBOOK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYQ3UterjMJF"
      },
      "source": [
        "# **Get Corpora**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6BTm4_mk-M7"
      },
      "source": [
        "corpora_ls[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1uV3CSqk8TB"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Fts10_lF6C"
      },
      "source": [
        "corpus_name = corpora_ls[0]\n",
        "\n",
        "!ls -altr $corpus_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s42B_qHLlYwd"
      },
      "source": [
        "temp_df = pd.read_csv(f'./{corpus_name}/corpus_text_sents_clean_{corpus_name}.csv')\n",
        "temp_df.rename(columns={'Unnamed: 0':'sent_no'}, inplace=True)\n",
        "temp_df['sent_clean'] = temp_df['sent_clean'].astype('string')\n",
        "temp_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtplBhyWk6z0"
      },
      "source": [
        "temp_df = f'./{corpora_ls[0]}/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0l-WY269us0"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ApuWfaAkSTv"
      },
      "source": [
        "# Get a Dictionary of clean text for every item in the corpora (listed in corpora_ls)\n",
        "\n",
        "corpora_dt = {}\n",
        "for i, acorpus in enumerate(corpora_ls):\n",
        "  print(f'\\nREADING #{i}: {acorpus}\\n========================================\\n')\n",
        "  # os.listdir(adir)\n",
        "  corpus_csv = f'./{acorpus}/corpus_text_sents_clean_{acorpus}.csv'\n",
        "  print(f'{os.getcwd()}\\n     {corpus_csv}')\n",
        "  temp_df = pd.DataFrame()\n",
        "  temp_df = pd.read_csv(corpus_csv, encoding='ISO-88591')\n",
        "  temp_df.rename(columns={'Unnamed: 0':'sent_no'}, inplace=True)\n",
        "  temp_df['sent_clean'] = temp_df['sent_clean'].astype('string')\n",
        "  corpora_dt[acorpus] = temp_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3BgRRT5NBiu"
      },
      "source": [
        "corpora_dt['cdickens_achristmascarol'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd2F-Onkm5n8"
      },
      "source": [
        "len(corpora_dt.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCtS7awhkR4S"
      },
      "source": [
        "[f'{corpus_name}' for corpus_name in corpora_dt.keys()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auUsC0WWod8N"
      },
      "source": [
        "corpora_dt['cdickens_achristmascarol'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLtU2fu9sYvs"
      },
      "source": [
        "corpora_dt['cdickens_achristmascarol'].info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESGThFMlojv0"
      },
      "source": [
        "corpora_dt['cdickens_achristmascarol'].shape"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}